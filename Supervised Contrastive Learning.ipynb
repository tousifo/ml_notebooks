{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMYArDT+I0CA9LeBhdV8atG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tousifo/ml_notebooks/blob/main/Supervised%E2%80%AFContrastive%E2%80%AFLearning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhDfhhGk4xyp",
        "outputId": "6290ed73-b176-40a0-fd72-1ba814974e10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch_lightning\n",
            "  Downloading pytorch_lightning-2.5.2-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: torch>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from pytorch_lightning) (2.6.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.11/dist-packages (from pytorch_lightning) (4.67.1)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.11/dist-packages (from pytorch_lightning) (6.0.2)\n",
            "Requirement already satisfied: fsspec>=2022.5.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2022.5.0->pytorch_lightning) (2025.3.2)\n",
            "Collecting torchmetrics>=0.7.0 (from pytorch_lightning)\n",
            "  Downloading torchmetrics-1.7.4-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from pytorch_lightning) (25.0)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from pytorch_lightning) (4.14.1)\n",
            "Collecting lightning-utilities>=0.10.0 (from pytorch_lightning)\n",
            "  Downloading lightning_utilities-0.14.3-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2022.5.0->pytorch_lightning) (3.11.15)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.10.0->pytorch_lightning) (75.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch_lightning) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch_lightning) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch_lightning) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.1.0->pytorch_lightning)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.1.0->pytorch_lightning)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.1.0->pytorch_lightning)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.1.0->pytorch_lightning)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.1.0->pytorch_lightning)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.1.0->pytorch_lightning)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.1.0->pytorch_lightning)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.1.0->pytorch_lightning)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.1.0->pytorch_lightning)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch_lightning) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch_lightning) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch_lightning) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.1.0->pytorch_lightning)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch_lightning) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch_lightning) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.1.0->pytorch_lightning) (1.3.0)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics>=0.7.0->pytorch_lightning) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.20.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.1.0->pytorch_lightning) (3.0.2)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (3.10)\n",
            "Downloading pytorch_lightning-2.5.2-py3-none-any.whl (825 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m825.4/825.4 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.14.3-py3-none-any.whl (28 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m115.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m81.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m57.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchmetrics-1.7.4-py3-none-any.whl (963 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m963.5/963.5 kB\u001b[0m \u001b[31m53.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, lightning-utilities, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torchmetrics, pytorch_lightning\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed lightning-utilities-0.14.3 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pytorch_lightning-2.5.2 torchmetrics-1.7.4\n",
            "Using device: cuda\n",
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/ninadaithal/imagesoasis?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.23G/1.23G [00:13<00:00, 95.8MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset downloaded to: /root/.cache/kagglehub/datasets/ninadaithal/imagesoasis/versions/1\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "#  Snippet 1 : Library imports, environment config, and        #\n",
        "#              downloading the OASIS dataset from Kaggle       #\n",
        "# ============================================================\n",
        "\n",
        "# ---- Standard libraries ------------------------------------\n",
        "import os           # For path manipulations and environment variables\n",
        "import zipfile      # To unzip any compressed Kaggle files\n",
        "import random       # For reproducible split shuffling\n",
        "import math         # For basic mathematical operations\n",
        "from pathlib import Path  # For elegant filesystem paths\n",
        "%pip install pytorch_lightning\n",
        "\n",
        "# ---- Numerical / data science ------------------------------\n",
        "import numpy as np              # Core numerical operations on nd‑arrays\n",
        "import pandas as pd             # Tabular data handling (metadata, splits)\n",
        "from tqdm import tqdm           # Neat progress bars for loops\n",
        "\n",
        "# ---- PyTorch ecosystem -------------------------------------\n",
        "import torch                    # Deep‑learning tensor library\n",
        "import torch.nn as nn           # Neural‑network layers and losses\n",
        "import torch.nn.functional as F # Functional interface (activations, etc.)\n",
        "from torch.utils.data import Dataset, DataLoader, Sampler # Data pipeline\n",
        "import torchvision              # Vision utilities and pretrained models\n",
        "import torchvision.transforms as T  # Composable image transforms\n",
        "\n",
        "# ---- Visualisation -----------------------------------------\n",
        "import matplotlib.pyplot as plt # Plotting curves and images\n",
        "import seaborn as sns           # Statistical visualisation (confusion‐mat.)\n",
        "\n",
        "# ---- KaggleHub (supplied by user) --------------------------\n",
        "import kagglehub                # Helper to pull Kaggle datasets in Colab\n",
        "\n",
        "# ---- Lightning (optional – easier multi‑GPU & LARS) --------\n",
        "import pytorch_lightning as pl   # High‑level training loop framework\n",
        "\n",
        "# ---- Environment & reproducibility -------------------------\n",
        "SEED = 42                        # Global random seed\n",
        "random.seed(SEED)                # Seed Python’s RNG\n",
        "np.random.seed(SEED)             # Seed NumPy RNG\n",
        "torch.manual_seed(SEED)          # Seed Torch (CPU) RNG\n",
        "torch.cuda.manual_seed_all(SEED) # Seed Torch (GPU) RNG\n",
        "\n",
        "# ---- Device selection --------------------------------------\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"  # Pick GPU if ready\n",
        "print(f\"Using device: {DEVICE}\")                         # Inform user\n",
        "\n",
        "# ---- Kaggle download ---------------------------------------\n",
        "#  Downloads Kaggle dataset `ninadaithal/imagesoasis` to default location\n",
        "oasis_path = kagglehub.dataset_download('ninadaithal/imagesoasis')  # Cache dir\n",
        "print(\"Dataset downloaded to:\", oasis_path)                          # Confirm\n",
        "\n",
        "# Note: files are already individual .jpgs inside class folders      # Info\n",
        "# End of Snippet 1                                                   # End"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "#  Snippet 2 : Build metadata, patient‑level splits,           #\n",
        "#              mean/std computation, transforms, datasets,    #\n",
        "#              balanced samplers, and DataLoaders             #\n",
        "# ============================================================\n",
        "\n",
        "# ---------- 1. Build metadata -------------------------------------------\n",
        "def build_metadata(root_dir):\n",
        "    \"\"\"\n",
        "    Walk the dataset directory, collect filepaths, integer labels,\n",
        "    and unique patient IDs.\n",
        "\n",
        "    Filenames look like:  'OAS1_0001_slice105.jpg'\n",
        "    True subject ID  ->    'OAS1_0001'  (first two underscore tokens)\n",
        "    \"\"\"\n",
        "    paths, labels, pids = [], [], []                              # Lists to fill\n",
        "\n",
        "    # Map each class folder to a numeric label (sorted for consistency)\n",
        "    class_names = sorted(os.listdir(root_dir))                    # e.g. ['Mild Dementia', ...]\n",
        "    class_map = {cls: idx for idx, cls in enumerate(class_names)} # Dict  name→idx\n",
        "    print(\"Found classes:\", class_names)                          # Debug info\n",
        "\n",
        "    # Walk through every *.jpg in every class directory\n",
        "    for cls in class_names:                                       # Loop each class\n",
        "        cls_dir = Path(root_dir) / cls                            # /root/class_name\n",
        "        for img_path in cls_dir.glob(\"*.jpg\"):                    # Loop each image\n",
        "            stem_parts = img_path.stem.split('_')                 # Split filename\n",
        "            pid = '_'.join(stem_parts[:2])                        # 'OAS1_0001'\n",
        "            paths.append(str(img_path))                           # Absolute path\n",
        "            labels.append(class_map[cls])                         # Integer label\n",
        "            pids.append(pid)                                      # Patient ID\n",
        "\n",
        "    # Assemble a DataFrame for easy manipulation\n",
        "    df = pd.DataFrame(\n",
        "        {\"filepath\": paths, \"label\": labels, \"patient_id\": pids}\n",
        "    )\n",
        "    print(f\"Total slices: {len(df)}\")                             # Count slices\n",
        "    print(f\"Total unique patients: {df['patient_id'].nunique()}\") # Count subjects\n",
        "    print(df.head())                                              # Show sample rows\n",
        "    return df                                                     # Return metadata\n",
        "\n",
        "# Build metadata from oasis_path produced in Snippet 1\n",
        "meta_df = build_metadata(os.path.join(oasis_path, 'Data')) # Modified to point to the correct subdirectory\n",
        "\n",
        "# ---------- 2. Patient‑level train/val/test split -----------------------\n",
        "def split_patients(meta, train_ratio=0.7, val_ratio=0.15, seed=42):\n",
        "    \"\"\"\n",
        "    Split patient IDs (not slices!) into train, val, test sets.\n",
        "    \"\"\"\n",
        "    rng = np.random.RandomState(seed)                             # Reproducible RNG\n",
        "    pats = meta['patient_id'].unique()                            # Unique IDs\n",
        "    rng.shuffle(pats)                                             # Shuffle order\n",
        "    n_train = int(len(pats) * train_ratio)                        # #train IDs\n",
        "    n_val   = int(len(pats) * val_ratio)                          # #val IDs\n",
        "    train_ids = pats[:n_train]                                    # Slice\n",
        "    val_ids   = pats[n_train:n_train + n_val]                     # Slice\n",
        "    test_ids  = pats[n_train + n_val:]                            # Remaining\n",
        "    return train_ids, val_ids, test_ids                           # Tuple\n",
        "\n",
        "train_ids, val_ids, test_ids = split_patients(meta_df)            # Perform split\n",
        "\n",
        "# Mark each row with its split label\n",
        "meta_df['split'] = np.select(\n",
        "    [meta_df.patient_id.isin(train_ids),\n",
        "     meta_df.patient_id.isin(val_ids)],\n",
        "    ['train', 'val'],\n",
        "    default='test'\n",
        ")\n",
        "\n",
        "print(\"Split distribution:\\n\", meta_df['split'].value_counts())   # Verify balance\n",
        "\n",
        "# ---------- 3. Compute global mean & std (grayscale) --------------------\n",
        "from PIL import Image                                             # Pillow import\n",
        "\n",
        "def compute_mean_std(df, sample_size=2000):\n",
        "    \"\"\"\n",
        "    Estimate per‑channel mean/std on a random subset for normalisation.\n",
        "    If df is empty (edge case), return 0.5/0.5 defaults.\n",
        "    \"\"\"\n",
        "    if len(df) == 0:                                              # Guard\n",
        "        print(\"Warning: Empty dataframe passed to compute_mean_std. \"\n",
        "              \"Returning default values.\")\n",
        "        return 0.5, 0.5                                           # Defaults\n",
        "    sample_paths = np.random.choice(df['filepath'],               # Random subset\n",
        "                                    size=min(sample_size, len(df)),\n",
        "                                    replace=False)\n",
        "    to_tensor = T.ToTensor()                                      # Simple tensor tfm\n",
        "    pixels = []                                                   # Collect tensors\n",
        "    for p in tqdm(sample_paths, desc=\"Mean/Std\"):\n",
        "        img = to_tensor(Image.open(p).convert('L'))               # Load grayscale\n",
        "        pixels.append(img)\n",
        "    stack = torch.stack(pixels)                                   # (N,1,H,W)\n",
        "    mean = stack.mean().item()                                    # Scalar mean\n",
        "    std  = stack.std().item()                                     # Scalar std\n",
        "    return mean, std\n",
        "\n",
        "MRI_MEAN, MRI_STD = compute_mean_std(meta_df[meta_df.split == 'train'])\n",
        "print(\"Dataset mean:\", MRI_MEAN, \"std:\", MRI_STD)\n",
        "\n",
        "# ---------- 4. Define transforms ----------------------------------------\n",
        "train_tfms = T.Compose([\n",
        "    T.Resize(224),                                                # Resize images\n",
        "    T.RandomRotation(10),                                         # ±10° rotation\n",
        "    T.RandomAffine(0, translate=(0.1, 0.1)),                      # 10 % translate\n",
        "    T.RandomHorizontalFlip(),                                     # LR flip (brain symmetric)\n",
        "    T.ToTensor(),                                                 # To [0,1]\n",
        "    T.Normalize(MRI_MEAN, MRI_STD)                                # Normalise\n",
        "])\n",
        "\n",
        "eval_tfms = T.Compose([\n",
        "    T.Resize(224),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(MRI_MEAN, MRI_STD)\n",
        "])\n",
        "\n",
        "# ---------- 5. Custom Dataset (2 views) ---------------------------------\n",
        "class OasisSliceDataset(torch.utils.data.Dataset):\n",
        "    \"\"\"\n",
        "    Returns *two* augmented views of each slice (for SupCon) and its label.\n",
        "    \"\"\"\n",
        "    def __init__(self, df, transform):\n",
        "        self.df = df.reset_index(drop=True)                       # Store subset df\n",
        "        self.transform = transform                                # Transform pipeline\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)                                       # Number of rows\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.loc[idx]                                    # Get row\n",
        "        img = Image.open(row.filepath).convert('L')               # Load as grayscale\n",
        "        v1 = self.transform(img)                                  # Augmented view 1\n",
        "        v2 = self.transform(img)                                  # Augmented view 2\n",
        "        pair = torch.stack([v1, v2], dim=0)                       # Shape (2,1,H,W)\n",
        "        return pair, row.label                                    # Return data\n",
        "\n",
        "# ---------- 6. Balanced batch sampler (using WeightedRandomSampler) -----\n",
        "from torch.utils.data.sampler import WeightedRandomSampler # Import the sampler\n",
        "import collections # Import collections for Counter\n",
        "\n",
        "def create_weighted_sampler(labels):\n",
        "    \"\"\"\n",
        "    Create a WeightedRandomSampler to balance classes based on inverse frequency.\n",
        "    \"\"\"\n",
        "    # Convert labels to standard Python integers for counting and weights dict keys\n",
        "    labels_int = [int(label) for label in labels]\n",
        "\n",
        "    # Calculate class counts using collections.Counter\n",
        "    class_counts = collections.Counter(labels_int)\n",
        "    print(f\"Class counts (int keys): {class_counts}\") # Debug print\n",
        "\n",
        "    # Calculate inverse frequency weights using standard integer keys\n",
        "    class_weights = {label: 1.0 / count for label, count in class_counts.items()}\n",
        "    print(f\"Class weights (int keys dict): {class_weights}\") # Debug print\n",
        "\n",
        "    # Assign weights to each sample based on its original label (which might be np.int64)\n",
        "    # Convert label to int before dictionary lookup\n",
        "    sample_weights = []\n",
        "    for label in labels:\n",
        "        # Convert label to standard int for lookup\n",
        "        weight = class_weights[int(label)]\n",
        "        sample_weights.append(weight)\n",
        "\n",
        "    sample_weights = np.array(sample_weights)\n",
        "\n",
        "\n",
        "    # The number of samples to draw in an epoch. Use the total number of\n",
        "    # samples in the dataset to ensure each sample is seen roughly once per epoch.\n",
        "    num_samples = len(labels)\n",
        "\n",
        "    sampler = WeightedRandomSampler(\n",
        "        weights=sample_weights,\n",
        "        num_samples=num_samples,\n",
        "        replacement=True # Use replacement to ensure sufficient samples from small classes\n",
        "    )\n",
        "    return sampler\n",
        "\n",
        "\n",
        "# ---------- 7. Create Dataset objects -----------------------------------\n",
        "train_df = meta_df[meta_df.split == 'train']\n",
        "val_df   = meta_df[meta_df.split == 'val']\n",
        "test_df  = meta_df[meta_df.split == 'test']\n",
        "\n",
        "# Safety check to ensure we actually have training data\n",
        "assert len(train_df) > 0, \"Train split is empty – check the splitting logic.\"\n",
        "\n",
        "train_ds = OasisSliceDataset(train_df, train_tfms)\n",
        "val_ds   = OasisSliceDataset(val_df,   eval_tfms)\n",
        "test_ds  = OasisSliceDataset(test_df,  eval_tfms)\n",
        "\n",
        "# ---------- 8. DataLoaders with weighted random sampler -----------------\n",
        "BATCH_SIZE = 32                                                   # Reduced batch size as suggested\n",
        "\n",
        "# Create weighted sampler for the training data\n",
        "train_sampler = create_weighted_sampler(train_df.label.values)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_ds,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,                                                 # Shuffle is done by the sampler\n",
        "    sampler=train_sampler,\n",
        "    num_workers=2,                                                # Reduced num_workers\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "    val_ds,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,                                                 # No sampler needed for validation/test\n",
        "    num_workers=2,                                                # Reduced num_workers\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    test_ds,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=2,                                                # Reduced num_workers\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "\n",
        "print(\"DataLoaders ready ✔\")                                       # Confirmation\n",
        "# End of Snippet 2                                                   #"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t92md7xrC6OF",
        "outputId": "32cdda9d-78a3-4fd3-c360-eabcc5b0be02"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found classes: ['Mild Dementia', 'Moderate Dementia', 'Non Demented', 'Very mild Dementia']\n",
            "Total slices: 86437\n",
            "Total unique patients: 347\n",
            "                                            filepath  label patient_id\n",
            "0  /root/.cache/kagglehub/datasets/ninadaithal/im...      0  OAS1_0291\n",
            "1  /root/.cache/kagglehub/datasets/ninadaithal/im...      0  OAS1_0073\n",
            "2  /root/.cache/kagglehub/datasets/ninadaithal/im...      0  OAS1_0278\n",
            "3  /root/.cache/kagglehub/datasets/ninadaithal/im...      0  OAS1_0316\n",
            "4  /root/.cache/kagglehub/datasets/ninadaithal/im...      0  OAS1_0122\n",
            "Split distribution:\n",
            " split\n",
            "train    61000\n",
            "test     12871\n",
            "val      12566\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Mean/Std: 100%|██████████| 2000/2000 [00:03<00:00, 595.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset mean: 0.16600006818771362 std: 0.1789686381816864\n",
            "Class counts (int keys): Counter({2: 47336, 3: 9516, 0: 3904, 1: 244})\n",
            "Class weights (int keys dict): {0: 0.00025614754098360657, 1: 0.004098360655737705, 2: 2.112557039040054e-05, 3: 0.00010508617065994115}\n",
            "DataLoaders ready ✔\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "#  Snippet 3 : SupCon model = ResNet backbone + projection MLP #\n",
        "#              and custom Supervised Contrastive loss          #\n",
        "# ============================================================\n",
        "\n",
        "class ProjectionHead(nn.Module):                                           # MLP head\n",
        "    \"\"\"\n",
        "    2‑layer MLP → 128‑D contrastive embedding (SupCon paper).              # Doc\n",
        "    \"\"\"\n",
        "    def __init__(self, in_dim=2048, hid_dim=2048, out_dim=128):            # Ctor\n",
        "        super().__init__()                                                 # Super call\n",
        "        self.fc1 = nn.Linear(in_dim, hid_dim)                              # First FC\n",
        "        self.relu = nn.ReLU(inplace=True)                                  # Non‑linearity\n",
        "        self.fc2 = nn.Linear(hid_dim, out_dim)                             # Second FC\n",
        "\n",
        "    def forward(self, x):                                                  # Forward\n",
        "        x = self.fc1(x)                                                    # FC1\n",
        "        x = self.relu(x)                                                   # ReLU\n",
        "        x = self.fc2(x)                                                    # FC2\n",
        "        return F.normalize(x, dim=1)                                       # ℓ2 normalise\n",
        "\n",
        "# ============================================================\n",
        "#  Patched SupCon model (grayscale‑ready)                     #\n",
        "#  => paste this over the old SupConNet class in Snippet 3    #\n",
        "# ============================================================\n",
        "\n",
        "class SupConNet(nn.Module):\n",
        "    \"\"\"\n",
        "    ResNet‑50 backbone adapted for 1‑channel MRI slices,\n",
        "    plus projection head (SupCon) and linear classifier.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_classes=4, in_channels=1):\n",
        "        super().__init__()\n",
        "\n",
        "        # -------- Load vanilla ResNet‑50 ---------------------\n",
        "        # resnet = torchvision.models.resnet50(weights=None)          # No ImageNet weights\n",
        "        # Optional: change resnet50 -> resnet18\n",
        "        resnet = torchvision.models.resnet18(weights=None)          # Using ResNet18\n",
        "\n",
        "        # -------- Patch first conv for grayscale -------------\n",
        "        if in_channels != 3:\n",
        "            # Save original conv to reuse its weights\n",
        "            orig_conv = resnet.conv1                                 # (64, 3, 7, 7)\n",
        "            # New conv: same hyper‑params but 1 input channel\n",
        "            resnet.conv1 = nn.Conv2d(\n",
        "                in_channels, 64, kernel_size=7, stride=2,\n",
        "                padding=3, bias=False\n",
        "            )\n",
        "            # Weight initialise: mean across RGB channels\n",
        "            with torch.no_grad():\n",
        "                resnet.conv1.weight[:] = orig_conv.weight.mean(dim=1, keepdim=True)\n",
        "\n",
        "        # -------- Register encoder / heads --------------------\n",
        "        # Adjust in_dim for ProjectionHead and classifier if using ResNet18\n",
        "        encoder_out_dim = 512  # ResNet18 output features\n",
        "        self.encoder = nn.Sequential(*list(resnet.children())[:-1])  # Remove FC\n",
        "        self.proj = ProjectionHead(in_dim=encoder_out_dim)                      # 2‑layer MLP\n",
        "        self.classifier = nn.Linear(encoder_out_dim, num_classes)               # Linear eval\n",
        "\n",
        "    def forward(self, x, contrastive=True):\n",
        "        \"\"\"\n",
        "        x : (N, 1, 256, 256)  MRI slice batch\n",
        "        \"\"\"\n",
        "        feat = self.encoder(x).squeeze()                             # (N, 2048) for ResNet50, (N, 512) for ResNet18\n",
        "        if contrastive:\n",
        "            z = self.proj(feat)                                      # 128‑D ℓ2 norm\n",
        "            return z\n",
        "        else:\n",
        "            # The user's code had `return self` here, which seems incorrect.\n",
        "            # Based on the structure and purpose of the class, it should likely\n",
        "            # return the logits from the classifier when contrastive is False.\n",
        "            logits = self.classifier(feat)\n",
        "            return logits\n",
        "\n",
        "# ============================================================\n",
        "#  Patched Supervised‑Contrastive loss (handles 2 views)      #\n",
        "# ============================================================\n",
        "\n",
        "class SupConLoss(nn.Module):\n",
        "    \"\"\"\n",
        "    Supervised Contrastive Loss from Khosla et al. (2020).\n",
        "    Works when `features` has `n_views` per sample (n_views = 2 here).\n",
        "    \"\"\"\n",
        "    def __init__(self, temperature: float = 0.1):\n",
        "        super().__init__()\n",
        "        self.T = temperature                       # temperature τ\n",
        "\n",
        "    def forward(self, features: torch.Tensor, labels: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Args\n",
        "        ----\n",
        "        features : tensor, shape (N, D) where N = n_views * batch_size\n",
        "                   Must be ℓ2‑normalised already.\n",
        "        labels   : tensor, shape (batch_size,)\n",
        "                   Class indices **before** duplication.\n",
        "        \"\"\"\n",
        "        device = features.device\n",
        "        batch_size = labels.size(0)                # B\n",
        "        n_views = features.size(0) // batch_size   # usually 2\n",
        "        assert n_views * batch_size == features.size(0), \"Mismatch n_views\"\n",
        "\n",
        "        # Build mask of positive pairs --------------------------------------\n",
        "        lbl = labels.view(-1, 1)                   # (B,1)\n",
        "        mask = torch.eq(lbl, lbl.T).float().to(device)  # (B,B)\n",
        "        mask = mask.repeat(n_views, n_views)       # → (N,N)\n",
        "\n",
        "        # Self‑contrast mask -------------------------------------------------\n",
        "        logits_mask = torch.ones_like(mask) - torch.eye(mask.size(0)).to(device) # N*N identity\n",
        "\n",
        "        # Compute positive log‑probabilities -------------------------------\n",
        "        # Equivalent to: sim_matrix = torch.matmul(features, features.T) / self.T\n",
        "        # Anchor‑positive pairs (excluding self):\n",
        "        anchor_dot_contrast = torch.div(\n",
        "            torch.matmul(features, features.T),\n",
        "            self.T)\n",
        "        # For numerical stability\n",
        "        logits_max, _ = torch.max(anchor_dot_contrast, dim=1, keepdim=True)\n",
        "        logits = anchor_dot_contrast - logits_max.detach() # subtract max for stability\n",
        "\n",
        "        # Apply masks and compute loss --------------------------------------\n",
        "        # Remove diagonal\n",
        "        logits = logits * logits_mask\n",
        "        # Calculate log-probability\n",
        "        exp_logits = torch.exp(logits) * logits_mask\n",
        "        log_prob = logits - torch.log(exp_logits.sum(1, keepdim=True))\n",
        "\n",
        "        # Positive log-probability\n",
        "        mean_log_prob_pos = (mask * log_prob).sum(1) / mask.sum(1)\n",
        "\n",
        "        loss = -mean_log_prob_pos.mean()\n",
        "\n",
        "        return loss\n",
        "\n",
        "\n",
        "# Instantiate model & loss                                                 # Comment\n",
        "model = SupConNet(num_classes=4).to(DEVICE)                                # Move to GPU\n",
        "criterion_supcon = SupConLoss().to(DEVICE)                                 # SupCon loss\n",
        "criterion_ce = nn.CrossEntropyLoss()                                       # CE loss\n",
        "# End of Snippet 3                                                         # End"
      ],
      "metadata": {
        "id": "A9pMLKkYEipJ"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "#  Snippet 4 (memory‑friendly) : SupCon pre‑train + linear eval\n",
        "# ============================================================\n",
        "\n",
        "# ---- Adjust global BATCH_SIZE FIRST (in Snippet 2) ----------\n",
        "# BATCH_SIZE = 64   # <= do this where loaders are created\n",
        "# -------------------------------------------------------------\n",
        "\n",
        "from torch.amp import autocast, GradScaler   # AMP utilities\n",
        "from sklearn.metrics import f1_score, accuracy_score # Import metrics\n",
        "\n",
        "EPOCHS_PRE = 10                                   # SupCon epochs\n",
        "scaler = GradScaler()                             # Removed device_type='cuda'\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
        "    optimizer, T_max=EPOCHS_PRE\n",
        ")\n",
        "\n",
        "def train_supcon():\n",
        "    model.train()\n",
        "    print(\"\\nStarting SupCon Pre-training...\")\n",
        "    for epoch in range(EPOCHS_PRE):\n",
        "        epoch_loss = 0\n",
        "        pbar = tqdm(train_loader, desc=f\"SupCon Epoch {epoch+1}/{EPOCHS_PRE}\")\n",
        "        for pairs, lbl in pbar:\n",
        "            pairs = pairs.to(DEVICE)              # (B,2,1,224,224)\n",
        "            lbl   = lbl.to(DEVICE)\n",
        "            bsz   = pairs.size(0)\n",
        "            pairs = pairs.view(-1, 1, 224, 224)   # Adjusted size to 224x224\n",
        "\n",
        "            optimizer.zero_grad(set_to_none=True) # Slightly faster\n",
        "\n",
        "            with autocast(device_type='cuda'):    # Reverted to original autocast call\n",
        "                feats = model(pairs, contrastive=True)\n",
        "                loss  = criterion_supcon(feats, lbl)\n",
        "\n",
        "            scaler.scale(loss).backward()        # Scaled backward\n",
        "            scaler.step(optimizer)               # Optimiser step\n",
        "            scaler.update()                      # Update scaler\n",
        "\n",
        "            epoch_loss += loss.item() * bsz\n",
        "            pbar.set_postfix({\"loss\": f\"{loss.item():.4f}\"})\n",
        "\n",
        "        scheduler.step()\n",
        "        torch.cuda.empty_cache()                 # Free VRAM\n",
        "        mean_loss = epoch_loss / len(train_loader.dataset)\n",
        "        print(f\"Epoch {epoch+1}/{EPOCHS_PRE}: SupCon Mean Loss: {mean_loss:.4f}\")\n",
        "\n",
        "# ---- Linear classifier (also AMP) ---------------------------\n",
        "def train_classifier(epochs=10, lr=1e-3):\n",
        "    \"\"\"\n",
        "    Freeze encoder, train linear classifier on embeddings and evaluate.\n",
        "    \"\"\"\n",
        "    print(\"\\nStarting Linear Classifier Training...\")\n",
        "    for p in model.encoder.parameters():\n",
        "        p.requires_grad = False\n",
        "    # Ensure classifier parameters are trainable\n",
        "    for p in model.classifier.parameters():\n",
        "        p.requires_grad = True\n",
        "\n",
        "    optimizer_l = torch.optim.Adam(model.classifier.parameters(), lr=lr)\n",
        "    scaler_l = GradScaler() # Removed device_type='cuda'\n",
        "\n",
        "    for ep in range(epochs):\n",
        "        model.train()\n",
        "        total, correct, ce_loss = 0, 0, 0\n",
        "        all_preds, all_labels = [], [] # To collect predictions and labels for metrics\n",
        "\n",
        "        pbar = tqdm(train_loader, desc=f\"Linear Train Epoch {ep+1}/{epochs}\")\n",
        "        for pairs, lbl in pbar:\n",
        "            img = pairs[:, 0].to(DEVICE) # Use first view\n",
        "            lbl = lbl.to(DEVICE)\n",
        "\n",
        "            optimizer_l.zero_grad(set_to_none=True)\n",
        "\n",
        "            with autocast(device_type='cuda'): # Reverted to original autocast call\n",
        "                logits = model(img, contrastive=False)\n",
        "                loss = criterion_ce(logits, lbl)\n",
        "\n",
        "            scaler_l.scale(loss).backward()\n",
        "            scaler_l.step(optimizer_l)\n",
        "            scaler_l.update()\n",
        "\n",
        "            pred = logits.argmax(1)\n",
        "            correct += (pred == lbl).sum().item()\n",
        "            total += lbl.size(0)\n",
        "            ce_loss += loss.item() * lbl.size(0)\n",
        "\n",
        "            all_preds.extend(pred.cpu().numpy())\n",
        "            all_labels.extend(lbl.cpu().numpy())\n",
        "\n",
        "        torch.cuda.empty_cache() # Free VRAM\n",
        "\n",
        "        # Calculate training metrics\n",
        "        train_acc = correct / total\n",
        "        train_f1 = f1_score(all_labels, all_preds, average='weighted') # Use weighted for imbalanced data\n",
        "        mean_ce_loss = ce_loss / total\n",
        "\n",
        "        print(f\"Epoch {ep+1}/{epochs}: Train Acc: {train_acc:.4f}, Train F1: {train_f1:.4f}, Train Loss: {mean_ce_loss:.4f}\")\n",
        "\n",
        "        # ---- Validation step ----------------------------------------\n",
        "        model.eval() # Set model to evaluation mode\n",
        "        val_total, val_correct, val_loss = 0, 0, 0\n",
        "        val_all_preds, val_all_labels = [], []\n",
        "\n",
        "        with torch.no_grad(): # No gradient calculation during validation\n",
        "             vbar = tqdm(val_loader, desc=f\"Linear Val Epoch {ep+1}/{epochs}\")\n",
        "             for pairs, lbl in vbar:\n",
        "                 img = pairs[:, 0].to(DEVICE)\n",
        "                 lbl = lbl.to(DEVICE)\n",
        "\n",
        "                 with autocast(device_type='cuda'):\n",
        "                    logits = model(img, contrastive=False)\n",
        "                    loss = criterion_ce(logits, lbl)\n",
        "\n",
        "                 pred = logits.argmax(1)\n",
        "                 val_correct += (pred == lbl).sum().item()\n",
        "                 val_total += lbl.size(0)\n",
        "                 val_loss += loss.item() * lbl.size(0)\n",
        "\n",
        "                 val_all_preds.extend(pred.cpu().numpy())\n",
        "                 val_all_labels.extend(lbl.cpu().numpy())\n",
        "\n",
        "        # Calculate validation metrics\n",
        "        val_acc = val_correct / val_total\n",
        "        val_f1 = f1_score(val_all_labels, val_all_preds, average='weighted')\n",
        "        mean_val_loss = val_loss / val_total\n",
        "\n",
        "        print(f\"Epoch {ep+1}/{epochs}: Val Acc: {val_acc:.4f}, Val F1: {val_f1:.4f}, Val Loss: {mean_val_loss:.4f}\")\n",
        "\n",
        "        torch.cuda.empty_cache() # Free VRAM\n",
        "\n",
        "\n",
        "# ---- Run training --------------------------------------------------------\n",
        "train_supcon()                                                 # Pre‑train SupCon\n",
        "train_classifier()                                             # Train classifier\n",
        "# End of Snippet 4                                                         # End"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_K2JxNt3EoHh",
        "outputId": "b0b2a695-25ad-4800-cc3c-88fe5217c58b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting SupCon Pre-training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "SupCon Epoch 1/10: 100%|██████████| 1907/1907 [07:52<00:00,  4.04it/s, loss=3.2305]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10: SupCon Mean Loss: 4.7992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "SupCon Epoch 2/10: 100%|██████████| 1907/1907 [07:42<00:00,  4.13it/s, loss=3.2290]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/10: SupCon Mean Loss: 4.7979\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "SupCon Epoch 3/10: 100%|██████████| 1907/1907 [07:43<00:00,  4.11it/s, loss=3.1054]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/10: SupCon Mean Loss: 4.7960\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "SupCon Epoch 4/10: 100%|██████████| 1907/1907 [07:49<00:00,  4.06it/s, loss=3.1147]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/10: SupCon Mean Loss: 4.7946\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "SupCon Epoch 5/10: 100%|██████████| 1907/1907 [07:54<00:00,  4.02it/s, loss=3.0588]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/10: SupCon Mean Loss: 4.7935\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "SupCon Epoch 6/10: 100%|██████████| 1907/1907 [07:48<00:00,  4.07it/s, loss=3.1135]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/10: SupCon Mean Loss: 4.7920\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "SupCon Epoch 7/10: 100%|██████████| 1907/1907 [07:41<00:00,  4.13it/s, loss=3.1100]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/10: SupCon Mean Loss: 4.7909\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "SupCon Epoch 8/10: 100%|██████████| 1907/1907 [07:40<00:00,  4.14it/s, loss=3.0563]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/10: SupCon Mean Loss: 4.7903\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "SupCon Epoch 9/10: 100%|██████████| 1907/1907 [07:36<00:00,  4.17it/s, loss=3.0729]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/10: SupCon Mean Loss: 4.7895\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "SupCon Epoch 10/10: 100%|██████████| 1907/1907 [07:40<00:00,  4.14it/s, loss=3.1199]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/10: SupCon Mean Loss: 4.7889\n",
            "\n",
            "Starting Linear Classifier Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Linear Train Epoch 1/10: 100%|██████████| 1907/1907 [06:22<00:00,  4.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10: Train Acc: 0.3945, Train F1: 0.3874, Train Loss: 1.2663\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Linear Val Epoch 1/10: 100%|██████████| 393/393 [01:01<00:00,  6.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10: Val Acc: 0.4465, Val F1: 0.5367, Val Loss: 1.2358\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Linear Train Epoch 2/10: 100%|██████████| 1907/1907 [06:18<00:00,  5.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/10: Train Acc: 0.4176, Train F1: 0.4094, Train Loss: 1.2413\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Linear Val Epoch 2/10: 100%|██████████| 393/393 [01:02<00:00,  6.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/10: Val Acc: 0.4760, Val F1: 0.5757, Val Loss: 1.1836\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Linear Train Epoch 3/10: 100%|██████████| 1907/1907 [06:07<00:00,  5.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/10: Train Acc: 0.4329, Train F1: 0.4248, Train Loss: 1.2260\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Linear Val Epoch 3/10: 100%|██████████| 393/393 [01:02<00:00,  6.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/10: Val Acc: 0.5143, Val F1: 0.6067, Val Loss: 1.0599\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Linear Train Epoch 4/10: 100%|██████████| 1907/1907 [06:17<00:00,  5.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/10: Train Acc: 0.4364, Train F1: 0.4295, Train Loss: 1.2189\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Linear Val Epoch 4/10: 100%|██████████| 393/393 [01:04<00:00,  6.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/10: Val Acc: 0.5376, Val F1: 0.6148, Val Loss: 1.0247\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Linear Train Epoch 5/10:  31%|███▏      | 598/1907 [01:56<05:49,  3.75it/s]"
          ]
        }
      ]
    }
  ]
}