{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1NxHcpDO_wVnacHMXnknlvgyS6HoyEKRZ",
      "authorship_tag": "ABX9TyOpoXtqZr0iBQ0+FrGRPSS4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tousifo/ml_notebooks/blob/main/pimcl_new.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K7qdkd3A2EkH",
        "outputId": "319403f0-db58-405f-8083-0287fa4adad7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using data root: /content/oasis_data/input\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 59.6MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Phase 0: MIL-only Baseline ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "MIL-only Ep1: 100%|██████████| 475/475 [00:42<00:00, 11.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep1 MIL-only F1=0.4310\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "MIL-only Ep2: 100%|██████████| 475/475 [00:37<00:00, 12.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep2 MIL-only F1=0.4975\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "MIL-only Ep3: 100%|██████████| 475/475 [00:37<00:00, 12.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep3 MIL-only F1=0.5091\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "MIL-only Ep4: 100%|██████████| 475/475 [00:39<00:00, 12.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep4 MIL-only F1=0.5274\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "MIL-only Ep5: 100%|██████████| 475/475 [00:38<00:00, 12.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep5 MIL-only F1=0.5519\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "MIL-only Ep6: 100%|██████████| 475/475 [00:36<00:00, 12.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep6 MIL-only F1=0.5668\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "MIL-only Ep7: 100%|██████████| 475/475 [00:38<00:00, 12.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep7 MIL-only F1=0.5715\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "MIL-only Ep8: 100%|██████████| 475/475 [00:38<00:00, 12.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep8 MIL-only F1=0.5826\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "MIL-only Ep9: 100%|██████████| 475/475 [00:37<00:00, 12.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep9 MIL-only F1=0.6077\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "MIL-only Ep10: 100%|██████████| 475/475 [00:37<00:00, 12.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep10 MIL-only F1=0.6058\n",
            "\n",
            "=== Phase 1: Prototype Pre-training ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Proto-pretrain Ep1: 100%|██████████| 475/475 [00:38<00:00, 12.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep1 Proto Loss=1.2507\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Proto-pretrain Ep2: 100%|██████████| 475/475 [00:38<00:00, 12.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep2 Proto Loss=1.2033\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Proto-pretrain Ep3: 100%|██████████| 475/475 [00:37<00:00, 12.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep3 Proto Loss=1.1760\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Proto-pretrain Ep4: 100%|██████████| 475/475 [00:38<00:00, 12.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep4 Proto Loss=1.1486\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Proto-pretrain Ep5: 100%|██████████| 475/475 [00:38<00:00, 12.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep5 Proto Loss=1.1329\n",
            "\n",
            "=== Phase 2: MIL-head Training ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "MIL-head Ep1: 100%|██████████| 475/475 [00:31<00:00, 15.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep1 MIL-head F1=0.6124\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "MIL-head Ep2: 100%|██████████| 475/475 [00:31<00:00, 15.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep2 MIL-head F1=0.6516\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "MIL-head Ep3: 100%|██████████| 475/475 [00:32<00:00, 14.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep3 MIL-head F1=0.6548\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "MIL-head Ep4: 100%|██████████| 475/475 [00:31<00:00, 15.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep4 MIL-head F1=0.6554\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "MIL-head Ep5: 100%|██████████| 475/475 [00:31<00:00, 15.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep5 MIL-head F1=0.6447\n",
            "\n",
            "=== Phase 3: End-to-End Fine-tuning ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "FT Ep1: 100%|██████████| 475/475 [00:38<00:00, 12.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep1 FT F1=0.6797\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "FT Ep2: 100%|██████████| 475/475 [00:38<00:00, 12.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep2 FT F1=0.7033\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "FT Ep3: 100%|██████████| 475/475 [00:37<00:00, 12.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep3 FT F1=0.7224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "FT Ep4: 100%|██████████| 475/475 [00:38<00:00, 12.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep4 FT F1=0.7268\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "FT Ep5: 100%|██████████| 475/475 [00:38<00:00, 12.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep5 FT F1=0.7229\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "FT Ep6: 100%|██████████| 475/475 [00:38<00:00, 12.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep6 FT F1=0.7275\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "FT Ep7: 100%|██████████| 475/475 [00:37<00:00, 12.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep7 FT F1=0.7345\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "FT Ep8: 100%|██████████| 475/475 [00:38<00:00, 12.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep8 FT F1=0.7465\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "FT Ep9: 100%|██████████| 475/475 [00:38<00:00, 12.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep9 FT F1=0.7454\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "FT Ep10: 100%|██████████| 475/475 [00:38<00:00, 12.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep10 FT F1=0.7446\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import zipfile\n",
        "import glob\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "from torchvision import transforms\n",
        "import torchvision\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ---------------------------\n",
        "# 1. Paths & Extraction\n",
        "# ---------------------------\n",
        "ZIP_PATH    = \"/content/drive/MyDrive/oaisis_9k.zip\"\n",
        "EXTRACT_DIR = \"/content/oasis_data\"\n",
        "\n",
        "if not os.path.exists(EXTRACT_DIR) or not os.listdir(EXTRACT_DIR):\n",
        "    print(f\"Extracting {ZIP_PATH} -> {EXTRACT_DIR}...\")\n",
        "    with zipfile.ZipFile(ZIP_PATH, 'r') as zf:\n",
        "        zf.extractall(EXTRACT_DIR)\n",
        "\n",
        "# Detect true data root\n",
        "LABEL_MAP = {\n",
        "    \"Non Demented\":       0,\n",
        "    \"Very mild Dementia\": 1,\n",
        "    \"Mild Dementia\":      2,\n",
        "    \"Moderate Dementia\":  3\n",
        "}\n",
        "\n",
        "candidates = [EXTRACT_DIR] + [os.path.join(EXTRACT_DIR, d) for d in os.listdir(EXTRACT_DIR)]\n",
        "DATA_ROOT = None\n",
        "for cand in candidates:\n",
        "    if all(os.path.isdir(os.path.join(cand, lbl)) for lbl in LABEL_MAP):\n",
        "        DATA_ROOT = cand\n",
        "        break\n",
        "if DATA_ROOT is None:\n",
        "    raise RuntimeError(f\"Could not find class folders under {EXTRACT_DIR}\")\n",
        "print(\"Using data root:\", DATA_ROOT)\n",
        "\n",
        "# ---------------------------\n",
        "# 2. Build samples & split\n",
        "# ---------------------------\n",
        "all_samples = []\n",
        "for label_name, lbl in LABEL_MAP.items():\n",
        "    pattern = os.path.join(DATA_ROOT, label_name, \"*.jpg\")\n",
        "    files = glob.glob(pattern)\n",
        "    if not files:\n",
        "        raise RuntimeError(f\"No images for '{label_name}' in {pattern}\")\n",
        "    all_samples += [(fp, lbl) for fp in files]\n",
        "\n",
        "paths, labels = zip(*all_samples)\n",
        "labels = np.array(labels)\n",
        "\n",
        "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
        "train_idx, val_idx = next(sss.split(paths, labels))\n",
        "train_list = [all_samples[i] for i in train_idx]\n",
        "val_list   = [all_samples[i] for i in val_idx]\n",
        "\n",
        "# Compute class weights\n",
        "train_labels = labels[train_idx]\n",
        "class_counts = np.bincount(train_labels, minlength=len(LABEL_MAP))\n",
        "class_weights = torch.tensor(1.0 / class_counts, dtype=torch.float32)\n",
        "\n",
        "# Sampler\n",
        "sample_weights = [class_weights[lbl].item() for _, lbl in train_list]\n",
        "train_sampler = WeightedRandomSampler(sample_weights, len(sample_weights), replacement=True)\n",
        "\n",
        "# ---------------------------\n",
        "# 3. Patch Extraction\n",
        "# ---------------------------\n",
        "PATCH_SIZE = (32, 32)\n",
        "LARGE_SIZE = (64, 64)\n",
        "NUM_PATCHES = 25\n",
        "\n",
        "def extract_multi_scale_patches(img_t, num_patches=NUM_PATCHES,\n",
        "                                patch_size=PATCH_SIZE, large_size=LARGE_SIZE):\n",
        "    C, H, W = img_t.shape\n",
        "    patches = []\n",
        "    ph, pw = patch_size\n",
        "    ph2, pw2 = large_size\n",
        "\n",
        "    # Center\n",
        "    top_c = H//2 - ph//2\n",
        "    left_c= W//2 - pw//2\n",
        "    patches.append(img_t[:, top_c:top_c+ph, left_c:left_c+pw])\n",
        "\n",
        "    # Random small\n",
        "    small_n = int((num_patches-1)*0.5)\n",
        "    for _ in range(small_n):\n",
        "        t = np.random.randint(0, H-ph+1)\n",
        "        l = np.random.randint(0, W-pw+1)\n",
        "        patches.append(img_t[:, t:t+ph, l:l+pw])\n",
        "\n",
        "    # Random large\n",
        "    large_n = (num_patches-1-small_n)\n",
        "    for _ in range(large_n):\n",
        "        t = np.random.randint(0, H-ph2+1)\n",
        "        l = np.random.randint(0, W-pw2+1)\n",
        "        lp = img_t[:, t:t+ph2, l:l+pw2].unsqueeze(0)\n",
        "        lp_res = F.interpolate(lp, size=patch_size, mode='bilinear', align_corners=False)\n",
        "        patches.append(lp_res.squeeze(0))\n",
        "\n",
        "    return torch.stack(patches[:num_patches], dim=0)\n",
        "\n",
        "# ---------------------------\n",
        "# 4. Dataset & DataLoaders\n",
        "# ---------------------------\n",
        "class OASISPatchDataset(Dataset):\n",
        "    def __init__(self, samples, transform):\n",
        "        self.samples = samples\n",
        "        self.transform = transform\n",
        "    def __len__(self): return len(self.samples)\n",
        "    def __getitem__(self, i):\n",
        "        fp, lbl = self.samples[i]\n",
        "        img = Image.open(fp).convert('L')\n",
        "        img_t = self.transform(img)\n",
        "        patches = extract_multi_scale_patches(img_t)\n",
        "        return patches, lbl\n",
        "\n",
        "train_tf = transforms.Compose([\n",
        "    transforms.Resize(280),\n",
        "    transforms.RandomCrop(256),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ColorJitter(brightness=0.1, contrast=0.1),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "val_tf = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(256),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "train_ds = OASISPatchDataset(train_list, train_tf)\n",
        "val_ds   = OASISPatchDataset(val_list,   val_tf)\n",
        "\n",
        "BATCH_SIZE = 16\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE,\n",
        "                          sampler=train_sampler, num_workers=2)\n",
        "val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE,\n",
        "                          shuffle=False, num_workers=2)\n",
        "\n",
        "# ---------------------------\n",
        "# 5. Model Definitions\n",
        "# ---------------------------\n",
        "EMBED_DIM   = 128\n",
        "NUM_CLASSES = len(LABEL_MAP)\n",
        "TEMPERATURE = 0.1\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "class PatchResNet(nn.Module):\n",
        "    def __init__(self, embed_dim):\n",
        "        super().__init__()\n",
        "        resnet = torchvision.models.resnet18(pretrained=True)\n",
        "        self.backbone = nn.Sequential(*list(resnet.children())[:-2])\n",
        "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.fc   = nn.Linear(resnet.fc.in_features, embed_dim)\n",
        "    def forward(self, x):\n",
        "        B,N = x.shape[:2]\n",
        "        x = x.view(B*N, 3, *x.shape[-2:])\n",
        "        x = self.backbone(x)\n",
        "        x = self.pool(x).view(B*N, -1)\n",
        "        x = F.normalize(self.fc(x), dim=1)\n",
        "        return x.view(B, N, -1)\n",
        "\n",
        "class TopKAttentionMIL(nn.Module):\n",
        "    def __init__(self, embed_dim, num_classes, k=5):\n",
        "        super().__init__()\n",
        "        self.scorer = nn.Linear(embed_dim,1)\n",
        "        self.cls    = nn.Linear(embed_dim,num_classes)\n",
        "        self.k      = k\n",
        "    def forward(self, emb):\n",
        "        scores = self.scorer(emb).squeeze(-1)\n",
        "        topv, topi = torch.topk(scores, self.k, dim=1)\n",
        "        idx = topi.unsqueeze(-1).expand(-1,-1,emb.size(-1))\n",
        "        sel = emb.gather(1, idx)\n",
        "        M = sel.mean(dim=1)\n",
        "        return self.cls(M), scores\n",
        "\n",
        "class PrototypeContrastiveLoss(nn.Module):\n",
        "    def __init__(self, n_cls, dim, temp):\n",
        "        super().__init__()\n",
        "        self.protos = nn.Parameter(torch.randn(n_cls, dim))\n",
        "        self.temp   = temp\n",
        "    def forward(self, emb, labels):\n",
        "        B,N,D = emb.shape\n",
        "        flat = emb.view(B*N, D)\n",
        "        labs = labels.unsqueeze(1).repeat(1,N).view(-1)\n",
        "        sims = F.cosine_similarity(flat.unsqueeze(1), self.protos.unsqueeze(0), dim=-1)/self.temp\n",
        "        return F.cross_entropy(sims, labs)\n",
        "\n",
        "class PMICL2D_ResNet_TopK(nn.Module):\n",
        "    def __init__(self, embed_dim, num_classes, temperature, topk=5):\n",
        "        super().__init__()\n",
        "        self.encoder    = PatchResNet(embed_dim)\n",
        "        self.aggregator = TopKAttentionMIL(embed_dim,num_classes, k=topk)\n",
        "        self.prot_loss  = PrototypeContrastiveLoss(num_classes, embed_dim, temperature)\n",
        "    def forward(self, patches, labels=None):\n",
        "        patches = patches.repeat(1,1,3,1,1)\n",
        "        emb, _ = self.encoder(patches), None\n",
        "        logits, scores = self.aggregator(emb)\n",
        "        p_loss = self.prot_loss(emb, labels) if labels is not None else 0\n",
        "        return logits, p_loss, scores\n",
        "    def bag_embedding(self, patches):\n",
        "        with torch.no_grad():\n",
        "            patches = patches.repeat(1,1,3,1,1)\n",
        "            emb = self.encoder(patches)\n",
        "            scores = self.aggregator.scorer(emb).squeeze(-1)\n",
        "            topv, topi = torch.topk(scores, self.aggregator.k, dim=1)\n",
        "            idx = topi.unsqueeze(-1).expand(-1,-1,emb.size(-1))\n",
        "            sel = emb.gather(1, idx)\n",
        "            return sel.mean(dim=1).cpu().numpy()\n",
        "\n",
        "# ---------------------------\n",
        "# 6. Training Phases\n",
        "# ---------------------------\n",
        "PROTO_WEIGHT = 0.1\n",
        "\n",
        "# Phase 0: MIL-only\n",
        "\n",
        "def train_mil_only(model, loader, epochs=10, lr=1e-4):\n",
        "    opt = torch.optim.AdamW(model.parameters(), lr=lr)\n",
        "    for ep in range(1, epochs+1):\n",
        "        model.train()\n",
        "        all_p, all_t = [], []\n",
        "        for patches, labels in tqdm(loader, desc=f\"MIL-only Ep{ep}\"):\n",
        "            patches, labels = patches.to(DEVICE), labels.to(DEVICE)\n",
        "            opt.zero_grad()\n",
        "            logits, _, _ = model(patches, labels)\n",
        "            loss = F.cross_entropy(logits, labels)\n",
        "            loss.backward(); opt.step()\n",
        "            preds = logits.argmax(1)\n",
        "            all_p += preds.cpu().tolist(); all_t += labels.cpu().tolist()\n",
        "        print(f\"Ep{ep} MIL-only F1={f1_score(all_t, all_p, average='weighted'):.4f}\")\n",
        "\n",
        "# Phase 1: Prototype pretrain\n",
        "\n",
        "def pretrain_encoder(model, loader, epochs=5, lr=1e-4):\n",
        "    enc = model.encoder\n",
        "    opt = torch.optim.AdamW(enc.parameters(), lr=lr)\n",
        "    for ep in range(1, epochs+1):\n",
        "        enc.train()\n",
        "        total=0\n",
        "        for patches, labels in tqdm(loader, desc=f\"Proto-pretrain Ep{ep}\"):\n",
        "            patches, labels = patches.to(DEVICE), labels.to(DEVICE)\n",
        "            opt.zero_grad()\n",
        "            patches3 = patches.repeat(1,1,3,1,1)\n",
        "            emb = enc(patches3)\n",
        "            loss = model.prot_loss(emb, labels)\n",
        "            loss.backward(); opt.step()\n",
        "            total += loss.item()\n",
        "        print(f\"Ep{ep} Proto Loss={total/len(loader):.4f}\")\n",
        "\n",
        "# Phase 2: MIL-head\n",
        "\n",
        "def train_mil_head(model, loader, epochs=5, lr=1e-4):\n",
        "    for p in model.encoder.parameters(): p.requires_grad=False\n",
        "    opt = torch.optim.AdamW(model.aggregator.parameters(), lr=lr)\n",
        "    for ep in range(1, epochs+1):\n",
        "        model.train()\n",
        "        all_p, all_t=[],[]; total=0\n",
        "        for patches, labels in tqdm(loader, desc=f\"MIL-head Ep{ep}\"):\n",
        "            patches, labels=patches.to(DEVICE),labels.to(DEVICE)\n",
        "            opt.zero_grad()\n",
        "            logits, _, _ = model(patches, labels)\n",
        "            loss = F.cross_entropy(logits, labels)\n",
        "            loss.backward(); opt.step(); total+=loss.item()\n",
        "            preds=logits.argmax(1)\n",
        "            all_p+=preds.cpu().tolist(); all_t+=labels.cpu().tolist()\n",
        "        print(f\"Ep{ep} MIL-head F1={f1_score(all_t, all_p, average='weighted'):.4f}\")\n",
        "\n",
        "# Phase 3: End-to-end\n",
        "\n",
        "def fine_tune_end2end(model, loader, epochs=10, lr=1e-5, proto_weight=PROTO_WEIGHT):\n",
        "    for p in model.encoder.parameters(): p.requires_grad=True\n",
        "    opt = torch.optim.AdamW(model.parameters(), lr=lr)\n",
        "    for ep in range(1, epochs+1):\n",
        "        model.train()\n",
        "        all_p, all_t=[],[]; total=0\n",
        "        for patches, labels in tqdm(loader, desc=f\"FT Ep{ep}\"):\n",
        "            patches, labels=patches.to(DEVICE),labels.to(DEVICE)\n",
        "            opt.zero_grad()\n",
        "            logits, p_loss, _ = model(patches, labels)\n",
        "            c_loss=F.cross_entropy(logits, labels)\n",
        "            loss = (1-proto_weight)*c_loss + proto_weight*p_loss\n",
        "            loss.backward(); opt.step(); total+=loss.item()\n",
        "            preds=logits.argmax(1)\n",
        "            all_p+=preds.cpu().tolist(); all_t+=labels.cpu().tolist()\n",
        "        print(f\"Ep{ep} FT F1={f1_score(all_t, all_p, average='weighted'):.4f}\")\n",
        "\n",
        "# ---------------------------\n",
        "# 7. Run Phases\n",
        "# ---------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    model = PMICL2D_ResNet_TopK(EMBED_DIM, NUM_CLASSES, TEMPERATURE, topk=5).to(DEVICE)\n",
        "\n",
        "    print(\"\\n=== Phase 0: MIL-only Baseline ===\")\n",
        "    train_mil_only(model, train_loader, epochs=10, lr=1e-4)\n",
        "\n",
        "    print(\"\\n=== Phase 1: Prototype Pre-training ===\")\n",
        "    pretrain_encoder(model, train_loader, epochs=5, lr=1e-4)\n",
        "\n",
        "    print(\"\\n=== Phase 2: MIL-head Training ===\")\n",
        "    train_mil_head(model, train_loader, epochs=5, lr=1e-4)\n",
        "\n",
        "    print(\"\\n=== Phase 3: End-to-End Fine-tuning ===\")\n",
        "    fine_tune_end2end(model, train_loader, epochs=10, lr=1e-5, proto_weight=0.1)\n"
      ]
    }
  ]
}