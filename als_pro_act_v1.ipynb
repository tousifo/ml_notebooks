{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tousifo/ml_notebooks/blob/main/als_pro_act_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vxEGJHt-Ya7I",
        "outputId": "569af3be-e20a-45b6-d0a3-b20ecfb7c0d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pennylane\n",
            "  Downloading pennylane-0.43.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from pennylane) (1.16.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from pennylane) (3.5)\n",
            "Collecting rustworkx>=0.14.0 (from pennylane)\n",
            "  Downloading rustworkx-0.17.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: autograd in /usr/local/lib/python3.12/dist-packages (from pennylane) (1.8.0)\n",
            "Collecting appdirs (from pennylane)\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting autoray==0.8.0 (from pennylane)\n",
            "  Downloading autoray-0.8.0-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.12/dist-packages (from pennylane) (5.5.2)\n",
            "Collecting pennylane-lightning>=0.43 (from pennylane)\n",
            "  Downloading pennylane_lightning-0.43.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from pennylane) (2.32.4)\n",
            "Requirement already satisfied: tomlkit in /usr/local/lib/python3.12/dist-packages (from pennylane) (0.13.3)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.12/dist-packages (from pennylane) (4.15.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from pennylane) (25.0)\n",
            "Collecting diastatic-malt (from pennylane)\n",
            "  Downloading diastatic_malt-2.15.2-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from pennylane) (2.0.2)\n",
            "Collecting scipy-openblas32>=0.3.26 (from pennylane-lightning>=0.43->pennylane)\n",
            "  Downloading scipy_openblas32-0.3.30.0.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.1/57.1 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: astunparse in /usr/local/lib/python3.12/dist-packages (from diastatic-malt->pennylane) (1.6.3)\n",
            "Requirement already satisfied: gast in /usr/local/lib/python3.12/dist-packages (from diastatic-malt->pennylane) (0.6.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.12/dist-packages (from diastatic-malt->pennylane) (3.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->pennylane) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->pennylane) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->pennylane) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->pennylane) (2025.10.5)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse->diastatic-malt->pennylane) (0.45.1)\n",
            "Requirement already satisfied: six<2.0,>=1.6.1 in /usr/local/lib/python3.12/dist-packages (from astunparse->diastatic-malt->pennylane) (1.17.0)\n",
            "Downloading pennylane-0.43.0-py3-none-any.whl (5.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m50.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading autoray-0.8.0-py3-none-any.whl (934 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m934.3/934.3 kB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pennylane_lightning-0.43.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m44.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rustworkx-0.17.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Downloading diastatic_malt-2.15.2-py3-none-any.whl (167 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy_openblas32-0.3.30.0.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m59.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: appdirs, scipy-openblas32, rustworkx, autoray, diastatic-malt, pennylane-lightning, pennylane\n",
            "Successfully installed appdirs-1.4.4 autoray-0.8.0 diastatic-malt-2.15.2 pennylane-0.43.0 pennylane-lightning-0.43.0 rustworkx-0.17.1 scipy-openblas32-0.3.30.0.6\n"
          ]
        }
      ],
      "source": [
        "!pip install pennylane"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TgwkVE8D4wRY",
        "outputId": "de9ff8c3-5816-4055-a3c0-62ccade0c4ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "STEP 1: INITIALIZATION AND DATA LOADING\n",
            "============================================================\n",
            "\n",
            "📂 Loading PROACT datasets...\n",
            "✅ ALSFRS records: 73,845\n",
            "✅ FVC records: 49,110\n",
            "✅ Vitals records: 84,721\n",
            "✅ Labs records: 2,937,162\n",
            "✅ Demographics: 12,504\n",
            "\n",
            "🧮 Computing ALSFRS scores...\n",
            "\n",
            "🔍 Identifying valid patients...\n",
            "✅ Valid patients identified: 2,442\n",
            "\n",
            "📈 Computing target ALSFRS slope (3-12 months)...\n",
            "✅ ALSFRS slope computed for 2,439 patients\n",
            "\n",
            "📊 Target Statistics:\n",
            "count    2439.000000\n",
            "mean       -0.388076\n",
            "std         0.496497\n",
            "min        -3.100000\n",
            "25%        -0.638298\n",
            "50%        -0.218978\n",
            "75%         0.000000\n",
            "max         1.052632\n",
            "Name: ALSFRS_slope_3to12m, dtype: float64\n",
            "\n",
            "🛠️  Setting up feature engineering functions...\n",
            "✅ Feature engineering functions ready\n",
            "\n",
            "📅 Extracting first 90 days data...\n",
            "✅ ALSFRS 3-month records: 8,210\n",
            "✅ FVC 3-month records: 5,880\n",
            "✅ Vitals 3-month records: 9,625\n",
            "✅ Labs 3-month records: 403,408\n",
            "\n",
            "🔨 Creating summarized features from time-series data...\n",
            "✅ ALSFRS features: 17 variables\n",
            "✅ FVC features: 8 variables\n",
            "✅ Vitals features: 27 variables\n",
            "✅ Labs features: 0 variables\n",
            "\n",
            "🔗 Merging all features...\n",
            "✅ Features merged. Shape: (2442, 580)\n",
            "\n",
            "🧹 Initial cleanup...\n",
            "✅ After cleanup. Shape: (2442, 518)\n",
            "\n",
            "📋 Missing values per column: 691,712 total\n",
            "📋 Columns with >30% missing: 318\n",
            "\n",
            "============================================================\n",
            "✅ STEP 1 COMPLETED SUCCESSFULLY\n",
            "============================================================\n",
            "\n",
            "📊 Final dataset info:\n",
            "  - Total patients: 2,442\n",
            "  - Total features: 517\n",
            "  - Target variable: ALSFRS_slope_3to12m\n",
            "  - Patients with target: 2,439\n",
            "\n",
            "🔍 Preview:\n",
            "      Site_of_Onset  Onset_Delta  Diagnosis_Delta Subject_used_Riluzole  \\\n",
            "121     Onset: Limb          NaN              NaN                   Yes   \n",
            "1009   Onset: Other       -324.0            -63.0                   Yes   \n",
            "1036  Onset: Bulbar          NaN              NaN                   NaN   \n",
            "\n",
            "      Riluzole_use_Delta   Age     Sex  Q1_Speech_min  Q1_Speech_max  \\\n",
            "121                  0.0  52.0  Female            4.0            4.0   \n",
            "1009                 0.0  51.0    Male            4.0            4.0   \n",
            "1036                 NaN  67.0  Female            3.0            3.0   \n",
            "\n",
            "      Q1_Speech_mean  ...  Standing_BP_Diastolic_last  \\\n",
            "121              4.0  ...                         NaN   \n",
            "1009             4.0  ...                         NaN   \n",
            "1036             3.0  ...                         NaN   \n",
            "\n",
            "      Standing_BP_Systolic_min  Standing_BP_Systolic_max  \\\n",
            "121                        NaN                       NaN   \n",
            "1009                       NaN                       NaN   \n",
            "1036                       NaN                       NaN   \n",
            "\n",
            "      Standing_BP_Systolic_mean  Standing_BP_Systolic_median  \\\n",
            "121                         NaN                          NaN   \n",
            "1009                        NaN                          NaN   \n",
            "1036                        NaN                          NaN   \n",
            "\n",
            "      Standing_BP_Systolic_q25  Standing_BP_Systolic_q75  \\\n",
            "121                        NaN                       NaN   \n",
            "1009                       NaN                       NaN   \n",
            "1036                       NaN                       NaN   \n",
            "\n",
            "      Standing_BP_Systolic_first  Standing_BP_Systolic_last  \\\n",
            "121                          NaN                        NaN   \n",
            "1009                         NaN                        NaN   \n",
            "1036                         NaN                        NaN   \n",
            "\n",
            "      ALSFRS_slope_3to12m  \n",
            "121             -1.058824  \n",
            "1009             0.000000  \n",
            "1036                  NaN  \n",
            "\n",
            "[3 rows x 518 columns]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer, KNNImputer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"STEP 1: INITIALIZATION AND DATA LOADING\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# -------------------------------\n",
        "# 1. Load all relevant CSV tables\n",
        "# -------------------------------\n",
        "print(\"\\n📂 Loading PROACT datasets...\")\n",
        "alsfrs_df = pd.read_csv('PROACT_ALSFRS.csv')\n",
        "fvc_df = pd.read_csv('PROACT_FVC.csv')\n",
        "vitals_df = pd.read_csv('PROACT_VITALSIGNS.csv')\n",
        "labs_df = pd.read_csv('PROACT_LABS.csv')\n",
        "onset_df = pd.read_csv('PROACT_ALSHISTORY.csv')\n",
        "riluzole_df = pd.read_csv('PROACT_RILUZOLE.csv')\n",
        "demographics_df = pd.read_csv('PROACT_DEMOGRAPHICS.csv')\n",
        "\n",
        "print(f\"✅ ALSFRS records: {len(alsfrs_df):,}\")\n",
        "print(f\"✅ FVC records: {len(fvc_df):,}\")\n",
        "print(f\"✅ Vitals records: {len(vitals_df):,}\")\n",
        "print(f\"✅ Labs records: {len(labs_df):,}\")\n",
        "print(f\"✅ Demographics: {len(demographics_df):,}\")\n",
        "\n",
        "# -------------------------------\n",
        "# 2. Compute ALSFRS (convert ALSFRS-R to original if needed)\n",
        "# -------------------------------\n",
        "print(\"\\n🧮 Computing ALSFRS scores...\")\n",
        "\n",
        "def convert_alsfrs_row(row):\n",
        "    \"\"\"Convert ALSFRS-R to original ALSFRS if needed\"\"\"\n",
        "    if pd.notna(row.get('ALSFRS_Total')):\n",
        "        return row['ALSFRS_Total']\n",
        "    total = 0\n",
        "    for q in range(1, 10):\n",
        "        val = row.get(f'Q{q}', np.nan)\n",
        "        if pd.notna(val):\n",
        "            total += val\n",
        "    # Handle Q10 (respiratory)\n",
        "    if pd.notna(row.get('Q10_Respiratory')):\n",
        "        total += row['Q10_Respiratory']\n",
        "    elif pd.notna(row.get('R_1_Dyspnea')):\n",
        "        total += row.get('R_1_Dyspnea')\n",
        "    return total\n",
        "\n",
        "alsfrs_df['ALSFRS_Total_orig'] = alsfrs_df.apply(convert_alsfrs_row, axis=1)\n",
        "\n",
        "# -------------------------------\n",
        "# 3. Identify valid patients\n",
        "# -------------------------------\n",
        "print(\"\\n🔍 Identifying valid patients...\")\n",
        "months_start, months_end = 3, 12\n",
        "min_records_start, min_records_end = 2, 2\n",
        "days_start, days_end = months_start * 30, months_end * 30\n",
        "\n",
        "alsfrs_counts = alsfrs_df.groupby('subject_id')['ALSFRS_Delta'].agg(\n",
        "    records_before_start=lambda x: (x <= days_start).sum(),\n",
        "    records_after_end=lambda x: (x >= days_end).sum()\n",
        ")\n",
        "\n",
        "valid_patients_df = alsfrs_counts[\n",
        "    (alsfrs_counts['records_before_start'] >= min_records_start) &\n",
        "    (alsfrs_counts['records_after_end'] >= min_records_end)\n",
        "]\n",
        "valid_patients = sorted(valid_patients_df.index.tolist())\n",
        "\n",
        "print(f\"✅ Valid patients identified: {len(valid_patients):,}\")\n",
        "\n",
        "# -------------------------------\n",
        "# 4. Compute ALSFRS slope (3–12 months) - TARGET\n",
        "# -------------------------------\n",
        "print(\"\\n📈 Computing target ALSFRS slope (3-12 months)...\")\n",
        "slope_targets = {}\n",
        "\n",
        "for pid in valid_patients:\n",
        "    patient_data = alsfrs_df[alsfrs_df['subject_id'] == pid].copy()\n",
        "    patient_data.sort_values('ALSFRS_Delta', inplace=True)\n",
        "    t1 = patient_data[patient_data['ALSFRS_Delta'] > 90]\n",
        "    t2 = patient_data[patient_data['ALSFRS_Delta'] >= 365]\n",
        "\n",
        "    if len(t1) > 0 and len(t2) > 0:\n",
        "        t1_record = t1.iloc[0]\n",
        "        t2_record = t2.iloc[0]\n",
        "        delta_days = t2_record['ALSFRS_Delta'] - t1_record['ALSFRS_Delta']\n",
        "        if delta_days > 0:\n",
        "            slope = (t2_record['ALSFRS_Total_orig'] - t1_record['ALSFRS_Total_orig']) / (delta_days / 30.0)\n",
        "            slope_targets[pid] = slope\n",
        "\n",
        "target_df = pd.Series(slope_targets, name='ALSFRS_slope_3to12m')\n",
        "print(f\"✅ ALSFRS slope computed for {len(target_df):,} patients\")\n",
        "print(\"\\n📊 Target Statistics:\")\n",
        "print(target_df.describe())\n",
        "\n",
        "# -------------------------------\n",
        "# 5. Helper functions for feature engineering\n",
        "# -------------------------------\n",
        "print(\"\\n🛠️  Setting up feature engineering functions...\")\n",
        "\n",
        "def summarize_timeseries(df, time_col, value_col):\n",
        "    \"\"\"Enhanced time-series summarization with additional statistics\"\"\"\n",
        "    grp = df.groupby('subject_id')\n",
        "    summary = pd.DataFrame({\n",
        "        'min': grp[value_col].min(),\n",
        "        'max': grp[value_col].max(),\n",
        "        'mean': grp[value_col].mean(),  # Added mean\n",
        "        'median': grp[value_col].median(),\n",
        "        'std': grp[value_col].std(),\n",
        "        'q25': grp[value_col].quantile(0.25),  # Added 25th percentile\n",
        "        'q75': grp[value_col].quantile(0.75),  # Added 75th percentile\n",
        "        'first': grp.apply(lambda g: g.sort_values(time_col)[value_col].iloc[0], include_groups=False),\n",
        "        'last': grp.apply(lambda g: g.sort_values(time_col)[value_col].iloc[-1], include_groups=False)\n",
        "    })\n",
        "\n",
        "    # Compute slope (rate of change)\n",
        "    time_first = grp[time_col].min()\n",
        "    time_last = grp[time_col].max()\n",
        "    time_diff_months = (time_last - time_first) / 30.0\n",
        "    summary['slope'] = (summary['last'] - summary['first']) / time_diff_months\n",
        "    summary.loc[time_diff_months == 0, 'slope'] = np.nan\n",
        "\n",
        "    # Add range\n",
        "    summary['range'] = summary['max'] - summary['min']\n",
        "\n",
        "    return summary\n",
        "\n",
        "def summarize_all_numeric(df, time_col):\n",
        "    \"\"\"Summarize all numeric columns in a time-series DataFrame\"\"\"\n",
        "    numeric_cols = df.select_dtypes(include=['number']).columns.drop([time_col, 'subject_id'], errors='ignore')\n",
        "    summaries = {}\n",
        "    for col in numeric_cols:\n",
        "        summaries[col] = summarize_timeseries(df, time_col, col)\n",
        "        summaries[col].columns = [f'{col}_{c}' for c in summaries[col].columns]\n",
        "    return summaries\n",
        "\n",
        "print(\"✅ Feature engineering functions ready\")\n",
        "\n",
        "# -------------------------------\n",
        "# 6. Extract first 90 days data\n",
        "# -------------------------------\n",
        "print(\"\\n📅 Extracting first 90 days data...\")\n",
        "\n",
        "alsfrs_3m = alsfrs_df[alsfrs_df['subject_id'].isin(valid_patients) & (alsfrs_df['ALSFRS_Delta'] <= 90)]\n",
        "fvc_df['FVC'] = fvc_df[['Subject_Liters_Trial_1','Subject_Liters_Trial_2','Subject_Liters_Trial_3']].max(axis=1)\n",
        "fvc_3m = fvc_df[fvc_df['subject_id'].isin(valid_patients) & (fvc_df['Forced_Vital_Capacity_Delta'] <= 90)]\n",
        "vitals_3m = vitals_df[vitals_df['subject_id'].isin(valid_patients) & (vitals_df['Vital_Signs_Delta'] <= 90)]\n",
        "labs_3m = labs_df[labs_df['subject_id'].isin(valid_patients) & (labs_df['Laboratory_Delta'] <= 90)]\n",
        "\n",
        "print(f\"✅ ALSFRS 3-month records: {len(alsfrs_3m):,}\")\n",
        "print(f\"✅ FVC 3-month records: {len(fvc_3m):,}\")\n",
        "print(f\"✅ Vitals 3-month records: {len(vitals_3m):,}\")\n",
        "print(f\"✅ Labs 3-month records: {len(labs_3m):,}\")\n",
        "\n",
        "# -------------------------------\n",
        "# 7. Create summarized features\n",
        "# -------------------------------\n",
        "print(\"\\n🔨 Creating summarized features from time-series data...\")\n",
        "\n",
        "alsfrs_features = summarize_all_numeric(alsfrs_3m, 'ALSFRS_Delta')\n",
        "fvc_features = summarize_all_numeric(fvc_3m, 'Forced_Vital_Capacity_Delta')\n",
        "vitals_features = summarize_all_numeric(vitals_3m, 'Vital_Signs_Delta')\n",
        "labs_features = summarize_all_numeric(labs_3m, 'Laboratory_Delta')\n",
        "\n",
        "print(f\"✅ ALSFRS features: {len(alsfrs_features)} variables\")\n",
        "print(f\"✅ FVC features: {len(fvc_features)} variables\")\n",
        "print(f\"✅ Vitals features: {len(vitals_features)} variables\")\n",
        "print(f\"✅ Labs features: {len(labs_features)} variables\")\n",
        "\n",
        "# -------------------------------\n",
        "# 8. Merge all features\n",
        "# -------------------------------\n",
        "print(\"\\n🔗 Merging all features...\")\n",
        "\n",
        "features_df = pd.DataFrame(index=valid_patients)\n",
        "\n",
        "# Prepare static features\n",
        "onset_static = onset_df.drop_duplicates(subset='subject_id', keep='first').set_index('subject_id')[['Site_of_Onset', 'Onset_Delta', 'Diagnosis_Delta']]\n",
        "riluzole_static = riluzole_df.drop_duplicates(subset='subject_id', keep='first').set_index('subject_id')[['Subject_used_Riluzole', 'Riluzole_use_Delta']]\n",
        "demographics_static = demographics_df.drop_duplicates(subset='subject_id', keep='first').set_index('subject_id')[['Age', 'Sex']]\n",
        "\n",
        "# Join static features\n",
        "features_df = features_df.join(onset_static, how='left')\n",
        "features_df = features_df.join(riluzole_static, how='left', rsuffix='_rilu')\n",
        "features_df = features_df.join(demographics_static, how='left', rsuffix='_demo')\n",
        "\n",
        "# Add dynamic (summarized) features\n",
        "for group in [alsfrs_features, fvc_features, vitals_features, labs_features]:\n",
        "    for feat_df in group.values():\n",
        "        features_df = features_df.join(feat_df, how='left')\n",
        "\n",
        "# Add slope target\n",
        "features_df = features_df.join(target_df, how='left')\n",
        "\n",
        "print(f\"✅ Features merged. Shape: {features_df.shape}\")\n",
        "\n",
        "# -------------------------------\n",
        "# 9. Initial cleanup\n",
        "# -------------------------------\n",
        "print(\"\\n🧹 Initial cleanup...\")\n",
        "\n",
        "# Remove columns with all NaN values\n",
        "features_df = features_df.dropna(axis=1, how='all')\n",
        "\n",
        "# Remove columns with only one unique value\n",
        "features_df = features_df.loc[:, features_df.nunique() > 1]\n",
        "\n",
        "print(f\"✅ After cleanup. Shape: {features_df.shape}\")\n",
        "print(f\"\\n📋 Missing values per column: {features_df.isnull().sum().sum():,} total\")\n",
        "print(f\"📋 Columns with >30% missing: {(features_df.isnull().sum() / len(features_df) > 0.3).sum()}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"✅ STEP 1 COMPLETED SUCCESSFULLY\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"\\n📊 Final dataset info:\")\n",
        "print(f\"  - Total patients: {len(features_df):,}\")\n",
        "print(f\"  - Total features: {features_df.shape[1] - 1}\")  # -1 for target\n",
        "print(f\"  - Target variable: ALSFRS_slope_3to12m\")\n",
        "print(f\"  - Patients with target: {features_df['ALSFRS_slope_3to12m'].notna().sum():,}\")\n",
        "print(\"\\n🔍 Preview:\")\n",
        "print(features_df.head(3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "8FvNDrtz7VbD",
        "outputId": "f57b9ac8-bf29-4e0e-e473-fd88c2757b5d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Site_of_Onset  Onset_Delta  Diagnosis_Delta Subject_used_Riluzole  \\\n",
              "121     Onset: Limb          NaN              NaN                   Yes   \n",
              "1009   Onset: Other       -324.0            -63.0                   Yes   \n",
              "1036  Onset: Bulbar          NaN              NaN                   NaN   \n",
              "\n",
              "      Riluzole_use_Delta   Age     Sex  Q1_Speech_min  Q1_Speech_max  \\\n",
              "121                  0.0  52.0  Female            4.0            4.0   \n",
              "1009                 0.0  51.0    Male            4.0            4.0   \n",
              "1036                 NaN  67.0  Female            3.0            3.0   \n",
              "\n",
              "      Q1_Speech_mean  ...  Standing_BP_Diastolic_last  \\\n",
              "121              4.0  ...                         NaN   \n",
              "1009             4.0  ...                         NaN   \n",
              "1036             3.0  ...                         NaN   \n",
              "\n",
              "      Standing_BP_Systolic_min  Standing_BP_Systolic_max  \\\n",
              "121                        NaN                       NaN   \n",
              "1009                       NaN                       NaN   \n",
              "1036                       NaN                       NaN   \n",
              "\n",
              "      Standing_BP_Systolic_mean  Standing_BP_Systolic_median  \\\n",
              "121                         NaN                          NaN   \n",
              "1009                        NaN                          NaN   \n",
              "1036                        NaN                          NaN   \n",
              "\n",
              "      Standing_BP_Systolic_q25  Standing_BP_Systolic_q75  \\\n",
              "121                        NaN                       NaN   \n",
              "1009                       NaN                       NaN   \n",
              "1036                       NaN                       NaN   \n",
              "\n",
              "      Standing_BP_Systolic_first  Standing_BP_Systolic_last  \\\n",
              "121                          NaN                        NaN   \n",
              "1009                         NaN                        NaN   \n",
              "1036                         NaN                        NaN   \n",
              "\n",
              "      ALSFRS_slope_3to12m  \n",
              "121             -1.058824  \n",
              "1009             0.000000  \n",
              "1036                  NaN  \n",
              "\n",
              "[3 rows x 518 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cc37b74f-a955-4940-892a-f6653c36cf0c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Site_of_Onset</th>\n",
              "      <th>Onset_Delta</th>\n",
              "      <th>Diagnosis_Delta</th>\n",
              "      <th>Subject_used_Riluzole</th>\n",
              "      <th>Riluzole_use_Delta</th>\n",
              "      <th>Age</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Q1_Speech_min</th>\n",
              "      <th>Q1_Speech_max</th>\n",
              "      <th>Q1_Speech_mean</th>\n",
              "      <th>...</th>\n",
              "      <th>Standing_BP_Diastolic_last</th>\n",
              "      <th>Standing_BP_Systolic_min</th>\n",
              "      <th>Standing_BP_Systolic_max</th>\n",
              "      <th>Standing_BP_Systolic_mean</th>\n",
              "      <th>Standing_BP_Systolic_median</th>\n",
              "      <th>Standing_BP_Systolic_q25</th>\n",
              "      <th>Standing_BP_Systolic_q75</th>\n",
              "      <th>Standing_BP_Systolic_first</th>\n",
              "      <th>Standing_BP_Systolic_last</th>\n",
              "      <th>ALSFRS_slope_3to12m</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>121</th>\n",
              "      <td>Onset: Limb</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Yes</td>\n",
              "      <td>0.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>Female</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-1.058824</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1009</th>\n",
              "      <td>Onset: Other</td>\n",
              "      <td>-324.0</td>\n",
              "      <td>-63.0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>0.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>Male</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1036</th>\n",
              "      <td>Onset: Bulbar</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>67.0</td>\n",
              "      <td>Female</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3 rows × 518 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cc37b74f-a955-4940-892a-f6653c36cf0c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-cc37b74f-a955-4940-892a-f6653c36cf0c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-cc37b74f-a955-4940-892a-f6653c36cf0c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-00565280-5e20-470a-b164-9ca178c1f063\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-00565280-5e20-470a-b164-9ca178c1f063')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-00565280-5e20-470a-b164-9ca178c1f063 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "features_df"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "features_df.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Un9iRPKUoDPz"
      },
      "source": [
        "# leakage free preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yp-LYf_pqT0H",
        "outputId": "b013d4cf-b80e-402e-f78f-bb0a367fc41d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Built target `y`.\n",
            "features_df: (2424, 517) | y: (2424,) | mean: -0.383 std: 0.522\n",
            "✓ Confirmed: Target column removed from features_df\n"
          ]
        }
      ],
      "source": [
        "# ==== BUILD y (3→12m ALSFRS slope per ~30d), aligned to features_df ====\n",
        "\n",
        "import numpy as np, pandas as pd\n",
        "\n",
        "# --- locate long ALSFRS table ---\n",
        "def _first_existing(names):\n",
        "    g = globals()\n",
        "    for n in names:\n",
        "        if n in g and isinstance(g[n], pd.DataFrame):\n",
        "            return g[n], n\n",
        "    return None, None\n",
        "\n",
        "als_long, _als_name = _first_existing([\n",
        "    \"alsfrs_long\", \"alsfrs_all\", \"alsfrs_full\", \"alsfrs\", \"als_long\", \"alsfrs_df\"\n",
        "])\n",
        "if als_long is None:\n",
        "    raise RuntimeError(\"Long ALSFRS DataFrame not found. Load it (e.g., alsfrs_long).\")\n",
        "\n",
        "# --- detect columns (subject, time, score) ---\n",
        "def _pick_col(df, cands):\n",
        "    for c in cands:\n",
        "        if c in df.columns: return c\n",
        "    lc = {c.lower(): c for c in df.columns}\n",
        "    for c in cands:\n",
        "        if c.lower() in lc: return lc[c.lower()]\n",
        "    return None\n",
        "\n",
        "SUBJ  = _pick_col(als_long, [\"subject_id\",\"Subject_ID\",\"RID\",\"patient_id\"])\n",
        "TIME  = _pick_col(als_long, [\"ALSFRS_Delta\",\"days\",\"Days\",\"days_since_first\",\"days_since_baseline\"])\n",
        "SCORE = _pick_col(als_long, [\"ALSFRS_Total_orig\",\"ALSFRS_Total\",\"ALSFRS\",\"ALSFRS_R\",\"ALSFRS_R_Total\"])\n",
        "if any(v is None for v in [SUBJ,TIME,SCORE]):\n",
        "    raise RuntimeError(f\"Could not auto-detect columns: SUBJ={SUBJ}, TIME={TIME}, SCORE={SCORE}\")\n",
        "\n",
        "# --- slope per subject using points in (90, 365] days; per-30-days units ---\n",
        "def _slope_per30d(g: pd.DataFrame, t_col: str, y_col: str) -> float | None:\n",
        "    g = g[[t_col, y_col]].dropna()\n",
        "    g = g[(g[t_col] > 90) & (g[t_col] <= 365)]\n",
        "    if len(g) < 2:\n",
        "        return None\n",
        "    t = g[t_col].to_numpy(dtype=float)\n",
        "    y = g[y_col].to_numpy(dtype=float)\n",
        "    a, b = np.polyfit(t, y, deg=1)   # points/day\n",
        "    return float(a * 30.0)           # ≈ per month\n",
        "\n",
        "slopes = (\n",
        "    als_long\n",
        "    .groupby(SUBJ, group_keys=False)\n",
        "    .apply(lambda df: _slope_per30d(df, TIME, SCORE))\n",
        "    .rename(\"slope_3to12m\")\n",
        ")\n",
        "\n",
        "# --- align to features_df index; drop subjects without slope ---\n",
        "if \"features_df\" not in globals():\n",
        "    raise RuntimeError(\"features_df not found. Build your subject-level feature table first.\")\n",
        "\n",
        "# FIXED: Remove target column from features_df if it exists\n",
        "if 'ALSFRS_slope_3to12m' in features_df.columns:\n",
        "    features_df = features_df.drop(columns=['ALSFRS_slope_3to12m'])\n",
        "\n",
        "y = slopes.reindex(features_df.index)\n",
        "mask = y.notna()\n",
        "features_df = features_df.loc[mask].copy()\n",
        "y = y.loc[mask].copy()\n",
        "\n",
        "print(\"Built target `y`.\")\n",
        "print(\"features_df:\", features_df.shape, \"| y:\", y.shape, \"| mean:\", round(y.mean(),3), \"std:\", round(y.std(),3))\n",
        "print(f\"✓ Confirmed: Target column removed from features_df\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ZA14tz0oKHu",
        "outputId": "f240c244-b0f1-4359-b542-9348959653fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Train/test split complete\n",
            "  X_train: (1939, 517), X_test: (485, 517)\n",
            "  y_train: (1939,), y_test: (485,)\n",
            "  ✓ No target leakage - verified!\n"
          ]
        }
      ],
      "source": [
        "# ==== CLEAN TRAIN/TEST SPLIT (no transforms; no leakage) ====\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd, numpy as np\n",
        "\n",
        "# FIXED: Ensure target is not in features\n",
        "if 'ALSFRS_slope_3to12m' in features_df.columns:\n",
        "    features_df = features_df.drop(columns=['ALSFRS_slope_3to12m'])\n",
        "\n",
        "assert all(features_df.index == y.index), \"Index mismatch between features and target!\"\n",
        "assert 'ALSFRS_slope_3to12m' not in features_df.columns, \"Target column still in features!\"\n",
        "\n",
        "def stratify_bins(y_series, n_bins=10):\n",
        "    q = pd.qcut(y_series, q=np.minimum(n_bins, max(2, y_series.nunique())), duplicates='drop')\n",
        "    return pd.factorize(q, sort=True)[0]\n",
        "\n",
        "bins = stratify_bins(y, n_bins=10)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    features_df, y, test_size=0.2, random_state=42, stratify=bins\n",
        ")\n",
        "X_train = X_train.copy(); X_test = X_test.copy()\n",
        "y_train = y_train.copy(); y_test = y_test.copy()\n",
        "\n",
        "print(\"✓ Train/test split complete\")\n",
        "print(f\"  X_train: {X_train.shape}, X_test: {X_test.shape}\")\n",
        "print(f\"  y_train: {y_train.shape}, y_test: {y_test.shape}\")\n",
        "print(f\"  ✓ No target leakage - verified!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "DQgkM5tGoRPg"
      },
      "outputs": [],
      "source": [
        "# ==== BULLETPROOF PREPROCESSOR (categorical-safe, no leakage) ====\n",
        "import re\n",
        "import numpy as np, pandas as pd\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.feature_selection import mutual_info_regression\n",
        "\n",
        "\n",
        "class Preprocessor:\n",
        "    def __init__(self, top_k=25, max_missing=0.5, use_pca=False, pca_components=12,\n",
        "                 max_cats_per_col=8, numeric_threshold=1.0, force_cat=None):\n",
        "        \"\"\"\n",
        "        numeric_threshold=1.0  -> only columns 100% numeric-convertible are treated as numeric.\n",
        "        force_cat: list[str] of columns to always treat as categorical (optional).\n",
        "        \"\"\"\n",
        "        self.top_k = top_k\n",
        "        self.max_missing = max_missing\n",
        "        self.use_pca = use_pca\n",
        "        self.pca_components = pca_components\n",
        "        self.max_cats_per_col = max_cats_per_col\n",
        "        self.numeric_threshold = numeric_threshold\n",
        "        self.force_cat = set(force_cat or [])\n",
        "\n",
        "        # learned\n",
        "        self.num_cols_, self.cat_cols_ = [], []\n",
        "        self.cat_maps_ = {}      # col -> kept categories\n",
        "        self.keep_cols_ = []\n",
        "        self.scaler_ = None\n",
        "        self.pca_ = None\n",
        "        self.num_medians_ = None\n",
        "\n",
        "    # ----- helpers -----\n",
        "    @staticmethod\n",
        "    def _has_letters(sample_values) -> bool:\n",
        "        # Detect alpha characters in sample of values (flags columns like \"Onset: Limb\")\n",
        "        for v in sample_values:\n",
        "            if pd.isna(v):\n",
        "                continue\n",
        "            s = str(v)\n",
        "            if re.search(r\"[A-Za-z]\", s):\n",
        "                return True\n",
        "        return False\n",
        "\n",
        "    def _split_num_cat(self, X: pd.DataFrame):\n",
        "        num_cols, cat_cols = [], []\n",
        "        for c in X.columns:\n",
        "            if c in self.force_cat:\n",
        "                cat_cols.append(c); continue\n",
        "            s = X[c]\n",
        "            # quick letter check on 100 non-null samples\n",
        "            nonnull = s.dropna()\n",
        "            sample = nonnull.sample(min(100, len(nonnull)), random_state=42) if len(nonnull) else nonnull\n",
        "            if self._has_letters(sample.values):\n",
        "                cat_cols.append(c); continue\n",
        "            # numeric convertibility\n",
        "            s_num = pd.to_numeric(s, errors=\"coerce\")\n",
        "            frac_numeric = s_num.notna().mean()\n",
        "            if frac_numeric >= self.numeric_threshold:\n",
        "                num_cols.append(c)\n",
        "            else:\n",
        "                cat_cols.append(c)\n",
        "        return num_cols, cat_cols\n",
        "\n",
        "    def _encode_cats_fit(self, X_cat: pd.DataFrame) -> pd.DataFrame:\n",
        "        oh = []\n",
        "        for c in X_cat.columns:\n",
        "            s = X_cat[c].astype(\"object\")\n",
        "            s = s.astype(str).where(~s.isna(), \"MISSING\")\n",
        "            vc = s.value_counts(dropna=False)\n",
        "            keep = vc.index.tolist()[: max(1, self.max_cats_per_col - 1)]\n",
        "            if \"MISSING\" in s.values and \"MISSING\" not in keep:\n",
        "                if len(keep) >= self.max_cats_per_col:\n",
        "                    keep = keep[:-1] + [\"MISSING\"]\n",
        "                else:\n",
        "                    keep = keep + [\"MISSING\"]\n",
        "            keep = list(dict.fromkeys(keep))\n",
        "            self.cat_maps_[c] = keep\n",
        "            for k in keep:\n",
        "                col = f\"{c}__{k}\"\n",
        "                oh.append(pd.Series((s == k).astype(np.float32), index=s.index, name=col))\n",
        "            # OTHER bucket\n",
        "            other = ~s.isin(keep)\n",
        "            oh.append(pd.Series(other.astype(np.float32), index=s.index, name=f\"{c}__OTHER\"))\n",
        "        return pd.concat(oh, axis=1) if len(oh) else pd.DataFrame(index=X_cat.index)\n",
        "\n",
        "    def _encode_cats_apply(self, X_cat: pd.DataFrame) -> pd.DataFrame:\n",
        "        oh = []\n",
        "        for c in self.cat_cols_:\n",
        "            s = X_cat[c] if c in X_cat.columns else pd.Series(index=X_cat.index, dtype=\"object\")\n",
        "            s = s.astype(str).where(~s.isna(), \"MISSING\")\n",
        "            keep = self.cat_maps_.get(c, [])\n",
        "            for k in keep:\n",
        "                col = f\"{c}__{k}\"\n",
        "                oh.append(pd.Series((s == k).astype(np.float32), index=s.index, name=col))\n",
        "            other = ~s.isin(keep)\n",
        "            oh.append(pd.Series(other.astype(np.float32), index=s.index, name=f\"{c}__OTHER\"))\n",
        "        return pd.concat(oh, axis=1) if len(oh) else pd.DataFrame(index=X_cat.index)\n",
        "\n",
        "    def _feature_scores(self, X: pd.DataFrame, y: pd.Series) -> pd.Series:\n",
        "        # Ensure y is pure numpy\n",
        "        y_np = np.array(y.values if hasattr(y, 'values') else y, dtype=np.float64)\n",
        "\n",
        "        # RF importance\n",
        "        rf = RandomForestRegressor(n_estimators=500, random_state=42, n_jobs=-1)\n",
        "        rf.fit(X.values, y_np)  # Use .values to ensure numpy array\n",
        "        s_rf = pd.Series(rf.feature_importances_, index=X.columns)\n",
        "\n",
        "        # Mutual information\n",
        "        mi = mutual_info_regression(X.values, y_np, random_state=42)\n",
        "        s_mi = pd.Series(mi, index=X.columns)\n",
        "\n",
        "        # |Pearson r|\n",
        "        def safe_corr(col):\n",
        "            v = col.values\n",
        "            if np.std(v) == 0: return 0.0\n",
        "            return float(abs(np.corrcoef(v, y_np)[0,1]))\n",
        "        s_pr = X.apply(safe_corr)\n",
        "\n",
        "        # Blend (normalized)\n",
        "        def nz_norm(s):\n",
        "            s = s.fillna(0.0); m = s.max()\n",
        "            return s / m if m > 0 else s\n",
        "        blended = 0.5*nz_norm(s_rf) + 0.3*nz_norm(s_mi) + 0.2*nz_norm(s_pr)\n",
        "        return blended.sort_values(ascending=False)\n",
        "\n",
        "    # ----- API -----\n",
        "    def fit(self, X_train: pd.DataFrame, y_train: pd.Series):\n",
        "        # split by robust content check (no strings into numeric)\n",
        "        self.num_cols_, self.cat_cols_ = self._split_num_cat(X_train)\n",
        "\n",
        "        # numeric missingness filter on TRAIN only\n",
        "        num_keep = []\n",
        "        if self.num_cols_:\n",
        "            coerced = X_train[self.num_cols_].apply(pd.to_numeric, errors=\"coerce\")\n",
        "            miss = coerced.isna().mean()\n",
        "            num_keep = miss[miss <= self.max_missing].index.tolist()\n",
        "\n",
        "        cat_keep = self.cat_cols_\n",
        "        X_tr = X_train[num_keep + cat_keep].copy()\n",
        "\n",
        "        # numeric block (hard coerce to float32) + train medians\n",
        "        if num_keep:\n",
        "            X_tr_num = X_tr[num_keep].apply(pd.to_numeric, errors=\"coerce\").astype(np.float32)\n",
        "            self.num_medians_ = X_tr_num.median()\n",
        "            X_tr_num = X_tr_num.fillna(self.num_medians_)\n",
        "        else:\n",
        "            X_tr_num = pd.DataFrame(index=X_tr.index, dtype=np.float32)\n",
        "            self.num_medians_ = pd.Series(dtype=np.float32)\n",
        "\n",
        "        # categorical block → one-hot (fit)\n",
        "        X_tr_cat = X_tr[cat_keep] if cat_keep else pd.DataFrame(index=X_tr.index)\n",
        "        X_tr_cat_oh = self._encode_cats_fit(X_tr_cat)\n",
        "\n",
        "        # combine\n",
        "        X_tr_full = pd.concat([X_tr_num, X_tr_cat_oh], axis=1)\n",
        "\n",
        "        # feature scoring/selection on TRAIN only\n",
        "        scores = self._feature_scores(X_tr_full, y_train)\n",
        "        self.keep_cols_ = scores.head(self.top_k).index.tolist()\n",
        "\n",
        "        # scale fit on TRAIN selected\n",
        "        self.scaler_ = RobustScaler()\n",
        "        X_sel = X_tr_full[self.keep_cols_].values  # Use .values for pure numpy\n",
        "        X_scl = self.scaler_.fit_transform(X_sel)\n",
        "\n",
        "        # optional PCA\n",
        "        if self.use_pca:\n",
        "            n_comp = min(self.pca_components, X_scl.shape[1])\n",
        "            self.pca_ = PCA(n_components=n_comp, random_state=42)\n",
        "            self.pca_.fit(X_scl)\n",
        "        else:\n",
        "            self.pca_ = None\n",
        "        return self\n",
        "\n",
        "    def transform(self, X: pd.DataFrame) -> np.ndarray:\n",
        "        # numeric (coerce to float32, fill with TRAIN medians)\n",
        "        if len(self.num_cols_):\n",
        "            cols_num = [c for c in self.num_cols_ if c in X.columns]\n",
        "            X_num = X[cols_num].apply(pd.to_numeric, errors=\"coerce\").astype(np.float32)\n",
        "            # make sure all expected numeric cols exist\n",
        "            for c in self.num_medians_.index:\n",
        "                if c not in X_num.columns:\n",
        "                    X_num[c] = np.nan\n",
        "            X_num = X_num[self.num_medians_.index]\n",
        "            X_num = X_num.fillna(self.num_medians_)\n",
        "        else:\n",
        "            X_num = pd.DataFrame(index=X.index, dtype=np.float32)\n",
        "\n",
        "        # categorical\n",
        "        cols_cat = [c for c in self.cat_cols_ if c in X.columns]\n",
        "        X_cat = X[cols_cat] if cols_cat else pd.DataFrame(index=X.index)\n",
        "        X_cat_oh = self._encode_cats_apply(X_cat)\n",
        "\n",
        "        # combine & align to kept features\n",
        "        X_full = pd.concat([X_num, X_cat_oh], axis=1)\n",
        "        for c in self.keep_cols_:\n",
        "            if c not in X_full.columns:\n",
        "                X_full[c] = 0.0\n",
        "        X_full = X_full[self.keep_cols_]\n",
        "\n",
        "        # CRITICAL: Convert to pure numpy BEFORE scaling\n",
        "        X_np = X_full.values.astype(np.float32)\n",
        "        X_scl = self.scaler_.transform(X_np)\n",
        "\n",
        "        if self.pca_ is not None:\n",
        "            X_scl = self.pca_.transform(X_scl)\n",
        "\n",
        "        # CRITICAL: Return pure numpy array with explicit copy\n",
        "        return np.array(X_scl, dtype=np.float32, copy=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F27DMcoStomL",
        "outputId": "08fcd0c1-42fa-451e-d4f6-b6335c7e05b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "⚛️  PURE QNN (Manual Batching)\n",
            "======================================================================\n",
            "\n",
            "📊 Data: train=1551, val=388, test=485\n",
            "\n",
            "🔧 Preprocessing (top_k=30)...\n",
            "✓ Features: 30\n",
            "✓ Device: cpu\n",
            "\n",
            "🚀 Training...\n",
            "\n",
            "Epoch   1/400 | Loss 0.6176 | Val RMSE 0.9439 | Val PCC -0.4514\n",
            "Epoch   2/400 | Loss 0.6158 | Val RMSE 0.9421 | Val PCC -0.4508\n",
            "Epoch   3/400 | Loss 0.6133 | Val RMSE 0.9395 | Val PCC -0.4500\n",
            "Epoch  10/400 | Loss 0.5761 | Val RMSE 0.8975 | Val PCC -0.4303\n",
            "Epoch  20/400 | Loss 0.4409 | Val RMSE 0.7494 | Val PCC -0.2746\n",
            "Epoch  30/400 | Loss 0.2836 | Val RMSE 0.5795 | Val PCC 0.1513\n",
            "Epoch  40/400 | Loss 0.2211 | Val RMSE 0.5036 | Val PCC 0.3704\n",
            "Epoch  50/400 | Loss 0.1950 | Val RMSE 0.4649 | Val PCC 0.4616\n",
            "Epoch  60/400 | Loss 0.1814 | Val RMSE 0.4424 | Val PCC 0.4975\n",
            "Epoch  70/400 | Loss 0.1733 | Val RMSE 0.4290 | Val PCC 0.5137\n",
            "Epoch  80/400 | Loss 0.1682 | Val RMSE 0.4219 | Val PCC 0.5232\n",
            "Epoch  90/400 | Loss 0.1644 | Val RMSE 0.4185 | Val PCC 0.5276\n",
            "Epoch 100/400 | Loss 0.1638 | Val RMSE 0.4172 | Val PCC 0.5291\n",
            "Epoch 110/400 | Loss 0.1624 | Val RMSE 0.4167 | Val PCC 0.5294\n",
            "Epoch 120/400 | Loss 0.1614 | Val RMSE 0.4163 | Val PCC 0.5297\n",
            "Epoch 130/400 | Loss 0.1613 | Val RMSE 0.4161 | Val PCC 0.5300\n"
          ]
        }
      ],
      "source": [
        "# ==== FINAL WORKING PURE QNN (Manual Batching) ====\n",
        "\n",
        "import math, numpy as np, pandas as pd\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pennylane as qml\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from scipy.stats import pearsonr\n",
        "\n",
        "# Metrics\n",
        "def compute_metrics(y_true, y_pred):\n",
        "    y_true = np.array(y_true, dtype=np.float64).reshape(-1)\n",
        "    y_pred = np.array(y_pred, dtype=np.float64).reshape(-1)\n",
        "    rmse = float(np.sqrt(mean_squared_error(y_true, y_pred)))\n",
        "    mae = float(mean_absolute_error(y_true, y_pred))\n",
        "    r2 = float(r2_score(y_true, y_pred))\n",
        "    pcc = float(pearsonr(y_true, y_pred)[0]) if (np.std(y_true)>0 and np.std(y_pred)>0) else 0.0\n",
        "    return rmse, mae, r2, pcc\n",
        "\n",
        "# Correlation loss\n",
        "def corr_loss(y, yhat, eps=1e-6):\n",
        "    y = y.view(-1) - y.view(-1).mean()\n",
        "    yhat = yhat.view(-1) - yhat.view(-1).mean()\n",
        "    den = (y.std(unbiased=False) * yhat.std(unbiased=False)).clamp_min(eps)\n",
        "    corr = (y * yhat).mean() / den\n",
        "    return 1.0 - torch.clamp(corr, -1.0 + 1e-6, 1.0 - 1e-6)\n",
        "\n",
        "# Dataset\n",
        "class TabularDS(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        if isinstance(X, pd.DataFrame): X = X.values\n",
        "        if isinstance(y, pd.Series): y = y.values\n",
        "        self.X = torch.from_numpy(np.array(X, dtype=np.float32, copy=True))\n",
        "        self.y = torch.from_numpy(np.array(y, dtype=np.float32, copy=True).reshape(-1, 1))\n",
        "    def __len__(self): return len(self.y)\n",
        "    def __getitem__(self, i): return self.X[i], self.y[i]\n",
        "\n",
        "# Pure QNN (Manual Batching)\n",
        "class PureQNN_Manual(nn.Module):\n",
        "    def __init__(self, input_dim, n_wires=10, n_layers=4):\n",
        "        super().__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.n_wires = n_wires\n",
        "        self.n_layers = n_layers\n",
        "\n",
        "        dev = qml.device(\"default.qubit\", wires=n_wires)\n",
        "\n",
        "        @qml.qnode(dev, interface=\"torch\")\n",
        "        def circuit(inputs, mix, ent, read_phi, read_psi):\n",
        "            F, W, L = inputs.shape[0], n_wires, n_layers\n",
        "            stride = W\n",
        "\n",
        "            for l in range(L):\n",
        "                start = (l * stride) % F\n",
        "                idx = [(start + k) % F for k in range(W)]\n",
        "                chunk = inputs[idx]\n",
        "\n",
        "                for i in range(W):\n",
        "                    base = chunk[i]\n",
        "                    global_mix = torch.sum(inputs * mix[l, i])\n",
        "                    theta = 0.5 * math.pi * torch.tanh(base + 0.05 * global_mix)\n",
        "                    qml.RY(theta, wires=i)\n",
        "\n",
        "                qml.StronglyEntanglingLayers(ent[l].unsqueeze(0), wires=range(W))\n",
        "\n",
        "            # Fan-in\n",
        "            for i in range(1, W):\n",
        "                qml.CNOT(wires=[i, 0])\n",
        "\n",
        "            qml.RY(read_phi, wires=0)\n",
        "            qml.RZ(read_psi, wires=0)\n",
        "\n",
        "            return qml.expval(qml.PauliZ(0))\n",
        "\n",
        "        # Manual parameters\n",
        "        self.mix = nn.Parameter(torch.randn(n_layers, n_wires, input_dim) * 0.01)\n",
        "        self.ent = nn.Parameter(torch.randn(n_layers, n_wires, 3) * 0.1)\n",
        "        self.read_phi = nn.Parameter(torch.randn(1) * 0.1)\n",
        "        self.read_psi = nn.Parameter(torch.randn(1) * 0.1)\n",
        "        self.circuit = circuit\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.shape[0]\n",
        "        outputs = []\n",
        "        for i in range(batch_size):\n",
        "            result = self.circuit(x[i], self.mix, self.ent, self.read_phi[0], self.read_psi[0])\n",
        "            outputs.append(result)\n",
        "        return torch.stack(outputs).unsqueeze(1)\n",
        "\n",
        "# Evaluation\n",
        "def evaluate(model, loader, device):\n",
        "    model.eval()\n",
        "    preds, trues = [], []\n",
        "    with torch.no_grad():\n",
        "        for xb, yb in loader:\n",
        "            xb = xb.to(device)\n",
        "            yp = model(xb).cpu().numpy().reshape(-1)\n",
        "            yt = yb.numpy().reshape(-1)\n",
        "            preds.extend(yp); trues.extend(yt)\n",
        "\n",
        "    preds = np.array(preds); trues = np.array(trues)\n",
        "    rmse, mae, r2, pcc = compute_metrics(trues, preds)\n",
        "    return rmse, mae, r2, pcc, preds, trues\n",
        "\n",
        "# LR schedule\n",
        "def get_lr(epoch, config):\n",
        "    if epoch < config['warmup_epochs']:\n",
        "        return config['lr_start'] + (config['lr_max'] - config['lr_start']) * (epoch / config['warmup_epochs'])\n",
        "    progress = (epoch - config['warmup_epochs']) / max(1, config['epochs'] - config['warmup_epochs'])\n",
        "    return config['lr_max'] * 0.5 * (1 + math.cos(math.pi * progress))\n",
        "\n",
        "# Training\n",
        "def train_pure_qnn(X_train_df, X_test_df, y_train_s, y_test_s, config=None):\n",
        "    config = config or {\n",
        "        'epochs': 400, 'patience': 50, 'batch_size': 16,\n",
        "        'lr_start': 1e-5, 'lr_max': 2e-4, 'warmup_epochs': 25,\n",
        "        'n_wires': 10, 'n_layers': 3, 'lambda_corr': 0.05,\n",
        "        'weight_decay': 5e-4, 'random_state': 42\n",
        "    }\n",
        "\n",
        "    print(\"=\"*70)\n",
        "    print(\"⚛️  PURE QNN (Manual Batching)\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # Split\n",
        "    tr_idx, val_idx = train_test_split(np.arange(len(X_train_df)), test_size=0.2, random_state=config['random_state'])\n",
        "    X_tr, X_val = X_train_df.iloc[tr_idx], X_train_df.iloc[val_idx]\n",
        "    y_tr, y_val = y_train_s.iloc[tr_idx], y_train_s.iloc[val_idx]\n",
        "\n",
        "    print(f\"\\n📊 Data: train={len(X_tr)}, val={len(X_val)}, test={len(X_test_df)}\")\n",
        "\n",
        "    # Preprocess (30 features)\n",
        "    print(\"\\n🔧 Preprocessing (top_k=30)...\")\n",
        "    prep = Preprocessor(top_k=30, max_missing=0.5, use_pca=False, numeric_threshold=1.0).fit(X_tr, y_tr)\n",
        "    X_tr_np, X_val_np, X_te_np = prep.transform(X_tr), prep.transform(X_val), prep.transform(X_test_df)\n",
        "\n",
        "    y_tr_vals = np.clip(y_tr.values, *np.percentile(y_tr.values, [1, 99]))\n",
        "    y_tr_np = y_tr_vals.astype(np.float32)\n",
        "    y_val_np, y_te_np = y_val.values.astype(np.float32), y_test_s.values.astype(np.float32)\n",
        "\n",
        "    print(f\"✓ Features: {X_tr_np.shape[1]}\")\n",
        "\n",
        "    # Loaders\n",
        "    train_loader = DataLoader(TabularDS(X_tr_np, y_tr_np), batch_size=config['batch_size'], shuffle=True)\n",
        "    val_loader = DataLoader(TabularDS(X_val_np, y_val_np), batch_size=config['batch_size'], shuffle=False)\n",
        "    test_loader = DataLoader(TabularDS(X_te_np, y_te_np), batch_size=config['batch_size'], shuffle=False)\n",
        "\n",
        "    # Model\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"✓ Device: {device}\\n\")\n",
        "    model = PureQNN_Manual(input_dim=X_tr_np.shape[1], n_wires=config['n_wires'], n_layers=config['n_layers']).to(device)\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=config['lr_start'], weight_decay=config['weight_decay'])\n",
        "    huber_loss = nn.SmoothL1Loss(beta=0.5)\n",
        "\n",
        "    best_val_rmse = float('inf')\n",
        "    best_state = None\n",
        "    patience_counter = 0\n",
        "    history = {'train_loss': [], 'val_rmse': [], 'val_pcc': []}\n",
        "\n",
        "    print(\"🚀 Training...\\n\")\n",
        "\n",
        "    for epoch in range(config['epochs']):\n",
        "        lr = get_lr(epoch, config)\n",
        "        for g in optimizer.param_groups: g['lr'] = lr\n",
        "\n",
        "        # Train\n",
        "        model.train()\n",
        "        epoch_loss = 0.0\n",
        "        for xb, yb in train_loader:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            pred = model(xb)\n",
        "            loss = huber_loss(pred, yb) + config['lambda_corr'] * corr_loss(yb, pred)\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "            epoch_loss += loss.detach().item()\n",
        "\n",
        "        history['train_loss'].append(epoch_loss / len(train_loader))\n",
        "\n",
        "        # Validate\n",
        "        val_rmse, val_mae, val_r2, val_pcc, _, _ = evaluate(model, val_loader, device)\n",
        "        history['val_rmse'].append(val_rmse)\n",
        "        history['val_pcc'].append(val_pcc)\n",
        "\n",
        "        if (epoch + 1) % 10 == 0 or epoch < 3:\n",
        "            print(f\"Epoch {epoch+1:3d}/{config['epochs']} | Loss {history['train_loss'][-1]:.4f} | \"\n",
        "                  f\"Val RMSE {val_rmse:.4f} | Val PCC {val_pcc:.4f}\")\n",
        "\n",
        "        if val_rmse < best_val_rmse - 1e-5:\n",
        "            best_val_rmse = val_rmse\n",
        "            best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            if patience_counter >= config['patience']:\n",
        "                print(f\"\\n⏹️  Early stop at epoch {epoch+1}\")\n",
        "                break\n",
        "\n",
        "    # Test\n",
        "    model.load_state_dict(best_state)\n",
        "    model.to(device).eval()\n",
        "    test_rmse, test_mae, test_r2, test_pcc, _, _ = evaluate(model, test_loader, device)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"🎯 RESULTS\")\n",
        "    print(\"=\"*70)\n",
        "    print(f\"  RMSE: {test_rmse:.4f}  {'✅' if test_rmse < 0.34 else '⚠️'}\")\n",
        "    print(f\"  PCC:  {test_pcc:.4f}  {'✅' if test_pcc > 0.70 else '⚠️'}\")\n",
        "    print(f\"  MAE:  {test_mae:.4f}\")\n",
        "    print(f\"  R²:   {test_r2:.4f}\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    return {'test_rmse': test_rmse, 'test_pcc': test_pcc, 'history': history}\n",
        "\n",
        "# RUN\n",
        "config = {\n",
        "    'epochs': 400, 'patience': 50, 'batch_size': 16,\n",
        "    'lr_start': 1e-5, 'lr_max': 2e-4, 'warmup_epochs': 25,\n",
        "    'n_wires': 10, 'n_layers': 3, 'lambda_corr': 0.05,\n",
        "    'weight_decay': 5e-4, 'random_state': 42\n",
        "}\n",
        "\n",
        "results = train_pure_qnn(X_train, X_test, y_train, y_test, config)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}