{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 408,
          "sourceType": "datasetVersion",
          "datasetId": 180
        }
      ],
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tousifo/ml_notebooks/blob/main/qml_analysis_breast_cancer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "uciml_breast_cancer_wisconsin_data_path = kagglehub.dataset_download('uciml/breast-cancer-wisconsin-data')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "e1Z24ABlQCWn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b031c54d-2f88-477c-c963-0a166f988787"
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data source import complete.\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing-Value Imputation, Scaling & Feature Selection\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "\n",
        "# 1. Load the data\n",
        "df = pd.read_csv('/kaggle/input/breast-cancer-wisconsin-data/data.csv')\n",
        "\n",
        "# 2. Drop unneeded columns\n",
        "df = df.drop(columns=['id', 'Unnamed: 32'], errors='ignore')\n",
        "\n",
        "# 3. Encode target\n",
        "df['diagnosis'] = df['diagnosis'].map({'B': 0, 'M': 1})\n",
        "\n",
        "# 4. Split into features & label\n",
        "X_raw = df.drop(columns='diagnosis')\n",
        "y = df['diagnosis']\n",
        "\n",
        "# 5. Impute missing values with the median\n",
        "imputer = SimpleImputer(strategy='median')\n",
        "X_imputed = imputer.fit_transform(X_raw)\n",
        "\n",
        "# 6. Standard-scale features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_imputed)\n",
        "\n",
        "# 7. Select top 15 features via ANOVA-F\n",
        "selector = SelectKBest(score_func=f_classif, k=15)\n",
        "X_selected = selector.fit_transform(X_scaled, y)\n",
        "\n",
        "# 8. (Optional) Get the names of the selected features\n",
        "selected_features = X_raw.columns[selector.get_support()]\n",
        "print(\"Selected top 15 features:\")\n",
        "for feat in selected_features:\n",
        "    print(\"-\", feat)\n",
        "\n",
        "# 9. (Optional) Create a DataFrame of the trimmed feature set\n",
        "X_selected_df = pd.DataFrame(X_selected, columns=selected_features)\n"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "Kkvv7diBQCWp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "280c1bbe-8b2d-43c4-d99d-df49e0d127d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected top 15 features:\n",
            "- radius_mean\n",
            "- perimeter_mean\n",
            "- area_mean\n",
            "- compactness_mean\n",
            "- concavity_mean\n",
            "- concave points_mean\n",
            "- radius_se\n",
            "- perimeter_se\n",
            "- area_se\n",
            "- radius_worst\n",
            "- perimeter_worst\n",
            "- area_worst\n",
            "- compactness_worst\n",
            "- concavity_worst\n",
            "- concave points_worst\n"
          ]
        }
      ],
      "execution_count": 2
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Enforcing the “Small-N” Regime\n",
        "\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "# 3.1 Parameters\n",
        "N_max = 500\n",
        "random_state = 42\n",
        "\n",
        "# 3.2 Stratified subsampling (on the SELECTED feature set)\n",
        "#    X_selected_df: DataFrame of shape (569, 15) from Step 2\n",
        "#    y          : Series of labels (0/1)\n",
        "\n",
        "if X_selected_df.shape[0] > N_max:\n",
        "    sss = StratifiedShuffleSplit(\n",
        "        n_splits=1,\n",
        "        train_size=N_max,\n",
        "        random_state=random_state\n",
        "    )\n",
        "    for train_idx, _ in sss.split(X_selected_df, y):\n",
        "        X_sub = X_selected_df.iloc[train_idx].reset_index(drop=True)\n",
        "        y_sub = y.iloc[train_idx].reset_index(drop=True)\n",
        "else:\n",
        "    # Dataset already ≤ N_max\n",
        "    X_sub = X_selected_df.copy().reset_index(drop=True)\n",
        "    y_sub = y.copy().reset_index(drop=True)\n",
        "\n",
        "# 3.3 Quick sanity check\n",
        "print(f\"Subsampled dataset size: {X_sub.shape[0]} samples (max allowed = {N_max})\")\n",
        "print(\"Class proportions (benign=0 / malignant=1):\")\n",
        "print(y_sub.value_counts(normalize=True))\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "tkklSAPCQCWq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "934c9fc9-a9a5-4312-abfc-d9c71a650e12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Subsampled dataset size: 500 samples (max allowed = 500)\n",
            "Class proportions (benign=0 / malignant=1):\n",
            "diagnosis\n",
            "0    0.628\n",
            "1    0.372\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ],
      "execution_count": 3
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Class Balancing & Stratified Splitting\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Assume X_sub (DataFrame) and y_sub (Series) are from Step 3\n",
        "\n",
        "# 4.3.1 First split off the test set (20% of N_max)\n",
        "X_temp, X_test, y_temp, y_test = train_test_split(\n",
        "    X_sub, y_sub,\n",
        "    test_size=0.20,\n",
        "    stratify=y_sub,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# 4.3.2 Split the remaining into train (60% total) and val (20% total):\n",
        "# Remaining is 80% of original, so val = 0.25 * 0.80 = 0.20 of original\n",
        "X_train_temp, X_val, y_train_temp, y_val = train_test_split(\n",
        "    X_temp, y_temp,\n",
        "    test_size=0.25,\n",
        "    stratify=y_temp,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(\"Before SMOTE:\")\n",
        "print(\"  Train size:\", X_train_temp.shape[0])\n",
        "print(\"  Class distribution:\\n\", y_train_temp.value_counts())\n",
        "\n",
        "# 4.1 Apply SMOTE to the training split only\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train, y_train = smote.fit_resample(X_train_temp, y_train_temp)\n",
        "\n",
        "print(\"\\nAfter SMOTE:\")\n",
        "print(\"  Train size:\", X_train.shape[0])\n",
        "print(\"  Class distribution:\\n\", y_train.value_counts())\n",
        "\n",
        "# 4.3.3 Check validation and test sizes & distributions\n",
        "print(\"\\nValidation size:\", X_val.shape[0], \"Class distribution:\\n\", y_val.value_counts())\n",
        "print(\"Test size:\",       X_test.shape[0], \"Class distribution:\\n\", y_test.value_counts())\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "7XA52yTwQCWr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f48aa92-1775-4af9-b1aa-c13bb1fe97db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before SMOTE:\n",
            "  Train size: 300\n",
            "  Class distribution:\n",
            " diagnosis\n",
            "0    188\n",
            "1    112\n",
            "Name: count, dtype: int64\n",
            "\n",
            "After SMOTE:\n",
            "  Train size: 376\n",
            "  Class distribution:\n",
            " diagnosis\n",
            "1    188\n",
            "0    188\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Validation size: 100 Class distribution:\n",
            " diagnosis\n",
            "0    63\n",
            "1    37\n",
            "Name: count, dtype: int64\n",
            "Test size: 100 Class distribution:\n",
            " diagnosis\n",
            "0    63\n",
            "1    37\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "execution_count": 4
    },
    {
      "cell_type": "code",
      "source": [
        "# ── MONKEY-PATCH ALL ESTIMATORS TO HAVE VALID __sklearn_tags__ ──\n",
        "from sklearn.base import BaseEstimator\n",
        "from types import SimpleNamespace\n",
        "\n",
        "def _sklearn_tags(self):\n",
        "    t = SimpleNamespace()\n",
        "    t.estimator_type  = \"classifier\"\n",
        "    t.classifier_tags = SimpleNamespace()\n",
        "    t.input_tags      = SimpleNamespace(pairwise=False, sparse=False)\n",
        "    t.target_tags     = SimpleNamespace(required=True)\n",
        "    t.requires_fit    = True\n",
        "    return t\n",
        "\n",
        "BaseEstimator.__sklearn_tags__ = _sklearn_tags"
      ],
      "metadata": {
        "trusted": true,
        "id": "ITOt02UZQCWr"
      },
      "outputs": [],
      "execution_count": 5
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove any existing Qiskit components\n",
        "!pip uninstall -y qiskit qiskit-aer qiskit-terra qiskit-ibmq-provider qiskit-machine-learning"
      ],
      "metadata": {
        "trusted": true,
        "id": "18CqgBQ8QCWs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21d7be99-ae80-4c25-e1e1-7d087188badc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping qiskit as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping qiskit-aer as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping qiskit-terra as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping qiskit-ibmq-provider as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping qiskit-machine-learning as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "execution_count": 6
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6d177633",
        "outputId": "696d49d2-de3f-4cdf-d8ce-cebdb06ffac8"
      },
      "source": [
        "# Step 1: Completely clean up existing installations\n",
        "!pip uninstall -y -q qiskit-terra qiskit-aer qiskit-ibmq-provider qiskit qiskit-machine-learning"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping qiskit-terra as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping qiskit-ibmq-provider as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29aa5fa6"
      },
      "source": [
        "# Step 2: Install specific compatible versions\n",
        "!pip install -q \"qiskit-terra==0.23.3\" \"qiskit-aer==0.11.2\" \"qiskit-machine-learning==0.6.0\""
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QE70kGiNUp3r",
        "outputId": "15787bdf-7ca6-4f49-f100-a11c55eb8f81"
      },
      "source": [
        "# After restart, run this cell:\n",
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.svm import SVC as SVC_SK\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# Reproducibility\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Qiskit imports\n",
        "from qiskit import Aer\n",
        "# Removed import of QuantumInstance from qiskit.utils\n",
        "from qiskit.primitives import Sampler, Estimator # Added imports for Sampler and Estimator\n",
        "from qiskit.circuit.library import ZZFeatureMap, RealAmplitudes\n",
        "from qiskit_machine_learning.kernels import QuantumKernel\n",
        "from qiskit_machine_learning.algorithms import VQC\n",
        "from qiskit_machine_learning.neural_networks import EstimatorQNN\n",
        "from qiskit_machine_learning.connectors import TorchConnector\n",
        "from qiskit.algorithms.optimizers import SPSA\n",
        "\n",
        "# Initialize backend - USING OLD-STYLE AER IMPORT\n",
        "# Removed initialization of QuantumInstance\n",
        "# Initialized Sampler and Estimator without backend argument based on error\n",
        "sampler = Sampler()\n",
        "estimator = Estimator()\n",
        "\n",
        "\n",
        "print(\"All imports successful! Sampler and Estimator initialized.\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All imports successful! Sampler and Estimator initialized.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pOMJ0DgQUv1Y",
        "outputId": "1b4d9bda-4a75-41e1-9a2c-53938fce508c"
      },
      "source": [
        "# Re-run data loading and preprocessing steps\n",
        "import pandas as pd\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# 1. Load the data\n",
        "df = pd.read_csv('/kaggle/input/breast-cancer-wisconsin-data/data.csv')\n",
        "\n",
        "# 2. Drop unneeded columns\n",
        "df = df.drop(columns=['id', 'Unnamed: 32'], errors='ignore')\n",
        "\n",
        "# 3. Encode target\n",
        "df['diagnosis'] = df['diagnosis'].map({'B': 0, 'M': 1})\n",
        "\n",
        "# 4. Split into features & label\n",
        "X_raw = df.drop(columns='diagnosis')\n",
        "y = df['diagnosis']\n",
        "\n",
        "# 5. Impute missing values with the median\n",
        "imputer = SimpleImputer(strategy='median')\n",
        "X_imputed = imputer.fit_transform(X_raw)\n",
        "\n",
        "# 6. Standard-scale features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_imputed)\n",
        "\n",
        "# 7. Select top 15 features via ANOVA-F\n",
        "selector = SelectKBest(score_func=f_classif, k=15)\n",
        "X_selected = selector.fit_transform(X_scaled, y)\n",
        "\n",
        "# 8. Create a DataFrame of the trimmed feature set\n",
        "selected_features = X_raw.columns[selector.get_support()]\n",
        "X_selected_df = pd.DataFrame(X_selected, columns=selected_features)\n",
        "\n",
        "# 9. Enforcing the “Small-N” Regime\n",
        "N_max = 500\n",
        "random_state = 42\n",
        "\n",
        "if X_selected_df.shape[0] > N_max:\n",
        "    sss = StratifiedShuffleSplit(\n",
        "        n_splits=1,\n",
        "        train_size=N_max,\n",
        "        random_state=random_state\n",
        "    )\n",
        "    for train_idx, _ in sss.split(X_selected_df, y):\n",
        "        X_sub = X_selected_df.iloc[train_idx].reset_index(drop=True)\n",
        "        y_sub = y.iloc[train_idx].reset_index(drop=True)\n",
        "else:\n",
        "    X_sub = X_selected_df.copy().reset_index(drop=True)\n",
        "    y_sub = y.copy().reset_index(drop=True)\n",
        "\n",
        "# 10. Class Balancing & Stratified Splitting\n",
        "# 10.1 First split off the test set (20% of N_max)\n",
        "X_temp, X_test, y_temp, y_test = train_test_split(\n",
        "    X_sub, y_sub,\n",
        "    test_size=0.20,\n",
        "    stratify=y_sub,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# 10.2 Split the remaining into train (60% total) and val (20% total):\n",
        "X_train_temp, X_val, y_train_temp, y_val = train_test_split(\n",
        "    X_temp, y_temp,\n",
        "    test_size=0.25,\n",
        "    stratify=y_temp,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# 10.3 Apply SMOTE to the training split only\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train, y_train = smote.fit_resample(X_train_temp, y_train_temp)\n",
        "\n",
        "print(\"Data loading and preprocessing complete. X_train, y_train, X_test, y_test, X_val, y_val are defined.\")\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data loading and preprocessing complete. X_train, y_train, X_test, y_test, X_val, y_val are defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OBZ3i0dcU3GL",
        "outputId": "4a939dea-95f3-4446-e238-b32cfed6f0b7"
      },
      "source": [
        "# After restart, run this cell:\n",
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.svm import SVC as SVC_SK\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# Reproducibility\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Qiskit imports\n",
        "from qiskit import Aer\n",
        "from qiskit.utils import QuantumInstance # Reverted to the import that defines QuantumInstance\n",
        "from qiskit.circuit.library import ZZFeatureMap, RealAmplitudes\n",
        "from qiskit_machine_learning.kernels import QuantumKernel\n",
        "from qiskit_machine_learning.algorithms import VQC\n",
        "from qiskit_machine_learning.neural_networks import EstimatorQNN\n",
        "from qiskit_machine_learning.connectors import TorchConnector\n",
        "from qiskit.algorithms.optimizers import SPSA\n",
        "\n",
        "# Initialize backend - USING OLD-STYLE AER IMPORT\n",
        "backend = Aer.get_backend('aer_simulator_density_matrix')\n",
        "qi = QuantumInstance(\n",
        "    backend=backend,\n",
        "    shots=1000,\n",
        "    seed_simulator=42,\n",
        "    seed_transpiler=42\n",
        ")\n",
        "\n",
        "print(\"All imports successful! Backend and QuantumInstance initialized.\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All imports successful! Backend and QuantumInstance initialized.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "49c4ba9a",
        "outputId": "9c19783a-1841-442a-d818-80b7993ce53d"
      },
      "source": [
        "# --- VQC ---\n",
        "vqc_fm  = ZZFeatureMap(feature_dimension=X_train.shape[1], reps=2, entanglement='circular')\n",
        "vqc_ans = RealAmplitudes(num_qubits=X_train.shape[1], reps=2, entanglement='circular')\n",
        "\n",
        "# Initialize VQC with QuantumInstance\n",
        "vqc     = VQC(\n",
        "    feature_map = vqc_fm,\n",
        "    ansatz      = vqc_ans,\n",
        "    optimizer   = SPSA(maxiter=100),\n",
        "    quantum_instance   = qi # Using the initialized QuantumInstance\n",
        ")\n",
        "\n",
        "# Train VQC\n",
        "print(\"Training VQC...\")\n",
        "vqc.fit(X_train, y_train)\n",
        "print(\"VQC training complete.\")\n",
        "\n",
        "# Evaluate VQC\n",
        "y_pred_proba_vqc = vqc.predict_proba(X_test)[:, 1]\n",
        "y_pred_vqc = (y_pred_proba_vqc > 0.5).astype(int) # Convert probabilities to class labels\n",
        "\n",
        "print(\"\\nVQC Evaluation on Test Set:\")\n",
        "print(\"ROC AUC Score:\", roc_auc_score(y_test, y_pred_proba_vqc))\n",
        "print(\"F1 Score:\", f1_score(y_test, y_pred_vqc))\n",
        "print(\"Accuracy Score:\", accuracy_score(y_test, y_pred_vqc))\n",
        "print(\"Precision Score:\", precision_score(y_test, y_pred_vqc))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "OneHotEncoder.__init__() got an unexpected keyword argument 'sparse'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-26-2959277187.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Initialize VQC with QuantumInstance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m vqc     = VQC(\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mfeature_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvqc_fm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mansatz\u001b[0m      \u001b[0;34m=\u001b[0m \u001b[0mvqc_ans\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/qiskit_machine_learning/algorithms/classifiers/vqc.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, num_qubits, feature_map, ansatz, loss, optimizer, warm_start, quantum_instance, initial_point, callback, sampler)\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0minput_gradients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0mpass_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpass_manager\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         )\n\u001b[0m\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         super().__init__(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/qiskit_machine_learning/algorithms/classifiers/neural_network_classifier.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, neural_network, loss, one_hot, optimizer, warm_start, initial_point, callback)\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneural_network\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarm_start\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_point\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_one_hot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mone_hot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0;31m# encodes the target data if categorical\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_target_encoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOneHotEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msparse_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mone_hot\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: OneHotEncoder.__init__() got an unexpected keyword argument 'sparse'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "id": "uJrBsasEQCWu",
        "outputId": "9c7b2199-5154-41b1-9e7b-38767a7513e1"
      },
      "source": [
        "# After restart, run this cell:\n",
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.svm import SVC as SVC_SK\n",
        "from sklearn.metrics import roc_auc_score, f1_score, accuracy_score, precision_score\n",
        "\n",
        "# Reproducibility\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Qiskit imports\n",
        "# Removed import of Aer and QuantumInstance\n",
        "from qiskit.primitives import Sampler, Estimator # Added imports for Sampler and Estimator\n",
        "from qiskit.circuit.library import ZZFeatureMap, RealAmplitudes\n",
        "from qiskit_machine_learning.kernels import QuantumKernel\n",
        "from qiskit_machine_learning.algorithms import VQC\n",
        "from qiskit_machine_learning.neural_networks import EstimatorQNN\n",
        "from qiskit_machine_learning.connectors import TorchConnector\n",
        "from qiskit.algorithms.optimizers import SPSA\n",
        "\n",
        "# Initialize primitives\n",
        "sampler = Sampler()\n",
        "estimator = Estimator()\n",
        "\n",
        "\n",
        "print(\"All imports successful! Sampler and Estimator initialized.\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name 'QuantumKernel' from 'qiskit_machine_learning.kernels' (/usr/local/lib/python3.11/dist-packages/qiskit_machine_learning/kernels/__init__.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3-500208068.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mqiskit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimitives\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSampler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEstimator\u001b[0m \u001b[0;31m# Added imports for Sampler and Estimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mqiskit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcircuit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlibrary\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mZZFeatureMap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRealAmplitudes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mqiskit_machine_learning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mQuantumKernel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mqiskit_machine_learning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malgorithms\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVQC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mqiskit_machine_learning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneural_networks\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEstimatorQNN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'QuantumKernel' from 'qiskit_machine_learning.kernels' (/usr/local/lib/python3.11/dist-packages/qiskit_machine_learning/kernels/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a39f4418"
      },
      "source": [
        "# Step 1: Uninstall current qiskit-machine-learning\n",
        "!pip uninstall -y -q qiskit-machine-learning"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5c8648f2"
      },
      "source": [
        "# Step 2: Install a recent compatible version of qiskit-machine-learning\n",
        "!pip install -q qiskit-machine-learning"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "649022e9"
      },
      "source": [
        "**IMPORTANT:** After the installations in the previous cell are complete, **please restart the runtime manually** (Runtime -> Restart runtime) before proceeding."
      ]
    }
  ]
}