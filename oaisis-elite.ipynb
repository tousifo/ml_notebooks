{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de1e8296",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-11-17T18:50:35.210820Z",
     "iopub.status.busy": "2025-11-17T18:50:35.210541Z",
     "iopub.status.idle": "2025-11-17T18:50:59.135739Z",
     "shell.execute_reply": "2025-11-17T18:50:59.134931Z"
    },
    "papermill": {
     "duration": 23.942841,
     "end_time": "2025-11-17T18:50:59.137126",
     "exception": false,
     "start_time": "2025-11-17T18:50:35.194285",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SNIPPET S1: RAW NIFTI INDEX BUILDER\n",
      "================================================================================\n",
      "\n",
      "Checking dataset root for OASIS2_P1:\n",
      "  Path: /kaggle/input/oaisis-dataset-3-p1/OAS2_RAW_PART1\n",
      "  [✓] Found OASIS2_P1\n",
      "\n",
      "Checking dataset root for OASIS2_P2:\n",
      "  Path: /kaggle/input/oaisis-3-p2/OAS2_RAW_PART2\n",
      "  [✓] Found OASIS2_P2\n",
      "\n",
      "Checking dataset root for OASIS3:\n",
      "  Path: /kaggle/input/oaisis-3/oaisis3\n",
      "  [✓] Found OASIS3\n",
      "\n",
      "================================================================================\n",
      "All dataset roots verified successfully!\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "BUILDING INDICES FOR ALL DATASETS\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Scanning OASIS2 (PART1)\n",
      "Root: /kaggle/input/oaisis-dataset-3-p1/OAS2_RAW_PART1\n",
      "================================================================================\n",
      "Searching for *.hdr files (Analyze format)...\n",
      "  Found 772 .hdr files\n",
      "\n",
      "Sample paths (first 3):\n",
      "  1. mpr-1.nifti.hdr\n",
      "     /kaggle/input/oaisis-dataset-3-p1/OAS2_RAW_PART1/OAS2_0001_MR1/RAW\n",
      "  2. mpr-2.nifti.hdr\n",
      "     /kaggle/input/oaisis-dataset-3-p1/OAS2_RAW_PART1/OAS2_0001_MR1/RAW\n",
      "  3. mpr-3.nifti.hdr\n",
      "     /kaggle/input/oaisis-dataset-3-p1/OAS2_RAW_PART1/OAS2_0001_MR1/RAW\n",
      "\n",
      "================================================================================\n",
      "Scanning OASIS2 (PART2)\n",
      "Root: /kaggle/input/oaisis-3-p2/OAS2_RAW_PART2\n",
      "================================================================================\n",
      "Searching for *.hdr files (Analyze format)...\n",
      "  Found 596 .hdr files\n",
      "\n",
      "Sample paths (first 3):\n",
      "  1. mpr-1.nifti.hdr\n",
      "     /kaggle/input/oaisis-3-p2/OAS2_RAW_PART2/OAS2_0100_MR1/RAW\n",
      "  2. mpr-2.nifti.hdr\n",
      "     /kaggle/input/oaisis-3-p2/OAS2_RAW_PART2/OAS2_0100_MR1/RAW\n",
      "  3. mpr-3.nifti.hdr\n",
      "     /kaggle/input/oaisis-3-p2/OAS2_RAW_PART2/OAS2_0100_MR1/RAW\n",
      "\n",
      "================================================================================\n",
      "Scanning OASIS3 (FULL)\n",
      "Root: /kaggle/input/oaisis-3/oaisis3\n",
      "================================================================================\n",
      "Searching for *.nii files (NIfTI format)...\n",
      "  Found 1258 .nii files\n",
      "\n",
      "Sample paths (first 3):\n",
      "  1. sub-OAS30001_ses-d0129_run-01_T1w.nii\n",
      "     /kaggle/input/oaisis-3/oaisis3/OAS30001_MR_d0129/anat2/NIFTI\n",
      "  2. sub-OAS30001_sess-d0129_run-01_T1w.nii\n",
      "     /kaggle/input/oaisis-3/oaisis3/OAS30001_MR_d0129/anat2/NIFTI/sub-OAS30001_ses-d0129_run-01_T1w.nii\n",
      "  3. sub-OAS30001_ses-d0129_run-02_T1w.nii\n",
      "     /kaggle/input/oaisis-3/oaisis3/OAS30001_MR_d0129/anat3/NIFTI\n",
      "\n",
      "================================================================================\n",
      "COMBINING INDICES\n",
      "================================================================================\n",
      "\n",
      "Total candidate MRI volumes: 2626\n",
      "\n",
      "Counts by dataset + source:\n",
      "dataset source  count\n",
      " OASIS2  PART1    772\n",
      " OASIS2  PART2    596\n",
      " OASIS3   FULL   1258\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "File Extension Distribution:\n",
      "--------------------------------------------------------------------------------\n",
      "  .hdr      :  1368 files\n",
      "  .nii      :  1258 files\n",
      "\n",
      "================================================================================\n",
      "✓ Saved index to: raw_nifti_index.csv\n",
      "  Total rows: 2626\n",
      "  File size: 539.24 KB\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "COMBINED INDEX PREVIEW (First 10 rows)\n",
      "================================================================================\n",
      "\n",
      "                                                                           nifti_path dataset source         filename                                                          parent_dir   ext\n",
      "0  /kaggle/input/oaisis-dataset-3-p1/OAS2_RAW_PART1/OAS2_0001_MR1/RAW/mpr-1.nifti.hdr  OASIS2  PART1  mpr-1.nifti.hdr  /kaggle/input/oaisis-dataset-3-p1/OAS2_RAW_PART1/OAS2_0001_MR1/RAW  .hdr\n",
      "1  /kaggle/input/oaisis-dataset-3-p1/OAS2_RAW_PART1/OAS2_0001_MR1/RAW/mpr-2.nifti.hdr  OASIS2  PART1  mpr-2.nifti.hdr  /kaggle/input/oaisis-dataset-3-p1/OAS2_RAW_PART1/OAS2_0001_MR1/RAW  .hdr\n",
      "2  /kaggle/input/oaisis-dataset-3-p1/OAS2_RAW_PART1/OAS2_0001_MR1/RAW/mpr-3.nifti.hdr  OASIS2  PART1  mpr-3.nifti.hdr  /kaggle/input/oaisis-dataset-3-p1/OAS2_RAW_PART1/OAS2_0001_MR1/RAW  .hdr\n",
      "3  /kaggle/input/oaisis-dataset-3-p1/OAS2_RAW_PART1/OAS2_0001_MR2/RAW/mpr-1.nifti.hdr  OASIS2  PART1  mpr-1.nifti.hdr  /kaggle/input/oaisis-dataset-3-p1/OAS2_RAW_PART1/OAS2_0001_MR2/RAW  .hdr\n",
      "4  /kaggle/input/oaisis-dataset-3-p1/OAS2_RAW_PART1/OAS2_0001_MR2/RAW/mpr-2.nifti.hdr  OASIS2  PART1  mpr-2.nifti.hdr  /kaggle/input/oaisis-dataset-3-p1/OAS2_RAW_PART1/OAS2_0001_MR2/RAW  .hdr\n",
      "5  /kaggle/input/oaisis-dataset-3-p1/OAS2_RAW_PART1/OAS2_0001_MR2/RAW/mpr-3.nifti.hdr  OASIS2  PART1  mpr-3.nifti.hdr  /kaggle/input/oaisis-dataset-3-p1/OAS2_RAW_PART1/OAS2_0001_MR2/RAW  .hdr\n",
      "6  /kaggle/input/oaisis-dataset-3-p1/OAS2_RAW_PART1/OAS2_0002_MR1/RAW/mpr-1.nifti.hdr  OASIS2  PART1  mpr-1.nifti.hdr  /kaggle/input/oaisis-dataset-3-p1/OAS2_RAW_PART1/OAS2_0002_MR1/RAW  .hdr\n",
      "7  /kaggle/input/oaisis-dataset-3-p1/OAS2_RAW_PART1/OAS2_0002_MR1/RAW/mpr-2.nifti.hdr  OASIS2  PART1  mpr-2.nifti.hdr  /kaggle/input/oaisis-dataset-3-p1/OAS2_RAW_PART1/OAS2_0002_MR1/RAW  .hdr\n",
      "8  /kaggle/input/oaisis-dataset-3-p1/OAS2_RAW_PART1/OAS2_0002_MR1/RAW/mpr-3.nifti.hdr  OASIS2  PART1  mpr-3.nifti.hdr  /kaggle/input/oaisis-dataset-3-p1/OAS2_RAW_PART1/OAS2_0002_MR1/RAW  .hdr\n",
      "9  /kaggle/input/oaisis-dataset-3-p1/OAS2_RAW_PART1/OAS2_0002_MR1/RAW/mpr-4.nifti.hdr  OASIS2  PART1  mpr-4.nifti.hdr  /kaggle/input/oaisis-dataset-3-p1/OAS2_RAW_PART1/OAS2_0002_MR1/RAW  .hdr\n",
      "\n",
      "================================================================================\n",
      "SANITY CHECKS\n",
      "================================================================================\n",
      "\n",
      "1. Duplicate paths: 0\n",
      "\n",
      "2. Missing values per column:\n",
      "   [✓] No missing values\n",
      "\n",
      "3. File existence check (sampling first 5 paths):\n",
      "   ✓ Path 1: mpr-1.nifti.hdr\n",
      "   ✓ Path 2: mpr-2.nifti.hdr\n",
      "   ✓ Path 3: mpr-3.nifti.hdr\n",
      "   ✓ Path 4: mpr-1.nifti.hdr\n",
      "   ✓ Path 5: mpr-2.nifti.hdr\n",
      "\n",
      "================================================================================\n",
      "SNIPPET S1 COMPLETE\n",
      "================================================================================\n",
      "\n",
      "Next Steps:\n",
      "  → S2: Parse subject_id, session_id from file paths\n",
      "  → S3: Load clinical data (CDR, MMSE scores)\n",
      "  → S4: Test loading sample volumes with nibabel\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List, Tuple\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"SNIPPET S1: RAW NIFTI INDEX BUILDER\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 1: Define and Check Dataset Roots\n",
    "# ============================================================================\n",
    "\n",
    "OASIS2_P1_ROOT = Path(\"/kaggle/input/oaisis-dataset-3-p1/OAS2_RAW_PART1\")\n",
    "OASIS2_P2_ROOT = Path(\"/kaggle/input/oaisis-3-p2/OAS2_RAW_PART2\")\n",
    "OASIS3_ROOT    = Path(\"/kaggle/input/oaisis-3/oaisis3\")\n",
    "\n",
    "def check_root(path: Path, name: str) -> None:\n",
    "    \"\"\"\n",
    "    Verify that a dataset root path exists.\n",
    "    Raise FileNotFoundError with helpful message if missing.\n",
    "    \"\"\"\n",
    "    print(f\"\\nChecking dataset root for {name}:\")\n",
    "    print(f\"  Path: {path}\")\n",
    "    \n",
    "    if not path.exists():\n",
    "        error_msg = (\n",
    "            f\"\\n{'='*80}\\n\"\n",
    "            f\"ERROR: Dataset root not found for {name}\\n\"\n",
    "            f\"Path: {path}\\n\"\n",
    "            f\"{'='*80}\\n\"\n",
    "            f\"FIX: In Kaggle notebook, click 'Add Data' → Search for:\\n\"\n",
    "            f\"  - 'oaisis-dataset-3-p1' (for OASIS2 Part 1)\\n\"\n",
    "            f\"  - 'oaisis-3-p2' (for OASIS2 Part 2)\\n\"\n",
    "            f\"  - 'oaisis-3' (for OASIS3)\\n\"\n",
    "            f\"Then re-run this cell.\\n\"\n",
    "            f\"{'='*80}\\n\"\n",
    "        )\n",
    "        raise FileNotFoundError(error_msg)\n",
    "    else:\n",
    "        print(f\"  [✓] Found {name}\")\n",
    "\n",
    "# Check all roots\n",
    "check_root(OASIS2_P1_ROOT, \"OASIS2_P1\")\n",
    "check_root(OASIS2_P2_ROOT, \"OASIS2_P2\")\n",
    "check_root(OASIS3_ROOT,    \"OASIS3\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"All dataset roots verified successfully!\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 2: Build NIfTI Index Function\n",
    "# ============================================================================\n",
    "\n",
    "def build_nifti_index(root: Path, dataset_name: str, source_tag: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Recursively scan a root directory for NIfTI/Analyze files.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    root : Path\n",
    "        Root directory to scan\n",
    "    dataset_name : str\n",
    "        \"OASIS2\" or \"OASIS3\"\n",
    "    source_tag : str\n",
    "        \"PART1\", \"PART2\", or \"FULL\"\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame with columns:\n",
    "        - nifti_path: full path as string\n",
    "        - dataset: dataset name\n",
    "        - source: source tag\n",
    "        - filename: file name only\n",
    "        - parent_dir: parent directory path\n",
    "        - ext: file extension\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Scanning {dataset_name} ({source_tag})\")\n",
    "    print(f\"Root: {root}\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    all_paths = []\n",
    "    \n",
    "    if dataset_name == \"OASIS3\":\n",
    "        # OASIS3 uses NIfTI format (.nii)\n",
    "        print(\"Searching for *.nii files (NIfTI format)...\")\n",
    "        nii_files = list(root.rglob(\"*.nii\"))\n",
    "        all_paths = nii_files\n",
    "        print(f\"  Found {len(nii_files)} .nii files\")\n",
    "        \n",
    "    else:  # OASIS2\n",
    "        # OASIS2 uses Analyze format (.hdr + .img pairs)\n",
    "        print(\"Searching for *.hdr files (Analyze format)...\")\n",
    "        hdr_files = list(root.rglob(\"*.hdr\"))\n",
    "        all_paths = hdr_files\n",
    "        print(f\"  Found {len(hdr_files)} .hdr files\")\n",
    "    \n",
    "    # Sort paths for reproducibility\n",
    "    all_paths = sorted(all_paths)\n",
    "    \n",
    "    if len(all_paths) == 0:\n",
    "        print(f\"\\n  WARNING: No files found in {root}\")\n",
    "        print(f\"  Check if dataset structure matches expected patterns:\")\n",
    "        print(f\"    - OASIS2: OAS2_XXXX_MRY/RAW/mpr-1.nifti.hdr\")\n",
    "        print(f\"    - OASIS3: OASXXXXX_MR_dXXXX/anat*/NIFTI/*/sub-*_T1w.nii\")\n",
    "    \n",
    "    # Build DataFrame\n",
    "    records = []\n",
    "    for path in all_paths:\n",
    "        records.append({\n",
    "            'nifti_path': str(path),\n",
    "            'dataset': dataset_name,\n",
    "            'source': source_tag,\n",
    "            'filename': path.name,\n",
    "            'parent_dir': str(path.parent),\n",
    "            'ext': path.suffix\n",
    "        })\n",
    "    \n",
    "    df = pd.DataFrame(records)\n",
    "    \n",
    "    # Show sample\n",
    "    if len(df) > 0:\n",
    "        print(f\"\\nSample paths (first 3):\")\n",
    "        for idx, row in df.head(3).iterrows():\n",
    "            print(f\"  {idx+1}. {row['filename']}\")\n",
    "            print(f\"     {row['parent_dir']}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 3: Build Index for Each Dataset\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"BUILDING INDICES FOR ALL DATASETS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# OASIS2 Part 1\n",
    "df_o2_p1 = build_nifti_index(OASIS2_P1_ROOT, \"OASIS2\", \"PART1\")\n",
    "\n",
    "# OASIS2 Part 2\n",
    "df_o2_p2 = build_nifti_index(OASIS2_P2_ROOT, \"OASIS2\", \"PART2\")\n",
    "\n",
    "# OASIS3\n",
    "df_o3 = build_nifti_index(OASIS3_ROOT, \"OASIS3\", \"FULL\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 4: Combine and Save\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"COMBINING INDICES\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Concatenate all DataFrames\n",
    "combined_index = pd.concat([df_o2_p1, df_o2_p2, df_o3], ignore_index=True)\n",
    "\n",
    "print(f\"\\nTotal candidate MRI volumes: {len(combined_index)}\")\n",
    "\n",
    "# Group by dataset and source\n",
    "print(\"\\nCounts by dataset + source:\")\n",
    "counts = combined_index.groupby(['dataset', 'source']).size().reset_index(name='count')\n",
    "print(counts.to_string(index=False))\n",
    "\n",
    "# Additional statistics\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"File Extension Distribution:\")\n",
    "print(\"-\" * 80)\n",
    "ext_counts = combined_index['ext'].value_counts()\n",
    "for ext, count in ext_counts.items():\n",
    "    print(f\"  {ext:10s}: {count:5d} files\")\n",
    "\n",
    "# Save to CSV\n",
    "output_file = \"raw_nifti_index.csv\"\n",
    "combined_index.to_csv(output_file, index=False)\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"✓ Saved index to: {output_file}\")\n",
    "print(f\"  Total rows: {len(combined_index)}\")\n",
    "print(f\"  File size: {os.path.getsize(output_file) / 1024:.2f} KB\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 5: Preview Combined Index\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"COMBINED INDEX PREVIEW (First 10 rows)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Display with better formatting\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', 80)\n",
    "\n",
    "print(\"\\n\" + combined_index.head(10).to_string())\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 6: Sanity Checks\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SANITY CHECKS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Check for duplicate paths\n",
    "duplicates = combined_index['nifti_path'].duplicated().sum()\n",
    "print(f\"\\n1. Duplicate paths: {duplicates}\")\n",
    "if duplicates > 0:\n",
    "    print(\"   WARNING: Found duplicate paths (should be zero)\")\n",
    "    print(combined_index[combined_index['nifti_path'].duplicated(keep=False)]['nifti_path'].head(5))\n",
    "\n",
    "# Check for missing values\n",
    "missing = combined_index.isnull().sum()\n",
    "print(f\"\\n2. Missing values per column:\")\n",
    "for col, count in missing.items():\n",
    "    if count > 0:\n",
    "        print(f\"   {col}: {count} missing\")\n",
    "if missing.sum() == 0:\n",
    "    print(\"   [✓] No missing values\")\n",
    "\n",
    "# Verify all paths exist (sample check - first 5)\n",
    "print(f\"\\n3. File existence check (sampling first 5 paths):\")\n",
    "for idx, path_str in enumerate(combined_index['nifti_path'].head(5), 1):\n",
    "    path = Path(path_str)\n",
    "    status = \"✓\" if path.exists() else \"✗\"\n",
    "    print(f\"   {status} Path {idx}: {path.name}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SNIPPET S1 COMPLETE\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nNext Steps:\")\n",
    "print(\"  → S2: Parse subject_id, session_id from file paths\")\n",
    "print(\"  → S3: Load clinical data (CDR, MMSE scores)\")\n",
    "print(\"  → S4: Test loading sample volumes with nibabel\")\n",
    "print(\"\\n\" + \"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88a430e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T18:50:59.162506Z",
     "iopub.status.busy": "2025-11-17T18:50:59.162274Z",
     "iopub.status.idle": "2025-11-17T18:51:00.749643Z",
     "shell.execute_reply": "2025-11-17T18:51:00.748828Z"
    },
    "papermill": {
     "duration": 1.601635,
     "end_time": "2025-11-17T18:51:00.751224",
     "exception": false,
     "start_time": "2025-11-17T18:50:59.149589",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SNIPPET S2: PARSE SUBJECT/VISIT/RUN IDs FROM PATHS\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "LOADING RAW NIFTI INDEX\n",
      "================================================================================\n",
      "\n",
      "Loaded: raw_nifti_index.csv\n",
      "  Rows: 2626\n",
      "  Columns: ['nifti_path', 'dataset', 'source', 'filename', 'parent_dir', 'ext']\n",
      "\n",
      "Dataset distribution:\n",
      "dataset  source\n",
      "OASIS2   PART1      772\n",
      "         PART2      596\n",
      "OASIS3   FULL      1258\n",
      "dtype: int64\n",
      "\n",
      "================================================================================\n",
      "INITIALIZING NEW METADATA COLUMNS\n",
      "================================================================================\n",
      "\n",
      "New columns added:\n",
      "  - subject_id (str)\n",
      "  - visit_code (str)\n",
      "  - run_id (str)\n",
      "  - modality (str)\n",
      "  - is_t1w (bool)\n",
      "\n",
      "================================================================================\n",
      "PARSING OASIS2 METADATA\n",
      "================================================================================\n",
      "\n",
      "Processing 1368 OASIS2 rows...\n",
      "\n",
      "✓ Successfully parsed: 1368/1368 rows\n",
      "\n",
      "Sample OASIS2 parsed data (first 3 rows):\n",
      "       filename subject_id visit_code run_id modality  is_t1w\n",
      "mpr-1.nifti.hdr  OAS2_0001        MR1      1      T1w    True\n",
      "mpr-2.nifti.hdr  OAS2_0001        MR1      2      T1w    True\n",
      "mpr-3.nifti.hdr  OAS2_0001        MR1      3      T1w    True\n",
      "\n",
      "================================================================================\n",
      "PARSING OASIS3 METADATA\n",
      "================================================================================\n",
      "\n",
      "Processing 1258 OASIS3 rows...\n",
      "\n",
      "✓ Successfully parsed: 1258/1258 rows\n",
      "\n",
      "Sample OASIS3 parsed data (first 3 rows):\n",
      "                              filename subject_id visit_code run_id modality  is_t1w\n",
      " sub-OAS30001_ses-d0129_run-01_T1w.nii   OAS30001      d0129     01      T1w    True\n",
      "sub-OAS30001_sess-d0129_run-01_T1w.nii   OAS30001      d0129     01      T1w    True\n",
      " sub-OAS30001_ses-d0129_run-02_T1w.nii   OAS30001      d0129     02      T1w    True\n",
      "\n",
      "================================================================================\n",
      "CREATING UNIQUE SCAN_UIDs\n",
      "================================================================================\n",
      "\n",
      "✓ Generated 2626 scan_uid values\n",
      "\n",
      "Duplicate scan_uid count: 625\n",
      "\n",
      "⚠ WARNING: Found duplicate scan_uid values!\n",
      "This indicates multiple files for the same (subject, visit, run) combination.\n",
      "\n",
      "Sample duplicates:\n",
      "                      scan_uid                                filename                                                                                                                                 nifti_path\n",
      "73      OASIS2|OAS2_0012|MR2|3                        3906-3.nifti.hdr                                                        /kaggle/input/oaisis-dataset-3-p1/OAS2_RAW_PART1/OAS2_0012_MR2/RAW/3906-3.nifti.hdr\n",
      "76      OASIS2|OAS2_0012|MR2|3                         mpr-3.nifti.hdr                                                         /kaggle/input/oaisis-dataset-3-p1/OAS2_RAW_PART1/OAS2_0012_MR2/RAW/mpr-3.nifti.hdr\n",
      "1368  OASIS3|OAS30001|d0129|01   sub-OAS30001_ses-d0129_run-01_T1w.nii                                         /kaggle/input/oaisis-3/oaisis3/OAS30001_MR_d0129/anat2/NIFTI/sub-OAS30001_ses-d0129_run-01_T1w.nii\n",
      "1369  OASIS3|OAS30001|d0129|01  sub-OAS30001_sess-d0129_run-01_T1w.nii  /kaggle/input/oaisis-3/oaisis3/OAS30001_MR_d0129/anat2/NIFTI/sub-OAS30001_ses-d0129_run-01_T1w.nii/sub-OAS30001_sess-d0129_run-01_T1w.nii\n",
      "1370  OASIS3|OAS30001|d0129|02   sub-OAS30001_ses-d0129_run-02_T1w.nii                                         /kaggle/input/oaisis-3/oaisis3/OAS30001_MR_d0129/anat3/NIFTI/sub-OAS30001_ses-d0129_run-02_T1w.nii\n",
      "1371  OASIS3|OAS30001|d0129|02  sub-OAS30001_sess-d0129_run-02_T1w.nii  /kaggle/input/oaisis-3/oaisis3/OAS30001_MR_d0129/anat3/NIFTI/sub-OAS30001_ses-d0129_run-02_T1w.nii/sub-OAS30001_sess-d0129_run-02_T1w.nii\n",
      "1372  OASIS3|OAS30001|d0757|01   sub-OAS30001_ses-d0757_run-01_T1w.nii                                         /kaggle/input/oaisis-3/oaisis3/OAS30001_MR_d0757/anat2/NIFTI/sub-OAS30001_ses-d0757_run-01_T1w.nii\n",
      "1373  OASIS3|OAS30001|d0757|01  sub-OAS30001_sess-d0757_run-01_T1w.nii  /kaggle/input/oaisis-3/oaisis3/OAS30001_MR_d0757/anat2/NIFTI/sub-OAS30001_ses-d0757_run-01_T1w.nii/sub-OAS30001_sess-d0757_run-01_T1w.nii\n",
      "1375  OASIS3|OAS30001|d0757|02  sub-OAS30001_sess-d0757_run-02_T1w.nii  /kaggle/input/oaisis-3/oaisis3/OAS30001_MR_d0757/anat3/NIFTI/sub-OAS30001_ses-d0757_run-02_T1w.nii/sub-OAS30001_sess-d0757_run-02_T1w.nii\n",
      "1374  OASIS3|OAS30001|d0757|02   sub-OAS30001_ses-d0757_run-02_T1w.nii                                         /kaggle/input/oaisis-3/oaisis3/OAS30001_MR_d0757/anat3/NIFTI/sub-OAS30001_ses-d0757_run-02_T1w.nii\n",
      "\n",
      "Sample scan_uid values:\n",
      "['OASIS2|OAS2_0001|MR1|1', 'OASIS2|OAS2_0001|MR1|2', 'OASIS2|OAS2_0001|MR1|3', 'OASIS2|OAS2_0001|MR2|1', 'OASIS2|OAS2_0001|MR2|2']\n",
      "\n",
      "================================================================================\n",
      "SANITY CHECKS & STATISTICS\n",
      "================================================================================\n",
      "\n",
      "1. Missing values in parsed columns:\n",
      "   subject_id     :    0 missing ( 0.00%)\n",
      "   visit_code     :    0 missing ( 0.00%)\n",
      "   run_id         :    0 missing ( 0.00%)\n",
      "   modality       :    0 missing ( 0.00%)\n",
      "   scan_uid       :    0 missing ( 0.00%)\n",
      "\n",
      "2. Unique subjects per dataset:\n",
      "   OASIS2    :  150 subjects\n",
      "   OASIS3    :  300 subjects\n",
      "\n",
      "3. Visits per subject distribution:\n",
      "\n",
      "   OASIS2:\n",
      "     Mean visits/subject: 2.49\n",
      "     Median visits/subject: 2.0\n",
      "     Max visits/subject: 5\n",
      "        94 subjects with 2 visit(s)\n",
      "        43 subjects with 3 visit(s)\n",
      "         9 subjects with 4 visit(s)\n",
      "         4 subjects with 5 visit(s)\n",
      "\n",
      "   OASIS3:\n",
      "     Mean visits/subject: 1.41\n",
      "     Median visits/subject: 1.0\n",
      "     Max visits/subject: 2\n",
      "       177 subjects with 1 visit(s)\n",
      "       123 subjects with 2 visit(s)\n",
      "\n",
      "4. Modality distribution (OASIS3):\n",
      "   T1w       : 1258 scans\n",
      "\n",
      "   T1w scans (is_t1w=True): 1258/1258 (100.0%)\n",
      "\n",
      "5. Run distribution:\n",
      "\n",
      "   OASIS2:\n",
      "     run-1:  373 scans\n",
      "     run-2:  373 scans\n",
      "     run-3:  373 scans\n",
      "     run-4:  249 scans\n",
      "\n",
      "   OASIS3:\n",
      "     run-01:  841 scans\n",
      "     run-02:  403 scans\n",
      "     run-03:   11 scans\n",
      "     run-04:    3 scans\n",
      "\n",
      "================================================================================\n",
      "SAVING PARSED INDEX\n",
      "================================================================================\n",
      "\n",
      "✓ Saved parsed index to: nifti_index_parsed.csv\n",
      "  Total rows: 2626\n",
      "  Total columns: 12\n",
      "  File size: 667.30 KB\n",
      "\n",
      "Final columns:\n",
      "   1. nifti_path\n",
      "   2. dataset\n",
      "   3. source\n",
      "   4. filename\n",
      "   5. parent_dir\n",
      "   6. ext\n",
      "   7. subject_id\n",
      "   8. visit_code\n",
      "   9. run_id\n",
      "  10. modality\n",
      "  11. is_t1w\n",
      "  12. scan_uid\n",
      "\n",
      "================================================================================\n",
      "PARSED INDEX PREVIEW\n",
      "================================================================================\n",
      "\n",
      "OASIS2 samples (first 3):\n",
      "dataset subject_id visit_code run_id modality  is_t1w               scan_uid        filename\n",
      " OASIS2  OAS2_0001        MR1      1      T1w    True OASIS2|OAS2_0001|MR1|1 mpr-1.nifti.hdr\n",
      " OASIS2  OAS2_0001        MR1      2      T1w    True OASIS2|OAS2_0001|MR1|2 mpr-2.nifti.hdr\n",
      " OASIS2  OAS2_0001        MR1      3      T1w    True OASIS2|OAS2_0001|MR1|3 mpr-3.nifti.hdr\n",
      "\n",
      "OASIS3 samples (first 3):\n",
      "dataset subject_id visit_code run_id modality  is_t1w                 scan_uid                               filename\n",
      " OASIS3   OAS30001      d0129     01      T1w    True OASIS3|OAS30001|d0129|01  sub-OAS30001_ses-d0129_run-01_T1w.nii\n",
      " OASIS3   OAS30001      d0129     01      T1w    True OASIS3|OAS30001|d0129|01 sub-OAS30001_sess-d0129_run-01_T1w.nii\n",
      " OASIS3   OAS30001      d0129     02      T1w    True OASIS3|OAS30001|d0129|02  sub-OAS30001_ses-d0129_run-02_T1w.nii\n",
      "\n",
      "================================================================================\n",
      "SNIPPET S2 COMPLETE\n",
      "================================================================================\n",
      "\n",
      "Next Steps:\n",
      "  → S3: Load/generate clinical data (CDR, MMSE scores)\n",
      "  → S4: Select one representative scan per (subject, visit)\n",
      "  → S5: Test loading sample volumes with nibabel\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "SNIPPET S2: Parse Subject, Visit, Run IDs from Paths\n",
    "Goal to Extract structured metadata (subject_id, visit_code, run_id, modality)\n",
    "      from raw file paths and create unique scan_uid for each volume.\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"SNIPPET S2: PARSE SUBJECT/VISIT/RUN IDs FROM PATHS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 1: Load Raw Index\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"LOADING RAW NIFTI INDEX\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "input_file = \"raw_nifti_index.csv\"\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "print(f\"\\nLoaded: {input_file}\")\n",
    "print(f\"  Rows: {len(df)}\")\n",
    "print(f\"  Columns: {df.columns.tolist()}\")\n",
    "\n",
    "# Verify expected columns exist\n",
    "expected_cols = ['nifti_path', 'dataset', 'source', 'filename', 'parent_dir', 'ext']\n",
    "missing_cols = [col for col in expected_cols if col not in df.columns]\n",
    "if missing_cols:\n",
    "    raise ValueError(f\"Missing expected columns: {missing_cols}\")\n",
    "\n",
    "print(\"\\nDataset distribution:\")\n",
    "print(df.groupby(['dataset', 'source']).size())\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 2: Initialize New Columns\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"INITIALIZING NEW METADATA COLUMNS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Create new columns with default values\n",
    "df['subject_id'] = None\n",
    "df['visit_code'] = None\n",
    "df['run_id'] = None\n",
    "df['modality'] = None\n",
    "df['is_t1w'] = False\n",
    "\n",
    "print(\"\\nNew columns added:\")\n",
    "print(\"  - subject_id (str)\")\n",
    "print(\"  - visit_code (str)\")\n",
    "print(\"  - run_id (str)\")\n",
    "print(\"  - modality (str)\")\n",
    "print(\"  - is_t1w (bool)\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 3: Parse OASIS2 Rows\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"PARSING OASIS2 METADATA\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "mask_o2 = df['dataset'] == 'OASIS2'\n",
    "n_o2 = mask_o2.sum()\n",
    "print(f\"\\nProcessing {n_o2} OASIS2 rows...\")\n",
    "\n",
    "parse_errors_o2 = []\n",
    "\n",
    "for idx in df[mask_o2].index:\n",
    "    try:\n",
    "        parent_dir = df.loc[idx, 'parent_dir']\n",
    "        filename = df.loc[idx, 'filename']\n",
    "        \n",
    "        # Parse session directory\n",
    "        # Example: /path/to/OAS2_0001_MR1/RAW/mpr-1.nifti.hdr\n",
    "        # parent_dir ends with \"RAW\", parent of that is session dir\n",
    "        raw_dir = Path(parent_dir)\n",
    "        session_dir = raw_dir.parent.name  # \"OAS2_0001_MR1\"\n",
    "        \n",
    "        # Split session directory name\n",
    "        tokens = session_dir.split('_')\n",
    "        \n",
    "        if len(tokens) < 3:\n",
    "            raise ValueError(f\"Unexpected session_dir format: {session_dir}\")\n",
    "        \n",
    "        # Extract subject_id and visit_code\n",
    "        subject_id = f\"{tokens[0]}_{tokens[1]}\"  # \"OAS2_0001\"\n",
    "        visit_code = tokens[2]                    # \"MR1\"\n",
    "        \n",
    "        # Parse run_id from filename\n",
    "        # Example: \"mpr-1.nifti.hdr\" → run_id = \"1\"\n",
    "        base_no_ext = filename.split('.')[0]  # \"mpr-1\"\n",
    "        base_tokens = base_no_ext.split('-')\n",
    "        \n",
    "        if len(base_tokens) < 2:\n",
    "            # Handle cases like \"mpr.nifti.hdr\" (no run number)\n",
    "            run_id = \"1\"  # default\n",
    "        else:\n",
    "            run_id = base_tokens[1]  # \"1\", \"2\", etc.\n",
    "        \n",
    "        # Set modality (OASIS2 mpr-* are T1-weighted)\n",
    "        modality = \"T1w\"\n",
    "        is_t1w = True\n",
    "        \n",
    "        # Write to DataFrame\n",
    "        df.loc[idx, 'subject_id'] = subject_id\n",
    "        df.loc[idx, 'visit_code'] = visit_code\n",
    "        df.loc[idx, 'run_id'] = run_id\n",
    "        df.loc[idx, 'modality'] = modality\n",
    "        df.loc[idx, 'is_t1w'] = is_t1w\n",
    "        \n",
    "    except Exception as e:\n",
    "        parse_errors_o2.append({\n",
    "            'index': idx,\n",
    "            'filename': filename,\n",
    "            'error': str(e)\n",
    "        })\n",
    "\n",
    "# Report OASIS2 parsing results\n",
    "n_parsed_o2 = df[mask_o2]['subject_id'].notna().sum()\n",
    "print(f\"\\n✓ Successfully parsed: {n_parsed_o2}/{n_o2} rows\")\n",
    "\n",
    "if parse_errors_o2:\n",
    "    print(f\"\\n⚠ Parse errors: {len(parse_errors_o2)}\")\n",
    "    print(\"\\nFirst 3 errors:\")\n",
    "    for i, err in enumerate(parse_errors_o2[:3], 1):\n",
    "        print(f\"  {i}. Index {err['index']}: {err['filename']}\")\n",
    "        print(f\"     Error: {err['error']}\")\n",
    "\n",
    "# Show sample parsed OASIS2 data\n",
    "print(\"\\nSample OASIS2 parsed data (first 3 rows):\")\n",
    "o2_sample = df[mask_o2][['filename', 'subject_id', 'visit_code', 'run_id', 'modality', 'is_t1w']].head(3)\n",
    "print(o2_sample.to_string(index=False))\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 4: Parse OASIS3 Rows\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"PARSING OASIS3 METADATA\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "mask_o3 = df['dataset'] == 'OASIS3'\n",
    "n_o3 = mask_o3.sum()\n",
    "print(f\"\\nProcessing {n_o3} OASIS3 rows...\")\n",
    "\n",
    "parse_errors_o3 = []\n",
    "\n",
    "for idx in df[mask_o3].index:\n",
    "    try:\n",
    "        filename = df.loc[idx, 'filename']\n",
    "        \n",
    "        # Normalize \"sess-\" → \"ses-\"\n",
    "        fname_norm = filename.replace('sess-', 'ses-')\n",
    "        \n",
    "        # Remove extension\n",
    "        # Example: \"sub-OAS30001_ses-d0129_run-01_T1w.nii\" → \"sub-OAS30001_ses-d0129_run-01_T1w\"\n",
    "        base_no_ext = fname_norm.split('.')[0]\n",
    "        \n",
    "        # Split on underscore\n",
    "        parts = base_no_ext.split('_')\n",
    "        \n",
    "        if len(parts) < 3:\n",
    "            raise ValueError(f\"Unexpected filename format: {filename} (parts: {parts})\")\n",
    "        \n",
    "        # Extract subject_id\n",
    "        subject_token = parts[0]  # \"sub-OAS30001\"\n",
    "        if not subject_token.startswith('sub-'):\n",
    "            raise ValueError(f\"Expected 'sub-' prefix, got: {subject_token}\")\n",
    "        subject_id = subject_token.replace('sub-', '')  # \"OAS30001\"\n",
    "        \n",
    "        # Extract visit_code (session)\n",
    "        session_token = None\n",
    "        for part in parts:\n",
    "            if part.startswith('ses-'):\n",
    "                session_token = part\n",
    "                break\n",
    "        \n",
    "        if session_token is None:\n",
    "            raise ValueError(f\"No 'ses-' token found in: {parts}\")\n",
    "        \n",
    "        visit_code = session_token.replace('ses-', '')  # \"d0129\"\n",
    "        \n",
    "        # Extract run_id\n",
    "        run_token = None\n",
    "        for part in parts:\n",
    "            if part.startswith('run-'):\n",
    "                run_token = part\n",
    "                break\n",
    "        \n",
    "        if run_token is None:\n",
    "            # Some scans may not have run- prefix, default to \"01\"\n",
    "            run_id = \"01\"\n",
    "        else:\n",
    "            run_id = run_token.replace('run-', '')  # \"01\", \"02\"\n",
    "        \n",
    "        # Extract modality (last token)\n",
    "        modality = parts[-1]  # \"T1w\", \"T2w\", \"FLAIR\", etc.\n",
    "        is_t1w = 'T1w' in modality\n",
    "        \n",
    "        # Write to DataFrame\n",
    "        df.loc[idx, 'subject_id'] = subject_id\n",
    "        df.loc[idx, 'visit_code'] = visit_code\n",
    "        df.loc[idx, 'run_id'] = run_id\n",
    "        df.loc[idx, 'modality'] = modality\n",
    "        df.loc[idx, 'is_t1w'] = is_t1w\n",
    "        \n",
    "    except Exception as e:\n",
    "        parse_errors_o3.append({\n",
    "            'index': idx,\n",
    "            'filename': filename,\n",
    "            'error': str(e)\n",
    "        })\n",
    "\n",
    "# Report OASIS3 parsing results\n",
    "n_parsed_o3 = df[mask_o3]['subject_id'].notna().sum()\n",
    "print(f\"\\n✓ Successfully parsed: {n_parsed_o3}/{n_o3} rows\")\n",
    "\n",
    "if parse_errors_o3:\n",
    "    print(f\"\\n⚠ Parse errors: {len(parse_errors_o3)}\")\n",
    "    print(\"\\nFirst 3 errors:\")\n",
    "    for i, err in enumerate(parse_errors_o3[:3], 1):\n",
    "        print(f\"  {i}. Index {err['index']}: {err['filename']}\")\n",
    "        print(f\"     Error: {err['error']}\")\n",
    "\n",
    "# Show sample parsed OASIS3 data\n",
    "print(\"\\nSample OASIS3 parsed data (first 3 rows):\")\n",
    "o3_sample = df[mask_o3][['filename', 'subject_id', 'visit_code', 'run_id', 'modality', 'is_t1w']].head(3)\n",
    "print(o3_sample.to_string(index=False))\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 5: Build scan_uid\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"CREATING UNIQUE SCAN_UIDs\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Create scan_uid: \"{dataset}|{subject_id}|{visit_code}|{run_id}\"\n",
    "df['scan_uid'] = (\n",
    "    df['dataset'].astype(str) + '|' + \n",
    "    df['subject_id'].astype(str) + '|' + \n",
    "    df['visit_code'].astype(str) + '|' + \n",
    "    df['run_id'].astype(str)\n",
    ")\n",
    "\n",
    "print(f\"\\n✓ Generated {len(df)} scan_uid values\")\n",
    "\n",
    "# Check for duplicate scan_uid (should be zero)\n",
    "n_duplicates = df['scan_uid'].duplicated().sum()\n",
    "print(f\"\\nDuplicate scan_uid count: {n_duplicates}\")\n",
    "\n",
    "if n_duplicates > 0:\n",
    "    print(\"\\n⚠ WARNING: Found duplicate scan_uid values!\")\n",
    "    print(\"This indicates multiple files for the same (subject, visit, run) combination.\")\n",
    "    print(\"\\nSample duplicates:\")\n",
    "    dup_df = df[df['scan_uid'].duplicated(keep=False)].sort_values('scan_uid')\n",
    "    print(dup_df[['scan_uid', 'filename', 'nifti_path']].head(10).to_string())\n",
    "\n",
    "# Show sample scan_uid\n",
    "print(\"\\nSample scan_uid values:\")\n",
    "print(df['scan_uid'].head(5).tolist())\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 6: Sanity Checks & Statistics\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SANITY CHECKS & STATISTICS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Check for missing values in parsed columns\n",
    "print(\"\\n1. Missing values in parsed columns:\")\n",
    "parsed_cols = ['subject_id', 'visit_code', 'run_id', 'modality', 'scan_uid']\n",
    "for col in parsed_cols:\n",
    "    n_missing = df[col].isna().sum()\n",
    "    pct_missing = 100 * n_missing / len(df)\n",
    "    print(f\"   {col:15s}: {n_missing:4d} missing ({pct_missing:5.2f}%)\")\n",
    "\n",
    "# Unique subjects per dataset\n",
    "print(\"\\n2. Unique subjects per dataset:\")\n",
    "for dataset in df['dataset'].unique():\n",
    "    mask = df['dataset'] == dataset\n",
    "    n_subjects = df[mask]['subject_id'].nunique()\n",
    "    print(f\"   {dataset:10s}: {n_subjects:4d} subjects\")\n",
    "\n",
    "# Visit distribution per dataset\n",
    "print(\"\\n3. Visits per subject distribution:\")\n",
    "for dataset in df['dataset'].unique():\n",
    "    mask = df['dataset'] == dataset\n",
    "    visits_per_subject = df[mask].groupby('subject_id')['visit_code'].nunique()\n",
    "    print(f\"\\n   {dataset}:\")\n",
    "    print(f\"     Mean visits/subject: {visits_per_subject.mean():.2f}\")\n",
    "    print(f\"     Median visits/subject: {visits_per_subject.median():.1f}\")\n",
    "    print(f\"     Max visits/subject: {visits_per_subject.max()}\")\n",
    "    \n",
    "    # Distribution\n",
    "    visit_counts = visits_per_subject.value_counts().sort_index()\n",
    "    for n_visits, count in visit_counts.head(5).items():\n",
    "        print(f\"       {count:3d} subjects with {n_visits} visit(s)\")\n",
    "\n",
    "# T1w distribution (OASIS3 only)\n",
    "print(\"\\n4. Modality distribution (OASIS3):\")\n",
    "o3_modality = df[mask_o3]['modality'].value_counts()\n",
    "for mod, count in o3_modality.items():\n",
    "    print(f\"   {mod:10s}: {count:4d} scans\")\n",
    "\n",
    "n_t1w_o3 = df[mask_o3]['is_t1w'].sum()\n",
    "print(f\"\\n   T1w scans (is_t1w=True): {n_t1w_o3}/{n_o3} ({100*n_t1w_o3/n_o3:.1f}%)\")\n",
    "\n",
    "# Run distribution\n",
    "print(\"\\n5. Run distribution:\")\n",
    "for dataset in df['dataset'].unique():\n",
    "    mask = df['dataset'] == dataset\n",
    "    run_counts = df[mask]['run_id'].value_counts().sort_index()\n",
    "    print(f\"\\n   {dataset}:\")\n",
    "    for run, count in run_counts.head(5).items():\n",
    "        print(f\"     run-{run}: {count:4d} scans\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 7: Save Parsed Index\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SAVING PARSED INDEX\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "output_file = \"nifti_index_parsed.csv\"\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"\\n✓ Saved parsed index to: {output_file}\")\n",
    "print(f\"  Total rows: {len(df)}\")\n",
    "print(f\"  Total columns: {len(df.columns)}\")\n",
    "print(f\"  File size: {Path(output_file).stat().st_size / 1024:.2f} KB\")\n",
    "\n",
    "# Final column list\n",
    "print(\"\\nFinal columns:\")\n",
    "for i, col in enumerate(df.columns, 1):\n",
    "    print(f\"  {i:2d}. {col}\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 8: Preview Parsed Data\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"PARSED INDEX PREVIEW\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', 50)\n",
    "\n",
    "# Show mixed sample (OASIS2 + OASIS3)\n",
    "print(\"\\nOASIS2 samples (first 3):\")\n",
    "o2_display = df[mask_o2][['dataset', 'subject_id', 'visit_code', 'run_id', 'modality', 'is_t1w', 'scan_uid', 'filename']].head(3)\n",
    "print(o2_display.to_string(index=False))\n",
    "\n",
    "print(\"\\nOASIS3 samples (first 3):\")\n",
    "o3_display = df[mask_o3][['dataset', 'subject_id', 'visit_code', 'run_id', 'modality', 'is_t1w', 'scan_uid', 'filename']].head(3)\n",
    "print(o3_display.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SNIPPET S2 COMPLETE\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nNext Steps:\")\n",
    "print(\"  → S3: Load/generate clinical data (CDR, MMSE scores)\")\n",
    "print(\"  → S4: Select one representative scan per (subject, visit)\")\n",
    "print(\"  → S5: Test loading sample volumes with nibabel\")\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b20f5ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T18:51:00.777168Z",
     "iopub.status.busy": "2025-11-17T18:51:00.776946Z",
     "iopub.status.idle": "2025-11-17T18:51:01.270172Z",
     "shell.execute_reply": "2025-11-17T18:51:01.269273Z"
    },
    "papermill": {
     "duration": 0.507107,
     "end_time": "2025-11-17T18:51:01.271256",
     "exception": false,
     "start_time": "2025-11-17T18:51:00.764149",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "OASIS-2 Dataset Indexing Pipeline\n",
      "======================================================================\n",
      "Part 1 root: /kaggle/input/oaisis-dataset-3-p1/OAS2_RAW_PART1\n",
      "Part 2 root: /kaggle/input/oaisis-3-p2/OAS2_RAW_PART2\n",
      "Output file: oasis_index.csv\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "Step 1: Scanning PART1\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "Processing PART1: /kaggle/input/oaisis-dataset-3-p1/OAS2_RAW_PART1\n",
      "======================================================================\n",
      "Found 209 entries in PART1\n",
      "  ✓ Processed 200 valid scans...\r\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "✅ PART1 Complete\n",
      "  Valid scans found: 209\n",
      "  Skipped entries: 0\n",
      "\n",
      "======================================================================\n",
      "Step 2: Scanning PART2\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "Processing PART2: /kaggle/input/oaisis-3-p2/OAS2_RAW_PART2\n",
      "======================================================================\n",
      "Found 164 entries in PART2\n",
      "  ✓ Processed 160 valid scans...\r\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "✅ PART2 Complete\n",
      "  Valid scans found: 164\n",
      "  Skipped entries: 0\n",
      "\n",
      "======================================================================\n",
      "Step 3: Building Index DataFrame\n",
      "======================================================================\n",
      "\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "📊 Dataset Statistics\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "✓ Total scans (rows): 373\n",
      "✓ Unique subjects: 150\n",
      "✓ Unique sessions per subject: 2.49 (avg)\n",
      "\n",
      "✓ Scans per part:\n",
      "part\n",
      "PART1    209\n",
      "PART2    164\n",
      "\n",
      "✓ Sessions distribution:\n",
      "session_id\n",
      "MR1    150\n",
      "MR2    144\n",
      "MR3     58\n",
      "MR4     15\n",
      "MR5      6\n",
      "\n",
      "✅ No duplicate subject_session entries (good!)\n",
      "\n",
      "✓ Path validation (sampling 5 random scans):\n",
      "  ✓ mpr-1.nifti.hdr\n",
      "  ✓ mpr-1.nifti.hdr\n",
      "  ✓ mpr-1.nifti.hdr\n",
      "  ✓ mpr-1.nifti.hdr\n",
      "  ✓ mpr-1.nifti.hdr\n",
      "\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "📋 First 10 Rows (Preview)\n",
      "──────────────────────────────────────────────────────────────────────\n",
      " part subject_session subject_id session_id                                                                         nifti_path\n",
      "PART1   OAS2_0001_MR1  OAS2_0001        MR1 /kaggle/input/oaisis-dataset-3-p1/OAS2_RAW_PART1/OAS2_0001_MR1/RAW/mpr-1.nifti.hdr\n",
      "PART1   OAS2_0001_MR2  OAS2_0001        MR2 /kaggle/input/oaisis-dataset-3-p1/OAS2_RAW_PART1/OAS2_0001_MR2/RAW/mpr-1.nifti.hdr\n",
      "PART1   OAS2_0002_MR1  OAS2_0002        MR1 /kaggle/input/oaisis-dataset-3-p1/OAS2_RAW_PART1/OAS2_0002_MR1/RAW/mpr-1.nifti.hdr\n",
      "PART1   OAS2_0002_MR2  OAS2_0002        MR2 /kaggle/input/oaisis-dataset-3-p1/OAS2_RAW_PART1/OAS2_0002_MR2/RAW/mpr-1.nifti.hdr\n",
      "PART1   OAS2_0002_MR3  OAS2_0002        MR3 /kaggle/input/oaisis-dataset-3-p1/OAS2_RAW_PART1/OAS2_0002_MR3/RAW/mpr-1.nifti.hdr\n",
      "PART1   OAS2_0004_MR1  OAS2_0004        MR1 /kaggle/input/oaisis-dataset-3-p1/OAS2_RAW_PART1/OAS2_0004_MR1/RAW/mpr-1.nifti.hdr\n",
      "PART1   OAS2_0004_MR2  OAS2_0004        MR2 /kaggle/input/oaisis-dataset-3-p1/OAS2_RAW_PART1/OAS2_0004_MR2/RAW/mpr-1.nifti.hdr\n",
      "PART1   OAS2_0005_MR1  OAS2_0005        MR1 /kaggle/input/oaisis-dataset-3-p1/OAS2_RAW_PART1/OAS2_0005_MR1/RAW/mpr-1.nifti.hdr\n",
      "PART1   OAS2_0005_MR2  OAS2_0005        MR2 /kaggle/input/oaisis-dataset-3-p1/OAS2_RAW_PART1/OAS2_0005_MR2/RAW/mpr-1.nifti.hdr\n",
      "PART1   OAS2_0005_MR3  OAS2_0005        MR3 /kaggle/input/oaisis-dataset-3-p1/OAS2_RAW_PART1/OAS2_0005_MR3/RAW/mpr-1.nifti.hdr\n",
      "\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "📋 Last 5 Rows (Preview)\n",
      "──────────────────────────────────────────────────────────────────────\n",
      " part subject_session subject_id session_id                                                                 nifti_path\n",
      "PART2   OAS2_0185_MR2  OAS2_0185        MR2 /kaggle/input/oaisis-3-p2/OAS2_RAW_PART2/OAS2_0185_MR2/RAW/mpr-1.nifti.hdr\n",
      "PART2   OAS2_0185_MR3  OAS2_0185        MR3 /kaggle/input/oaisis-3-p2/OAS2_RAW_PART2/OAS2_0185_MR3/RAW/mpr-1.nifti.hdr\n",
      "PART2   OAS2_0186_MR1  OAS2_0186        MR1 /kaggle/input/oaisis-3-p2/OAS2_RAW_PART2/OAS2_0186_MR1/RAW/mpr-1.nifti.hdr\n",
      "PART2   OAS2_0186_MR2  OAS2_0186        MR2 /kaggle/input/oaisis-3-p2/OAS2_RAW_PART2/OAS2_0186_MR2/RAW/mpr-1.nifti.hdr\n",
      "PART2   OAS2_0186_MR3  OAS2_0186        MR3 /kaggle/input/oaisis-3-p2/OAS2_RAW_PART2/OAS2_0186_MR3/RAW/mpr-1.nifti.hdr\n",
      "\n",
      "======================================================================\n",
      "Step 4: Saving Index\n",
      "======================================================================\n",
      "✅ Successfully saved index to: oasis_index.csv\n",
      "   File size: 41.39 KB\n",
      "   Columns: ['part', 'subject_session', 'subject_id', 'session_id', 'nifti_path']\n",
      "   Shape: (373, 5)\n",
      "\n",
      "======================================================================\n",
      "✅ OASIS-2 Indexing Complete!\n",
      "======================================================================\n",
      "📊 Summary:\n",
      "   • Total scans indexed: 373\n",
      "   • Unique subjects: 150\n",
      "   • PART1 scans: 209\n",
      "   • PART2 scans: 164\n",
      "   • Output saved: oasis_index.csv\n",
      "\n",
      "🎯 Next Steps:\n",
      "   1. Load clinical metadata CSV (CDR labels)\n",
      "   2. Join labels with this index\n",
      "   3. Create stratified train/val/test splits (subject-level)\n",
      "   4. Build PyTorch Dataset class\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# Snippet 3: Build OASIS-2 subject/session index\n",
    "# ============================================\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# ============================================\n",
    "# Configuration\n",
    "# ============================================\n",
    "\n",
    "ROOT_P1 = \"/kaggle/input/oaisis-dataset-3-p1/OAS2_RAW_PART1\"\n",
    "ROOT_P2 = \"/kaggle/input/oaisis-3-p2/OAS2_RAW_PART2\"\n",
    "OUTPUT_CSV = \"oasis_index.csv\"\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"OASIS-2 Dataset Indexing Pipeline\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Part 1 root: {ROOT_P1}\")\n",
    "print(f\"Part 2 root: {ROOT_P2}\")\n",
    "print(f\"Output file: {OUTPUT_CSV}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# FUNCTION: Collect records from one root directory\n",
    "# ============================================\n",
    "\n",
    "def collect_records_for_root(root_path, part_name):\n",
    "    \"\"\"\n",
    "    Scan a root directory (PART1 or PART2) and collect metadata for all valid scans.\n",
    "    \n",
    "    Args:\n",
    "        root_path (str): Path to OAS2_RAW_PART1 or OAS2_RAW_PART2\n",
    "        part_name (str): \"PART1\" or \"PART2\" for tracking\n",
    "        \n",
    "    Returns:\n",
    "        list: List of dictionaries, each representing one scan record\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Processing {part_name}: {root_path}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    # Verify root exists\n",
    "    if not os.path.exists(root_path):\n",
    "        print(f\"❌ ERROR: Root path does not exist: {root_path}\")\n",
    "        return []\n",
    "    \n",
    "    if not os.path.isdir(root_path):\n",
    "        print(f\"❌ ERROR: Path is not a directory: {root_path}\")\n",
    "        return []\n",
    "    \n",
    "    records = []\n",
    "    skipped_count = 0\n",
    "    warning_log = []\n",
    "    \n",
    "    # 1. List all entries in root directory (sorted for determinism)\n",
    "    try:\n",
    "        dir_names = sorted(os.listdir(root_path))\n",
    "    except Exception as e:\n",
    "        print(f\"❌ ERROR: Cannot list directory {root_path}: {e}\")\n",
    "        return []\n",
    "    \n",
    "    print(f\"Found {len(dir_names)} entries in {part_name}\")\n",
    "    \n",
    "    # 2. Process each directory\n",
    "    for idx, dir_name in enumerate(dir_names):\n",
    "        full_dir = os.path.join(root_path, dir_name)\n",
    "        \n",
    "        # Skip non-directories\n",
    "        if not os.path.isdir(full_dir):\n",
    "            continue\n",
    "        \n",
    "        # Only process directories starting with \"OAS2_\"\n",
    "        if not dir_name.startswith(\"OAS2_\"):\n",
    "            continue\n",
    "        \n",
    "        # Parse folder name: expected format \"OAS2_XXXX_MRY\"\n",
    "        parts = dir_name.split(\"_\")\n",
    "        if len(parts) < 3:\n",
    "            warning_msg = f\"⚠️  Unexpected folder name format (skipping): {dir_name}\"\n",
    "            warning_log.append(warning_msg)\n",
    "            skipped_count += 1\n",
    "            continue\n",
    "        \n",
    "        # Extract IDs\n",
    "        subject_id = f\"{parts[0]}_{parts[1]}\"  # e.g., \"OAS2_0001\"\n",
    "        session_id = parts[2]                   # e.g., \"MR1\"\n",
    "        subject_session = dir_name              # e.g., \"OAS2_0001_MR1\"\n",
    "        \n",
    "        # 3. Look for RAW folder\n",
    "        raw_dir = os.path.join(full_dir, \"RAW\")\n",
    "        if not os.path.exists(raw_dir) or not os.path.isdir(raw_dir):\n",
    "            warning_msg = f\"⚠️  No RAW folder: {subject_session}\"\n",
    "            warning_log.append(warning_msg)\n",
    "            skipped_count += 1\n",
    "            continue\n",
    "        \n",
    "        # 4. Find .nifti.hdr files in RAW folder\n",
    "        pattern = os.path.join(raw_dir, \"*.nifti.hdr\")\n",
    "        nifti_files = sorted(glob.glob(pattern))\n",
    "        \n",
    "        if len(nifti_files) == 0:\n",
    "            warning_msg = f\"⚠️  No .nifti.hdr files: {subject_session}/RAW/\"\n",
    "            warning_log.append(warning_msg)\n",
    "            skipped_count += 1\n",
    "            continue\n",
    "        \n",
    "        # 5. Select first file (deterministic if multiple exist)\n",
    "        nifti_path = nifti_files[0]\n",
    "        \n",
    "        # Verify corresponding .img file exists\n",
    "        img_path = nifti_path.replace(\".hdr\", \".img\")\n",
    "        if not os.path.exists(img_path):\n",
    "            warning_msg = f\"⚠️  Missing .img pair: {subject_session} (has .hdr but no .img)\"\n",
    "            warning_log.append(warning_msg)\n",
    "            skipped_count += 1\n",
    "            continue\n",
    "        \n",
    "        # 6. Create record\n",
    "        record = {\n",
    "            \"part\": part_name,\n",
    "            \"subject_session\": subject_session,\n",
    "            \"subject_id\": subject_id,\n",
    "            \"session_id\": session_id,\n",
    "            \"nifti_path\": nifti_path,\n",
    "        }\n",
    "        records.append(record)\n",
    "        \n",
    "        # Progress indicator (every 20 scans)\n",
    "        if (len(records)) % 20 == 0:\n",
    "            print(f\"  ✓ Processed {len(records)} valid scans...\", end=\"\\r\")\n",
    "    \n",
    "    # Summary\n",
    "    print(f\"\\n{'─'*70}\")\n",
    "    print(f\"✅ {part_name} Complete\")\n",
    "    print(f\"  Valid scans found: {len(records)}\")\n",
    "    print(f\"  Skipped entries: {skipped_count}\")\n",
    "    \n",
    "    # Print warnings if any (limited to first 10)\n",
    "    if warning_log:\n",
    "        print(f\"\\n  Warnings ({len(warning_log)} total):\")\n",
    "        for warn in warning_log[:10]:\n",
    "            print(f\"    {warn}\")\n",
    "        if len(warning_log) > 10:\n",
    "            print(f\"    ... and {len(warning_log) - 10} more warnings\")\n",
    "    \n",
    "    return records\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# MAIN EXECUTION\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Step 1: Scanning PART1\")\n",
    "print(\"=\"*70)\n",
    "records_p1 = collect_records_for_root(ROOT_P1, part_name=\"PART1\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Step 2: Scanning PART2\")\n",
    "print(\"=\"*70)\n",
    "records_p2 = collect_records_for_root(ROOT_P2, part_name=\"PART2\")\n",
    "\n",
    "# ============================================\n",
    "# Combine and create DataFrame\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Step 3: Building Index DataFrame\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "all_records = records_p1 + records_p2\n",
    "\n",
    "if len(all_records) == 0:\n",
    "    print(\"❌ ERROR: No valid records found! Check paths and data structure.\")\n",
    "    exit(1)\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(all_records)\n",
    "\n",
    "# ============================================\n",
    "# Data Quality Checks\n",
    "# ============================================\n",
    "\n",
    "print(f\"\\n{'─'*70}\")\n",
    "print(\"📊 Dataset Statistics\")\n",
    "print(f\"{'─'*70}\")\n",
    "\n",
    "print(f\"✓ Total scans (rows): {len(df)}\")\n",
    "print(f\"✓ Unique subjects: {df['subject_id'].nunique()}\")\n",
    "print(f\"✓ Unique sessions per subject: {df.groupby('subject_id').size().mean():.2f} (avg)\")\n",
    "\n",
    "print(f\"\\n✓ Scans per part:\")\n",
    "print(df['part'].value_counts().to_string())\n",
    "\n",
    "print(f\"\\n✓ Sessions distribution:\")\n",
    "session_counts = df['session_id'].value_counts().sort_index()\n",
    "print(session_counts.head(10).to_string())\n",
    "if len(session_counts) > 10:\n",
    "    print(f\"  ... and {len(session_counts) - 10} more session types\")\n",
    "\n",
    "# Check for duplicates\n",
    "duplicates = df.duplicated(subset=['subject_session'], keep=False)\n",
    "if duplicates.any():\n",
    "    print(f\"\\n⚠️  WARNING: Found {duplicates.sum()} duplicate subject_session entries!\")\n",
    "    print(df[duplicates][['part', 'subject_session']].head())\n",
    "else:\n",
    "    print(f\"\\n✅ No duplicate subject_session entries (good!)\")\n",
    "\n",
    "# Verify paths exist (sample check)\n",
    "print(f\"\\n✓ Path validation (sampling 5 random scans):\")\n",
    "sample_paths = df.sample(min(5, len(df)))['nifti_path'].tolist()\n",
    "for path in sample_paths:\n",
    "    exists = \"✓\" if os.path.exists(path) else \"✗\"\n",
    "    print(f\"  {exists} {Path(path).name}\")\n",
    "\n",
    "# ============================================\n",
    "# Display sample rows\n",
    "# ============================================\n",
    "\n",
    "print(f\"\\n{'─'*70}\")\n",
    "print(\"📋 First 10 Rows (Preview)\")\n",
    "print(f\"{'─'*70}\")\n",
    "print(df.head(10).to_string(index=False))\n",
    "\n",
    "print(f\"\\n{'─'*70}\")\n",
    "print(\"📋 Last 5 Rows (Preview)\")\n",
    "print(f\"{'─'*70}\")\n",
    "print(df.tail(5).to_string(index=False))\n",
    "\n",
    "# ============================================\n",
    "# Save to CSV\n",
    "# ============================================\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"Step 4: Saving Index\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "try:\n",
    "    df.to_csv(OUTPUT_CSV, index=False)\n",
    "    file_size = os.path.getsize(OUTPUT_CSV) / 1024  # KB\n",
    "    print(f\"✅ Successfully saved index to: {OUTPUT_CSV}\")\n",
    "    print(f\"   File size: {file_size:.2f} KB\")\n",
    "    print(f\"   Columns: {list(df.columns)}\")\n",
    "    print(f\"   Shape: {df.shape}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ ERROR saving CSV: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "# ============================================\n",
    "# Final Summary\n",
    "# ============================================\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"✅ OASIS-2 Indexing Complete!\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"📊 Summary:\")\n",
    "print(f\"   • Total scans indexed: {len(df)}\")\n",
    "print(f\"   • Unique subjects: {df['subject_id'].nunique()}\")\n",
    "print(f\"   • PART1 scans: {len(records_p1)}\")\n",
    "print(f\"   • PART2 scans: {len(records_p2)}\")\n",
    "print(f\"   • Output saved: {OUTPUT_CSV}\")\n",
    "print(f\"\\n🎯 Next Steps:\")\n",
    "print(f\"   1. Load clinical metadata CSV (CDR labels)\")\n",
    "print(f\"   2. Join labels with this index\")\n",
    "print(f\"   3. Create stratified train/val/test splits (subject-level)\")\n",
    "print(f\"   4. Build PyTorch Dataset class\")\n",
    "print(f\"{'='*70}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d04de01c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T18:51:01.297599Z",
     "iopub.status.busy": "2025-11-17T18:51:01.297316Z",
     "iopub.status.idle": "2025-11-17T18:51:01.350304Z",
     "shell.execute_reply": "2025-11-17T18:51:01.349573Z"
    },
    "papermill": {
     "duration": 0.067151,
     "end_time": "2025-11-17T18:51:01.351498",
     "exception": false,
     "start_time": "2025-11-17T18:51:01.284347",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SNIPPET S3: BUILD VISIT-LEVEL INDEX FROM PARSED SCANS\n",
      "================================================================================\n",
      "\n",
      "Loaded: nifti_index_parsed.csv\n",
      "  Rows: 2626\n",
      "  Columns: ['nifti_path', 'dataset', 'source', 'filename', 'parent_dir', 'ext', 'subject_id', 'visit_code', 'run_id', 'modality', 'is_t1w', 'scan_uid']\n",
      "\n",
      "T1w scans: 2626/2626\n",
      "\n",
      "Per-visit representative scans:\n",
      "  Total visits: 796\n",
      "  Visits per dataset:\n",
      "dataset\n",
      "OASIS3    423\n",
      "OASIS2    373\n",
      "Name: count, dtype: int64\n",
      "\n",
      "visit_level_index preview (first 5 rows):\n",
      "dataset            visit_uid subject_id visit_code                                                                         nifti_path        filename  run_id modality               scan_uid\n",
      " OASIS2 OASIS2|OAS2_0001|MR1  OAS2_0001        MR1 /kaggle/input/oaisis-dataset-3-p1/OAS2_RAW_PART1/OAS2_0001_MR1/RAW/mpr-1.nifti.hdr mpr-1.nifti.hdr       1      T1w OASIS2|OAS2_0001|MR1|1\n",
      " OASIS2 OASIS2|OAS2_0001|MR2  OAS2_0001        MR2 /kaggle/input/oaisis-dataset-3-p1/OAS2_RAW_PART1/OAS2_0001_MR2/RAW/mpr-1.nifti.hdr mpr-1.nifti.hdr       1      T1w OASIS2|OAS2_0001|MR2|1\n",
      " OASIS2 OASIS2|OAS2_0002|MR1  OAS2_0002        MR1 /kaggle/input/oaisis-dataset-3-p1/OAS2_RAW_PART1/OAS2_0002_MR1/RAW/mpr-1.nifti.hdr mpr-1.nifti.hdr       1      T1w OASIS2|OAS2_0002|MR1|1\n",
      " OASIS2 OASIS2|OAS2_0002|MR2  OAS2_0002        MR2 /kaggle/input/oaisis-dataset-3-p1/OAS2_RAW_PART1/OAS2_0002_MR2/RAW/mpr-1.nifti.hdr mpr-1.nifti.hdr       1      T1w OASIS2|OAS2_0002|MR2|1\n",
      " OASIS2 OASIS2|OAS2_0002|MR3  OAS2_0002        MR3 /kaggle/input/oaisis-dataset-3-p1/OAS2_RAW_PART1/OAS2_0002_MR3/RAW/mpr-1.nifti.hdr mpr-1.nifti.hdr       1      T1w OASIS2|OAS2_0002|MR3|1\n",
      "\n",
      "✓ Saved visit-level index to: visit_level_index.csv\n",
      "  Rows: 796\n",
      "  Columns: ['dataset', 'visit_uid', 'subject_id', 'visit_code', 'nifti_path', 'filename', 'run_id', 'modality', 'scan_uid']\n",
      "  File size: 145.31 KB\n",
      "\n",
      "SNIPPET S3 COMPLETE\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# SNIPPET S3.5: BUILD VISIT-LEVEL INDEX\n",
    "# ============================================\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"SNIPPET S3: BUILD VISIT-LEVEL INDEX FROM PARSED SCANS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 1. Load parsed index from S2\n",
    "# ---------------------------------------------------------\n",
    "parsed_file = \"nifti_index_parsed.csv\"\n",
    "df = pd.read_csv(parsed_file)\n",
    "\n",
    "print(f\"\\nLoaded: {parsed_file}\")\n",
    "print(f\"  Rows: {len(df)}\")\n",
    "print(f\"  Columns: {df.columns.tolist()}\")\n",
    "\n",
    "# Sanity: required columns\n",
    "required_cols = [\"dataset\", \"subject_id\", \"visit_code\", \"run_id\",\n",
    "                 \"nifti_path\", \"filename\", \"is_t1w\"]\n",
    "missing = [c for c in required_cols if c not in df.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"Missing required columns in {parsed_file}: {missing}\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 2. Filter to T1w scans only\n",
    "# ---------------------------------------------------------\n",
    "t1_df = df[df[\"is_t1w\"] == True].copy()\n",
    "print(f\"\\nT1w scans: {len(t1_df)}/{len(df)}\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 3. Pick ONE run per (dataset, subject_id, visit_code)\n",
    "#    Strategy: smallest numeric run_id (stable, deterministic)\n",
    "# ---------------------------------------------------------\n",
    "def to_run_order(x):\n",
    "    # Extract digits if needed, convert to int; fall back to 999 if bad\n",
    "    s = str(x)\n",
    "    digits = \"\".join(ch for ch in s if ch.isdigit())\n",
    "    try:\n",
    "        return int(digits) if digits else 999\n",
    "    except ValueError:\n",
    "        return 999\n",
    "\n",
    "t1_df[\"run_order\"] = t1_df[\"run_id\"].apply(to_run_order)\n",
    "\n",
    "t1_sorted = t1_df.sort_values(\n",
    "    [\"dataset\", \"subject_id\", \"visit_code\", \"run_order\"]\n",
    ")\n",
    "\n",
    "# Take first scan per (dataset, subject_id, visit_code)\n",
    "visit_df = (\n",
    "    t1_sorted\n",
    "    .groupby([\"dataset\", \"subject_id\", \"visit_code\"], as_index=False)\n",
    "    .first()\n",
    ")\n",
    "\n",
    "print(\"\\nPer-visit representative scans:\")\n",
    "print(f\"  Total visits: {len(visit_df)}\")\n",
    "print(\"  Visits per dataset:\")\n",
    "print(visit_df[\"dataset\"].value_counts())\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 4. Build visit_uid and final schema for S4\n",
    "# ---------------------------------------------------------\n",
    "visit_df[\"visit_uid\"] = (\n",
    "    visit_df[\"dataset\"].astype(str)\n",
    "    + \"|\" + visit_df[\"subject_id\"].astype(str)\n",
    "    + \"|\" + visit_df[\"visit_code\"].astype(str)\n",
    ")\n",
    "\n",
    "# Reorder columns: minimal set S4 expects + some useful extras\n",
    "cols = [\n",
    "    \"dataset\",\n",
    "    \"visit_uid\",\n",
    "    \"subject_id\",\n",
    "    \"visit_code\",\n",
    "    \"nifti_path\",\n",
    "    \"filename\",\n",
    "    \"run_id\",\n",
    "    \"modality\",\n",
    "    \"scan_uid\",\n",
    "]\n",
    "cols = [c for c in cols if c in visit_df.columns]\n",
    "\n",
    "visit_index = visit_df[cols].copy()\n",
    "\n",
    "print(\"\\nvisit_level_index preview (first 5 rows):\")\n",
    "print(visit_index.head().to_string(index=False))\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 5. Save to CSV\n",
    "# ---------------------------------------------------------\n",
    "output_file = \"visit_level_index.csv\"\n",
    "visit_index.to_csv(output_file, index=False)\n",
    "\n",
    "size_kb = Path(output_file).stat().st_size / 1024\n",
    "print(f\"\\n✓ Saved visit-level index to: {output_file}\")\n",
    "print(f\"  Rows: {len(visit_index)}\")\n",
    "print(f\"  Columns: {list(visit_index.columns)}\")\n",
    "print(f\"  File size: {size_kb:.2f} KB\")\n",
    "\n",
    "print(\"\\nSNIPPET S3 COMPLETE\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38363df7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T18:51:01.378339Z",
     "iopub.status.busy": "2025-11-17T18:51:01.377875Z",
     "iopub.status.idle": "2025-11-17T18:51:01.542264Z",
     "shell.execute_reply": "2025-11-17T18:51:01.541411Z"
    },
    "papermill": {
     "duration": 0.179268,
     "end_time": "2025-11-17T18:51:01.543496",
     "exception": false,
     "start_time": "2025-11-17T18:51:01.364228",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SNIPPET S4: CLINICAL DATA MERGE\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "LOADING VISIT-LEVEL INDEX\n",
      "================================================================================\n",
      "\n",
      "Loaded visit_level_index.csv\n",
      "  Total visits: 796\n",
      "  OASIS2: 373\n",
      "  OASIS3: 423\n",
      "\n",
      "================================================================================\n",
      "OASIS2: LOADING CLINICAL DATA\n",
      "================================================================================\n",
      "\n",
      "✓ Loaded: /kaggle/input/mri-and-alzheimers/oasis_longitudinal.csv\n",
      "  Rows: 373\n",
      "  Columns: 15\n",
      "\n",
      "Available columns:\n",
      "   1. Subject ID\n",
      "   2. MRI ID\n",
      "   3. Group\n",
      "   4. Visit\n",
      "   5. MR Delay\n",
      "   6. M/F\n",
      "   7. Hand\n",
      "   8. Age\n",
      "   9. EDUC\n",
      "  10. SES\n",
      "  11. MMSE\n",
      "  12. CDR\n",
      "  13. eTIV\n",
      "  14. nWBV\n",
      "  15. ASF\n",
      "\n",
      "First 3 rows:\n",
      "  Subject ID         MRI ID        Group  Visit  MR Delay M/F Hand  Age  EDUC  SES  MMSE  CDR  eTIV   nWBV    ASF\n",
      "0  OAS2_0001  OAS2_0001_MR1  Nondemented      1         0   M    R   87    14  2.0  27.0  0.0  1987  0.696  0.883\n",
      "1  OAS2_0001  OAS2_0001_MR2  Nondemented      2       457   M    R   88    14  2.0  30.0  0.0  2004  0.681  0.876\n",
      "2  OAS2_0002  OAS2_0002_MR1     Demented      1         0   M    R   75    12  NaN  23.0  0.5  1678  0.736  1.046\n",
      "\n",
      "================================================================================\n",
      "OASIS2: MERGING IMAGING + CLINICAL\n",
      "================================================================================\n",
      "\n",
      "OASIS2 imaging visits: 373\n",
      "  Sample MRI_ID_KEY: OAS2_0001_MR1\n",
      "\n",
      "Merge key found: 'MRI ID'\n",
      "  Sample clinical key: OAS2_0001_MR1\n",
      "\n",
      "✓ Merge complete\n",
      "  Imaging visits: 373\n",
      "  Clinical rows:  373\n",
      "  Merged rows:    373\n",
      "  Match rate:     100.0%\n",
      "\n",
      "Group distribution ('Group'):\n",
      "Group\n",
      "Nondemented    190\n",
      "Demented       146\n",
      "Converted       37\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Diagnosis mapping:\n",
      "  CN (0): 190\n",
      "  AD (1): 146\n",
      "  Unknown/MCI (NaN): 37\n",
      "\n",
      "Standardized column names applied\n",
      "\n",
      "OASIS2 final columns: 19\n",
      "  Columns: ['dataset', 'visit_uid', 'subject_id', 'visit_code', 'nifti_path', 'filename', 'diagnosis_binary', 'age', 'sex', 'group', 'mmse', 'cdr', 'education', 'ses', 'visit_number', 'mr_delay_days', 'etiv', 'nwbv', 'asf']\n",
      "\n",
      "================================================================================\n",
      "OASIS3: LOADING CLINICAL DATA\n",
      "================================================================================\n",
      "\n",
      "✓ Loaded: /kaggle/input/oaisis-3-longitiudinal/oaisis3longitiudinal.csv\n",
      "  Rows: 8626\n",
      "  Columns: 23\n",
      "\n",
      "Available columns:\n",
      "   1. OASISID\n",
      "   2. OASIS_session_label\n",
      "   3. days_to_visit\n",
      "   4. age at visit\n",
      "   5. MMSE\n",
      "   6. memory\n",
      "   7. orient\n",
      "   8. judgment\n",
      "   9. commun\n",
      "  10. homehobb\n",
      "  11. perscare\n",
      "  12. CDRSUM\n",
      "  13. CDRTOT\n",
      "  14. dx1_code\n",
      "  15. dx2_code\n",
      "  16. dx3_code\n",
      "  17. dx4_code\n",
      "  18. dx5_code\n",
      "  19. dx1\n",
      "  20. dx2\n",
      "  21. dx3\n",
      "  22. dx4\n",
      "  23. dx5\n",
      "\n",
      "First 3 rows:\n",
      "    OASISID   OASIS_session_label  days_to_visit  age at visit  MMSE  memory  orient  judgment  commun  homehobb  perscare  CDRSUM  CDRTOT  dx1_code  dx2_code  dx3_code  dx4_code  dx5_code                 dx1 dx2 dx3 dx4 dx5\n",
      "0  OAS30001  OAS30001_UDSb4_d0000              0         65.19  28.0     0.0     0.0       0.0     0.0       0.0       0.0     0.0     0.0       1.0       NaN       NaN       NaN       NaN  Cognitively normal   .   .   .   .\n",
      "1  OAS30001  OAS30001_UDSb4_d0339            339         66.12  28.0     0.0     0.0       0.0     0.0       0.0       0.0     0.0     0.0       1.0       NaN       NaN       NaN       NaN  Cognitively normal   .   .   .   .\n",
      "2  OAS30001  OAS30001_UDSb4_d0722            722         67.17  30.0     0.0     0.0       0.0     0.0       0.0       0.0     0.0     0.0       1.0       NaN       NaN       NaN       NaN  Cognitively normal   .   .   .   .\n",
      "\n",
      "================================================================================\n",
      "OASIS3: MERGING IMAGING + CLINICAL\n",
      "================================================================================\n",
      "\n",
      "OASIS3 imaging visits: 423\n",
      "\n",
      "Session label column: 'OASIS_session_label'\n",
      "  Sample session codes: ['d0000', 'd0339', 'd0722']\n",
      "Subject ID column: 'OASISID'\n",
      "\n",
      "✓ Merge complete\n",
      "  Imaging visits: 423\n",
      "  Clinical rows:  8626\n",
      "  Merged rows:    4\n",
      "  Match rate:     0.9%\n",
      "\n",
      "⚠ WARNING: No CDR column found\n",
      "  Available columns: ['dataset', 'visit_uid', 'subject_id', 'visit_code', 'nifti_path', 'filename', 'run_id', 'modality', 'scan_uid', 'OASISID', 'OASIS_session_label', 'days_to_visit', 'age at visit', 'MMSE', 'memory', 'orient', 'judgment', 'commun', 'homehobb', 'perscare', 'CDRSUM', 'CDRTOT', 'dx1_code', 'dx2_code', 'dx3_code', 'dx4_code', 'dx5_code', 'dx1', 'dx2', 'dx3', 'dx4', 'dx5', 'session_code']\n",
      "\n",
      "Standardized column names applied\n",
      "\n",
      "OASIS3 final columns: 16\n",
      "  Columns: ['dataset', 'visit_uid', 'subject_id', 'visit_code', 'nifti_path', 'filename', 'diagnosis_binary', 'age', 'mmse', 'days_to_visit', 'memory', 'orient', 'judgment', 'commun', 'homehobb', 'session_label']\n",
      "\n",
      "================================================================================\n",
      "CREATING MASTER VISIT METADATA\n",
      "================================================================================\n",
      "\n",
      "✓ Master table created\n",
      "  Total visits: 377\n",
      "  OASIS2: 373\n",
      "  OASIS3: 4\n",
      "\n",
      "================================================================================\n",
      "MASTER TABLE STATISTICS\n",
      "================================================================================\n",
      "\n",
      "1. Diagnosis distribution:\n",
      "  CN (0):   190\n",
      "  AD (1):   146\n",
      "  Unknown:   41\n",
      "\n",
      "2. Diagnosis by dataset:\n",
      "\n",
      "   OASIS2:\n",
      "     CN:   190\n",
      "     AD:   146\n",
      "     Unknown:   37\n",
      "\n",
      "   OASIS3:\n",
      "     CN:     0\n",
      "     AD:     0\n",
      "     Unknown:    4\n",
      "\n",
      "3. Age statistics:\n",
      "                  count       mean       std   min   25%   50%   75%   max\n",
      "diagnosis_binary                                                          \n",
      "0.0               190.0  77.057895  8.096104  60.0  71.0  77.0  82.0  97.0\n",
      "1.0               146.0  76.260274  6.940193  61.0  71.0  76.0  81.0  98.0\n",
      "\n",
      "4. MMSE statistics:\n",
      "  Available: 375/377\n",
      "                  count       mean       std   min   25%   50%   75%   max\n",
      "diagnosis_binary                                                          \n",
      "0.0               190.0  29.226316  0.882722  26.0  29.0  29.0  30.0  30.0\n",
      "1.0               144.0  24.513889  4.497064   4.0  22.0  26.0  28.0  30.0\n",
      "\n",
      "5. Missing data summary:\n",
      "  diagnosis_binary    :   41 missing ( 10.9%)\n",
      "  age                 :    0 missing (  0.0%)\n",
      "  mmse                :    2 missing (  0.5%)\n",
      "  cdr                 :    4 missing (  1.1%)\n",
      "  nifti_path          :    0 missing (  0.0%)\n",
      "\n",
      "================================================================================\n",
      "SAVING MASTER VISIT METADATA\n",
      "================================================================================\n",
      "\n",
      "✓ Saved master table to: master_visit_metadata.csv\n",
      "  Total rows: 377\n",
      "  Total columns: 26\n",
      "  File size: 78.33 KB\n",
      "\n",
      "Columns in master table:\n",
      "   1. dataset\n",
      "   2. visit_uid\n",
      "   3. subject_id\n",
      "   4. visit_code\n",
      "   5. nifti_path\n",
      "   6. filename\n",
      "   7. diagnosis_binary\n",
      "   8. age\n",
      "   9. sex\n",
      "  10. group\n",
      "  11. mmse\n",
      "  12. cdr\n",
      "  13. education\n",
      "  14. ses\n",
      "  15. visit_number\n",
      "  16. mr_delay_days\n",
      "  17. etiv\n",
      "  18. nwbv\n",
      "  19. asf\n",
      "  20. days_to_visit\n",
      "  21. memory\n",
      "  22. orient\n",
      "  23. judgment\n",
      "  24. commun\n",
      "  25. homehobb\n",
      "  26. session_label\n",
      "\n",
      "================================================================================\n",
      "MASTER TABLE PREVIEW\n",
      "================================================================================\n",
      "\n",
      "Sample rows (first 10):\n",
      "  dataset subject_id visit_code  diagnosis_binary   age  mmse\n",
      "0  OASIS2  OAS2_0001        MR1               0.0  87.0  27.0\n",
      "1  OASIS2  OAS2_0001        MR2               0.0  88.0  30.0\n",
      "2  OASIS2  OAS2_0002        MR1               1.0  75.0  23.0\n",
      "3  OASIS2  OAS2_0002        MR2               1.0  76.0  28.0\n",
      "4  OASIS2  OAS2_0002        MR3               1.0  80.0  22.0\n",
      "5  OASIS2  OAS2_0004        MR1               0.0  88.0  28.0\n",
      "6  OASIS2  OAS2_0004        MR2               0.0  90.0  27.0\n",
      "7  OASIS2  OAS2_0005        MR1               0.0  80.0  28.0\n",
      "8  OASIS2  OAS2_0005        MR2               0.0  83.0  29.0\n",
      "9  OASIS2  OAS2_0005        MR3               0.0  85.0  30.0\n",
      "\n",
      "================================================================================\n",
      "SNIPPET S4 COMPLETE\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "SNIPPET S4: Clinical Data Merge\n",
    "Merge visit_level_index.csv with clinical data (CDR, MMSE, demographics)\n",
    "      to create master_visit_metadata.csv with diagnosis labels.\n",
    "\n",
    "Merge Strategy:\n",
    "- OASIS2: Join on MRI_ID (subject_id + \"_\" + visit_code)\n",
    "- OASIS3: Join on (subject_id, visit_code extracted from session_label)\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"SNIPPET S4: CLINICAL DATA MERGE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 1: Load Visit-Level Index\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"LOADING VISIT-LEVEL INDEX\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "visit_df = pd.read_csv(\"visit_level_index.csv\")\n",
    "\n",
    "print(f\"\\nLoaded visit_level_index.csv\")\n",
    "print(f\"  Total visits: {len(visit_df)}\")\n",
    "print(f\"  OASIS2: {(visit_df['dataset'] == 'OASIS2').sum()}\")\n",
    "print(f\"  OASIS3: {(visit_df['dataset'] == 'OASIS3').sum()}\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 2: OASIS2 - Load and Inspect Clinical Data\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"OASIS2: LOADING CLINICAL DATA\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "o2_clin_path = \"/kaggle/input/mri-and-alzheimers/oasis_longitudinal.csv\"\n",
    "\n",
    "try:\n",
    "    o2_clin = pd.read_csv(o2_clin_path)\n",
    "    print(f\"\\n✓ Loaded: {o2_clin_path}\")\n",
    "    print(f\"  Rows: {len(o2_clin)}\")\n",
    "    print(f\"  Columns: {len(o2_clin.columns)}\")\n",
    "    \n",
    "    # Show columns\n",
    "    print(\"\\nAvailable columns:\")\n",
    "    for i, col in enumerate(o2_clin.columns, 1):\n",
    "        print(f\"  {i:2d}. {col}\")\n",
    "    \n",
    "    # Show sample\n",
    "    print(\"\\nFirst 3 rows:\")\n",
    "    print(o2_clin.head(3).to_string())\n",
    "    \n",
    "    o2_clinical_available = True\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(f\"\\n⚠ WARNING: Clinical file not found at {o2_clin_path}\")\n",
    "    print(\"  Continuing without OASIS2 clinical data...\")\n",
    "    o2_clinical_available = False\n",
    "    o2_clin = pd.DataFrame()\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 3: OASIS2 - Merge Imaging + Clinical\n",
    "# ============================================================================\n",
    "\n",
    "if o2_clinical_available:\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"OASIS2: MERGING IMAGING + CLINICAL\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Subset OASIS2 imaging visits\n",
    "    o2_img = visit_df[visit_df['dataset'] == 'OASIS2'].copy()\n",
    "    print(f\"\\nOASIS2 imaging visits: {len(o2_img)}\")\n",
    "    \n",
    "    # Create MRI_ID key for matching\n",
    "    o2_img['MRI_ID_KEY'] = o2_img['subject_id'] + '_' + o2_img['visit_code']\n",
    "    print(f\"  Sample MRI_ID_KEY: {o2_img['MRI_ID_KEY'].iloc[0]}\")\n",
    "    \n",
    "    # Determine clinical merge key\n",
    "    # Common column names: 'MRI ID', 'MRI_ID', 'MRIID'\n",
    "    merge_key_candidates = ['MRI ID', 'MRI_ID', 'MRIID', 'mri_id']\n",
    "    clinical_merge_key = None\n",
    "    \n",
    "    for key in merge_key_candidates:\n",
    "        if key in o2_clin.columns:\n",
    "            clinical_merge_key = key\n",
    "            break\n",
    "    \n",
    "    if clinical_merge_key is None:\n",
    "        print(\"\\n⚠ ERROR: Could not find MRI ID column in clinical data\")\n",
    "        print(\"  Available columns:\", o2_clin.columns.tolist())\n",
    "        raise ValueError(\"Cannot merge OASIS2 - missing MRI ID column\")\n",
    "    \n",
    "    print(f\"\\nMerge key found: '{clinical_merge_key}'\")\n",
    "    print(f\"  Sample clinical key: {o2_clin[clinical_merge_key].iloc[0]}\")\n",
    "    \n",
    "    # Merge\n",
    "    o2_merged = pd.merge(\n",
    "        left=o2_img,\n",
    "        right=o2_clin,\n",
    "        left_on='MRI_ID_KEY',\n",
    "        right_on=clinical_merge_key,\n",
    "        how='inner'\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n✓ Merge complete\")\n",
    "    print(f\"  Imaging visits: {len(o2_img)}\")\n",
    "    print(f\"  Clinical rows:  {len(o2_clin)}\")\n",
    "    print(f\"  Merged rows:    {len(o2_merged)}\")\n",
    "    print(f\"  Match rate:     {100*len(o2_merged)/len(o2_img):.1f}%\")\n",
    "    \n",
    "    # Check for Group column\n",
    "    group_col_candidates = ['Group', 'GROUP', 'group', 'diagnosis']\n",
    "    group_col = None\n",
    "    for col in group_col_candidates:\n",
    "        if col in o2_merged.columns:\n",
    "            group_col = col\n",
    "            break\n",
    "    \n",
    "    if group_col:\n",
    "        print(f\"\\nGroup distribution ('{group_col}'):\")\n",
    "        print(o2_merged[group_col].value_counts())\n",
    "        \n",
    "        # Create diagnosis_binary\n",
    "        # Nondemented -> CN (0)\n",
    "        # Demented -> AD (1)\n",
    "        # Others (Converted, etc.) -> NaN\n",
    "        def map_diagnosis_o2(group_val):\n",
    "            if pd.isna(group_val):\n",
    "                return np.nan\n",
    "            group_str = str(group_val).strip().lower()\n",
    "            if 'nondemented' in group_str:\n",
    "                return 0  # CN\n",
    "            elif 'demented' in group_str and 'non' not in group_str:\n",
    "                return 1  # AD\n",
    "            else:\n",
    "                return np.nan  # MCI/Converted/Unknown\n",
    "        \n",
    "        o2_merged['diagnosis_binary'] = o2_merged[group_col].apply(map_diagnosis_o2)\n",
    "        \n",
    "        print(\"\\nDiagnosis mapping:\")\n",
    "        print(f\"  CN (0): {(o2_merged['diagnosis_binary'] == 0).sum()}\")\n",
    "        print(f\"  AD (1): {(o2_merged['diagnosis_binary'] == 1).sum()}\")\n",
    "        print(f\"  Unknown/MCI (NaN): {o2_merged['diagnosis_binary'].isna().sum()}\")\n",
    "    else:\n",
    "        print(\"\\n⚠ WARNING: No Group column found\")\n",
    "        o2_merged['diagnosis_binary'] = np.nan\n",
    "    \n",
    "    # Standardize column names\n",
    "    column_mapping = {\n",
    "        'Subject ID': 'subject_id_clin',\n",
    "        'MRI ID': 'mri_id_clin',\n",
    "        'M/F': 'sex',\n",
    "        'Age': 'age',\n",
    "        'Group': 'group',\n",
    "        'Visit': 'visit_number',\n",
    "        'MR Delay': 'mr_delay_days',\n",
    "        'EDUC': 'education',\n",
    "        'SES': 'ses',\n",
    "        'MMSE': 'mmse',\n",
    "        'CDR': 'cdr',\n",
    "        'eTIV': 'etiv',\n",
    "        'nWBV': 'nwbv',\n",
    "        'ASF': 'asf'\n",
    "    }\n",
    "    \n",
    "    # Apply renaming (only for columns that exist)\n",
    "    rename_dict = {k: v for k, v in column_mapping.items() if k in o2_merged.columns}\n",
    "    o2_merged.rename(columns=rename_dict, inplace=True)\n",
    "    \n",
    "    print(\"\\nStandardized column names applied\")\n",
    "    \n",
    "    # Select columns for master table\n",
    "    master_cols = [\n",
    "        'dataset', 'visit_uid', 'subject_id', 'visit_code', 'nifti_path', 'filename',\n",
    "        'diagnosis_binary'\n",
    "    ]\n",
    "    \n",
    "    # Add optional columns if they exist\n",
    "    optional_cols = ['age', 'sex', 'group', 'mmse', 'cdr', 'education', 'ses', \n",
    "                     'visit_number', 'mr_delay_days', 'etiv', 'nwbv', 'asf']\n",
    "    \n",
    "    for col in optional_cols:\n",
    "        if col in o2_merged.columns:\n",
    "            master_cols.append(col)\n",
    "    \n",
    "    o2_final = o2_merged[master_cols].copy()\n",
    "    \n",
    "    print(f\"\\nOASIS2 final columns: {len(o2_final.columns)}\")\n",
    "    print(f\"  Columns: {o2_final.columns.tolist()}\")\n",
    "\n",
    "else:\n",
    "    print(\"\\nSkipping OASIS2 merge (no clinical data available)\")\n",
    "    o2_final = pd.DataFrame()\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 4: OASIS3 - Load and Inspect Clinical Data\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"OASIS3: LOADING CLINICAL DATA\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "o3_clin_path = \"/kaggle/input/oaisis-3-longitiudinal/oaisis3longitiudinal.csv\"\n",
    "\n",
    "try:\n",
    "    o3_clin = pd.read_csv(o3_clin_path)\n",
    "    print(f\"\\n✓ Loaded: {o3_clin_path}\")\n",
    "    print(f\"  Rows: {len(o3_clin)}\")\n",
    "    print(f\"  Columns: {len(o3_clin.columns)}\")\n",
    "    \n",
    "    # Show columns\n",
    "    print(\"\\nAvailable columns:\")\n",
    "    for i, col in enumerate(o3_clin.columns, 1):\n",
    "        print(f\"  {i:2d}. {col}\")\n",
    "    \n",
    "    # Show sample\n",
    "    print(\"\\nFirst 3 rows:\")\n",
    "    pd.set_option('display.max_columns', 15)\n",
    "    print(o3_clin.head(3).to_string())\n",
    "    \n",
    "    o3_clinical_available = True\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(f\"\\n⚠ WARNING: Clinical file not found at {o3_clin_path}\")\n",
    "    print(\"  Continuing without OASIS3 clinical data...\")\n",
    "    o3_clinical_available = False\n",
    "    o3_clin = pd.DataFrame()\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 5: OASIS3 - Merge Imaging + Clinical\n",
    "# ============================================================================\n",
    "\n",
    "if o3_clinical_available:\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"OASIS3: MERGING IMAGING + CLINICAL\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Subset OASIS3 imaging visits\n",
    "    o3_img = visit_df[visit_df['dataset'] == 'OASIS3'].copy()\n",
    "    print(f\"\\nOASIS3 imaging visits: {len(o3_img)}\")\n",
    "    \n",
    "    # Extract session_code from OASIS_session_label\n",
    "    # Example: \"OAS30001_UDSb4_d0000\" -> \"d0000\"\n",
    "    def extract_session_code(label):\n",
    "        \"\"\"Extract dXXXX code from session label\"\"\"\n",
    "        if pd.isna(label):\n",
    "            return np.nan\n",
    "        parts = str(label).split('_')\n",
    "        return parts[-1]  # Last part should be dXXXX\n",
    "    \n",
    "    # Find session label column\n",
    "    session_col_candidates = ['OASIS_session_label', 'session_label', 'Session', 'SESSION']\n",
    "    session_col = None\n",
    "    for col in session_col_candidates:\n",
    "        if col in o3_clin.columns:\n",
    "            session_col = col\n",
    "            break\n",
    "    \n",
    "    if session_col is None:\n",
    "        print(\"\\n⚠ ERROR: Could not find session label column\")\n",
    "        print(\"  Available columns:\", o3_clin.columns.tolist())\n",
    "        raise ValueError(\"Cannot merge OASIS3 - missing session label\")\n",
    "    \n",
    "    print(f\"\\nSession label column: '{session_col}'\")\n",
    "    o3_clin['session_code'] = o3_clin[session_col].apply(extract_session_code)\n",
    "    \n",
    "    print(f\"  Sample session codes: {o3_clin['session_code'].head(3).tolist()}\")\n",
    "    \n",
    "    # Find subject ID column\n",
    "    subject_col_candidates = ['OASISID', 'Subject', 'subject_id', 'SUBJECT_ID']\n",
    "    subject_col = None\n",
    "    for col in subject_col_candidates:\n",
    "        if col in o3_clin.columns:\n",
    "            subject_col = col\n",
    "            break\n",
    "    \n",
    "    if subject_col is None:\n",
    "        print(\"\\n⚠ ERROR: Could not find subject ID column\")\n",
    "        raise ValueError(\"Cannot merge OASIS3 - missing subject ID\")\n",
    "    \n",
    "    print(f\"Subject ID column: '{subject_col}'\")\n",
    "    \n",
    "    # Merge on (subject_id, visit_code) = (OASISID, session_code)\n",
    "    o3_merged = pd.merge(\n",
    "        left=o3_img,\n",
    "        right=o3_clin,\n",
    "        left_on=['subject_id', 'visit_code'],\n",
    "        right_on=[subject_col, 'session_code'],\n",
    "        how='inner'\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n✓ Merge complete\")\n",
    "    print(f\"  Imaging visits: {len(o3_img)}\")\n",
    "    print(f\"  Clinical rows:  {len(o3_clin)}\")\n",
    "    print(f\"  Merged rows:    {len(o3_merged)}\")\n",
    "    print(f\"  Match rate:     {100*len(o3_merged)/len(o3_img):.1f}%\")\n",
    "    \n",
    "    # Look for CDR column (global CDR for diagnosis)\n",
    "    cdr_col_candidates = ['cdr_global', 'CDR', 'cdr', 'CDRGLOB']\n",
    "    cdr_col = None\n",
    "    for col in cdr_col_candidates:\n",
    "        if col in o3_merged.columns:\n",
    "            cdr_col = col\n",
    "            break\n",
    "    \n",
    "    if cdr_col:\n",
    "        print(f\"\\nCDR column found: '{cdr_col}'\")\n",
    "        print(\"CDR distribution:\")\n",
    "        print(o3_merged[cdr_col].value_counts().sort_index())\n",
    "        \n",
    "        # Create diagnosis_binary\n",
    "        # CDR = 0.0 -> CN (0)\n",
    "        # CDR >= 1.0 -> AD (1)\n",
    "        # CDR = 0.5 -> MCI (NaN, will exclude later)\n",
    "        def map_diagnosis_o3(cdr_val):\n",
    "            if pd.isna(cdr_val):\n",
    "                return np.nan\n",
    "            try:\n",
    "                cdr_float = float(cdr_val)\n",
    "                if cdr_float == 0.0:\n",
    "                    return 0  # CN\n",
    "                elif cdr_float >= 1.0:\n",
    "                    return 1  # AD\n",
    "                else:\n",
    "                    return np.nan  # MCI (0.5)\n",
    "            except (ValueError, TypeError):\n",
    "                return np.nan\n",
    "        \n",
    "        o3_merged['diagnosis_binary'] = o3_merged[cdr_col].apply(map_diagnosis_o3)\n",
    "        \n",
    "        print(\"\\nDiagnosis mapping:\")\n",
    "        print(f\"  CN (0): {(o3_merged['diagnosis_binary'] == 0).sum()}\")\n",
    "        print(f\"  AD (1): {(o3_merged['diagnosis_binary'] == 1).sum()}\")\n",
    "        print(f\"  MCI/Unknown (NaN): {o3_merged['diagnosis_binary'].isna().sum()}\")\n",
    "    else:\n",
    "        print(\"\\n⚠ WARNING: No CDR column found\")\n",
    "        print(\"  Available columns:\", o3_merged.columns.tolist())\n",
    "        o3_merged['diagnosis_binary'] = np.nan\n",
    "    \n",
    "    # Standardize column names\n",
    "    column_mapping = {\n",
    "        'OASISID': 'subject_id_clin',\n",
    "        'OASIS_session_label': 'session_label',\n",
    "        'age at visit': 'age',\n",
    "        'Age': 'age',\n",
    "        'MMSE': 'mmse',\n",
    "        'days_to_visit': 'days_to_visit',\n",
    "        'memory': 'memory',\n",
    "        'orient': 'orient',\n",
    "        'judgment': 'judgment',\n",
    "        'commun': 'commun',\n",
    "        'homehobb': 'homehobb',\n",
    "        cdr_col: 'cdr' if cdr_col else None\n",
    "    }\n",
    "    \n",
    "    # Apply renaming\n",
    "    rename_dict = {k: v for k, v in column_mapping.items() if k and k in o3_merged.columns and v}\n",
    "    o3_merged.rename(columns=rename_dict, inplace=True)\n",
    "    \n",
    "    print(\"\\nStandardized column names applied\")\n",
    "    \n",
    "    # Select columns for master table\n",
    "    master_cols = [\n",
    "        'dataset', 'visit_uid', 'subject_id', 'visit_code', 'nifti_path', 'filename',\n",
    "        'diagnosis_binary'\n",
    "    ]\n",
    "    \n",
    "    # Add optional columns if they exist\n",
    "    optional_cols = ['age', 'mmse', 'cdr', 'days_to_visit', 'memory', 'orient', \n",
    "                     'judgment', 'commun', 'homehobb', 'session_label']\n",
    "    \n",
    "    for col in optional_cols:\n",
    "        if col in o3_merged.columns:\n",
    "            master_cols.append(col)\n",
    "    \n",
    "    o3_final = o3_merged[master_cols].copy()\n",
    "    \n",
    "    print(f\"\\nOASIS3 final columns: {len(o3_final.columns)}\")\n",
    "    print(f\"  Columns: {o3_final.columns.tolist()}\")\n",
    "\n",
    "else:\n",
    "    print(\"\\nSkipping OASIS3 merge (no clinical data available)\")\n",
    "    o3_final = pd.DataFrame()\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 6: Combine OASIS2 + OASIS3 into Master Table\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"CREATING MASTER VISIT METADATA\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Combine datasets\n",
    "master_parts = []\n",
    "if len(o2_final) > 0:\n",
    "    master_parts.append(o2_final)\n",
    "if len(o3_final) > 0:\n",
    "    master_parts.append(o3_final)\n",
    "\n",
    "if len(master_parts) == 0:\n",
    "    raise ValueError(\"No clinical data merged - cannot create master table\")\n",
    "\n",
    "master = pd.concat(master_parts, ignore_index=True)\n",
    "\n",
    "print(f\"\\n✓ Master table created\")\n",
    "print(f\"  Total visits: {len(master)}\")\n",
    "print(f\"  OASIS2: {(master['dataset'] == 'OASIS2').sum()}\")\n",
    "print(f\"  OASIS3: {(master['dataset'] == 'OASIS3').sum()}\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 7: Master Table Statistics\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"MASTER TABLE STATISTICS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Diagnosis distribution\n",
    "print(\"\\n1. Diagnosis distribution:\")\n",
    "diag_counts = master['diagnosis_binary'].value_counts(dropna=False)\n",
    "print(f\"  CN (0):  {diag_counts.get(0, 0):4d}\")\n",
    "print(f\"  AD (1):  {diag_counts.get(1, 0):4d}\")\n",
    "print(f\"  Unknown: {master['diagnosis_binary'].isna().sum():4d}\")\n",
    "\n",
    "# Per-dataset diagnosis\n",
    "print(\"\\n2. Diagnosis by dataset:\")\n",
    "for dataset in ['OASIS2', 'OASIS3']:\n",
    "    mask = master['dataset'] == dataset\n",
    "    if mask.sum() > 0:\n",
    "        cn = ((master['diagnosis_binary'] == 0) & mask).sum()\n",
    "        ad = ((master['diagnosis_binary'] == 1) & mask).sum()\n",
    "        unk = (master['diagnosis_binary'].isna() & mask).sum()\n",
    "        print(f\"\\n   {dataset}:\")\n",
    "        print(f\"     CN:  {cn:4d}\")\n",
    "        print(f\"     AD:  {ad:4d}\")\n",
    "        print(f\"     Unknown: {unk:4d}\")\n",
    "\n",
    "# Age statistics\n",
    "if 'age' in master.columns:\n",
    "    print(\"\\n3. Age statistics:\")\n",
    "    age_stats = master.groupby('diagnosis_binary')['age'].describe()\n",
    "    print(age_stats)\n",
    "\n",
    "# MMSE statistics\n",
    "if 'mmse' in master.columns:\n",
    "    print(\"\\n4. MMSE statistics:\")\n",
    "    print(f\"  Available: {master['mmse'].notna().sum()}/{len(master)}\")\n",
    "    mmse_stats = master.groupby('diagnosis_binary')['mmse'].describe()\n",
    "    print(mmse_stats)\n",
    "\n",
    "# Missing data summary\n",
    "print(\"\\n5. Missing data summary:\")\n",
    "key_cols = ['diagnosis_binary', 'age', 'mmse', 'cdr', 'nifti_path']\n",
    "for col in key_cols:\n",
    "    if col in master.columns:\n",
    "        n_missing = master[col].isna().sum()\n",
    "        pct = 100 * n_missing / len(master)\n",
    "        print(f\"  {col:20s}: {n_missing:4d} missing ({pct:5.1f}%)\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 8: Save Master Table\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SAVING MASTER VISIT METADATA\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "output_file = \"master_visit_metadata.csv\"\n",
    "master.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"\\n✓ Saved master table to: {output_file}\")\n",
    "print(f\"  Total rows: {len(master)}\")\n",
    "print(f\"  Total columns: {len(master.columns)}\")\n",
    "print(f\"  File size: {Path(output_file).stat().st_size / 1024:.2f} KB\")\n",
    "\n",
    "print(\"\\nColumns in master table:\")\n",
    "for i, col in enumerate(master.columns, 1):\n",
    "    print(f\"  {i:2d}. {col}\")\n",
    "\n",
    "# Show sample rows\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"MASTER TABLE PREVIEW\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "display_cols = ['dataset', 'subject_id', 'visit_code', 'diagnosis_binary', 'age', 'mmse']\n",
    "display_cols = [col for col in display_cols if col in master.columns]\n",
    "\n",
    "print(\"\\nSample rows (first 10):\")\n",
    "print(master[display_cols].head(10).to_string())\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SNIPPET S4 COMPLETE\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8695bfbd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T18:51:01.573249Z",
     "iopub.status.busy": "2025-11-17T18:51:01.573063Z",
     "iopub.status.idle": "2025-11-17T18:51:02.397413Z",
     "shell.execute_reply": "2025-11-17T18:51:02.396225Z"
    },
    "papermill": {
     "duration": 0.840435,
     "end_time": "2025-11-17T18:51:02.398759",
     "exception": false,
     "start_time": "2025-11-17T18:51:01.558324",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SNIPPET S4B: OASIS-3 NEAREST-NEIGHBOR TEMPORAL MERGE (FIX)\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "LOADING DATA\n",
      "================================================================================\n",
      "\n",
      "Loaded visit_level_index.csv: 796 rows\n",
      "OASIS-3 imaging visits: 423\n",
      "\n",
      "Loaded clinical data: /kaggle/input/oaisis-3-longitiudinal/oaisis3longitiudinal.csv\n",
      "  Clinical rows: 8626\n",
      "  Unique subjects: 1378\n",
      "\n",
      "================================================================================\n",
      "EXTRACTING MRI VISIT DAYS\n",
      "================================================================================\n",
      "\n",
      "Converted 423/423 visit codes to days\n",
      "\n",
      "Sample conversions:\n",
      "subject_id visit_code  visit_days\n",
      "  OAS30001      d0129         129\n",
      "  OAS30001      d0757         757\n",
      "  OAS30006      d2341        2341\n",
      "  OAS30006      d2342        2342\n",
      "  OAS30011      d0055          55\n",
      "\n",
      "Visit days statistics:\n",
      "  Min:    0 days\n",
      "  Median: 436 days\n",
      "  Max:    8651 days\n",
      "\n",
      "================================================================================\n",
      "PREPARING CLINICAL DATA\n",
      "================================================================================\n",
      "\n",
      "Subjects with clinical data: 1378\n",
      "Subjects with imaging data:  300\n",
      "Subjects in both:            300\n",
      "Imaging-only subjects:       0\n",
      "Clinical-only subjects:      1078\n",
      "\n",
      "Clinical visit days statistics:\n",
      "  Min:    -39520 days\n",
      "  Median: 1510 days\n",
      "  Max:    12334 days\n",
      "\n",
      "================================================================================\n",
      "NEAREST-NEIGHBOR TEMPORAL MATCHING\n",
      "================================================================================\n",
      "\n",
      "Matching parameters:\n",
      "  Max temporal delta: 365 days (±1 year)\n",
      "\n",
      "Processing 300 subjects...\n",
      "  Progress: 50/300 subjects...\n",
      "  Progress: 100/300 subjects...\n",
      "  Progress: 150/300 subjects...\n",
      "  Progress: 200/300 subjects...\n",
      "  Progress: 250/300 subjects...\n",
      "  Progress: 300/300 subjects...\n",
      "\n",
      "✓ Matching complete\n",
      "\n",
      "================================================================================\n",
      "BUILDING MATCHED DATAFRAME\n",
      "================================================================================\n",
      "\n",
      "Matching results:\n",
      "  Imaging visits:     423\n",
      "  Matched visits:     416\n",
      "  Unmatched visits:   7\n",
      "  Match rate:         98.3%\n",
      "\n",
      "Temporal matching quality:\n",
      "  Mean delta:   91.6 days\n",
      "  Median delta: 84.0 days\n",
      "  90th percentile: 166.0 days\n",
      "  Max delta:    302.0 days\n",
      "\n",
      "Delta distribution:\n",
      "  0-30 days      :   44 ( 10.6%)\n",
      "  31-90 days     :  178 ( 42.8%)\n",
      "  91-180 days    :  166 ( 39.9%)\n",
      "  181-365 days   :   24 (  5.8%)\n",
      "\n",
      "================================================================================\n",
      "CREATING DIAGNOSIS LABELS\n",
      "================================================================================\n",
      "\n",
      "Using CDR column: 'CDRTOT'\n",
      "\n",
      "CDR distribution:\n",
      "  CDR 0.0:  293\n",
      "  CDR 0.5:   89\n",
      "  CDR 1.0:   30\n",
      "  CDR 2.0:    4\n",
      "\n",
      "Diagnosis mapping:\n",
      "  CN (0):         293\n",
      "  AD (1):         34\n",
      "  Unknown/MCI:    89\n",
      "\n",
      "================================================================================\n",
      "STANDARDIZING COLUMN NAMES\n",
      "================================================================================\n",
      "\n",
      "Renamed 10 columns\n",
      "\n",
      "================================================================================\n",
      "SELECTING FINAL COLUMNS\n",
      "================================================================================\n",
      "\n",
      "OASIS-3 final columns: 18\n",
      "   1. dataset\n",
      "   2. visit_uid\n",
      "   3. subject_id\n",
      "   4. visit_code\n",
      "   5. nifti_path\n",
      "   6. filename\n",
      "   7. diagnosis_binary\n",
      "   8. age\n",
      "   9. mmse\n",
      "  10. cdr\n",
      "  11. days_to_visit\n",
      "  12. match_delta_days\n",
      "  13. memory\n",
      "  14. orient\n",
      "  15. judgment\n",
      "  16. commun\n",
      "  17. homehobb\n",
      "  18. session_label\n",
      "\n",
      "================================================================================\n",
      "REBUILDING MASTER TABLE\n",
      "================================================================================\n",
      "\n",
      "Loaded OASIS-2 from previous master: 373 visits\n",
      "\n",
      "✓ Master table created\n",
      "  Total visits: 789\n",
      "  OASIS-2: 373\n",
      "  OASIS-3: 416\n",
      "\n",
      "================================================================================\n",
      "MASTER TABLE STATISTICS\n",
      "================================================================================\n",
      "\n",
      "1. Overall diagnosis distribution:\n",
      "  CN (0):      483 (72.9%)\n",
      "  AD (1):      180 (27.1%)\n",
      "  Unknown:     126\n",
      "  Total valid: 663\n",
      "\n",
      "2. Diagnosis by dataset:\n",
      "\n",
      "   OASIS2:\n",
      "     CN:       190 (56.5% if total > 0)\n",
      "     AD:       146 (43.5% if total > 0)\n",
      "     Unknown:   37\n",
      "\n",
      "   OASIS3:\n",
      "     CN:       293 (89.6% if total > 0)\n",
      "     AD:        34 (10.4% if total > 0)\n",
      "     Unknown:   89\n",
      "\n",
      "3. Age statistics by diagnosis:\n",
      "                  count       mean       std   min    25%   50%   75%   max\n",
      "diagnosis_binary                                                           \n",
      "0.0               483.0  74.837909  7.009512  60.0  69.22  74.0  80.0  97.0\n",
      "1.0               180.0  76.400833  6.846320  61.0  71.00  76.0  81.0  98.0\n",
      "\n",
      "4. MMSE statistics:\n",
      "  Available: 786/789 (99.6%)\n",
      "                  count       mean       std   min   25%   50%   75%   max\n",
      "diagnosis_binary                                                          \n",
      "0.0               483.0  29.018634  1.259678  21.0  28.5  29.0  30.0  30.0\n",
      "1.0               178.0  23.910112  4.743453   4.0  21.0  25.0  27.0  30.0\n",
      "\n",
      "================================================================================\n",
      "SAVING UPDATED MASTER TABLE\n",
      "================================================================================\n",
      "\n",
      "✓ Saved updated master table to: master_visit_metadata.csv\n",
      "  Total rows: 789\n",
      "  Total columns: 27\n",
      "  File size: 180.45 KB\n",
      "\n",
      "================================================================================\n",
      "MASTER TABLE PREVIEW\n",
      "================================================================================\n",
      "\n",
      "Sample rows (5 from each dataset):\n",
      "\n",
      "OASIS2:\n",
      "dataset subject_id visit_code  diagnosis_binary  age  mmse\n",
      " OASIS2  OAS2_0001        MR1               0.0 87.0  27.0\n",
      " OASIS2  OAS2_0001        MR2               0.0 88.0  30.0\n",
      " OASIS2  OAS2_0002        MR1               1.0 75.0  23.0\n",
      " OASIS2  OAS2_0002        MR2               1.0 76.0  28.0\n",
      " OASIS2  OAS2_0002        MR3               1.0 80.0  22.0\n",
      "\n",
      "OASIS3:\n",
      "dataset subject_id visit_code  diagnosis_binary   age  mmse\n",
      " OASIS3   OAS30001      d0129               0.0 65.19  28.0\n",
      " OASIS3   OAS30001      d0757               0.0 67.17  30.0\n",
      " OASIS3   OAS30006      d2341               0.0 68.34  30.0\n",
      " OASIS3   OAS30006      d2342               0.0 68.34  30.0\n",
      " OASIS3   OAS30011      d0055               0.0 78.52  28.0\n",
      "\n",
      "================================================================================\n",
      "SNIPPET S4B COMPLETE\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "SNIPPET S4B: OASIS-3 Nearest-Neighbor Temporal Merge\n",
    "Fix OASIS-3 merge using temporal nearest-neighbor matching\n",
    "      instead of exact visit code matching.\n",
    "\n",
    "Problem: MRI visits (d0129, d0757) don't match clinical visit days (0, 339, 722)\n",
    "Solution: Match each MRI to the nearest clinical visit within ±365 days\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"SNIPPET S4B: OASIS-3 NEAREST-NEIGHBOR TEMPORAL MERGE (FIX)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 1: Load Data\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"LOADING DATA\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Load visit-level index\n",
    "visit_df = pd.read_csv(\"visit_level_index.csv\")\n",
    "print(f\"\\nLoaded visit_level_index.csv: {len(visit_df)} rows\")\n",
    "\n",
    "# Subset OASIS-3 imaging visits\n",
    "o3_img = visit_df[visit_df['dataset'] == 'OASIS3'].copy()\n",
    "print(f\"OASIS-3 imaging visits: {len(o3_img)}\")\n",
    "\n",
    "# Load OASIS-3 clinical data\n",
    "o3_clin_path = \"/kaggle/input/oaisis-3-longitiudinal/oaisis3longitiudinal.csv\"\n",
    "\n",
    "try:\n",
    "    o3_clin = pd.read_csv(o3_clin_path)\n",
    "    print(f\"\\nLoaded clinical data: {o3_clin_path}\")\n",
    "    print(f\"  Clinical rows: {len(o3_clin)}\")\n",
    "    print(f\"  Unique subjects: {o3_clin['OASISID'].nunique()}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"\\n⚠ ERROR: Clinical file not found at {o3_clin_path}\")\n",
    "    raise\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 2: Extract Visit Days from MRI Visit Codes\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"EXTRACTING MRI VISIT DAYS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "def code_to_days(code):\n",
    "    \"\"\"\n",
    "    Convert visit code like \"d0129\" to integer days (129).\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    code : str\n",
    "        Visit code like \"d0129\", \"d0757\"\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    int or NaN\n",
    "        Integer days or NaN if parsing fails\n",
    "    \"\"\"\n",
    "    if pd.isna(code):\n",
    "        return np.nan\n",
    "    \n",
    "    code = str(code).strip()\n",
    "    \n",
    "    if not code.startswith('d'):\n",
    "        return np.nan\n",
    "    \n",
    "    digits = code[1:]  # Remove 'd' prefix\n",
    "    \n",
    "    try:\n",
    "        return int(digits)\n",
    "    except (ValueError, TypeError):\n",
    "        return np.nan\n",
    "\n",
    "# Apply conversion\n",
    "o3_img['visit_days'] = o3_img['visit_code'].apply(code_to_days)\n",
    "\n",
    "# Check conversion success\n",
    "n_converted = o3_img['visit_days'].notna().sum()\n",
    "print(f\"\\nConverted {n_converted}/{len(o3_img)} visit codes to days\")\n",
    "\n",
    "if n_converted < len(o3_img):\n",
    "    print(f\"  ⚠ Warning: {len(o3_img) - n_converted} visit codes failed conversion\")\n",
    "    failed = o3_img[o3_img['visit_days'].isna()]['visit_code'].unique()\n",
    "    print(f\"  Failed codes: {failed[:5]}\")\n",
    "\n",
    "# Show sample conversions\n",
    "print(\"\\nSample conversions:\")\n",
    "sample = o3_img[['subject_id', 'visit_code', 'visit_days']].head(5)\n",
    "print(sample.to_string(index=False))\n",
    "\n",
    "# Statistics\n",
    "print(f\"\\nVisit days statistics:\")\n",
    "print(f\"  Min:    {o3_img['visit_days'].min():.0f} days\")\n",
    "print(f\"  Median: {o3_img['visit_days'].median():.0f} days\")\n",
    "print(f\"  Max:    {o3_img['visit_days'].max():.0f} days\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 3: Prepare Clinical Data\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"PREPARING CLINICAL DATA\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Ensure days_to_visit is numeric\n",
    "o3_clin['days_to_visit'] = pd.to_numeric(o3_clin['days_to_visit'], errors='coerce')\n",
    "\n",
    "# Check for subjects with clinical data\n",
    "n_subjects_clin = o3_clin['OASISID'].nunique()\n",
    "n_subjects_img = o3_img['subject_id'].nunique()\n",
    "\n",
    "print(f\"\\nSubjects with clinical data: {n_subjects_clin}\")\n",
    "print(f\"Subjects with imaging data:  {n_subjects_img}\")\n",
    "\n",
    "# Find overlap\n",
    "img_subjects = set(o3_img['subject_id'].unique())\n",
    "clin_subjects = set(o3_clin['OASISID'].unique())\n",
    "overlap = img_subjects & clin_subjects\n",
    "\n",
    "print(f\"Subjects in both:            {len(overlap)}\")\n",
    "print(f\"Imaging-only subjects:       {len(img_subjects - clin_subjects)}\")\n",
    "print(f\"Clinical-only subjects:      {len(clin_subjects - img_subjects)}\")\n",
    "\n",
    "# Show clinical visit days distribution\n",
    "print(f\"\\nClinical visit days statistics:\")\n",
    "print(f\"  Min:    {o3_clin['days_to_visit'].min():.0f} days\")\n",
    "print(f\"  Median: {o3_clin['days_to_visit'].median():.0f} days\")\n",
    "print(f\"  Max:    {o3_clin['days_to_visit'].max():.0f} days\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 4: Nearest-Neighbor Temporal Matching\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"NEAREST-NEIGHBOR TEMPORAL MATCHING\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "MAX_DELTA_DAYS = 365  # 1 year tolerance\n",
    "\n",
    "print(f\"\\nMatching parameters:\")\n",
    "print(f\"  Max temporal delta: {MAX_DELTA_DAYS} days (±1 year)\")\n",
    "\n",
    "matched_rows = []\n",
    "unmatched_count = 0\n",
    "delta_days_list = []\n",
    "\n",
    "# Get unique subjects with imaging\n",
    "subjects_to_process = o3_img['subject_id'].unique()\n",
    "\n",
    "print(f\"\\nProcessing {len(subjects_to_process)} subjects...\")\n",
    "\n",
    "for i, subj in enumerate(subjects_to_process, 1):\n",
    "    # Progress indicator\n",
    "    if i % 50 == 0:\n",
    "        print(f\"  Progress: {i}/{len(subjects_to_process)} subjects...\")\n",
    "    \n",
    "    # Get imaging visits for this subject\n",
    "    img_sub = o3_img[o3_img['subject_id'] == subj].copy()\n",
    "    \n",
    "    # Get clinical visits for this subject\n",
    "    clin_sub = o3_clin[o3_clin['OASISID'] == subj].copy()\n",
    "    \n",
    "    # Skip if no clinical data\n",
    "    if len(clin_sub) == 0:\n",
    "        unmatched_count += len(img_sub)\n",
    "        continue\n",
    "    \n",
    "    # Filter clinical rows with valid days_to_visit\n",
    "    clin_sub = clin_sub[clin_sub['days_to_visit'].notna()].copy()\n",
    "    \n",
    "    if len(clin_sub) == 0:\n",
    "        unmatched_count += len(img_sub)\n",
    "        continue\n",
    "    \n",
    "    # For each imaging visit, find nearest clinical visit\n",
    "    for idx_img in img_sub.index:\n",
    "        v_days = img_sub.loc[idx_img, 'visit_days']\n",
    "        \n",
    "        if pd.isna(v_days):\n",
    "            unmatched_count += 1\n",
    "            continue\n",
    "        \n",
    "        # Compute temporal distance to all clinical visits\n",
    "        clin_sub['delta_days'] = np.abs(clin_sub['days_to_visit'] - v_days)\n",
    "        \n",
    "        # Find best match\n",
    "        best_idx = clin_sub['delta_days'].idxmin()\n",
    "        best_delta = clin_sub.loc[best_idx, 'delta_days']\n",
    "        \n",
    "        # Check if within tolerance\n",
    "        if best_delta <= MAX_DELTA_DAYS:\n",
    "            # Merge imaging + clinical data\n",
    "            img_row = img_sub.loc[idx_img]\n",
    "            clin_row = clin_sub.loc[best_idx]\n",
    "            \n",
    "            # Create merged dictionary\n",
    "            merged_dict = {}\n",
    "            \n",
    "            # Add imaging columns\n",
    "            for col in img_row.index:\n",
    "                merged_dict[col] = img_row[col]\n",
    "            \n",
    "            # Add clinical columns (avoid overwriting imaging columns)\n",
    "            for col in clin_row.index:\n",
    "                if col not in merged_dict:\n",
    "                    merged_dict[col] = clin_row[col]\n",
    "                else:\n",
    "                    # Store clinical version with suffix if duplicate\n",
    "                    merged_dict[f\"{col}_clin\"] = clin_row[col]\n",
    "            \n",
    "            # Store delta for quality check\n",
    "            merged_dict['match_delta_days'] = best_delta\n",
    "            \n",
    "            matched_rows.append(merged_dict)\n",
    "            delta_days_list.append(best_delta)\n",
    "        else:\n",
    "            unmatched_count += 1\n",
    "\n",
    "print(f\"\\n✓ Matching complete\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 5: Build Matched DataFrame\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"BUILDING MATCHED DATAFRAME\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "o3_merged_nn = pd.DataFrame(matched_rows)\n",
    "\n",
    "print(f\"\\nMatching results:\")\n",
    "print(f\"  Imaging visits:     {len(o3_img)}\")\n",
    "print(f\"  Matched visits:     {len(o3_merged_nn)}\")\n",
    "print(f\"  Unmatched visits:   {unmatched_count}\")\n",
    "print(f\"  Match rate:         {100*len(o3_merged_nn)/len(o3_img):.1f}%\")\n",
    "\n",
    "# Show delta statistics\n",
    "if len(delta_days_list) > 0:\n",
    "    delta_array = np.array(delta_days_list)\n",
    "    print(f\"\\nTemporal matching quality:\")\n",
    "    print(f\"  Mean delta:   {delta_array.mean():.1f} days\")\n",
    "    print(f\"  Median delta: {np.median(delta_array):.1f} days\")\n",
    "    print(f\"  90th percentile: {np.percentile(delta_array, 90):.1f} days\")\n",
    "    print(f\"  Max delta:    {delta_array.max():.1f} days\")\n",
    "    \n",
    "    # Show delta distribution\n",
    "    print(f\"\\nDelta distribution:\")\n",
    "    bins = [0, 30, 90, 180, 365]\n",
    "    labels = ['0-30 days', '31-90 days', '91-180 days', '181-365 days']\n",
    "    for i, (low, high) in enumerate(zip(bins[:-1], bins[1:])):\n",
    "        count = ((delta_array > low) & (delta_array <= high)).sum()\n",
    "        pct = 100 * count / len(delta_array)\n",
    "        print(f\"  {labels[i]:15s}: {count:4d} ({pct:5.1f}%)\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 6: Extract CDR and Create Diagnosis Labels\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"CREATING DIAGNOSIS LABELS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Look for CDR column\n",
    "cdr_col_candidates = ['CDRTOT', 'cdr_global', 'CDR', 'cdr']\n",
    "cdr_col = None\n",
    "\n",
    "for col in cdr_col_candidates:\n",
    "    if col in o3_merged_nn.columns:\n",
    "        cdr_col = col\n",
    "        break\n",
    "\n",
    "if cdr_col is None:\n",
    "    print(\"\\n⚠ ERROR: No CDR column found\")\n",
    "    print(f\"  Available columns: {o3_merged_nn.columns.tolist()}\")\n",
    "    raise ValueError(\"Cannot create diagnosis labels - missing CDR\")\n",
    "\n",
    "print(f\"\\nUsing CDR column: '{cdr_col}'\")\n",
    "\n",
    "# Copy to standard 'cdr' column\n",
    "o3_merged_nn['cdr'] = o3_merged_nn[cdr_col]\n",
    "\n",
    "# Show CDR distribution\n",
    "print(\"\\nCDR distribution:\")\n",
    "cdr_counts = o3_merged_nn['cdr'].value_counts(dropna=False).sort_index()\n",
    "for cdr_val, count in cdr_counts.items():\n",
    "    print(f\"  CDR {cdr_val}: {count:4d}\")\n",
    "\n",
    "# Create diagnosis_binary\n",
    "def map_diagnosis_o3(cdr_val):\n",
    "    \"\"\"\n",
    "    Map CDR to binary diagnosis:\n",
    "    - CDR = 0.0 -> CN (0)\n",
    "    - CDR >= 1.0 -> AD (1)\n",
    "    - CDR = 0.5 or NaN -> Unknown/MCI (NaN)\n",
    "    \"\"\"\n",
    "    if pd.isna(cdr_val):\n",
    "        return np.nan\n",
    "    \n",
    "    try:\n",
    "        cdr_float = float(cdr_val)\n",
    "        if cdr_float == 0.0:\n",
    "            return 0  # CN\n",
    "        elif cdr_float >= 1.0:\n",
    "            return 1  # AD\n",
    "        else:\n",
    "            return np.nan  # MCI (0.5)\n",
    "    except (ValueError, TypeError):\n",
    "        return np.nan\n",
    "\n",
    "o3_merged_nn['diagnosis_binary'] = o3_merged_nn['cdr'].apply(map_diagnosis_o3)\n",
    "\n",
    "print(\"\\nDiagnosis mapping:\")\n",
    "print(f\"  CN (0):         {(o3_merged_nn['diagnosis_binary'] == 0).sum()}\")\n",
    "print(f\"  AD (1):         {(o3_merged_nn['diagnosis_binary'] == 1).sum()}\")\n",
    "print(f\"  Unknown/MCI:    {o3_merged_nn['diagnosis_binary'].isna().sum()}\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 7: Standardize Columns\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STANDARDIZING COLUMN NAMES\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Column mapping for consistency with OASIS-2\n",
    "column_mapping = {\n",
    "    'OASISID': 'subject_id_clin',\n",
    "    'OASIS_session_label': 'session_label',\n",
    "    'age at visit': 'age',\n",
    "    'MMSE': 'mmse',\n",
    "    'days_to_visit': 'days_to_visit',\n",
    "    'memory': 'memory',\n",
    "    'orient': 'orient',\n",
    "    'judgment': 'judgment',\n",
    "    'commun': 'commun',\n",
    "    'homehobb': 'homehobb'\n",
    "}\n",
    "\n",
    "# Apply renaming (only for columns that exist)\n",
    "rename_dict = {k: v for k, v in column_mapping.items() if k in o3_merged_nn.columns}\n",
    "o3_merged_nn.rename(columns=rename_dict, inplace=True)\n",
    "\n",
    "print(f\"\\nRenamed {len(rename_dict)} columns\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 8: Select Final Columns\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SELECTING FINAL COLUMNS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Core columns (must have)\n",
    "core_cols = [\n",
    "    'dataset', 'visit_uid', 'subject_id', 'visit_code', 'nifti_path', 'filename',\n",
    "    'diagnosis_binary'\n",
    "]\n",
    "\n",
    "# Optional columns (include if available)\n",
    "optional_cols = [\n",
    "    'age', 'mmse', 'cdr', 'days_to_visit', 'match_delta_days',\n",
    "    'memory', 'orient', 'judgment', 'commun', 'homehobb', 'session_label'\n",
    "]\n",
    "\n",
    "# Build final column list\n",
    "final_cols = []\n",
    "for col in core_cols:\n",
    "    if col in o3_merged_nn.columns:\n",
    "        final_cols.append(col)\n",
    "    else:\n",
    "        print(f\"  ⚠ Warning: Missing core column '{col}'\")\n",
    "\n",
    "for col in optional_cols:\n",
    "    if col in o3_merged_nn.columns:\n",
    "        final_cols.append(col)\n",
    "\n",
    "# Select columns\n",
    "o3_final = o3_merged_nn[final_cols].copy()\n",
    "\n",
    "print(f\"\\nOASIS-3 final columns: {len(o3_final.columns)}\")\n",
    "for i, col in enumerate(o3_final.columns, 1):\n",
    "    print(f\"  {i:2d}. {col}\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 9: Rebuild Master Table\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"REBUILDING MASTER TABLE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Load previous OASIS-2 data (if exists)\n",
    "try:\n",
    "    master_old = pd.read_csv(\"master_visit_metadata.csv\")\n",
    "    o2_final = master_old[master_old['dataset'] == 'OASIS2'].copy()\n",
    "    print(f\"\\nLoaded OASIS-2 from previous master: {len(o2_final)} visits\")\n",
    "except FileNotFoundError:\n",
    "    print(\"\\n⚠ Warning: Previous master_visit_metadata.csv not found\")\n",
    "    print(\"  Creating master table with OASIS-3 only\")\n",
    "    o2_final = pd.DataFrame()\n",
    "\n",
    "# Combine OASIS-2 and OASIS-3\n",
    "master_parts = []\n",
    "if len(o2_final) > 0:\n",
    "    master_parts.append(o2_final)\n",
    "if len(o3_final) > 0:\n",
    "    master_parts.append(o3_final)\n",
    "\n",
    "if len(master_parts) == 0:\n",
    "    raise ValueError(\"No data to combine into master table\")\n",
    "\n",
    "master = pd.concat(master_parts, ignore_index=True)\n",
    "\n",
    "print(f\"\\n✓ Master table created\")\n",
    "print(f\"  Total visits: {len(master)}\")\n",
    "print(f\"  OASIS-2: {(master['dataset'] == 'OASIS2').sum()}\")\n",
    "print(f\"  OASIS-3: {(master['dataset'] == 'OASIS3').sum()}\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 10: Final Statistics\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"MASTER TABLE STATISTICS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Overall diagnosis distribution\n",
    "print(\"\\n1. Overall diagnosis distribution:\")\n",
    "diag_counts = master['diagnosis_binary'].value_counts(dropna=False)\n",
    "total_valid = diag_counts.get(0, 0) + diag_counts.get(1, 0)\n",
    "print(f\"  CN (0):     {diag_counts.get(0, 0):4d} ({100*diag_counts.get(0, 0)/total_valid:.1f}%)\")\n",
    "print(f\"  AD (1):     {diag_counts.get(1, 0):4d} ({100*diag_counts.get(1, 0)/total_valid:.1f}%)\")\n",
    "print(f\"  Unknown:    {master['diagnosis_binary'].isna().sum():4d}\")\n",
    "print(f\"  Total valid: {total_valid}\")\n",
    "\n",
    "# Per-dataset diagnosis\n",
    "print(\"\\n2. Diagnosis by dataset:\")\n",
    "for dataset in ['OASIS2', 'OASIS3']:\n",
    "    mask = master['dataset'] == dataset\n",
    "    if mask.sum() > 0:\n",
    "        cn = ((master['diagnosis_binary'] == 0) & mask).sum()\n",
    "        ad = ((master['diagnosis_binary'] == 1) & mask).sum()\n",
    "        unk = (master['diagnosis_binary'].isna() & mask).sum()\n",
    "        total = cn + ad\n",
    "        print(f\"\\n   {dataset}:\")\n",
    "        print(f\"     CN:      {cn:4d} ({100*cn/total:.1f}% if total > 0)\")\n",
    "        print(f\"     AD:      {ad:4d} ({100*ad/total:.1f}% if total > 0)\")\n",
    "        print(f\"     Unknown: {unk:4d}\")\n",
    "\n",
    "# Age statistics\n",
    "if 'age' in master.columns:\n",
    "    print(\"\\n3. Age statistics by diagnosis:\")\n",
    "    age_stats = master[master['diagnosis_binary'].notna()].groupby('diagnosis_binary')['age'].describe()\n",
    "    print(age_stats)\n",
    "\n",
    "# MMSE statistics\n",
    "if 'mmse' in master.columns:\n",
    "    print(\"\\n4. MMSE statistics:\")\n",
    "    print(f\"  Available: {master['mmse'].notna().sum()}/{len(master)} ({100*master['mmse'].notna().sum()/len(master):.1f}%)\")\n",
    "    if master['mmse'].notna().sum() > 0:\n",
    "        mmse_stats = master[master['diagnosis_binary'].notna()].groupby('diagnosis_binary')['mmse'].describe()\n",
    "        print(mmse_stats)\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 11: Save Updated Master Table\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SAVING UPDATED MASTER TABLE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "output_file = \"master_visit_metadata.csv\"\n",
    "master.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"\\n✓ Saved updated master table to: {output_file}\")\n",
    "print(f\"  Total rows: {len(master)}\")\n",
    "print(f\"  Total columns: {len(master.columns)}\")\n",
    "print(f\"  File size: {Path(output_file).stat().st_size / 1024:.2f} KB\")\n",
    "\n",
    "# Preview\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"MASTER TABLE PREVIEW\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "display_cols = ['dataset', 'subject_id', 'visit_code', 'diagnosis_binary', 'age', 'mmse']\n",
    "display_cols = [col for col in display_cols if col in master.columns]\n",
    "\n",
    "print(\"\\nSample rows (5 from each dataset):\")\n",
    "for dataset in ['OASIS2', 'OASIS3']:\n",
    "    mask = master['dataset'] == dataset\n",
    "    if mask.sum() > 0:\n",
    "        print(f\"\\n{dataset}:\")\n",
    "        print(master[mask][display_cols].head(5).to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SNIPPET S4B COMPLETE\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d156cf0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T18:51:02.428320Z",
     "iopub.status.busy": "2025-11-17T18:51:02.427944Z",
     "iopub.status.idle": "2025-11-17T18:51:03.682618Z",
     "shell.execute_reply": "2025-11-17T18:51:03.681745Z"
    },
    "papermill": {
     "duration": 1.270677,
     "end_time": "2025-11-17T18:51:03.683874",
     "exception": false,
     "start_time": "2025-11-17T18:51:02.413197",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SNIPPET S5: CDR-CONSISTENT CN/AD LABELING + CLASSIFICATION COHORT\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "LOADING MASTER VISIT METADATA\n",
      "================================================================================\n",
      "\n",
      "Loaded master_visit_metadata.csv\n",
      "  Total rows: 789\n",
      "\n",
      "Dataset distribution:\n",
      "  OASIS3: 416\n",
      "  OASIS2: 373\n",
      "\n",
      "================================================================================\n",
      "INSPECTING CDR COLUMN\n",
      "================================================================================\n",
      "\n",
      "CDR missing: 0/789 (0.0%)\n",
      "\n",
      "CDR distribution (overall):\n",
      "  CDR 0.0:  499 ( 63.2%)\n",
      "  CDR 0.5:  212 ( 26.9%)\n",
      "  CDR 1.0:   71 (  9.0%)\n",
      "  CDR 2.0:    7 (  0.9%)\n",
      "\n",
      "CDR distribution by dataset:\n",
      "\n",
      "  OASIS2:\n",
      "    CDR 0.0:  206 ( 55.2%)\n",
      "    CDR 0.5:  123 ( 33.0%)\n",
      "    CDR 1.0:   41 ( 11.0%)\n",
      "    CDR 2.0:    3 (  0.8%)\n",
      "\n",
      "  OASIS3:\n",
      "    CDR 0.0:  293 ( 70.4%)\n",
      "    CDR 0.5:   89 ( 21.4%)\n",
      "    CDR 1.0:   30 (  7.2%)\n",
      "    CDR 2.0:    4 (  1.0%)\n",
      "\n",
      "================================================================================\n",
      "COMPARING OLD vs NEW LABELING APPROACH\n",
      "================================================================================\n",
      "\n",
      "Old diagnosis distribution:\n",
      "  CN (0):   483\n",
      "  AD (1):   180\n",
      "  Unknown:  126\n",
      "\n",
      "================================================================================\n",
      "APPLYING UNIFIED CDR-BASED DIAGNOSIS MAPPING\n",
      "================================================================================\n",
      "\n",
      "Mapping rules:\n",
      "  CN (0): CDR == 0.0\n",
      "  AD (1): CDR >= 1.0\n",
      "  MCI/Unknown (NaN): CDR == 0.5 or missing\n",
      "\n",
      "✓ Mapping applied\n",
      "\n",
      "================================================================================\n",
      "NEW DIAGNOSIS DISTRIBUTION\n",
      "================================================================================\n",
      "\n",
      "Overall diagnosis distribution:\n",
      "  CN (0):      499 (86.5%)\n",
      "  AD (1):       78 (13.5%)\n",
      "  Unknown:     212\n",
      "  Total valid: 577\n",
      "\n",
      "Diagnosis by dataset:\n",
      "\n",
      "  OASIS2:\n",
      "    Total visits:  373\n",
      "    CN (0):         206 (82.4% of valid)\n",
      "    AD (1):          44 (17.6% of valid)\n",
      "    Unknown/MCI:    123\n",
      "    CN/AD ratio:   4.68:1\n",
      "\n",
      "  OASIS3:\n",
      "    Total visits:  416\n",
      "    CN (0):         293 (89.6% of valid)\n",
      "    AD (1):          34 (10.4% of valid)\n",
      "    Unknown/MCI:     89\n",
      "    CN/AD ratio:   8.62:1\n",
      "\n",
      "================================================================================\n",
      "LABEL CHANGE ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "Label changes:\n",
      "  Unchanged:          559\n",
      "  Unknown → Valid:     18 (recovered)\n",
      "  Valid → Unknown:    104 (lost to MCI)\n",
      "  Value changed:        0 (0↔1)\n",
      "\n",
      "================================================================================\n",
      "BUILDING CLASSIFICATION COHORT\n",
      "================================================================================\n",
      "\n",
      "Classification cohort created\n",
      "  Total visits: 577\n",
      "  Excluded (MCI/Unknown): 212\n",
      "  Retention rate: 73.1%\n",
      "\n",
      "Visits by dataset:\n",
      "  OASIS3: 327\n",
      "  OASIS2: 250\n",
      "\n",
      "Labels in classification cohort:\n",
      "  CN (0):  499 (86.5%)\n",
      "  AD (1):   78 (13.5%)\n",
      "  CN/AD ratio: 6.40:1\n",
      "\n",
      "Label × Dataset cross-tabulation:\n",
      "diagnosis_binary  0.0  1.0  All\n",
      "dataset                        \n",
      "OASIS2            206   44  250\n",
      "OASIS3            293   34  327\n",
      "All               499   78  577\n",
      "\n",
      "================================================================================\n",
      "CLINICAL VARIABLE COMPLETENESS\n",
      "================================================================================\n",
      "\n",
      "Missing data in classification cohort:\n",
      "  age            :    0 missing (  0.0%)\n",
      "  mmse           :    2 missing (  0.3%)\n",
      "  cdr            :    0 missing (  0.0%)\n",
      "  sex            :  327 missing ( 56.7%)\n",
      "  education      :  327 missing ( 56.7%)\n",
      "\n",
      "================================================================================\n",
      "DESCRIPTIVE STATISTICS BY DIAGNOSIS\n",
      "================================================================================\n",
      "\n",
      "Age statistics:\n",
      "                  count       mean       std   min    25%     50%   75%   max\n",
      "diagnosis_binary                                                             \n",
      "0.0               499.0  74.949319  7.067182  60.0  69.22  74.000  80.0  97.0\n",
      "1.0                78.0  76.053205  6.872498  61.0  71.00  76.215  80.0  98.0\n",
      "\n",
      "  t-test: t=-1.288, p=0.1984\n",
      "\n",
      "MMSE statistics:\n",
      "                  count       mean       std   min   25%   50%   75%   max\n",
      "diagnosis_binary                                                          \n",
      "0.0               499.0  29.024048  1.260866  21.0  29.0  29.0  30.0  30.0\n",
      "1.0                76.0  21.157895  5.169275   4.0  18.0  21.0  25.0  30.0\n",
      "\n",
      "  t-test: t=28.921, p=0.0000\n",
      "\n",
      "Sex distribution by diagnosis:\n",
      "sex                 F   M  All\n",
      "diagnosis_binary              \n",
      "0.0               142  64  206\n",
      "1.0                21  23   44\n",
      "All               163  87  250\n",
      "\n",
      "================================================================================\n",
      "VERIFYING CRITICAL COLUMNS FOR MODELING\n",
      "================================================================================\n",
      "\n",
      "Required columns:\n",
      "  ✓ nifti_path          : 577/577 valid\n",
      "  ✓ subject_id          : 577/577 valid\n",
      "  ✓ visit_uid           : 577/577 valid\n",
      "  ✓ diagnosis_binary    : 577/577 valid\n",
      "\n",
      "Optional columns (for XAI validation):\n",
      "  ✓ age                 : 577/577 valid (100.0%)\n",
      "  ✓ mmse                : 575/577 valid (99.7%)\n",
      "  ✓ cdr                 : 577/577 valid (100.0%)\n",
      "  ✓ sex                 : 250/577 valid (43.3%)\n",
      "\n",
      "================================================================================\n",
      "SAVING CLASSIFICATION COHORT\n",
      "================================================================================\n",
      "\n",
      "✓ Saved classification cohort to: classification_visit_metadata.csv\n",
      "  Total rows: 577\n",
      "  Total columns: 28\n",
      "  File size: 135.69 KB\n",
      "\n",
      "✓ Updated master table saved to: master_visit_metadata.csv\n",
      "\n",
      "================================================================================\n",
      "FINAL SUMMARY\n",
      "================================================================================\n",
      "\n",
      "✅ CDR-based labeling complete\n",
      "   Total visits in master: 789\n",
      "   Classification cohort:  577 (CN + AD only)\n",
      "\n",
      "✅ Label distribution:\n",
      "   CN: 499 (86.5%)\n",
      "   AD: 78 (13.5%)\n",
      "\n",
      "✅ Multi-site distribution:\n",
      "   OASIS2: 206 CN, 44 AD\n",
      "   OASIS3: 293 CN, 34 AD\n",
      "\n",
      "✅ Clinical data completeness:\n",
      "   MMSE: 575/577 (99.7%)\n",
      "\n",
      "================================================================================\n",
      "SNIPPET S5 COMPLETE\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "SNIPPET S5: CDR-Consistent CN/AD Labeling + Classification Cohort\n",
    "Re-derive diagnosis labels using unified CDR-based criteria across both datasets\n",
    "      to ensure methodological consistency for multi-site analysis.\n",
    "\n",
    "Unified Criteria:\n",
    "- CN (0): CDR == 0.0\n",
    "- AD (1): CDR >= 1.0\n",
    "- MCI/Unknown (NaN): CDR == 0.5 or missing → excluded from 2-class classifier\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"SNIPPET S5: CDR-CONSISTENT CN/AD LABELING + CLASSIFICATION COHORT\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 1: Load Master Metadata\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"LOADING MASTER VISIT METADATA\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "df = pd.read_csv(\"master_visit_metadata.csv\")\n",
    "\n",
    "print(f\"\\nLoaded master_visit_metadata.csv\")\n",
    "print(f\"  Total rows: {len(df)}\")\n",
    "\n",
    "# Dataset distribution\n",
    "print(\"\\nDataset distribution:\")\n",
    "dataset_counts = df['dataset'].value_counts()\n",
    "for dataset, count in dataset_counts.items():\n",
    "    print(f\"  {dataset}: {count}\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 2: Inspect Current CDR Column\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"INSPECTING CDR COLUMN\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Check if CDR column exists\n",
    "if 'cdr' not in df.columns:\n",
    "    print(\"\\n⚠ ERROR: 'cdr' column not found in master table\")\n",
    "    print(f\"  Available columns: {df.columns.tolist()}\")\n",
    "    raise ValueError(\"Missing 'cdr' column - cannot proceed with labeling\")\n",
    "\n",
    "# Convert to numeric (handle any string values)\n",
    "df['cdr'] = pd.to_numeric(df['cdr'], errors='coerce')\n",
    "\n",
    "# Missing CDR statistics\n",
    "n_missing = df['cdr'].isna().sum()\n",
    "pct_missing = 100 * n_missing / len(df)\n",
    "print(f\"\\nCDR missing: {n_missing}/{len(df)} ({pct_missing:.1f}%)\")\n",
    "\n",
    "# CDR distribution by dataset\n",
    "print(\"\\nCDR distribution (overall):\")\n",
    "cdr_overall = df['cdr'].value_counts(dropna=False).sort_index()\n",
    "for cdr_val, count in cdr_overall.items():\n",
    "    pct = 100 * count / len(df)\n",
    "    print(f\"  CDR {cdr_val}: {count:4d} ({pct:5.1f}%)\")\n",
    "\n",
    "print(\"\\nCDR distribution by dataset:\")\n",
    "for dataset in df['dataset'].unique():\n",
    "    mask = df['dataset'] == dataset\n",
    "    print(f\"\\n  {dataset}:\")\n",
    "    cdr_dist = df[mask]['cdr'].value_counts(dropna=False).sort_index()\n",
    "    for cdr_val, count in cdr_dist.items():\n",
    "        pct = 100 * count / mask.sum()\n",
    "        print(f\"    CDR {cdr_val}: {count:4d} ({pct:5.1f}%)\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 3: Compare Old vs New Labels (Before Re-mapping)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"COMPARING OLD vs NEW LABELING APPROACH\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Store old labels if they exist\n",
    "if 'diagnosis_binary' in df.columns:\n",
    "    df['diagnosis_binary_old'] = df['diagnosis_binary'].copy()\n",
    "    \n",
    "    print(\"\\nOld diagnosis distribution:\")\n",
    "    old_dist = df['diagnosis_binary_old'].value_counts(dropna=False)\n",
    "    print(f\"  CN (0):  {old_dist.get(0, 0):4d}\")\n",
    "    print(f\"  AD (1):  {old_dist.get(1, 0):4d}\")\n",
    "    print(f\"  Unknown: {df['diagnosis_binary_old'].isna().sum():4d}\")\n",
    "else:\n",
    "    df['diagnosis_binary_old'] = np.nan\n",
    "    print(\"\\nNo previous diagnosis_binary column found\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 4: Apply Unified CDR-Based Diagnosis Mapping\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"APPLYING UNIFIED CDR-BASED DIAGNOSIS MAPPING\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\nMapping rules:\")\n",
    "print(\"  CN (0): CDR == 0.0\")\n",
    "print(\"  AD (1): CDR >= 1.0\")\n",
    "print(\"  MCI/Unknown (NaN): CDR == 0.5 or missing\")\n",
    "\n",
    "def map_diagnosis_from_cdr(cdr):\n",
    "    \"\"\"\n",
    "    Unified CDR-based diagnosis mapping for both OASIS-2 and OASIS-3.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    cdr : float or NaN\n",
    "        Clinical Dementia Rating score\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    int or NaN\n",
    "        0 (CN), 1 (AD), or NaN (MCI/Unknown)\n",
    "    \"\"\"\n",
    "    if pd.isna(cdr):\n",
    "        return np.nan\n",
    "    \n",
    "    try:\n",
    "        c = float(cdr)\n",
    "    except (ValueError, TypeError):\n",
    "        return np.nan\n",
    "    \n",
    "    # Apply unified criteria\n",
    "    if c == 0.0:\n",
    "        return 0  # CN\n",
    "    elif c >= 1.0:\n",
    "        return 1  # AD\n",
    "    else:  # c == 0.5 or other intermediate values\n",
    "        return np.nan  # MCI/Unknown\n",
    "\n",
    "# Apply mapping\n",
    "df['diagnosis_binary'] = df['cdr'].apply(map_diagnosis_from_cdr)\n",
    "\n",
    "print(\"\\n✓ Mapping applied\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 5: Analyze New Label Distribution\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"NEW DIAGNOSIS DISTRIBUTION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Overall distribution\n",
    "print(\"\\nOverall diagnosis distribution:\")\n",
    "new_dist = df['diagnosis_binary'].value_counts(dropna=False)\n",
    "total_valid = new_dist.get(0, 0) + new_dist.get(1, 0)\n",
    "print(f\"  CN (0):     {new_dist.get(0, 0):4d} ({100*new_dist.get(0, 0)/total_valid:.1f}%)\")\n",
    "print(f\"  AD (1):     {new_dist.get(1, 0):4d} ({100*new_dist.get(1, 0)/total_valid:.1f}%)\")\n",
    "print(f\"  Unknown:    {df['diagnosis_binary'].isna().sum():4d}\")\n",
    "print(f\"  Total valid: {total_valid}\")\n",
    "\n",
    "# Per-dataset distribution\n",
    "print(\"\\nDiagnosis by dataset:\")\n",
    "for dataset in df['dataset'].unique():\n",
    "    mask = df['dataset'] == dataset\n",
    "    cn = ((df['diagnosis_binary'] == 0) & mask).sum()\n",
    "    ad = ((df['diagnosis_binary'] == 1) & mask).sum()\n",
    "    unk = (df['diagnosis_binary'].isna() & mask).sum()\n",
    "    total = cn + ad\n",
    "    \n",
    "    print(f\"\\n  {dataset}:\")\n",
    "    print(f\"    Total visits:  {mask.sum()}\")\n",
    "    print(f\"    CN (0):        {cn:4d} ({100*cn/total:.1f}% of valid)\")\n",
    "    print(f\"    AD (1):        {ad:4d} ({100*ad/total:.1f}% of valid)\")\n",
    "    print(f\"    Unknown/MCI:   {unk:4d}\")\n",
    "    print(f\"    CN/AD ratio:   {cn/ad if ad > 0 else np.inf:.2f}:1\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 6: Label Change Analysis (Old vs New)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"LABEL CHANGE ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if 'diagnosis_binary_old' in df.columns:\n",
    "    # Compare old vs new\n",
    "    changes = df[['diagnosis_binary_old', 'diagnosis_binary']].copy()\n",
    "    \n",
    "    # Count changes\n",
    "    unchanged = (changes['diagnosis_binary_old'] == changes['diagnosis_binary']).sum()\n",
    "    nan_to_valid = (changes['diagnosis_binary_old'].isna() & changes['diagnosis_binary'].notna()).sum()\n",
    "    valid_to_nan = (changes['diagnosis_binary_old'].notna() & changes['diagnosis_binary'].isna()).sum()\n",
    "    value_changed = (\n",
    "        (changes['diagnosis_binary_old'] != changes['diagnosis_binary']) &\n",
    "        changes['diagnosis_binary_old'].notna() &\n",
    "        changes['diagnosis_binary'].notna()\n",
    "    ).sum()\n",
    "    \n",
    "    print(f\"\\nLabel changes:\")\n",
    "    print(f\"  Unchanged:         {unchanged:4d}\")\n",
    "    print(f\"  Unknown → Valid:   {nan_to_valid:4d} (recovered)\")\n",
    "    print(f\"  Valid → Unknown:   {valid_to_nan:4d} (lost to MCI)\")\n",
    "    print(f\"  Value changed:     {value_changed:4d} (0↔1)\")\n",
    "    \n",
    "    if value_changed > 0:\n",
    "        print(\"\\n  ⚠ Warning: Some labels flipped between CN and AD\")\n",
    "        print(\"  This may indicate CDR inconsistencies - inspect manually:\")\n",
    "        flipped = changes[\n",
    "            (changes['diagnosis_binary_old'] != changes['diagnosis_binary']) &\n",
    "            changes['diagnosis_binary_old'].notna() &\n",
    "            changes['diagnosis_binary'].notna()\n",
    "        ]\n",
    "        if len(flipped) > 0:\n",
    "            print(f\"\\n  First 5 flipped cases:\")\n",
    "            flip_display = df.loc[flipped.index, ['dataset', 'subject_id', 'visit_code', \n",
    "                                                    'cdr', 'diagnosis_binary_old', 'diagnosis_binary']]\n",
    "            print(flip_display.head(5).to_string())\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 7: Build Classification Cohort (CN + AD only)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"BUILDING CLASSIFICATION COHORT\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Filter to CN/AD only (exclude NaN labels)\n",
    "cls_df = df[df['diagnosis_binary'].isin([0, 1])].copy()\n",
    "\n",
    "print(f\"\\nClassification cohort created\")\n",
    "print(f\"  Total visits: {len(cls_df)}\")\n",
    "print(f\"  Excluded (MCI/Unknown): {len(df) - len(cls_df)}\")\n",
    "print(f\"  Retention rate: {100*len(cls_df)/len(df):.1f}%\")\n",
    "\n",
    "# Dataset distribution\n",
    "print(\"\\nVisits by dataset:\")\n",
    "dataset_dist = cls_df['dataset'].value_counts()\n",
    "for dataset, count in dataset_dist.items():\n",
    "    print(f\"  {dataset}: {count}\")\n",
    "\n",
    "# Label distribution\n",
    "print(\"\\nLabels in classification cohort:\")\n",
    "label_dist = cls_df['diagnosis_binary'].value_counts()\n",
    "cn_count = label_dist.get(0, 0)\n",
    "ad_count = label_dist.get(1, 0)\n",
    "print(f\"  CN (0): {cn_count:4d} ({100*cn_count/len(cls_df):.1f}%)\")\n",
    "print(f\"  AD (1): {ad_count:4d} ({100*ad_count/len(cls_df):.1f}%)\")\n",
    "print(f\"  CN/AD ratio: {cn_count/ad_count:.2f}:1\")\n",
    "\n",
    "# Cross-tabulation\n",
    "print(\"\\nLabel × Dataset cross-tabulation:\")\n",
    "crosstab = pd.crosstab(cls_df['dataset'], cls_df['diagnosis_binary'], margins=True)\n",
    "print(crosstab)\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 8: Clinical Variable Completeness\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"CLINICAL VARIABLE COMPLETENESS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Key clinical variables\n",
    "clinical_vars = ['age', 'mmse', 'cdr', 'sex', 'education']\n",
    "\n",
    "print(\"\\nMissing data in classification cohort:\")\n",
    "for var in clinical_vars:\n",
    "    if var in cls_df.columns:\n",
    "        n_missing = cls_df[var].isna().sum()\n",
    "        pct_missing = 100 * n_missing / len(cls_df)\n",
    "        print(f\"  {var:15s}: {n_missing:4d} missing ({pct_missing:5.1f}%)\")\n",
    "    else:\n",
    "        print(f\"  {var:15s}: column not found\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 9: Descriptive Statistics by Diagnosis\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"DESCRIPTIVE STATISTICS BY DIAGNOSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Age statistics\n",
    "if 'age' in cls_df.columns:\n",
    "    print(\"\\nAge statistics:\")\n",
    "    age_stats = cls_df.groupby('diagnosis_binary')['age'].describe()\n",
    "    print(age_stats)\n",
    "    \n",
    "    # Statistical test (t-test)\n",
    "    from scipy import stats\n",
    "    cn_age = cls_df[cls_df['diagnosis_binary'] == 0]['age'].dropna()\n",
    "    ad_age = cls_df[cls_df['diagnosis_binary'] == 1]['age'].dropna()\n",
    "    \n",
    "    if len(cn_age) > 0 and len(ad_age) > 0:\n",
    "        t_stat, p_val = stats.ttest_ind(cn_age, ad_age)\n",
    "        print(f\"\\n  t-test: t={t_stat:.3f}, p={p_val:.4f}\")\n",
    "\n",
    "# MMSE statistics\n",
    "if 'mmse' in cls_df.columns:\n",
    "    print(\"\\nMMSE statistics:\")\n",
    "    mmse_stats = cls_df.groupby('diagnosis_binary')['mmse'].describe()\n",
    "    print(mmse_stats)\n",
    "    \n",
    "    # Statistical test\n",
    "    cn_mmse = cls_df[cls_df['diagnosis_binary'] == 0]['mmse'].dropna()\n",
    "    ad_mmse = cls_df[cls_df['diagnosis_binary'] == 1]['mmse'].dropna()\n",
    "    \n",
    "    if len(cn_mmse) > 0 and len(ad_mmse) > 0:\n",
    "        t_stat, p_val = stats.ttest_ind(cn_mmse, ad_mmse)\n",
    "        print(f\"\\n  t-test: t={t_stat:.3f}, p={p_val:.4f}\")\n",
    "\n",
    "# Sex distribution\n",
    "if 'sex' in cls_df.columns:\n",
    "    print(\"\\nSex distribution by diagnosis:\")\n",
    "    sex_diag = pd.crosstab(cls_df['diagnosis_binary'], cls_df['sex'], margins=True)\n",
    "    print(sex_diag)\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 10: Verify Critical Columns for Modeling\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"VERIFYING CRITICAL COLUMNS FOR MODELING\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Must-have columns\n",
    "required_cols = ['nifti_path', 'subject_id', 'visit_uid', 'diagnosis_binary']\n",
    "optional_cols = ['age', 'mmse', 'cdr', 'sex']\n",
    "\n",
    "print(\"\\nRequired columns:\")\n",
    "for col in required_cols:\n",
    "    if col in cls_df.columns:\n",
    "        n_valid = cls_df[col].notna().sum()\n",
    "        print(f\"  ✓ {col:20s}: {n_valid}/{len(cls_df)} valid\")\n",
    "    else:\n",
    "        print(f\"  ✗ {col:20s}: MISSING\")\n",
    "\n",
    "print(\"\\nOptional columns (for XAI validation):\")\n",
    "for col in optional_cols:\n",
    "    if col in cls_df.columns:\n",
    "        n_valid = cls_df[col].notna().sum()\n",
    "        pct = 100 * n_valid / len(cls_df)\n",
    "        print(f\"  ✓ {col:20s}: {n_valid}/{len(cls_df)} valid ({pct:.1f}%)\")\n",
    "    else:\n",
    "        print(f\"  - {col:20s}: not available\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 11: Save Classification Cohort\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SAVING CLASSIFICATION COHORT\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "output_file = \"classification_visit_metadata.csv\"\n",
    "cls_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"\\n✓ Saved classification cohort to: {output_file}\")\n",
    "print(f\"  Total rows: {len(cls_df)}\")\n",
    "print(f\"  Total columns: {len(cls_df.columns)}\")\n",
    "print(f\"  File size: {Path(output_file).stat().st_size / 1024:.2f} KB\")\n",
    "\n",
    "# Also save updated master table (with new diagnosis_binary)\n",
    "master_output = \"master_visit_metadata.csv\"\n",
    "df.to_csv(master_output, index=False)\n",
    "print(f\"\\n✓ Updated master table saved to: {master_output}\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 12: Final Summary\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"FINAL SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\n✅ CDR-based labeling complete\")\n",
    "print(f\"   Total visits in master: {len(df)}\")\n",
    "print(f\"   Classification cohort:  {len(cls_df)} (CN + AD only)\")\n",
    "\n",
    "print(\"\\n✅ Label distribution:\")\n",
    "print(f\"   CN: {cn_count} ({100*cn_count/len(cls_df):.1f}%)\")\n",
    "print(f\"   AD: {ad_count} ({100*ad_count/len(cls_df):.1f}%)\")\n",
    "\n",
    "print(\"\\n✅ Multi-site distribution:\")\n",
    "for dataset in cls_df['dataset'].unique():\n",
    "    mask = cls_df['dataset'] == dataset\n",
    "    cn = ((cls_df['diagnosis_binary'] == 0) & mask).sum()\n",
    "    ad = ((cls_df['diagnosis_binary'] == 1) & mask).sum()\n",
    "    print(f\"   {dataset}: {cn} CN, {ad} AD\")\n",
    "\n",
    "print(\"\\n✅ Clinical data completeness:\")\n",
    "if 'mmse' in cls_df.columns:\n",
    "    mmse_avail = cls_df['mmse'].notna().sum()\n",
    "    print(f\"   MMSE: {mmse_avail}/{len(cls_df)} ({100*mmse_avail/len(cls_df):.1f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SNIPPET S5 COMPLETE\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8231552f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T18:51:03.713233Z",
     "iopub.status.busy": "2025-11-17T18:51:03.713026Z",
     "iopub.status.idle": "2025-11-17T18:51:04.124260Z",
     "shell.execute_reply": "2025-11-17T18:51:04.123528Z"
    },
    "papermill": {
     "duration": 0.427976,
     "end_time": "2025-11-17T18:51:04.126318",
     "exception": false,
     "start_time": "2025-11-17T18:51:03.698342",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SNIPPET S6: SUBJECT-LEVEL TRAIN/VAL/TEST SPLITS\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "LOCKED CONFIGURATION\n",
      "================================================================================\n",
      "\n",
      "Test size:      20.0% of subjects\n",
      "Random state:   42\n",
      "CV folds:       5\n",
      "Lock date:      20251116\n",
      "\n",
      "⚠️  WARNING: These parameters are LOCKED and must never change!\n",
      "   Changing them after today will invalidate all results.\n",
      "\n",
      "================================================================================\n",
      "LOADING CLASSIFICATION VISIT METADATA\n",
      "================================================================================\n",
      "\n",
      "Loaded classification_visit_metadata.csv\n",
      "  Total visits: 577\n",
      "\n",
      "Dataset distribution:\n",
      "dataset\n",
      "OASIS3    327\n",
      "OASIS2    250\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Diagnosis distribution:\n",
      "diagnosis_binary\n",
      "0.0    499\n",
      "1.0     78\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Diagnosis × Dataset:\n",
      "diagnosis_binary  0.0  1.0  All\n",
      "dataset                        \n",
      "OASIS2            206   44  250\n",
      "OASIS3            293   34  327\n",
      "All               499   78  577\n",
      "\n",
      "================================================================================\n",
      "BUILDING SUBJECT-LEVEL SUMMARY\n",
      "================================================================================\n",
      "\n",
      "Total subjects: 347\n",
      "\n",
      "Subjects by dataset:\n",
      "dataset\n",
      "OASIS3    235\n",
      "OASIS2    112\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Subjects by majority label:\n",
      "majority_label\n",
      "0    288\n",
      "1     59\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Mixed-label subjects:\n",
      "  1 subjects have both CN and AD visits\n",
      "  These will be assigned to 5-fold CV based on majority label\n",
      "\n",
      "  Sample mixed-label subjects:\n",
      "dataset subject_id  n_cn  n_ad  majority_label\n",
      " OASIS3   OAS30830     1     1               0\n",
      "\n",
      "Visits per subject statistics:\n",
      "  Mean:   1.66\n",
      "  Median: 2.0\n",
      "  Min:    1\n",
      "  Max:    5\n",
      "\n",
      "================================================================================\n",
      "CREATING STRATIFIED TEST SPLIT\n",
      "================================================================================\n",
      "\n",
      "Splitting strategy:\n",
      "  - Stratify by (dataset, majority_label)\n",
      "  - Test size: 20.0% of subjects per stratum\n",
      "  - Random state: 42 (LOCKED)\n",
      "\n",
      "OASIS2:\n",
      "  Total subjects: 112\n",
      "  CN subjects: 86\n",
      "  AD subjects: 26\n",
      "  Train+Val: 89 subjects\n",
      "  Test:      23 subjects\n",
      "    CN: 18, AD: 5\n",
      "\n",
      "OASIS3:\n",
      "  Total subjects: 235\n",
      "  CN subjects: 202\n",
      "  AD subjects: 33\n",
      "  Train+Val: 188 subjects\n",
      "  Test:      47 subjects\n",
      "    CN: 40, AD: 7\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "OVERALL SPLIT SUMMARY\n",
      "--------------------------------------------------------------------------------\n",
      "Train+Val subjects: 277\n",
      "Test subjects:      70\n",
      "Total:              347\n",
      "\n",
      "================================================================================\n",
      "VERIFYING SPLIT QUALITY\n",
      "================================================================================\n",
      "\n",
      "1. Subject leakage check:\n",
      "   Subjects in both train and test: 0\n",
      "   ✅ No leakage (good)\n",
      "\n",
      "2. Label distribution:\n",
      "\n",
      "   Train+Val:\n",
      "     CN: 230 (83.0%)\n",
      "     AD: 47 (17.0%)\n",
      "\n",
      "   Test:\n",
      "     CN: 58 (82.9%)\n",
      "     AD: 12 (17.1%)\n",
      "\n",
      "3. Dataset distribution:\n",
      "\n",
      "   Train+Val:\n",
      "dataset\n",
      "OASIS3    188\n",
      "OASIS2     89\n",
      "Name: count, dtype: int64\n",
      "\n",
      "   Test:\n",
      "dataset\n",
      "OASIS3    47\n",
      "OASIS2    23\n",
      "Name: count, dtype: int64\n",
      "\n",
      "================================================================================\n",
      "ASSIGNING SPLIT LABELS TO VISITS\n",
      "================================================================================\n",
      "\n",
      "Split assignment results:\n",
      "  Unassigned visits: 0\n",
      "\n",
      "Visits per split:\n",
      "split\n",
      "trainval    462\n",
      "test        115\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Visits per split × dataset × diagnosis:\n",
      "   split dataset  diagnosis_binary  count\n",
      "    test  OASIS2               0.0     42\n",
      "    test  OASIS2               1.0      7\n",
      "    test  OASIS3               0.0     59\n",
      "    test  OASIS3               1.0      7\n",
      "trainval  OASIS2               0.0    164\n",
      "trainval  OASIS2               1.0     37\n",
      "trainval  OASIS3               0.0    234\n",
      "trainval  OASIS3               1.0     27\n",
      "\n",
      "================================================================================\n",
      "CREATING 5-FOLD CROSS-VALIDATION\n",
      "================================================================================\n",
      "\n",
      "CV strategy:\n",
      "  - Applied to train+val subjects only\n",
      "  - Stratified by majority label\n",
      "  - 5 folds\n",
      "  - Random state: 42 (LOCKED)\n",
      "\n",
      "Train+Val label distribution:\n",
      "  CN: 230\n",
      "  AD: 47\n",
      "\n",
      "Creating 5 folds...\n",
      "  Fold 0: 56 subjects (CN: 46, AD: 10)\n",
      "  Fold 1: 56 subjects (CN: 46, AD: 10)\n",
      "  Fold 2: 55 subjects (CN: 46, AD: 9)\n",
      "  Fold 3: 55 subjects (CN: 46, AD: 9)\n",
      "  Fold 4: 55 subjects (CN: 46, AD: 9)\n",
      "\n",
      "✓ CV fold assignment complete\n",
      "  Total fold assignments: 277\n",
      "\n",
      "Fold distribution:\n",
      "cv_fold\n",
      "0    56\n",
      "1    56\n",
      "2    55\n",
      "3    55\n",
      "4    55\n",
      "Name: count, dtype: int64\n",
      "\n",
      "================================================================================\n",
      "MERGING CV FOLDS TO VISIT TABLE\n",
      "================================================================================\n",
      "\n",
      "CV fold presence by split:\n",
      "  trainval  : 462/462 visits have cv_fold (100.0%)\n",
      "  test      : 0/115 visits have cv_fold (0.0%)\n",
      "\n",
      "================================================================================\n",
      "SAVING SPLIT DEFINITIONS (LOCKING PERMANENTLY)\n",
      "================================================================================\n",
      "\n",
      "✓ Saved: classification_visit_metadata_with_splits.csv\n",
      "  Rows: 577\n",
      "  Columns: 30\n",
      "\n",
      "✓ Saved: test_subjects_LOCKED_20251116.csv\n",
      "  Test subjects: 70\n",
      "\n",
      "✓ Saved: trainval_subjects_20251116.csv\n",
      "  Train+Val subjects: 277\n",
      "\n",
      "✓ Saved: trainval_subjects_cv_folds_5fold_20251116.csv\n",
      "  CV fold assignments: 277\n",
      "\n",
      "================================================================================\n",
      "FINAL SUMMARY\n",
      "================================================================================\n",
      "\n",
      "✅ Subject-level splits created successfully\n",
      "\n",
      "   Total subjects:     347\n",
      "   Train+Val:          277 (79.8%)\n",
      "   Test:               70 (20.2%)\n",
      "\n",
      "✅ Visit-level assignments:\n",
      "   Total visits:       577\n",
      "   Train+Val visits:   462\n",
      "   Test visits:        115\n",
      "\n",
      "✅ Cross-validation:\n",
      "   5-fold CV on train+val subjects\n",
      "   Test set excluded from CV\n",
      "\n",
      "================================================================================\n",
      "⚠️  CRITICAL WARNINGS\n",
      "================================================================================\n",
      "\n",
      "1. Test set is now LOCKED (random_state=42, date=20251116)\n",
      "2. NEVER use test set for:\n",
      "   - Hyperparameter tuning\n",
      "   - Model selection\n",
      "   - Feature engineering\n",
      "   - Threshold optimization\n",
      "\n",
      "3. Test set should be evaluated EXACTLY ONCE after all modeling decisions\n",
      "\n",
      "4. If you need to re-run splits, you MUST:\n",
      "   - Change LOCK_DATE\n",
      "   - Document why in your thesis/paper\n",
      "   - Re-run ALL subsequent experiments\n",
      "\n",
      "================================================================================\n",
      "SNIPPET S6 COMPLETE\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "SNIPPET S6: Subject-Level Train/Val/Test Splits\n",
    "Create fixed train/val/test splits at SUBJECT level to prevent data leakage.\n",
    "\n",
    "Critical Rules:\n",
    "1. No subject appears in multiple splits\n",
    "2. All visits of a subject stay in the same split\n",
    "3. Test set: 20% subjects, stratified by (dataset, diagnosis)\n",
    "4. 5-fold CV on train/val subjects for model selection\n",
    "5. Random seed LOCKED (random_state=42) - never change after today\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"SNIPPET S6: SUBJECT-LEVEL TRAIN/VAL/TEST SPLITS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURATION: LOCKED PARAMETERS (NEVER CHANGE AFTER TODAY)\n",
    "# ============================================================================\n",
    "\n",
    "TEST_SIZE = 0.20          # 20% subjects for test\n",
    "RANDOM_STATE = 42         # Fixed random seed\n",
    "N_FOLDS = 5               # 5-fold cross-validation\n",
    "LOCK_DATE = \"20251116\"    # Today's date (YYYYMMDD)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"LOCKED CONFIGURATION\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nTest size:      {TEST_SIZE:.1%} of subjects\")\n",
    "print(f\"Random state:   {RANDOM_STATE}\")\n",
    "print(f\"CV folds:       {N_FOLDS}\")\n",
    "print(f\"Lock date:      {LOCK_DATE}\")\n",
    "print(\"\\n⚠️  WARNING: These parameters are LOCKED and must never change!\")\n",
    "print(\"   Changing them after today will invalidate all results.\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 1: Load Classification Visit Metadata\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"LOADING CLASSIFICATION VISIT METADATA\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "vis_df = pd.read_csv(\"classification_visit_metadata.csv\")\n",
    "\n",
    "print(f\"\\nLoaded classification_visit_metadata.csv\")\n",
    "print(f\"  Total visits: {len(vis_df)}\")\n",
    "\n",
    "# Verify required columns\n",
    "required_cols = ['subject_id', 'dataset', 'diagnosis_binary', 'visit_uid']\n",
    "missing_cols = [col for col in required_cols if col not in vis_df.columns]\n",
    "if missing_cols:\n",
    "    raise ValueError(f\"Missing required columns: {missing_cols}\")\n",
    "\n",
    "print(\"\\nDataset distribution:\")\n",
    "print(vis_df['dataset'].value_counts())\n",
    "\n",
    "print(\"\\nDiagnosis distribution:\")\n",
    "print(vis_df['diagnosis_binary'].value_counts())\n",
    "\n",
    "print(\"\\nDiagnosis × Dataset:\")\n",
    "print(pd.crosstab(vis_df['dataset'], vis_df['diagnosis_binary'], margins=True))\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 2: Build Subject-Level Summary\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"BUILDING SUBJECT-LEVEL SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Aggregate visits to subject level\n",
    "grp = vis_df.groupby(['dataset', 'subject_id'])\n",
    "\n",
    "subj_df = grp['diagnosis_binary'].agg(\n",
    "    n_visits='count',\n",
    "    n_ad=lambda x: (x == 1).sum(),\n",
    "    n_cn=lambda x: (x == 0).sum()\n",
    ").reset_index()\n",
    "\n",
    "# Define majority label per subject (for stratification)\n",
    "def majority_label(row):\n",
    "    \"\"\"\n",
    "    Determine majority diagnosis for stratification.\n",
    "    Ties (e.g., 1 CN + 1 AD) default to CN.\n",
    "    \"\"\"\n",
    "    if row['n_ad'] > row['n_cn']:\n",
    "        return 1  # AD\n",
    "    else:\n",
    "        return 0  # CN\n",
    "\n",
    "subj_df['majority_label'] = subj_df.apply(majority_label, axis=1)\n",
    "\n",
    "# Flag subjects with mixed labels (informational only)\n",
    "subj_df['is_mixed'] = (subj_df['n_ad'] > 0) & (subj_df['n_cn'] > 0)\n",
    "\n",
    "print(f\"\\nTotal subjects: {len(subj_df)}\")\n",
    "\n",
    "print(\"\\nSubjects by dataset:\")\n",
    "print(subj_df['dataset'].value_counts())\n",
    "\n",
    "print(\"\\nSubjects by majority label:\")\n",
    "print(subj_df['majority_label'].value_counts())\n",
    "\n",
    "print(\"\\nMixed-label subjects:\")\n",
    "n_mixed = subj_df['is_mixed'].sum()\n",
    "print(f\"  {n_mixed} subjects have both CN and AD visits\")\n",
    "if n_mixed > 0:\n",
    "    print(f\"  These will be assigned to {N_FOLDS}-fold CV based on majority label\")\n",
    "    print(\"\\n  Sample mixed-label subjects:\")\n",
    "    mixed_sample = subj_df[subj_df['is_mixed']][['dataset', 'subject_id', 'n_cn', 'n_ad', 'majority_label']].head(3)\n",
    "    print(mixed_sample.to_string(index=False))\n",
    "\n",
    "# Visits per subject statistics\n",
    "print(\"\\nVisits per subject statistics:\")\n",
    "print(f\"  Mean:   {subj_df['n_visits'].mean():.2f}\")\n",
    "print(f\"  Median: {subj_df['n_visits'].median():.1f}\")\n",
    "print(f\"  Min:    {subj_df['n_visits'].min()}\")\n",
    "print(f\"  Max:    {subj_df['n_visits'].max()}\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 3: Create Stratified Test Split (Per Dataset)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"CREATING STRATIFIED TEST SPLIT\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\\nSplitting strategy:\")\n",
    "print(f\"  - Stratify by (dataset, majority_label)\")\n",
    "print(f\"  - Test size: {TEST_SIZE:.1%} of subjects per stratum\")\n",
    "print(f\"  - Random state: {RANDOM_STATE} (LOCKED)\")\n",
    "\n",
    "test_subj_list = []\n",
    "trainval_subj_list = []\n",
    "\n",
    "for dataset in ['OASIS2', 'OASIS3']:\n",
    "    ds_subj = subj_df[subj_df['dataset'] == dataset].copy()\n",
    "    \n",
    "    if len(ds_subj) == 0:\n",
    "        print(f\"\\n⚠️  Warning: No subjects in {dataset} - skipping\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\n{dataset}:\")\n",
    "    print(f\"  Total subjects: {len(ds_subj)}\")\n",
    "    \n",
    "    # Check if stratification is possible\n",
    "    label_counts = ds_subj['majority_label'].value_counts()\n",
    "    print(f\"  CN subjects: {label_counts.get(0, 0)}\")\n",
    "    print(f\"  AD subjects: {label_counts.get(1, 0)}\")\n",
    "    \n",
    "    # Verify minimum samples per class for stratification\n",
    "    min_samples = label_counts.min()\n",
    "    test_samples = int(len(ds_subj) * TEST_SIZE)\n",
    "    \n",
    "    if min_samples < 2:\n",
    "        print(f\"  ⚠️  Warning: Class with <2 samples - cannot stratify\")\n",
    "        print(f\"     Using random split without stratification\")\n",
    "        stratify_by = None\n",
    "    elif test_samples < 2:\n",
    "        print(f\"  ⚠️  Warning: Test size too small for stratification\")\n",
    "        print(f\"     Using random split without stratification\")\n",
    "        stratify_by = None\n",
    "    else:\n",
    "        stratify_by = ds_subj['majority_label'].values\n",
    "    \n",
    "    # Perform split\n",
    "    X = ds_subj['subject_id'].values\n",
    "    y = ds_subj['majority_label'].values\n",
    "    \n",
    "    subj_train, subj_test, y_train, y_test = train_test_split(\n",
    "        X,\n",
    "        y,\n",
    "        test_size=TEST_SIZE,\n",
    "        random_state=RANDOM_STATE,\n",
    "        stratify=stratify_by\n",
    "    )\n",
    "    \n",
    "    print(f\"  Train+Val: {len(subj_train)} subjects\")\n",
    "    print(f\"  Test:      {len(subj_test)} subjects\")\n",
    "    print(f\"    CN: {(y_test == 0).sum()}, AD: {(y_test == 1).sum()}\")\n",
    "    \n",
    "    # Store splits\n",
    "    trainval_subj_list.extend([(dataset, sid) for sid in subj_train])\n",
    "    test_subj_list.extend([(dataset, sid) for sid in subj_test])\n",
    "\n",
    "# Convert to DataFrames\n",
    "trainval_subj_df = pd.DataFrame(trainval_subj_list, columns=['dataset', 'subject_id'])\n",
    "test_subj_df = pd.DataFrame(test_subj_list, columns=['dataset', 'subject_id'])\n",
    "\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"OVERALL SPLIT SUMMARY\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"Train+Val subjects: {len(trainval_subj_df)}\")\n",
    "print(f\"Test subjects:      {len(test_subj_df)}\")\n",
    "print(f\"Total:              {len(trainval_subj_df) + len(test_subj_df)}\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 4: Verify Split Quality\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"VERIFYING SPLIT QUALITY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Merge labels back for verification\n",
    "trainval_subj_labeled = trainval_subj_df.merge(\n",
    "    subj_df[['dataset', 'subject_id', 'majority_label', 'n_visits']],\n",
    "    on=['dataset', 'subject_id'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "test_subj_labeled = test_subj_df.merge(\n",
    "    subj_df[['dataset', 'subject_id', 'majority_label', 'n_visits']],\n",
    "    on=['dataset', 'subject_id'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Check for leakage (should be zero)\n",
    "overlap = set(trainval_subj_df['subject_id']) & set(test_subj_df['subject_id'])\n",
    "print(f\"\\n1. Subject leakage check:\")\n",
    "print(f\"   Subjects in both train and test: {len(overlap)}\")\n",
    "if len(overlap) > 0:\n",
    "    print(f\"   ❌ ERROR: Data leakage detected!\")\n",
    "    print(f\"   Overlapping subjects: {list(overlap)[:5]}\")\n",
    "    raise ValueError(\"Subject leakage detected - split is invalid\")\n",
    "else:\n",
    "    print(f\"   ✅ No leakage (good)\")\n",
    "\n",
    "# Label distribution\n",
    "print(f\"\\n2. Label distribution:\")\n",
    "print(f\"\\n   Train+Val:\")\n",
    "trainval_label_dist = trainval_subj_labeled['majority_label'].value_counts()\n",
    "print(f\"     CN: {trainval_label_dist.get(0, 0)} ({100*trainval_label_dist.get(0, 0)/len(trainval_subj_labeled):.1f}%)\")\n",
    "print(f\"     AD: {trainval_label_dist.get(1, 0)} ({100*trainval_label_dist.get(1, 0)/len(trainval_subj_labeled):.1f}%)\")\n",
    "\n",
    "print(f\"\\n   Test:\")\n",
    "test_label_dist = test_subj_labeled['majority_label'].value_counts()\n",
    "print(f\"     CN: {test_label_dist.get(0, 0)} ({100*test_label_dist.get(0, 0)/len(test_subj_labeled):.1f}%)\")\n",
    "print(f\"     AD: {test_label_dist.get(1, 0)} ({100*test_label_dist.get(1, 0)/len(test_subj_labeled):.1f}%)\")\n",
    "\n",
    "# Dataset balance\n",
    "print(f\"\\n3. Dataset distribution:\")\n",
    "print(f\"\\n   Train+Val:\")\n",
    "print(trainval_subj_labeled['dataset'].value_counts())\n",
    "print(f\"\\n   Test:\")\n",
    "print(test_subj_labeled['dataset'].value_counts())\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 5: Assign Split Labels to Visits\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ASSIGNING SPLIT LABELS TO VISITS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Initialize split column\n",
    "vis_df['split'] = 'UNASSIGNED'\n",
    "\n",
    "# Mark test visits\n",
    "vis_df = vis_df.merge(\n",
    "    test_subj_df.assign(split_marker='test'),\n",
    "    on=['dataset', 'subject_id'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "vis_df.loc[vis_df['split_marker'] == 'test', 'split'] = 'test'\n",
    "vis_df.drop(columns=['split_marker'], inplace=True, errors='ignore')\n",
    "\n",
    "# Mark trainval visits\n",
    "vis_df.loc[vis_df['split'] == 'UNASSIGNED', 'split'] = 'trainval'\n",
    "\n",
    "# Verify all visits assigned\n",
    "n_unassigned = (vis_df['split'] == 'UNASSIGNED').sum()\n",
    "print(f\"\\nSplit assignment results:\")\n",
    "print(f\"  Unassigned visits: {n_unassigned}\")\n",
    "if n_unassigned > 0:\n",
    "    print(f\"  ❌ ERROR: {n_unassigned} visits not assigned to any split\")\n",
    "    raise ValueError(\"Some visits not assigned to splits\")\n",
    "\n",
    "print(\"\\nVisits per split:\")\n",
    "print(vis_df['split'].value_counts())\n",
    "\n",
    "print(\"\\nVisits per split × dataset × diagnosis:\")\n",
    "split_summary = vis_df.groupby(['split', 'dataset', 'diagnosis_binary']).size().reset_index(name='count')\n",
    "print(split_summary.to_string(index=False))\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 6: Create 5-Fold CV on Train+Val Subjects\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(f\"CREATING {N_FOLDS}-FOLD CROSS-VALIDATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\\nCV strategy:\")\n",
    "print(f\"  - Applied to train+val subjects only\")\n",
    "print(f\"  - Stratified by majority label\")\n",
    "print(f\"  - {N_FOLDS} folds\")\n",
    "print(f\"  - Random state: {RANDOM_STATE} (LOCKED)\")\n",
    "\n",
    "# Merge labels for stratification\n",
    "trainval_subj_labeled = trainval_subj_df.merge(\n",
    "    subj_df[['dataset', 'subject_id', 'majority_label']],\n",
    "    on=['dataset', 'subject_id'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Check for valid stratification\n",
    "label_counts = trainval_subj_labeled['majority_label'].value_counts()\n",
    "print(f\"\\nTrain+Val label distribution:\")\n",
    "print(f\"  CN: {label_counts.get(0, 0)}\")\n",
    "print(f\"  AD: {label_counts.get(1, 0)}\")\n",
    "\n",
    "min_label_count = label_counts.min()\n",
    "if min_label_count < N_FOLDS:\n",
    "    print(f\"\\n⚠️  WARNING: Smallest class has {min_label_count} subjects < {N_FOLDS} folds\")\n",
    "    print(f\"   Stratification may fail - consider reducing n_folds\")\n",
    "\n",
    "# Create folds\n",
    "skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "X_subj = trainval_subj_labeled[['dataset', 'subject_id']].values\n",
    "y_subj = trainval_subj_labeled['majority_label'].values\n",
    "\n",
    "fold_assignments = []\n",
    "\n",
    "print(f\"\\nCreating {N_FOLDS} folds...\")\n",
    "for fold_idx, (train_idx, val_idx) in enumerate(skf.split(X_subj, y_subj)):\n",
    "    # Get validation subjects for this fold\n",
    "    val_subjects = trainval_subj_labeled.iloc[val_idx][['dataset', 'subject_id']]\n",
    "    \n",
    "    for _, row in val_subjects.iterrows():\n",
    "        fold_assignments.append({\n",
    "            'dataset': row['dataset'],\n",
    "            'subject_id': row['subject_id'],\n",
    "            'cv_fold': fold_idx\n",
    "        })\n",
    "    \n",
    "    # Print fold statistics\n",
    "    val_labels = y_subj[val_idx]\n",
    "    print(f\"  Fold {fold_idx}: {len(val_idx)} subjects (CN: {(val_labels==0).sum()}, AD: {(val_labels==1).sum()})\")\n",
    "\n",
    "fold_df = pd.DataFrame(fold_assignments)\n",
    "\n",
    "print(f\"\\n✓ CV fold assignment complete\")\n",
    "print(f\"  Total fold assignments: {len(fold_df)}\")\n",
    "print(f\"\\nFold distribution:\")\n",
    "print(fold_df['cv_fold'].value_counts().sort_index())\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 7: Merge CV Folds Back to Visit Table\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"MERGING CV FOLDS TO VISIT TABLE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Merge fold assignments\n",
    "vis_df = vis_df.merge(\n",
    "    fold_df,\n",
    "    on=['dataset', 'subject_id'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Verify: test visits should have NaN cv_fold\n",
    "print(\"\\nCV fold presence by split:\")\n",
    "for split_name in ['trainval', 'test']:\n",
    "    mask = vis_df['split'] == split_name\n",
    "    n_with_fold = vis_df[mask]['cv_fold'].notna().sum()\n",
    "    pct = 100 * n_with_fold / mask.sum() if mask.sum() > 0 else 0\n",
    "    print(f\"  {split_name:10s}: {n_with_fold}/{mask.sum()} visits have cv_fold ({pct:.1f}%)\")\n",
    "\n",
    "# Test set should have 0% with cv_fold\n",
    "test_with_fold = vis_df[vis_df['split'] == 'test']['cv_fold'].notna().sum()\n",
    "if test_with_fold > 0:\n",
    "    print(f\"\\n❌ ERROR: {test_with_fold} test visits have cv_fold assigned\")\n",
    "    raise ValueError(\"Test set contaminated with CV fold assignments\")\n",
    "\n",
    "# Trainval should have 100% with cv_fold\n",
    "trainval_with_fold = vis_df[vis_df['split'] == 'trainval']['cv_fold'].notna().sum()\n",
    "trainval_total = (vis_df['split'] == 'trainval').sum()\n",
    "if trainval_with_fold != trainval_total:\n",
    "    print(f\"\\n⚠️  WARNING: Only {trainval_with_fold}/{trainval_total} trainval visits have cv_fold\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 8: Save Split Definitions (LOCK THEM PERMANENTLY)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SAVING SPLIT DEFINITIONS (LOCKING PERMANENTLY)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Save visit-level metadata with splits\n",
    "output_visits = \"classification_visit_metadata_with_splits.csv\"\n",
    "vis_df.to_csv(output_visits, index=False)\n",
    "print(f\"\\n✓ Saved: {output_visits}\")\n",
    "print(f\"  Rows: {len(vis_df)}\")\n",
    "print(f\"  Columns: {len(vis_df.columns)}\")\n",
    "\n",
    "# Save subject-level splits (for reproducibility and documentation)\n",
    "output_test_subjects = f\"test_subjects_LOCKED_{LOCK_DATE}.csv\"\n",
    "test_subj_df.to_csv(output_test_subjects, index=False)\n",
    "print(f\"\\n✓ Saved: {output_test_subjects}\")\n",
    "print(f\"  Test subjects: {len(test_subj_df)}\")\n",
    "\n",
    "output_trainval_subjects = f\"trainval_subjects_{LOCK_DATE}.csv\"\n",
    "trainval_subj_df.to_csv(output_trainval_subjects, index=False)\n",
    "print(f\"\\n✓ Saved: {output_trainval_subjects}\")\n",
    "print(f\"  Train+Val subjects: {len(trainval_subj_df)}\")\n",
    "\n",
    "output_cv_folds = f\"trainval_subjects_cv_folds_{N_FOLDS}fold_{LOCK_DATE}.csv\"\n",
    "fold_df.to_csv(output_cv_folds, index=False)\n",
    "print(f\"\\n✓ Saved: {output_cv_folds}\")\n",
    "print(f\"  CV fold assignments: {len(fold_df)}\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 9: Final Summary & Warnings\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"FINAL SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\\n✅ Subject-level splits created successfully\")\n",
    "print(f\"\\n   Total subjects:     {len(subj_df)}\")\n",
    "print(f\"   Train+Val:          {len(trainval_subj_df)} ({100*len(trainval_subj_df)/len(subj_df):.1f}%)\")\n",
    "print(f\"   Test:               {len(test_subj_df)} ({100*len(test_subj_df)/len(subj_df):.1f}%)\")\n",
    "\n",
    "print(f\"\\n✅ Visit-level assignments:\")\n",
    "print(f\"   Total visits:       {len(vis_df)}\")\n",
    "print(f\"   Train+Val visits:   {(vis_df['split']=='trainval').sum()}\")\n",
    "print(f\"   Test visits:        {(vis_df['split']=='test').sum()}\")\n",
    "\n",
    "print(f\"\\n✅ Cross-validation:\")\n",
    "print(f\"   {N_FOLDS}-fold CV on train+val subjects\")\n",
    "print(f\"   Test set excluded from CV\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"⚠️  CRITICAL WARNINGS\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\n1. Test set is now LOCKED (random_state={RANDOM_STATE}, date={LOCK_DATE})\")\n",
    "print(f\"2. NEVER use test set for:\")\n",
    "print(f\"   - Hyperparameter tuning\")\n",
    "print(f\"   - Model selection\")\n",
    "print(f\"   - Feature engineering\")\n",
    "print(f\"   - Threshold optimization\")\n",
    "print(f\"\\n3. Test set should be evaluated EXACTLY ONCE after all modeling decisions\")\n",
    "print(f\"\\n4. If you need to re-run splits, you MUST:\")\n",
    "print(f\"   - Change LOCK_DATE\")\n",
    "print(f\"   - Document why in your thesis/paper\")\n",
    "print(f\"   - Re-run ALL subsequent experiments\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SNIPPET S6 COMPLETE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dcbd0eaa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T18:51:04.156180Z",
     "iopub.status.busy": "2025-11-17T18:51:04.155959Z",
     "iopub.status.idle": "2025-11-17T18:51:18.040117Z",
     "shell.execute_reply": "2025-11-17T18:51:18.039160Z"
    },
    "papermill": {
     "duration": 13.90015,
     "end_time": "2025-11-17T18:51:18.041226",
     "exception": false,
     "start_time": "2025-11-17T18:51:04.141076",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SNIPPET S7a: ACQUIRE MNI TEMPLATE PATH\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "OPTION A: Checking for pre-uploaded Kaggle dataset\n",
      "================================================================================\n",
      "✗ No pre-uploaded Kaggle dataset found\n",
      "  Checked paths:\n",
      "    - /kaggle/input/mni152-2mm/MNI152_T1_2mm_brain.nii.gz\n",
      "    - /kaggle/input/mni-templates/MNI152_T1_2mm_brain.nii.gz\n",
      "    - /kaggle/input/mni-template-neuroimaging/MNI152_T1_2mm_brain.nii.gz\n",
      "    - /kaggle/input/mni152-template/MNI152_T1_2mm_brain.nii.gz\n",
      "\n",
      "================================================================================\n",
      "OPTION B: Trying TemplateFlow\n",
      "================================================================================\n",
      "Installing TemplateFlow...\n",
      "✓ TemplateFlow installed\n",
      "\n",
      "Downloading MNI template via TemplateFlow...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://templateflow.s3.amazonaws.com/tpl-MNI152NLin2009cAsym/tpl-MNI152NLin2009cAsym_res-02_desc-brain_T1w.nii.gz\n",
      "100%|██████████| 452k/452k [00:00<00:00, 4.05MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ TemplateFlow download successful\n",
      "  Path: /root/.cache/templateflow/tpl-MNI152NLin2009cAsym/tpl-MNI152NLin2009cAsym_res-02_desc-brain_T1w.nii.gz\n",
      "\n",
      "================================================================================\n",
      "TEMPLATE VALIDATION\n",
      "================================================================================\n",
      "\n",
      "Template path: /root/.cache/templateflow/tpl-MNI152NLin2009cAsym/tpl-MNI152NLin2009cAsym_res-02_desc-brain_T1w.nii.gz\n",
      "File size: 0.43 MB\n",
      "⚠ WARNING: File size suspiciously small (<1 MB)\n",
      "  Template may be corrupted or incomplete\n",
      "\n",
      "Loading template with nibabel...\n",
      "✓ Template loaded successfully\n",
      "\n",
      "Template properties:\n",
      "  Shape:      (97, 115, 97)\n",
      "  Voxel size: (2.0, 2.0, 2.0)\n",
      "  Data type:  int16\n",
      "  Affine:\n",
      "[[   2.     0.     0.   -96.5]\n",
      " [   0.     2.     0.  -132.5]\n",
      " [   0.     0.     2.   -78.5]\n",
      " [   0.     0.     0.     1. ]]\n",
      "\n",
      "⚠ WARNING: Shape mismatch!\n",
      "  Expected: (91, 109, 91)\n",
      "  Got:      (97, 115, 97)\n",
      "  This may still work, but verify it's a valid 2mm template\n",
      "✓ Voxel spacing matches 2mm isotropic\n",
      "\n",
      "================================================================================\n",
      "TEMPLATE ACQUISITION COMPLETE\n",
      "================================================================================\n",
      "\n",
      "✅ MNI_TEMPLATE_PATH is set:\n",
      "   /root/.cache/templateflow/tpl-MNI152NLin2009cAsym/tpl-MNI152NLin2009cAsym_res-02_desc-brain_T1w.nii.gz\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "SNIPPET S7a: Acquire MNI Template Path\n",
    "Get MNI_TEMPLATE_PATH as a validated string path to a 2mm MNI T1 template.\n",
    "\n",
    "Priority Order:\n",
    "1. Pre-uploaded Kaggle dataset (fastest)\n",
    "2. TemplateFlow download (reliable)\n",
    "3. Direct HTTP download (fallback)\n",
    "4. Manual upload required (last resort)\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"SNIPPET S7a: ACQUIRE MNI TEMPLATE PATH\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Initialize\n",
    "MNI_TEMPLATE_PATH = None\n",
    "\n",
    "# ============================================================================\n",
    "# OPTION A: Pre-Uploaded Kaggle Dataset (Fastest)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"OPTION A: Checking for pre-uploaded Kaggle dataset\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Common Kaggle dataset paths to check\n",
    "KAGGLE_PATHS = [\n",
    "    \"/kaggle/input/mni152-2mm/MNI152_T1_2mm_brain.nii.gz\",\n",
    "    \"/kaggle/input/mni-templates/MNI152_T1_2mm_brain.nii.gz\",\n",
    "    \"/kaggle/input/mni-template-neuroimaging/MNI152_T1_2mm_brain.nii.gz\",\n",
    "    \"/kaggle/input/mni152-template/MNI152_T1_2mm_brain.nii.gz\"\n",
    "]\n",
    "\n",
    "for path in KAGGLE_PATHS:\n",
    "    if os.path.exists(path):\n",
    "        MNI_TEMPLATE_PATH = path\n",
    "        print(f\"✓ Found pre-uploaded template: {MNI_TEMPLATE_PATH}\")\n",
    "        break\n",
    "\n",
    "if MNI_TEMPLATE_PATH is None:\n",
    "    print(\"✗ No pre-uploaded Kaggle dataset found\")\n",
    "    print(\"  Checked paths:\")\n",
    "    for p in KAGGLE_PATHS:\n",
    "        print(f\"    - {p}\")\n",
    "\n",
    "# ============================================================================\n",
    "# OPTION B: TemplateFlow (Programmatic Download)\n",
    "# ============================================================================\n",
    "\n",
    "if MNI_TEMPLATE_PATH is None:\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"OPTION B: Trying TemplateFlow\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    try:\n",
    "        # Install TemplateFlow\n",
    "        print(\"Installing TemplateFlow...\")\n",
    "        import subprocess\n",
    "        result = subprocess.run(\n",
    "            [sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"templateflow\"],\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            timeout=60\n",
    "        )\n",
    "        \n",
    "        if result.returncode != 0:\n",
    "            raise RuntimeError(f\"pip install failed: {result.stderr}\")\n",
    "        \n",
    "        print(\"✓ TemplateFlow installed\")\n",
    "        \n",
    "        # Import and download template\n",
    "        print(\"\\nDownloading MNI template via TemplateFlow...\")\n",
    "        from templateflow import api as tflow\n",
    "        \n",
    "        tpl_path = tflow.get(\n",
    "            \"MNI152NLin2009cAsym\",\n",
    "            resolution=2,\n",
    "            desc=\"brain\",\n",
    "            suffix=\"T1w\",\n",
    "            extension=\"nii.gz\"\n",
    "        )\n",
    "        \n",
    "        MNI_TEMPLATE_PATH = str(tpl_path)\n",
    "        print(f\"✓ TemplateFlow download successful\")\n",
    "        print(f\"  Path: {MNI_TEMPLATE_PATH}\")\n",
    "        \n",
    "    except subprocess.TimeoutExpired:\n",
    "        print(\"✗ TemplateFlow installation timeout (>60s)\")\n",
    "    except ImportError as e:\n",
    "        print(f\"✗ TemplateFlow import failed: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"✗ TemplateFlow download failed: {type(e).__name__}\")\n",
    "        print(f\"  Error: {str(e)[:200]}\")\n",
    "\n",
    "# ============================================================================\n",
    "# OPTION C: Direct HTTP Download (Fallback)\n",
    "# ============================================================================\n",
    "\n",
    "if MNI_TEMPLATE_PATH is None:\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"OPTION C: Direct HTTP download\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    try:\n",
    "        import urllib.request\n",
    "        \n",
    "        # Create download directory\n",
    "        download_dir = Path(\"/kaggle/working/templates\")\n",
    "        download_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        target_path = download_dir / \"MNI152_T1_2mm_brain.nii.gz\"\n",
    "        \n",
    "        if target_path.exists():\n",
    "            print(f\"✓ Template already exists locally: {target_path}\")\n",
    "            MNI_TEMPLATE_PATH = str(target_path)\n",
    "        else:\n",
    "            print(\"Downloading from NeuroVault...\")\n",
    "            \n",
    "            # Try multiple mirror URLs\n",
    "            urls = [\n",
    "                \"https://neurovault.org/media/images/262/MNI152_T1_2mm_brain.nii.gz\",\n",
    "                \"https://ndownloader.figshare.com/files/3133832\",  # Figshare mirror\n",
    "            ]\n",
    "            \n",
    "            download_success = False\n",
    "            for url in urls:\n",
    "                try:\n",
    "                    print(f\"  Trying: {url[:50]}...\")\n",
    "                    urllib.request.urlretrieve(url, str(target_path))\n",
    "                    download_success = True\n",
    "                    print(f\"  ✓ Success\")\n",
    "                    break\n",
    "                except Exception as e:\n",
    "                    print(f\"  ✗ Failed: {str(e)[:50]}\")\n",
    "                    continue\n",
    "            \n",
    "            if download_success:\n",
    "                MNI_TEMPLATE_PATH = str(target_path)\n",
    "                print(f\"✓ Downloaded to: {MNI_TEMPLATE_PATH}\")\n",
    "            else:\n",
    "                print(\"✗ All download URLs failed\")\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"✗ Direct download failed: {type(e).__name__}\")\n",
    "        print(f\"  Error: {str(e)[:200]}\")\n",
    "\n",
    "# ============================================================================\n",
    "# VERIFICATION: Validate Template File\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"TEMPLATE VALIDATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if MNI_TEMPLATE_PATH is None:\n",
    "    print(\"\\n❌ CRITICAL ERROR: No MNI template could be acquired\")\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"MANUAL ACTION REQUIRED\")\n",
    "    print(\"=\" * 80)\n",
    "    print(\"\\nPlease follow these steps:\")\n",
    "    print(\"\\n1. Download MNI152 template locally:\")\n",
    "    print(\"   wget https://neurovault.org/media/images/262/MNI152_T1_2mm_brain.nii.gz\")\n",
    "    print(\"\\n2. Create a Kaggle dataset:\")\n",
    "    print(\"   - Go to: https://www.kaggle.com/datasets\")\n",
    "    print(\"   - Click 'New Dataset'\")\n",
    "    print(\"   - Upload: MNI152_T1_2mm_brain.nii.gz\")\n",
    "    print(\"   - Name: 'mni152-2mm'\")\n",
    "    print(\"   - Make public or private\")\n",
    "    print(\"\\n3. Add dataset to this notebook:\")\n",
    "    print(\"   - Click 'Add Data'\")\n",
    "    print(\"   - Search for your dataset\")\n",
    "    print(\"   - Add it\")\n",
    "    print(\"\\n4. Update KAGGLE_PATHS in this script with your dataset path\")\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    \n",
    "    raise RuntimeError(\"No valid MNI template available. Manual upload required.\")\n",
    "\n",
    "else:\n",
    "    print(f\"\\nTemplate path: {MNI_TEMPLATE_PATH}\")\n",
    "    \n",
    "    # Check file exists\n",
    "    if not os.path.exists(MNI_TEMPLATE_PATH):\n",
    "        raise FileNotFoundError(f\"Template path does not exist: {MNI_TEMPLATE_PATH}\")\n",
    "    \n",
    "    # Check file size (should be ~5-10 MB for compressed)\n",
    "    file_size_mb = os.path.getsize(MNI_TEMPLATE_PATH) / (1024 * 1024)\n",
    "    print(f\"File size: {file_size_mb:.2f} MB\")\n",
    "    \n",
    "    if file_size_mb < 1:\n",
    "        print(\"⚠ WARNING: File size suspiciously small (<1 MB)\")\n",
    "        print(\"  Template may be corrupted or incomplete\")\n",
    "    elif file_size_mb > 50:\n",
    "        print(\"⚠ WARNING: File size suspiciously large (>50 MB)\")\n",
    "        print(\"  May not be the correct 2mm template\")\n",
    "    else:\n",
    "        print(\"✓ File size looks reasonable\")\n",
    "    \n",
    "    # Try to load with nibabel\n",
    "    try:\n",
    "        import nibabel as nib\n",
    "        \n",
    "        print(\"\\nLoading template with nibabel...\")\n",
    "        img = nib.load(MNI_TEMPLATE_PATH)\n",
    "        \n",
    "        print(f\"✓ Template loaded successfully\")\n",
    "        print(f\"\\nTemplate properties:\")\n",
    "        print(f\"  Shape:      {img.shape}\")\n",
    "        print(f\"  Voxel size: {img.header.get_zooms()}\")\n",
    "        print(f\"  Data type:  {img.get_data_dtype()}\")\n",
    "        print(f\"  Affine:\\n{img.affine}\")\n",
    "        \n",
    "        # Verify expected dimensions\n",
    "        expected_shape = (91, 109, 91)  # Standard MNI152 2mm\n",
    "        if img.shape == expected_shape:\n",
    "            print(f\"\\n✓ Shape matches expected MNI152 2mm: {expected_shape}\")\n",
    "        else:\n",
    "            print(f\"\\n⚠ WARNING: Shape mismatch!\")\n",
    "            print(f\"  Expected: {expected_shape}\")\n",
    "            print(f\"  Got:      {img.shape}\")\n",
    "            print(\"  This may still work, but verify it's a valid 2mm template\")\n",
    "        \n",
    "        # Verify voxel spacing\n",
    "        expected_zoom = (2.0, 2.0, 2.0)\n",
    "        actual_zoom = img.header.get_zooms()[:3]\n",
    "        zoom_match = all(abs(a - e) < 0.1 for a, e in zip(actual_zoom, expected_zoom))\n",
    "        \n",
    "        if zoom_match:\n",
    "            print(f\"✓ Voxel spacing matches 2mm isotropic\")\n",
    "        else:\n",
    "            print(f\"⚠ WARNING: Voxel spacing mismatch\")\n",
    "            print(f\"  Expected: {expected_zoom}\")\n",
    "            print(f\"  Got:      {actual_zoom}\")\n",
    "        \n",
    "    except ImportError:\n",
    "        print(\"\\n⚠ nibabel not available for validation\")\n",
    "        print(\"  Will assume template is valid\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n❌ ERROR: Could not load template with nibabel\")\n",
    "        print(f\"  {type(e).__name__}: {str(e)[:200]}\")\n",
    "        raise RuntimeError(f\"Template validation failed: {e}\")\n",
    "\n",
    "# ============================================================================\n",
    "# FINAL SUMMARY\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"TEMPLATE ACQUISITION COMPLETE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\\n✅ MNI_TEMPLATE_PATH is set:\")\n",
    "print(f\"   {MNI_TEMPLATE_PATH}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "930cc33a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T18:51:18.072538Z",
     "iopub.status.busy": "2025-11-17T18:51:18.071974Z",
     "iopub.status.idle": "2025-11-17T18:51:25.763169Z",
     "shell.execute_reply": "2025-11-17T18:51:25.762382Z"
    },
    "papermill": {
     "duration": 7.708356,
     "end_time": "2025-11-17T18:51:25.764881",
     "exception": false,
     "start_time": "2025-11-17T18:51:18.056525",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SNIPPET S7c: ROBUST LOADER + REGISTRATION DEBUG\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "STEP 1: DEFINING ROBUST PREPROCESSING UTILITIES\n",
      "================================================================================\n",
      "\n",
      "✓ Enhanced preprocessing functions defined:\n",
      "  1. resolve_nifti_path() - handles directory paths\n",
      "  2. load_t1_sitk() - robust loading with debug\n",
      "  3. rigid_register_to_mni() - float casting + fallback\n",
      "  4. percentile_normalize_sitk() - intensity normalization\n",
      "\n",
      "================================================================================\n",
      "STEP 2: LOADING SAMPLE VISITS\n",
      "================================================================================\n",
      "\n",
      "Train+Val visits: 462\n",
      "  Sampled OASIS2 CN: OAS2_0143_MR3\n",
      "  Sampled OASIS2 AD: OAS2_0087_MR1\n",
      "  Sampled OASIS3 CN: OAS30253_d4746\n",
      "  Sampled OASIS3 AD: OAS30334_d0889\n",
      "\n",
      "✓ Sampled 4 test visits\n",
      "\n",
      "Sample details:\n",
      "dataset subject_id visit_code  diagnosis_binary                                                                                  nifti_path\n",
      " OASIS2  OAS2_0143        MR3               0.0                  /kaggle/input/oaisis-3-p2/OAS2_RAW_PART2/OAS2_0143_MR3/RAW/mpr-1.nifti.hdr\n",
      " OASIS2  OAS2_0087        MR1               1.0          /kaggle/input/oaisis-dataset-3-p1/OAS2_RAW_PART1/OAS2_0087_MR1/RAW/mpr-1.nifti.hdr\n",
      " OASIS3   OAS30253      d4746               0.0 /kaggle/input/oaisis-3/oaisis3/OAS30253_MR_d4746/anat1/NIFTI/sub-OAS30253_ses-d4746_T1w.nii\n",
      " OASIS3   OAS30334      d0889               1.0 /kaggle/input/oaisis-3/oaisis3/OAS30334_MR_d0889/anat2/NIFTI/sub-OAS30334_ses-d0889_T1w.nii\n",
      "\n",
      "================================================================================\n",
      "STEP 3: LOADING MNI TEMPLATE\n",
      "================================================================================\n",
      "\n",
      "✓ MNI template loaded: /root/.cache/templateflow/tpl-MNI152NLin2009cAsym/tpl-MNI152NLin2009cAsym_res-02_desc-brain_T1w.nii.gz\n",
      "  Size:    (97, 115, 97)\n",
      "  Spacing: (2.0, 2.0, 2.0)\n",
      "  Pixel:   16-bit signed integer\n",
      "  ✓ Cast to Float32\n",
      "\n",
      "================================================================================\n",
      "STEP 4: RUNNING PREPROCESSING WITH ENHANCED DEBUG\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "VISIT 1/4: OASIS2 | OAS2_0143_MR3 | CN\n",
      "================================================================================\n",
      "\n",
      "[STEP 1/3] LOADING RAW IMAGE\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "  [load] Input path: /kaggle/input/oaisis-3-p2/OAS2_RAW_PART2/OAS2_0143_MR3/RAW/mpr-1.nifti.hdr\n",
      "  [load] ✓ Image loaded successfully\n",
      "  [load]   Dimension:  3D\n",
      "  [load]   Pixel type: 32-bit float\n",
      "  [load]   Size:       (256, 256, 128)\n",
      "  [load]   Spacing:    (1.0, 1.0, 1.25)\n",
      "  [load]   Origin:     (-78.1, 127.5, -126.5)\n",
      "\n",
      "[STEP 2/3] RIGID REGISTRATION TO MNI\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "  [rigid] Starting registration...\n",
      "  [rigid] Fixed image:\n",
      "          Size:       (97, 115, 97)\n",
      "          Spacing:    (2.0, 2.0, 2.0)\n",
      "          Pixel type: 32-bit float\n",
      "  [rigid] Moving image:\n",
      "          Size:       (256, 256, 128)\n",
      "          Spacing:    (1.0, 1.0, 1.25)\n",
      "          Pixel type: 32-bit float\n",
      "  [rigid] Initializing transform (GEOMETRY mode)...\n",
      "  [rigid] ✓ Transform initialized\n",
      "          Parameters: (0.0, 0.0, 0.0, 0.75, -18.5, -16.5)\n",
      "  [rigid] Executing registration (50 iterations)...\n",
      "  [rigid] ✓ Registration converged\n",
      "          Stop condition: RegularStepGradientDescentOptimizerv4: Gradient magnitude tolerance met after 20 iterations. Gradient magnitude (8.78773e-05) is less than gradient magnitude tolerance (0.0001).\n",
      "          Final metric:   -0.2649\n",
      "          Iterations:     21\n",
      "  [rigid] ✓ Registration completed in 1.09s\n",
      "          Output size: (97, 115, 97)\n",
      "  [rigid] ✓ Output matches MNI dimensions\n",
      "\n",
      "[STEP 3/3] INTENSITY NORMALIZATION\n",
      "--------------------------------------------------------------------------------\n",
      "  [norm] Percentiles: p1.0=66.24, p99.0=2541.34\n",
      "  [norm] ✓ Normalized to [0.0000, 1.0000]\n",
      "  [norm]   Mean: 0.1521, Std: 0.2229\n",
      "  [norm]   Output shape [z,y,x]: (97, 115, 97)\n",
      "  [norm]   Mid-slice (z=48) mean/std: 0.2339 / 0.2642\n",
      "\n",
      "✓ PREPROCESSING COMPLETE in 1.80s\n",
      "\n",
      "================================================================================\n",
      "VISIT 2/4: OASIS2 | OAS2_0087_MR1 | AD\n",
      "================================================================================\n",
      "\n",
      "[STEP 1/3] LOADING RAW IMAGE\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "  [load] Input path: /kaggle/input/oaisis-dataset-3-p1/OAS2_RAW_PART1/OAS2_0087_MR1/RAW/mpr-1.nifti.hdr\n",
      "  [load] ✓ Image loaded successfully\n",
      "  [load]   Dimension:  3D\n",
      "  [load]   Pixel type: 32-bit float\n",
      "  [load]   Size:       (256, 256, 128)\n",
      "  [load]   Spacing:    (1.0, 1.0, 1.25)\n",
      "  [load]   Origin:     (-78.1, 127.5, -126.5)\n",
      "\n",
      "[STEP 2/3] RIGID REGISTRATION TO MNI\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "  [rigid] Starting registration...\n",
      "  [rigid] Fixed image:\n",
      "          Size:       (97, 115, 97)\n",
      "          Spacing:    (2.0, 2.0, 2.0)\n",
      "          Pixel type: 32-bit float\n",
      "  [rigid] Moving image:\n",
      "          Size:       (256, 256, 128)\n",
      "          Spacing:    (1.0, 1.0, 1.25)\n",
      "          Pixel type: 32-bit float\n",
      "  [rigid] Initializing transform (GEOMETRY mode)...\n",
      "  [rigid] ✓ Transform initialized\n",
      "          Parameters: (0.0, 0.0, 0.0, 0.75, -18.5, -16.5)\n",
      "  [rigid] Executing registration (50 iterations)...\n",
      "  [rigid] ✓ Registration converged\n",
      "          Stop condition: RegularStepGradientDescentOptimizerv4: Maximum number of iterations (50) exceeded.\n",
      "          Final metric:   -0.1583\n",
      "          Iterations:     50\n",
      "  [rigid] ✓ Registration completed in 1.09s\n",
      "          Output size: (97, 115, 97)\n",
      "  [rigid] ✓ Output matches MNI dimensions\n",
      "\n",
      "[STEP 3/3] INTENSITY NORMALIZATION\n",
      "--------------------------------------------------------------------------------\n",
      "  [norm] Percentiles: p1.0=67.90, p99.0=2717.25\n",
      "  [norm] ✓ Normalized to [0.0000, 1.0000]\n",
      "  [norm]   Mean: 0.1571, Std: 0.2132\n",
      "  [norm]   Output shape [z,y,x]: (97, 115, 97)\n",
      "  [norm]   Mid-slice (z=48) mean/std: 0.2156 / 0.2566\n",
      "\n",
      "✓ PREPROCESSING COMPLETE in 1.65s\n",
      "\n",
      "================================================================================\n",
      "VISIT 3/4: OASIS3 | OAS30253_d4746 | CN\n",
      "================================================================================\n",
      "\n",
      "[STEP 1/3] LOADING RAW IMAGE\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "  [load] Input path: /kaggle/input/oaisis-3/oaisis3/OAS30253_MR_d4746/anat1/NIFTI/sub-OAS30253_ses-d4746_T1w.nii\n",
      "  [resolve] Path is directory: /kaggle/input/oaisis-3/oaisis3/OAS30253_MR_d4746/anat1/NIFTI/sub-OAS30253_ses-d4746_T1w.nii\n",
      "  [resolve] Found 1 candidate(s), using: sub-OAS30253_sess-d4746_T1w.nii\n",
      "  [load] ✓ Image loaded successfully\n",
      "  [load]   Dimension:  3D\n",
      "  [load]   Pixel type: 16-bit signed integer\n",
      "  [load]   Size:       (176, 256, 256)\n",
      "  [load]   Spacing:    (1.0, 1.0, 1.0)\n",
      "  [load]   Origin:     (86.1, 94.7, -147.2)\n",
      "\n",
      "[STEP 2/3] RIGID REGISTRATION TO MNI\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "  [rigid] Starting registration...\n",
      "  [rigid] Fixed image:\n",
      "          Size:       (97, 115, 97)\n",
      "          Spacing:    (2.0, 2.0, 2.0)\n",
      "          Pixel type: 32-bit float\n",
      "  [rigid] Moving image:\n",
      "          Size:       (176, 256, 256)\n",
      "          Spacing:    (0.9999938607215881, 1.0, 1.0)\n",
      "          Pixel type: 32-bit float\n",
      "  [rigid] Initializing transform (GEOMETRY mode)...\n",
      "  [rigid] ✓ Transform initialized\n",
      "          Parameters: (0.0, 0.0, 0.0, -1.2910178244245714, -30.313553487150728, -18.856470123870622)\n",
      "  [rigid] Executing registration (50 iterations)...\n",
      "  [rigid] ✓ Registration converged\n",
      "          Stop condition: RegularStepGradientDescentOptimizerv4: Gradient magnitude tolerance met after 23 iterations. Gradient magnitude (7.79224e-05) is less than gradient magnitude tolerance (0.0001).\n",
      "          Final metric:   -0.2708\n",
      "          Iterations:     24\n",
      "  [rigid] ✓ Registration completed in 1.43s\n",
      "          Output size: (97, 115, 97)\n",
      "  [rigid] ✓ Output matches MNI dimensions\n",
      "\n",
      "[STEP 3/3] INTENSITY NORMALIZATION\n",
      "--------------------------------------------------------------------------------\n",
      "  [norm] Percentiles: p1.0=0.11, p99.0=278.73\n",
      "  [norm] ✓ Normalized to [0.0000, 1.0000]\n",
      "  [norm]   Mean: 0.1763, Std: 0.2693\n",
      "  [norm]   Output shape [z,y,x]: (97, 115, 97)\n",
      "  [norm]   Mid-slice (z=48) mean/std: 0.2711 / 0.3137\n",
      "\n",
      "✓ PREPROCESSING COMPLETE in 1.79s\n",
      "\n",
      "================================================================================\n",
      "VISIT 4/4: OASIS3 | OAS30334_d0889 | AD\n",
      "================================================================================\n",
      "\n",
      "[STEP 1/3] LOADING RAW IMAGE\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "  [load] Input path: /kaggle/input/oaisis-3/oaisis3/OAS30334_MR_d0889/anat2/NIFTI/sub-OAS30334_ses-d0889_T1w.nii\n",
      "  [resolve] Path is directory: /kaggle/input/oaisis-3/oaisis3/OAS30334_MR_d0889/anat2/NIFTI/sub-OAS30334_ses-d0889_T1w.nii\n",
      "  [resolve] Found 1 candidate(s), using: sub-OAS30334_sess-d0889_T1w.nii\n",
      "  [load] ✓ Image loaded successfully\n",
      "  [load]   Dimension:  3D\n",
      "  [load]   Pixel type: 16-bit signed integer\n",
      "  [load]   Size:       (176, 256, 256)\n",
      "  [load]   Spacing:    (1.0, 1.0, 1.0)\n",
      "  [load]   Origin:     (80.4, 89.5, -142.5)\n",
      "\n",
      "[STEP 2/3] RIGID REGISTRATION TO MNI\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "  [rigid] Starting registration...\n",
      "  [rigid] Fixed image:\n",
      "          Size:       (97, 115, 97)\n",
      "          Spacing:    (2.0, 2.0, 2.0)\n",
      "          Pixel type: 32-bit float\n",
      "  [rigid] Moving image:\n",
      "          Size:       (176, 256, 256)\n",
      "          Spacing:    (0.9999952912330627, 1.0, 1.0)\n",
      "          Pixel type: 32-bit float\n",
      "  [rigid] Initializing transform (GEOMETRY mode)...\n",
      "  [rigid] ✓ Transform initialized\n",
      "          Parameters: (0.0, 0.0, 0.0, -15.799522433041147, -54.00275623227482, -35.94001244137807)\n",
      "  [rigid] Executing registration (50 iterations)...\n",
      "  [rigid] ✓ Registration converged\n",
      "          Stop condition: RegularStepGradientDescentOptimizerv4: Gradient magnitude tolerance met after 13 iterations. Gradient magnitude (6.60762e-05) is less than gradient magnitude tolerance (0.0001).\n",
      "          Final metric:   -0.2167\n",
      "          Iterations:     14\n",
      "  [rigid] ✓ Registration completed in 1.46s\n",
      "          Output size: (97, 115, 97)\n",
      "  [rigid] ✓ Output matches MNI dimensions\n",
      "\n",
      "[STEP 3/3] INTENSITY NORMALIZATION\n",
      "--------------------------------------------------------------------------------\n",
      "  [norm] Percentiles: p1.0=1.43, p99.0=349.50\n",
      "  [norm] ✓ Normalized to [0.0000, 1.0000]\n",
      "  [norm]   Mean: 0.1980, Std: 0.2724\n",
      "  [norm]   Output shape [z,y,x]: (97, 115, 97)\n",
      "  [norm]   Mid-slice (z=48) mean/std: 0.2557 / 0.2844\n",
      "\n",
      "✓ PREPROCESSING COMPLETE in 1.74s\n",
      "\n",
      "================================================================================\n",
      "FINAL SUMMARY\n",
      "================================================================================\n",
      "\n",
      "Success rate: 4/4 (100.0%)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "SUCCESSFUL VISITS:\n",
      "--------------------------------------------------------------------------------\n",
      "dataset subject_id diagnosis    norm_shape  norm_mean  time_sec\n",
      " OASIS2  OAS2_0143        CN (97, 115, 97)   0.152066  1.804457\n",
      " OASIS2  OAS2_0087        AD (97, 115, 97)   0.157070  1.653606\n",
      " OASIS3   OAS30253        CN (97, 115, 97)   0.176329  1.791773\n",
      " OASIS3   OAS30334        AD (97, 115, 97)   0.198023  1.736920\n",
      "\n",
      "✓ Results saved to: preprocessing_debug_results.csv\n",
      "\n",
      "================================================================================\n",
      "SNIPPET S7c COMPLETE\n",
      "================================================================================\n",
      "\n",
      "✅ All visits preprocessed successfully\n",
      "✅ Directory path handling works\n",
      "✅ Registration pipeline validated\n",
      "\n",
      "Ready to proceed to full-scale preprocessing (S8)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "SNIPPET S7c: Robust Loader + Registration Debug\n",
    "Fix OASIS-3 directory path issues and debug registration failures.\n",
    "\n",
    "Fixes:\n",
    "1. Directory-aware .nii loader (OASIS-3 nested structure)\n",
    "2. Explicit float casting and dimension checks\n",
    "3. Comprehensive debug logging\n",
    "4. Graceful error handling with detailed messages\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import SimpleITK as sitk\n",
    "import time\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"SNIPPET S7c: ROBUST LOADER + REGISTRATION DEBUG\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Configuration\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# Verify MNI_TEMPLATE_PATH exists from S7a\n",
    "if 'MNI_TEMPLATE_PATH' not in globals():\n",
    "    raise RuntimeError(\"MNI_TEMPLATE_PATH not defined. Run S7a first.\")\n",
    "\n",
    "if not Path(MNI_TEMPLATE_PATH).exists():\n",
    "    raise FileNotFoundError(f\"MNI template not found: {MNI_TEMPLATE_PATH}\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 1: Enhanced Preprocessing Utilities with Debug Logging\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STEP 1: DEFINING ROBUST PREPROCESSING UTILITIES\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "def resolve_nifti_path(path):\n",
    "    \"\"\"\n",
    "    Resolve actual NIfTI file path, handling directory cases.\n",
    "    \n",
    "    OASIS-3 has nested structure:\n",
    "    .../sub-OAS30001_ses-d0129_T1w.nii/ (directory)\n",
    "      └── sub-OAS30001_ses-d0129_T1w.nii (actual file)\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    path : str\n",
    "        Input path (may be file or directory)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    str\n",
    "        Resolved file path\n",
    "    \"\"\"\n",
    "    path_obj = Path(path)\n",
    "    \n",
    "    # Check if path is a directory\n",
    "    if path_obj.is_dir():\n",
    "        print(f\"  [resolve] Path is directory: {path}\")\n",
    "        \n",
    "        # List contents\n",
    "        entries = sorted([f for f in path_obj.iterdir()])\n",
    "        \n",
    "        # Filter for .nii / .nii.gz files\n",
    "        candidates = [\n",
    "            e for e in entries \n",
    "            if e.suffix in ['.nii', '.gz'] or str(e).endswith('.nii.gz')\n",
    "        ]\n",
    "        \n",
    "        if not candidates:\n",
    "            raise FileNotFoundError(\n",
    "                f\"No .nii/.nii.gz files found inside directory: {path}\\n\"\n",
    "                f\"Directory contents: {[str(e.name) for e in entries]}\"\n",
    "            )\n",
    "        \n",
    "        # Pick first candidate (usually only one file)\n",
    "        resolved = candidates[0]\n",
    "        print(f\"  [resolve] Found {len(candidates)} candidate(s), using: {resolved.name}\")\n",
    "        \n",
    "        return str(resolved)\n",
    "    \n",
    "    elif path_obj.is_file():\n",
    "        return str(path)\n",
    "    \n",
    "    else:\n",
    "        raise FileNotFoundError(f\"Path does not exist: {path}\")\n",
    "\n",
    "\n",
    "def load_t1_sitk(nifti_path):\n",
    "    \"\"\"\n",
    "    Load T1 MRI with robust path resolution and debugging.\n",
    "    \n",
    "    Handles:\n",
    "    - ANALYZE format (.hdr/.img) - OASIS-2\n",
    "    - NIfTI format (.nii/.nii.gz) - OASIS-3\n",
    "    - Directory paths (OASIS-3 nested structure)\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    nifti_path : str\n",
    "        Path to MRI file or directory\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    SimpleITK.Image\n",
    "        Loaded MRI image\n",
    "    \"\"\"\n",
    "    print(\"\\n  [load] Input path: {}\".format(nifti_path))\n",
    "    \n",
    "    # Step 1: Resolve directory-based paths\n",
    "    try:\n",
    "        resolved_path = resolve_nifti_path(nifti_path)\n",
    "    except Exception as e:\n",
    "        print(f\"  [load] ✗ Path resolution failed: {e}\")\n",
    "        raise\n",
    "    \n",
    "    # Step 2: Load with SimpleITK\n",
    "    try:\n",
    "        img = sitk.ReadImage(resolved_path)\n",
    "        \n",
    "        # Debug information\n",
    "        print(f\"  [load] ✓ Image loaded successfully\")\n",
    "        print(f\"  [load]   Dimension:  {img.GetDimension()}D\")\n",
    "        print(f\"  [load]   Pixel type: {img.GetPixelIDTypeAsString()}\")\n",
    "        print(f\"  [load]   Size:       {img.GetSize()}\")\n",
    "        print(f\"  [load]   Spacing:    {tuple(round(s, 3) for s in img.GetSpacing())}\")\n",
    "        print(f\"  [load]   Origin:     {tuple(round(o, 1) for o in img.GetOrigin())}\")\n",
    "        \n",
    "        # Validate dimension\n",
    "        if img.GetDimension() != 3:\n",
    "            raise ValueError(\n",
    "                f\"Expected 3D image, got {img.GetDimension()}D: {img.GetSize()}\"\n",
    "            )\n",
    "        \n",
    "        return img\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  [load] ✗ SimpleITK.ReadImage failed: {type(e).__name__}\")\n",
    "        print(f\"  [load]   Error: {str(e)[:200]}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "def rigid_register_to_mni(moving_img, fixed_img, verbose=True):\n",
    "    \"\"\"\n",
    "    Rigidly register moving image to MNI with robust error handling.\n",
    "    \n",
    "    Enhancements over S7b:\n",
    "    - Explicit dimension checking\n",
    "    - Float32 casting for both images\n",
    "    - Detailed debug logging\n",
    "    - Better error messages\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    moving_img : SimpleITK.Image\n",
    "        Subject T1 image\n",
    "    fixed_img : SimpleITK.Image\n",
    "        MNI template\n",
    "    verbose : bool\n",
    "        Print registration progress\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    SimpleITK.Image\n",
    "        Registered image in MNI space\n",
    "    \"\"\"\n",
    "    if verbose:\n",
    "        print(\"\\n  [rigid] Starting registration...\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Step 0: Sanity checks on dimensions\n",
    "    dim_m = moving_img.GetDimension()\n",
    "    dim_f = fixed_img.GetDimension()\n",
    "    \n",
    "    if dim_m != dim_f:\n",
    "        raise ValueError(\n",
    "            f\"Dimension mismatch: moving={dim_m}D, fixed={dim_f}D. \"\n",
    "            f\"Cannot register images with different dimensions.\"\n",
    "        )\n",
    "    \n",
    "    if dim_m != 3:\n",
    "        raise ValueError(\n",
    "            f\"Registration requires 3D images, got {dim_m}D\"\n",
    "        )\n",
    "    \n",
    "    # Step 1: Cast to Float32 (required for robust registration)\n",
    "    moving_f = sitk.Cast(moving_img, sitk.sitkFloat32)\n",
    "    fixed_f = sitk.Cast(fixed_img, sitk.sitkFloat32)\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"  [rigid] Fixed image:\")\n",
    "        print(f\"          Size:       {fixed_f.GetSize()}\")\n",
    "        print(f\"          Spacing:    {fixed_f.GetSpacing()}\")\n",
    "        print(f\"          Pixel type: {fixed_f.GetPixelIDTypeAsString()}\")\n",
    "        \n",
    "        print(f\"  [rigid] Moving image:\")\n",
    "        print(f\"          Size:       {moving_f.GetSize()}\")\n",
    "        print(f\"          Spacing:    {moving_f.GetSpacing()}\")\n",
    "        print(f\"          Pixel type: {moving_f.GetPixelIDTypeAsString()}\")\n",
    "    \n",
    "    # Step 2: Initialize transform\n",
    "    try:\n",
    "        if verbose:\n",
    "            print(f\"  [rigid] Initializing transform (GEOMETRY mode)...\")\n",
    "        \n",
    "        initial_tx = sitk.CenteredTransformInitializer(\n",
    "            fixed_f,\n",
    "            moving_f,\n",
    "            sitk.Euler3DTransform(),\n",
    "            sitk.CenteredTransformInitializerFilter.GEOMETRY\n",
    "        )\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"  [rigid] ✓ Transform initialized\")\n",
    "            print(f\"          Parameters: {initial_tx.GetParameters()}\")\n",
    "        \n",
    "    except RuntimeError as e:\n",
    "        # If GEOMETRY fails, try MOMENTS\n",
    "        error_msg = str(e)\n",
    "        print(f\"  [rigid] ✗ GEOMETRY initialization failed: {error_msg[:100]}\")\n",
    "        print(f\"  [rigid]   Trying MOMENTS mode as fallback...\")\n",
    "        \n",
    "        try:\n",
    "            initial_tx = sitk.CenteredTransformInitializer(\n",
    "                fixed_f,\n",
    "                moving_f,\n",
    "                sitk.Euler3DTransform(),\n",
    "                sitk.CenteredTransformInitializerFilter.MOMENTS\n",
    "            )\n",
    "            print(f\"  [rigid] ✓ MOMENTS initialization successful\")\n",
    "        except Exception as e2:\n",
    "            print(f\"  [rigid] ✗ MOMENTS also failed: {str(e2)[:100]}\")\n",
    "            raise RuntimeError(\n",
    "                f\"Transform initialization failed with both GEOMETRY and MOMENTS.\\n\"\n",
    "                f\"GEOMETRY error: {error_msg}\\n\"\n",
    "                f\"MOMENTS error: {str(e2)}\"\n",
    "            )\n",
    "    \n",
    "    # Step 3: Configure registration\n",
    "    reg = sitk.ImageRegistrationMethod()\n",
    "    \n",
    "    # Metric: Mattes Mutual Information\n",
    "    reg.SetMetricAsMattesMutualInformation(numberOfHistogramBins=32)\n",
    "    reg.SetMetricSamplingStrategy(reg.RANDOM)\n",
    "    reg.SetMetricSamplingPercentage(0.01)\n",
    "    \n",
    "    # Optimizer: Regular Step Gradient Descent\n",
    "    reg.SetOptimizerAsRegularStepGradientDescent(\n",
    "        learningRate=2.0,\n",
    "        minStep=1e-3,\n",
    "        numberOfIterations=50,  # Reduced for faster prototyping\n",
    "        relaxationFactor=0.5\n",
    "    )\n",
    "    reg.SetOptimizerScalesFromPhysicalShift()\n",
    "    \n",
    "    # Interpolation\n",
    "    reg.SetInterpolator(sitk.sitkLinear)\n",
    "    \n",
    "    # Initial transform\n",
    "    reg.SetInitialTransform(initial_tx, inPlace=False)\n",
    "    \n",
    "    # Step 4: Execute registration\n",
    "    try:\n",
    "        if verbose:\n",
    "            print(f\"  [rigid] Executing registration (50 iterations)...\")\n",
    "        \n",
    "        final_tx = reg.Execute(fixed_f, moving_f)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"  [rigid] ✓ Registration converged\")\n",
    "            print(f\"          Stop condition: {reg.GetOptimizerStopConditionDescription()}\")\n",
    "            print(f\"          Final metric:   {reg.GetMetricValue():.4f}\")\n",
    "            print(f\"          Iterations:     {reg.GetOptimizerIteration()}\")\n",
    "        \n",
    "        # Step 5: Resample to MNI space\n",
    "        resampled = sitk.Resample(\n",
    "            moving_f,\n",
    "            fixed_f,\n",
    "            final_tx,\n",
    "            sitk.sitkLinear,\n",
    "            0.0,\n",
    "            sitk.sitkFloat32\n",
    "        )\n",
    "        \n",
    "        elapsed = time.time() - start_time\n",
    "        if verbose:\n",
    "            print(f\"  [rigid] ✓ Registration completed in {elapsed:.2f}s\")\n",
    "            print(f\"          Output size: {resampled.GetSize()}\")\n",
    "        \n",
    "        return resampled\n",
    "        \n",
    "    except Exception as e:\n",
    "        elapsed = time.time() - start_time\n",
    "        print(f\"  [rigid] ✗ Registration failed after {elapsed:.2f}s\")\n",
    "        print(f\"          {type(e).__name__}: {str(e)[:200]}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "def percentile_normalize_sitk(img, p1=1.0, p99=99.0):\n",
    "    \"\"\"\n",
    "    Percentile-based intensity normalization to [0, 1].\n",
    "    \n",
    "    Same as S7b, operates on non-zero voxels only.\n",
    "    \"\"\"\n",
    "    arr = sitk.GetArrayFromImage(img).astype(np.float32)\n",
    "    mask = arr != 0\n",
    "    \n",
    "    if not np.any(mask):\n",
    "        print(\"  [norm] ⚠ Warning: All voxels are zero\")\n",
    "        return arr\n",
    "    \n",
    "    vals = arr[mask]\n",
    "    lo = np.percentile(vals, p1)\n",
    "    hi = np.percentile(vals, p99)\n",
    "    \n",
    "    print(f\"  [norm] Percentiles: p{p1}={lo:.2f}, p{p99}={hi:.2f}\")\n",
    "    \n",
    "    if hi <= lo:\n",
    "        print(f\"  [norm] ⚠ Warning: p{p99} <= p{p1}\")\n",
    "        return np.clip((arr - lo), 0, None)\n",
    "    \n",
    "    arr = np.clip(arr, lo, hi)\n",
    "    arr = (arr - lo) / (hi - lo)\n",
    "    \n",
    "    print(f\"  [norm] ✓ Normalized to [{arr.min():.4f}, {arr.max():.4f}]\")\n",
    "    print(f\"  [norm]   Mean: {arr.mean():.4f}, Std: {arr.std():.4f}\")\n",
    "    \n",
    "    return arr\n",
    "\n",
    "print(\"\\n✓ Enhanced preprocessing functions defined:\")\n",
    "print(\"  1. resolve_nifti_path() - handles directory paths\")\n",
    "print(\"  2. load_t1_sitk() - robust loading with debug\")\n",
    "print(\"  3. rigid_register_to_mni() - float casting + fallback\")\n",
    "print(\"  4. percentile_normalize_sitk() - intensity normalization\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 2: Load Sample Visits\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STEP 2: LOADING SAMPLE VISITS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Load classification metadata with splits\n",
    "df = pd.read_csv(\"classification_visit_metadata_with_splits.csv\")\n",
    "trainval_df = df[df[\"split\"] == \"trainval\"].copy()\n",
    "\n",
    "print(f\"\\nTrain+Val visits: {len(trainval_df)}\")\n",
    "\n",
    "# Sample 1 CN + 1 AD from each dataset\n",
    "samples = []\n",
    "\n",
    "for dataset in [\"OASIS2\", \"OASIS3\"]:\n",
    "    ds_df = trainval_df[trainval_df[\"dataset\"] == dataset]\n",
    "    \n",
    "    for label in [0.0, 1.0]:\n",
    "        sub = ds_df[ds_df[\"diagnosis_binary\"] == label]\n",
    "        \n",
    "        if len(sub) == 0:\n",
    "            print(f\"⚠ Warning: No {dataset} visits with label={label}\")\n",
    "            continue\n",
    "        \n",
    "        sample = sub.sample(1, random_state=RANDOM_STATE)\n",
    "        samples.append(sample)\n",
    "        \n",
    "        row = sample.iloc[0]\n",
    "        label_str = \"CN\" if label == 0 else \"AD\"\n",
    "        print(f\"  Sampled {dataset} {label_str}: {row['subject_id']}_{row['visit_code']}\")\n",
    "\n",
    "sample_df = pd.concat(samples, ignore_index=True)\n",
    "\n",
    "print(f\"\\n✓ Sampled {len(sample_df)} test visits\")\n",
    "print(\"\\nSample details:\")\n",
    "display_cols = ['dataset', 'subject_id', 'visit_code', 'diagnosis_binary', 'nifti_path']\n",
    "print(sample_df[display_cols].to_string(index=False))\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 3: Load MNI Template\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STEP 3: LOADING MNI TEMPLATE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "try:\n",
    "    mni_img = sitk.ReadImage(MNI_TEMPLATE_PATH)\n",
    "    print(f\"\\n✓ MNI template loaded: {MNI_TEMPLATE_PATH}\")\n",
    "    print(f\"  Size:    {mni_img.GetSize()}\")\n",
    "    print(f\"  Spacing: {mni_img.GetSpacing()}\")\n",
    "    print(f\"  Pixel:   {mni_img.GetPixelIDTypeAsString()}\")\n",
    "    \n",
    "    # Cast to Float32 for consistency\n",
    "    mni_img = sitk.Cast(mni_img, sitk.sitkFloat32)\n",
    "    print(f\"  ✓ Cast to Float32\")\n",
    "    \n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"Failed to load MNI template: {e}\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 4: Run Preprocessing with Debug\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STEP 4: RUNNING PREPROCESSING WITH ENHANCED DEBUG\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "results = []\n",
    "\n",
    "for idx, row in sample_df.iterrows():\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    \n",
    "    label_str = \"CN\" if row['diagnosis_binary'] == 0 else \"AD\"\n",
    "    print(f\"VISIT {idx+1}/{len(sample_df)}: {row['dataset']} | {row['subject_id']}_{row['visit_code']} | {label_str}\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    path = row['nifti_path']\n",
    "    \n",
    "    try:\n",
    "        visit_start = time.time()\n",
    "        \n",
    "        # Step 1: Load raw image\n",
    "        print(\"\\n[STEP 1/3] LOADING RAW IMAGE\")\n",
    "        print(\"-\" * 80)\n",
    "        mov_img = load_t1_sitk(path)\n",
    "        \n",
    "        # Step 2: Rigid registration\n",
    "        print(\"\\n[STEP 2/3] RIGID REGISTRATION TO MNI\")\n",
    "        print(\"-\" * 80)\n",
    "        reg_img = rigid_register_to_mni(mov_img, mni_img, verbose=True)\n",
    "        \n",
    "        # Verify output\n",
    "        if reg_img.GetSize() == mni_img.GetSize():\n",
    "            print(f\"  [rigid] ✓ Output matches MNI dimensions\")\n",
    "        else:\n",
    "            print(f\"  [rigid] ⚠ Output size mismatch: {reg_img.GetSize()} vs {mni_img.GetSize()}\")\n",
    "        \n",
    "        # Step 3: Intensity normalization\n",
    "        print(\"\\n[STEP 3/3] INTENSITY NORMALIZATION\")\n",
    "        print(\"-\" * 80)\n",
    "        arr_norm = percentile_normalize_sitk(reg_img)\n",
    "        \n",
    "        print(f\"  [norm]   Output shape [z,y,x]: {arr_norm.shape}\")\n",
    "        \n",
    "        # Mid-slice quality check\n",
    "        z_mid = arr_norm.shape[0] // 2\n",
    "        mid_slice = arr_norm[z_mid, :, :]\n",
    "        print(f\"  [norm]   Mid-slice (z={z_mid}) mean/std: {mid_slice.mean():.4f} / {mid_slice.std():.4f}\")\n",
    "        \n",
    "        elapsed = time.time() - visit_start\n",
    "        print(f\"\\n✓ PREPROCESSING COMPLETE in {elapsed:.2f}s\")\n",
    "        \n",
    "        results.append({\n",
    "            'dataset': row['dataset'],\n",
    "            'subject_id': row['subject_id'],\n",
    "            'visit_code': row['visit_code'],\n",
    "            'diagnosis': label_str,\n",
    "            'status': 'SUCCESS',\n",
    "            'time_sec': elapsed,\n",
    "            'norm_shape': str(arr_norm.shape),\n",
    "            'norm_mean': float(arr_norm.mean()),\n",
    "            'norm_std': float(arr_norm.std()),\n",
    "            'norm_min': float(arr_norm.min()),\n",
    "            'norm_max': float(arr_norm.max())\n",
    "        })\n",
    "        \n",
    "    except Exception as e:\n",
    "        elapsed = time.time() - visit_start\n",
    "        print(f\"\\n✗ PREPROCESSING FAILED after {elapsed:.2f}s\")\n",
    "        print(f\"   {type(e).__name__}: {str(e)[:300]}\")\n",
    "        \n",
    "        results.append({\n",
    "            'dataset': row['dataset'],\n",
    "            'subject_id': row['subject_id'],\n",
    "            'visit_code': row['visit_code'],\n",
    "            'diagnosis': label_str,\n",
    "            'status': 'FAILED',\n",
    "            'error_type': type(e).__name__,\n",
    "            'error_msg': str(e)[:300]\n",
    "        })\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 5: Summary\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"FINAL SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "n_success = (results_df['status'] == 'SUCCESS').sum()\n",
    "n_total = len(results_df)\n",
    "\n",
    "print(f\"\\nSuccess rate: {n_success}/{n_total} ({100*n_success/n_total:.1f}%)\")\n",
    "\n",
    "if n_success > 0:\n",
    "    success_df = results_df[results_df['status'] == 'SUCCESS']\n",
    "    print(\"\\n\" + \"-\" * 80)\n",
    "    print(\"SUCCESSFUL VISITS:\")\n",
    "    print(\"-\" * 80)\n",
    "    display_cols = ['dataset', 'subject_id', 'diagnosis', 'norm_shape', 'norm_mean', 'time_sec']\n",
    "    print(success_df[display_cols].to_string(index=False))\n",
    "\n",
    "if n_success < n_total:\n",
    "    failed_df = results_df[results_df['status'] == 'FAILED']\n",
    "    print(\"\\n\" + \"-\" * 80)\n",
    "    print(\"FAILED VISITS:\")\n",
    "    print(\"-\" * 80)\n",
    "    for _, row in failed_df.iterrows():\n",
    "        print(f\"\\n{row['dataset']} | {row['subject_id']} | {row['diagnosis']}\")\n",
    "        print(f\"  Error type: {row.get('error_type', 'Unknown')}\")\n",
    "        print(f\"  Message: {row.get('error_msg', 'No message')[:200]}\")\n",
    "\n",
    "# Save results\n",
    "output_file = \"preprocessing_debug_results.csv\"\n",
    "results_df.to_csv(output_file, index=False)\n",
    "print(f\"\\n✓ Results saved to: {output_file}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SNIPPET S7c COMPLETE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if n_success == n_total:\n",
    "    print(\"\\n✅ All visits preprocessed successfully\")\n",
    "    print(\"✅ Directory path handling works\")\n",
    "    print(\"✅ Registration pipeline validated\")\n",
    "    print(\"\\nReady to proceed to full-scale preprocessing (S8)\")\n",
    "else:\n",
    "    print(f\"\\n⚠ {n_total - n_success}/{n_total} visits failed\")\n",
    "    print(\"\\nReview error messages above before proceeding\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9726af89",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T18:51:25.797228Z",
     "iopub.status.busy": "2025-11-17T18:51:25.796994Z",
     "iopub.status.idle": "2025-11-17T19:06:47.034670Z",
     "shell.execute_reply": "2025-11-17T19:06:47.033416Z"
    },
    "papermill": {
     "duration": 921.255265,
     "end_time": "2025-11-17T19:06:47.036130",
     "exception": false,
     "start_time": "2025-11-17T18:51:25.780865",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SNIPPET S8b: FULL-SCALE MNI PREPROCESSING (FIXED SHAPE)\n",
      "================================================================================\n",
      "Start time: 2025-11-17 18:51:25\n",
      "\n",
      "⚠️  CRITICAL FIX:\n",
      "   Expected shape changed from (91,109,91) to (97,115,97)\n",
      "   This matches TemplateFlow MNI152NLin2009cAsym res-02 template\n",
      "\n",
      "================================================================================\n",
      "CONFIGURATION\n",
      "================================================================================\n",
      "\n",
      "Expected volume shape: (97, 115, 97)\n",
      "  (Z, Y, X) = (97, 115, 97)\n",
      "  Voxel size: 2×2×2 mm\n",
      "\n",
      "Input:\n",
      "  Metadata: classification_visit_metadata_with_splits.csv\n",
      "  MNI template: /root/.cache/templateflow/tpl-MNI152NLin2009cAsym/tpl-MNI152NLin2009cAsym_res-02_desc-brain_T1w.nii.gz\n",
      "\n",
      "Output:\n",
      "  Root: /kaggle/working/mni_preproc_v2\n",
      "  Volumes: /kaggle/working/mni_preproc_v2/volumes\n",
      "  Log: /kaggle/working/mni_preproc_v2/preprocessing_all_visits_log_v2.csv\n",
      "  Metadata: classification_mni_volumes_metadata_v2.csv\n",
      "\n",
      "================================================================================\n",
      "LOADING METADATA\n",
      "================================================================================\n",
      "\n",
      "Loaded: classification_visit_metadata_with_splits.csv\n",
      "  Total rows: 577\n",
      "\n",
      "Visits to process: 577\n",
      "\n",
      "Distribution:\n",
      "split\n",
      "trainval    462\n",
      "test        115\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Dataset × Diagnosis:\n",
      "diagnosis_binary  0.0  1.0  All\n",
      "dataset                        \n",
      "OASIS2            206   44  250\n",
      "OASIS3            293   34  327\n",
      "All               499   78  577\n",
      "\n",
      "================================================================================\n",
      "LOADING & VERIFYING MNI TEMPLATE\n",
      "================================================================================\n",
      "\n",
      "✓ MNI template loaded\n",
      "  Size:    (97, 115, 97)\n",
      "  Spacing: (2.0, 2.0, 2.0)\n",
      "\n",
      "✓ MNI size matches EXPECTED_SHAPE: (97, 115, 97)\n",
      "\n",
      "================================================================================\n",
      "LOADING PREPROCESSING UTILITIES\n",
      "================================================================================\n",
      "\n",
      "✓ Preprocessing utilities loaded\n",
      "\n",
      "================================================================================\n",
      "STARTING PREPROCESSING LOOP\n",
      "================================================================================\n",
      "\n",
      "Total visits to process: 577\n",
      "Expected shape per volume: (97, 115, 97)\n",
      "\n",
      "Progress every 10 visits\n",
      "--------------------------------------------------------------------------------\n",
      "[ 10/577]   1.7% | OK: 10 | BadShape: 0 | Failed: 0 | ETA: 15.2min\n",
      "[ 20/577]   3.5% | OK: 20 | BadShape: 0 | Failed: 0 | ETA: 15.0min\n",
      "[ 30/577]   5.2% | OK: 30 | BadShape: 0 | Failed: 0 | ETA: 14.2min\n",
      "[ 40/577]   6.9% | OK: 40 | BadShape: 0 | Failed: 0 | ETA: 13.7min\n",
      "[ 50/577]   8.7% | OK: 50 | BadShape: 0 | Failed: 0 | ETA: 13.3min\n",
      "[ 60/577]  10.4% | OK: 60 | BadShape: 0 | Failed: 0 | ETA: 13.0min\n",
      "[ 70/577]  12.1% | OK: 70 | BadShape: 0 | Failed: 0 | ETA: 12.8min\n",
      "[ 80/577]  13.9% | OK: 80 | BadShape: 0 | Failed: 0 | ETA: 12.5min\n",
      "[ 90/577]  15.6% | OK: 90 | BadShape: 0 | Failed: 0 | ETA: 12.3min\n",
      "[100/577]  17.3% | OK: 100 | BadShape: 0 | Failed: 0 | ETA: 12.1min\n",
      "[110/577]  19.1% | OK: 110 | BadShape: 0 | Failed: 0 | ETA: 11.8min\n",
      "[120/577]  20.8% | OK: 120 | BadShape: 0 | Failed: 0 | ETA: 11.6min\n",
      "[130/577]  22.5% | OK: 130 | BadShape: 0 | Failed: 0 | ETA: 11.3min\n",
      "[140/577]  24.3% | OK: 140 | BadShape: 0 | Failed: 0 | ETA: 11.1min\n",
      "[150/577]  26.0% | OK: 150 | BadShape: 0 | Failed: 0 | ETA: 10.8min\n",
      "[160/577]  27.7% | OK: 160 | BadShape: 0 | Failed: 0 | ETA: 10.6min\n",
      "[170/577]  29.5% | OK: 170 | BadShape: 0 | Failed: 0 | ETA: 10.3min\n",
      "[180/577]  31.2% | OK: 180 | BadShape: 0 | Failed: 0 | ETA: 10.0min\n",
      "[190/577]  32.9% | OK: 190 | BadShape: 0 | Failed: 0 | ETA: 9.8min\n",
      "[200/577]  34.7% | OK: 200 | BadShape: 0 | Failed: 0 | ETA: 9.5min\n",
      "[210/577]  36.4% | OK: 210 | BadShape: 0 | Failed: 0 | ETA: 9.3min\n",
      "[220/577]  38.1% | OK: 220 | BadShape: 0 | Failed: 0 | ETA: 9.0min\n",
      "[230/577]  39.9% | OK: 230 | BadShape: 0 | Failed: 0 | ETA: 8.8min\n",
      "[240/577]  41.6% | OK: 240 | BadShape: 0 | Failed: 0 | ETA: 8.5min\n",
      "[250/577]  43.3% | OK: 250 | BadShape: 0 | Failed: 0 | ETA: 8.2min\n",
      "[260/577]  45.1% | OK: 260 | BadShape: 0 | Failed: 0 | ETA: 8.0min\n",
      "[270/577]  46.8% | OK: 270 | BadShape: 0 | Failed: 0 | ETA: 7.8min\n",
      "[280/577]  48.5% | OK: 280 | BadShape: 0 | Failed: 0 | ETA: 7.5min\n",
      "[290/577]  50.3% | OK: 290 | BadShape: 0 | Failed: 0 | ETA: 7.3min\n",
      "[300/577]  52.0% | OK: 300 | BadShape: 0 | Failed: 0 | ETA: 7.1min\n",
      "[310/577]  53.7% | OK: 310 | BadShape: 0 | Failed: 0 | ETA: 6.8min\n",
      "[320/577]  55.5% | OK: 320 | BadShape: 0 | Failed: 0 | ETA: 6.6min\n",
      "[330/577]  57.2% | OK: 330 | BadShape: 0 | Failed: 0 | ETA: 6.4min\n",
      "[340/577]  58.9% | OK: 340 | BadShape: 0 | Failed: 0 | ETA: 6.1min\n",
      "[350/577]  60.7% | OK: 350 | BadShape: 0 | Failed: 0 | ETA: 5.9min\n",
      "[360/577]  62.4% | OK: 360 | BadShape: 0 | Failed: 0 | ETA: 5.6min\n",
      "[370/577]  64.1% | OK: 370 | BadShape: 0 | Failed: 0 | ETA: 5.4min\n",
      "[380/577]  65.9% | OK: 380 | BadShape: 0 | Failed: 0 | ETA: 5.1min\n",
      "[390/577]  67.6% | OK: 390 | BadShape: 0 | Failed: 0 | ETA: 4.9min\n",
      "[400/577]  69.3% | OK: 400 | BadShape: 0 | Failed: 0 | ETA: 4.6min\n",
      "[410/577]  71.1% | OK: 410 | BadShape: 0 | Failed: 0 | ETA: 4.4min\n",
      "[420/577]  72.8% | OK: 420 | BadShape: 0 | Failed: 0 | ETA: 4.1min\n",
      "[430/577]  74.5% | OK: 430 | BadShape: 0 | Failed: 0 | ETA: 3.8min\n",
      "[440/577]  76.3% | OK: 440 | BadShape: 0 | Failed: 0 | ETA: 3.6min\n",
      "[450/577]  78.0% | OK: 450 | BadShape: 0 | Failed: 0 | ETA: 3.3min\n",
      "[460/577]  79.7% | OK: 460 | BadShape: 0 | Failed: 0 | ETA: 3.1min\n",
      "[470/577]  81.5% | OK: 470 | BadShape: 0 | Failed: 0 | ETA: 2.8min\n",
      "[480/577]  83.2% | OK: 480 | BadShape: 0 | Failed: 0 | ETA: 2.6min\n",
      "[490/577]  84.9% | OK: 490 | BadShape: 0 | Failed: 0 | ETA: 2.3min\n",
      "[500/577]  86.7% | OK: 500 | BadShape: 0 | Failed: 0 | ETA: 2.0min\n",
      "[510/577]  88.4% | OK: 510 | BadShape: 0 | Failed: 0 | ETA: 1.8min\n",
      "[520/577]  90.1% | OK: 520 | BadShape: 0 | Failed: 0 | ETA: 1.5min\n",
      "[530/577]  91.9% | OK: 530 | BadShape: 0 | Failed: 0 | ETA: 1.2min\n",
      "[540/577]  93.6% | OK: 540 | BadShape: 0 | Failed: 0 | ETA: 1.0min\n",
      "[550/577]  95.3% | OK: 550 | BadShape: 0 | Failed: 0 | ETA: 0.7min\n",
      "[560/577]  97.1% | OK: 560 | BadShape: 0 | Failed: 0 | ETA: 0.5min\n",
      "[570/577]  98.8% | OK: 570 | BadShape: 0 | Failed: 0 | ETA: 0.2min\n",
      "--------------------------------------------------------------------------------\n",
      "✓ Processing complete in 15.4 minutes\n",
      "\n",
      "================================================================================\n",
      "SAVING LOGS & METADATA\n",
      "================================================================================\n",
      "\n",
      "✓ Saved log: /kaggle/working/mni_preproc_v2/preprocessing_all_visits_log_v2.csv\n",
      "\n",
      "Status counts:\n",
      "  ok             :  577 (100.0%)\n",
      "\n",
      "✓ Saved metadata: classification_mni_volumes_metadata_v2.csv\n",
      "\n",
      "================================================================================\n",
      "QUALITY CONTROL STATISTICS\n",
      "================================================================================\n",
      "\n",
      "Volume shapes (should all be (97, 115, 97)):\n",
      "  (97, 115, 97):  577 (100.0%)\n",
      "\n",
      "Success rate by dataset:\n",
      "  OASIS2    : 250/250 (100.0%)\n",
      "  OASIS3    : 327/327 (100.0%)\n",
      "\n",
      "Intensity statistics (successful volumes):\n",
      "  Mean: 0.1765 ± 0.0214\n",
      "  Std:  0.2445 ± 0.0223\n",
      "\n",
      "Timing statistics:\n",
      "  Total:  15.4 min\n",
      "  Avg:    1.60s per visit\n",
      "  Median: 1.60s\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "SAMPLE SUCCESSFUL VOLUMES:\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "OASIS2:\n",
      "  OASIS2|OAS2_0097|MR1           | CN | shape=(97, 115, 97) | mean=0.1723\n",
      "  OASIS2|OAS2_0007|MR3           | AD | shape=(97, 115, 97) | mean=0.1282\n",
      "  OASIS2|OAS2_0069|MR2           | CN | shape=(97, 115, 97) | mean=0.1451\n",
      "\n",
      "OASIS3:\n",
      "  OASIS3|OAS30898|d0946          | CN | shape=(97, 115, 97) | mean=0.1689\n",
      "  OASIS3|OAS30305|d0245          | CN | shape=(97, 115, 97) | mean=0.1863\n",
      "  OASIS3|OAS30967|d0098          | CN | shape=(97, 115, 97) | mean=0.1722\n",
      "\n",
      "================================================================================\n",
      "FINAL SUMMARY\n",
      "================================================================================\n",
      "\n",
      "✅ Preprocessing complete\n",
      "\n",
      "   Processed:   577/577\n",
      "   Successful:  577 (100.0%)\n",
      "   Bad shape:   0\n",
      "   Errors:      0\n",
      "   Skipped:     0\n",
      "\n",
      "✅ High success rate (≥95%) - excellent!\n",
      "✅ Ready for downstream tasks\n",
      "\n",
      "✅ Output:\n",
      "   Volumes: /kaggle/working/mni_preproc_v2/volumes (577 .npy files)\n",
      "   Shape:   (97, 115, 97) per volume\n",
      "   Size:    ~4.13 MB per file\n",
      "\n",
      "================================================================================\n",
      "End time: 2025-11-17 19:06:47\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "VERIFICATION CODE FOR NEXT CELL\n",
      "================================================================================\n",
      "\n",
      "# Run this in the next cell to verify results:\n",
      "\n",
      "import pandas as pd\n",
      "\n",
      "log = pd.read_csv(\"/kaggle/working/mni_preproc_v2/preprocessing_all_visits_log_v2.csv\")\n",
      "\n",
      "print(\"Status distribution:\")\n",
      "print(log[\"status\"].value_counts())\n",
      "\n",
      "print(\"\\nShape distribution (successful volumes):\")\n",
      "ok_log = log[log[\"status\"] == \"ok\"]\n",
      "print(ok_log[\"vol_shape\"].value_counts())\n",
      "\n",
      "print(\"\\nSuccess by dataset:\")\n",
      "print(log.groupby([\"dataset\", \"status\"]).size())\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "SNIPPET S8b: Full-Scale MNI Preprocessing (Fixed Shape Validation)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import SimpleITK as sitk\n",
    "import time\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"SNIPPET S8b: FULL-SCALE MNI PREPROCESSING (FIXED SHAPE)\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Start time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "print(\"\\n⚠️  CRITICAL FIX:\")\n",
    "print(\"   Expected shape changed from (91,109,91) to (97,115,97)\")\n",
    "print(\"   This matches TemplateFlow MNI152NLin2009cAsym res-02 template\")\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURATION\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"CONFIGURATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# CRITICAL: Updated expected shape\n",
    "EXPECTED_SHAPE = (97, 115, 97)  # TemplateFlow MNI 2mm (was 91,109,91 in S8)\n",
    "\n",
    "# Input paths\n",
    "CLASS_META_PATH = \"classification_visit_metadata_with_splits.csv\"\n",
    "\n",
    "# Verify MNI template\n",
    "if 'MNI_TEMPLATE_PATH' not in globals():\n",
    "    raise RuntimeError(\"MNI_TEMPLATE_PATH not defined. Run S7a first.\")\n",
    "\n",
    "# Output paths (new directory to avoid collision with S8)\n",
    "OUTPUT_ROOT = Path(\"/kaggle/working/mni_preproc_v2\")\n",
    "VOLUME_DIR = OUTPUT_ROOT / \"volumes\"\n",
    "LOG_CSV_PATH = OUTPUT_ROOT / \"preprocessing_all_visits_log_v2.csv\"\n",
    "META_OUT_PATH = \"classification_mni_volumes_metadata_v2.csv\"\n",
    "\n",
    "# Processing mode\n",
    "PROCESS_MODE = \"all\"\n",
    "\n",
    "# Create output directories\n",
    "OUTPUT_ROOT.mkdir(exist_ok=True)\n",
    "VOLUME_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"\\nExpected volume shape: {EXPECTED_SHAPE}\")\n",
    "print(f\"  (Z, Y, X) = {EXPECTED_SHAPE}\")\n",
    "print(f\"  Voxel size: 2×2×2 mm\")\n",
    "\n",
    "print(f\"\\nInput:\")\n",
    "print(f\"  Metadata: {CLASS_META_PATH}\")\n",
    "print(f\"  MNI template: {MNI_TEMPLATE_PATH}\")\n",
    "\n",
    "print(f\"\\nOutput:\")\n",
    "print(f\"  Root: {OUTPUT_ROOT}\")\n",
    "print(f\"  Volumes: {VOLUME_DIR}\")\n",
    "print(f\"  Log: {LOG_CSV_PATH}\")\n",
    "print(f\"  Metadata: {META_OUT_PATH}\")\n",
    "\n",
    "# ============================================================================\n",
    "# LOAD METADATA\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"LOADING METADATA\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "meta = pd.read_csv(CLASS_META_PATH)\n",
    "\n",
    "print(f\"\\nLoaded: {CLASS_META_PATH}\")\n",
    "print(f\"  Total rows: {len(meta)}\")\n",
    "\n",
    "# Filter by processing mode\n",
    "if PROCESS_MODE == \"trainval_only\":\n",
    "    df = meta[meta['split'] == 'trainval'].copy()\n",
    "elif PROCESS_MODE == \"test_only\":\n",
    "    df = meta[meta['split'] == 'test'].copy()\n",
    "else:\n",
    "    df = meta.copy()\n",
    "\n",
    "print(f\"\\nVisits to process: {len(df)}\")\n",
    "print(\"\\nDistribution:\")\n",
    "print(df['split'].value_counts())\n",
    "print(\"\\nDataset × Diagnosis:\")\n",
    "print(pd.crosstab(df['dataset'], df['diagnosis_binary'], margins=True))\n",
    "\n",
    "# ============================================================================\n",
    "# LOAD MNI TEMPLATE & VERIFY SHAPE\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"LOADING & VERIFYING MNI TEMPLATE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "try:\n",
    "    mni_img = sitk.ReadImage(MNI_TEMPLATE_PATH)\n",
    "    mni_img = sitk.Cast(mni_img, sitk.sitkFloat32)\n",
    "    \n",
    "    mni_size = mni_img.GetSize()\n",
    "    mni_spacing = mni_img.GetSpacing()\n",
    "    \n",
    "    print(f\"\\n✓ MNI template loaded\")\n",
    "    print(f\"  Size:    {mni_size}\")\n",
    "    print(f\"  Spacing: {mni_spacing}\")\n",
    "    \n",
    "    # Verify shape matches expected\n",
    "    if mni_size != EXPECTED_SHAPE:\n",
    "        print(f\"\\n⚠️  WARNING: MNI size mismatch!\")\n",
    "        print(f\"   Expected: {EXPECTED_SHAPE}\")\n",
    "        print(f\"   Got:      {mni_size}\")\n",
    "        print(f\"   Will update EXPECTED_SHAPE to match template\")\n",
    "        EXPECTED_SHAPE = mni_size\n",
    "    else:\n",
    "        print(f\"\\n✓ MNI size matches EXPECTED_SHAPE: {EXPECTED_SHAPE}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"Failed to load MNI template: {e}\")\n",
    "\n",
    "# ============================================================================\n",
    "# PREPROCESSING UTILITIES (from S7c)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"LOADING PREPROCESSING UTILITIES\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "def resolve_nifti_path(path):\n",
    "    \"\"\"Resolve actual NIfTI file path, handling directory cases.\"\"\"\n",
    "    path_obj = Path(path)\n",
    "    \n",
    "    if path_obj.is_dir():\n",
    "        entries = sorted([f for f in path_obj.iterdir()])\n",
    "        candidates = [\n",
    "            e for e in entries \n",
    "            if e.suffix in ['.nii', '.gz'] or str(e).endswith('.nii.gz')\n",
    "        ]\n",
    "        \n",
    "        if not candidates:\n",
    "            raise FileNotFoundError(f\"No .nii/.nii.gz in directory: {path}\")\n",
    "        \n",
    "        return str(candidates[0])\n",
    "    \n",
    "    elif path_obj.is_file():\n",
    "        return str(path)\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"Path does not exist: {path}\")\n",
    "\n",
    "\n",
    "def load_t1_sitk(nifti_path):\n",
    "    \"\"\"Load T1 MRI with robust path resolution.\"\"\"\n",
    "    resolved_path = resolve_nifti_path(nifti_path)\n",
    "    img = sitk.ReadImage(resolved_path)\n",
    "    \n",
    "    if img.GetDimension() != 3:\n",
    "        raise ValueError(f\"Expected 3D image, got {img.GetDimension()}D\")\n",
    "    \n",
    "    return img\n",
    "\n",
    "\n",
    "def rigid_register_to_mni(moving_img, fixed_img):\n",
    "    \"\"\"Rigidly register moving image to MNI with fallback.\"\"\"\n",
    "    if moving_img.GetDimension() != fixed_img.GetDimension():\n",
    "        raise ValueError(f\"Dimension mismatch: {moving_img.GetDimension()} vs {fixed_img.GetDimension()}\")\n",
    "    \n",
    "    moving_f = sitk.Cast(moving_img, sitk.sitkFloat32)\n",
    "    fixed_f = sitk.Cast(fixed_img, sitk.sitkFloat32)\n",
    "    \n",
    "    try:\n",
    "        initial_tx = sitk.CenteredTransformInitializer(\n",
    "            fixed_f, moving_f, sitk.Euler3DTransform(),\n",
    "            sitk.CenteredTransformInitializerFilter.GEOMETRY\n",
    "        )\n",
    "    except:\n",
    "        initial_tx = sitk.CenteredTransformInitializer(\n",
    "            fixed_f, moving_f, sitk.Euler3DTransform(),\n",
    "            sitk.CenteredTransformInitializerFilter.MOMENTS\n",
    "        )\n",
    "    \n",
    "    reg = sitk.ImageRegistrationMethod()\n",
    "    reg.SetMetricAsMattesMutualInformation(numberOfHistogramBins=32)\n",
    "    reg.SetMetricSamplingStrategy(reg.RANDOM)\n",
    "    reg.SetMetricSamplingPercentage(0.01)\n",
    "    reg.SetOptimizerAsRegularStepGradientDescent(\n",
    "        learningRate=2.0, minStep=1e-3, numberOfIterations=50, relaxationFactor=0.5\n",
    "    )\n",
    "    reg.SetOptimizerScalesFromPhysicalShift()\n",
    "    reg.SetInterpolator(sitk.sitkLinear)\n",
    "    reg.SetInitialTransform(initial_tx, inPlace=False)\n",
    "    \n",
    "    final_tx = reg.Execute(fixed_f, moving_f)\n",
    "    \n",
    "    resampled = sitk.Resample(moving_f, fixed_f, final_tx, sitk.sitkLinear, 0.0, sitk.sitkFloat32)\n",
    "    return resampled\n",
    "\n",
    "\n",
    "def percentile_normalize_sitk(img, p1=1.0, p99=99.0):\n",
    "    \"\"\"Percentile-based intensity normalization to [0,1].\"\"\"\n",
    "    arr = sitk.GetArrayFromImage(img).astype(np.float32)\n",
    "    mask = arr != 0\n",
    "    \n",
    "    if not np.any(mask):\n",
    "        return arr, 0.0, 0.0\n",
    "    \n",
    "    vals = arr[mask]\n",
    "    lo = np.percentile(vals, p1)\n",
    "    hi = np.percentile(vals, p99)\n",
    "    \n",
    "    if hi <= lo:\n",
    "        return np.clip((arr - lo), 0, None), lo, hi\n",
    "    \n",
    "    arr = np.clip(arr, lo, hi)\n",
    "    arr = (arr - lo) / (hi - lo)\n",
    "    \n",
    "    return arr, lo, hi\n",
    "\n",
    "print(\"\\n✓ Preprocessing utilities loaded\")\n",
    "\n",
    "# ============================================================================\n",
    "# MAIN PREPROCESSING LOOP\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STARTING PREPROCESSING LOOP\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "log_records = []\n",
    "start_time_total = time.time()\n",
    "\n",
    "# Counters\n",
    "n_total = len(df)\n",
    "n_processed = 0\n",
    "n_success = 0\n",
    "n_skipped = 0\n",
    "n_bad_shape = 0\n",
    "n_failed = 0\n",
    "\n",
    "print(f\"\\nTotal visits to process: {n_total}\")\n",
    "print(f\"Expected shape per volume: {EXPECTED_SHAPE}\")\n",
    "print(\"\\nProgress every 10 visits\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    visit_uid = row['visit_uid']\n",
    "    subject_id = row['subject_id']\n",
    "    dataset = row['dataset']\n",
    "    split = row['split']\n",
    "    label = row['diagnosis_binary']\n",
    "    raw_path = row['nifti_path']\n",
    "    \n",
    "    out_path = VOLUME_DIR / f\"{visit_uid}.npy\"\n",
    "    \n",
    "    # Skip if already processed\n",
    "    if out_path.exists():\n",
    "        n_skipped += 1\n",
    "        \n",
    "        # Still load to get shape for logging\n",
    "        try:\n",
    "            vol_check = np.load(out_path)\n",
    "            vol_shape = vol_check.shape\n",
    "        except:\n",
    "            vol_shape = None\n",
    "        \n",
    "        log_records.append({\n",
    "            'visit_uid': visit_uid,\n",
    "            'subject_id': subject_id,\n",
    "            'dataset': dataset,\n",
    "            'split': split,\n",
    "            'diagnosis_binary': label,\n",
    "            'raw_path': raw_path,\n",
    "            'volume_path': str(out_path),\n",
    "            'status': 'skipped_exists',\n",
    "            'vol_shape': str(vol_shape),\n",
    "            'time_sec': 0.0\n",
    "        })\n",
    "        continue\n",
    "    \n",
    "    # Process visit\n",
    "    start_time_visit = time.time()\n",
    "    status = 'ok'\n",
    "    error_msg = ''\n",
    "    vol_shape = None\n",
    "    mean_val = None\n",
    "    std_val = None\n",
    "    p1_val = None\n",
    "    p99_val = None\n",
    "    \n",
    "    try:\n",
    "        # 1. Load\n",
    "        img = load_t1_sitk(raw_path)\n",
    "        \n",
    "        # 2. Register to MNI\n",
    "        img_mni = rigid_register_to_mni(img, mni_img)\n",
    "        \n",
    "        # 3. Normalize\n",
    "        vol, p1_val, p99_val = percentile_normalize_sitk(img_mni)\n",
    "        \n",
    "        # 4. Check shape (CRITICAL FIX)\n",
    "        vol_shape = vol.shape\n",
    "        \n",
    "        if vol_shape != EXPECTED_SHAPE:\n",
    "            status = 'bad_shape'\n",
    "            error_msg = f\"Expected {EXPECTED_SHAPE}, got {vol_shape}\"\n",
    "            n_bad_shape += 1\n",
    "        else:\n",
    "            # 5. Compute stats\n",
    "            mean_val = float(vol.mean())\n",
    "            std_val = float(vol.std())\n",
    "            \n",
    "            # 6. Save as .npy\n",
    "            vol_float32 = vol.astype(np.float32)\n",
    "            np.save(out_path, vol_float32)\n",
    "            n_success += 1\n",
    "            status = 'ok'\n",
    "    \n",
    "    except Exception as e:\n",
    "        status = 'error'\n",
    "        error_msg = f\"{type(e).__name__}: {str(e)[:200]}\"\n",
    "        n_failed += 1\n",
    "    \n",
    "    elapsed = time.time() - start_time_visit\n",
    "    n_processed += 1\n",
    "    \n",
    "    # Log record\n",
    "    log_records.append({\n",
    "        'visit_uid': visit_uid,\n",
    "        'subject_id': subject_id,\n",
    "        'dataset': dataset,\n",
    "        'split': split,\n",
    "        'diagnosis_binary': label,\n",
    "        'raw_path': raw_path,\n",
    "        'volume_path': str(out_path) if status == 'ok' else '',\n",
    "        'status': status,\n",
    "        'vol_shape': str(vol_shape),\n",
    "        'mean': mean_val,\n",
    "        'std': std_val,\n",
    "        'p1': p1_val,\n",
    "        'p99': p99_val,\n",
    "        'error_msg': error_msg,\n",
    "        'time_sec': elapsed\n",
    "    })\n",
    "    \n",
    "    # Progress update\n",
    "    if n_processed % 10 == 0:\n",
    "        pct = 100 * n_processed / n_total\n",
    "        elapsed_total = time.time() - start_time_total\n",
    "        avg_time = elapsed_total / n_processed\n",
    "        eta_sec = avg_time * (n_total - n_processed)\n",
    "        eta_min = eta_sec / 60\n",
    "        \n",
    "        print(f\"[{n_processed:3d}/{n_total}] {pct:5.1f}% | \"\n",
    "              f\"OK: {n_success} | BadShape: {n_bad_shape} | Failed: {n_failed} | \"\n",
    "              f\"ETA: {eta_min:.1f}min\")\n",
    "\n",
    "elapsed_total = time.time() - start_time_total\n",
    "print(\"-\" * 80)\n",
    "print(f\"✓ Processing complete in {elapsed_total/60:.1f} minutes\")\n",
    "\n",
    "# ============================================================================\n",
    "# SAVE LOGS & METADATA\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SAVING LOGS & METADATA\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "log_df = pd.DataFrame(log_records)\n",
    "log_df.to_csv(LOG_CSV_PATH, index=False)\n",
    "print(f\"\\n✓ Saved log: {LOG_CSV_PATH}\")\n",
    "\n",
    "print(\"\\nStatus counts:\")\n",
    "status_counts = log_df['status'].value_counts()\n",
    "for status, count in status_counts.items():\n",
    "    pct = 100 * count / len(log_df)\n",
    "    print(f\"  {status:15s}: {count:4d} ({pct:5.1f}%)\")\n",
    "\n",
    "# Merge back to metadata\n",
    "meta_with_vol = meta.merge(\n",
    "    log_df[['visit_uid', 'volume_path', 'vol_shape', 'mean', 'std', 'p1', 'p99', 'status', 'error_msg', 'time_sec']],\n",
    "    on='visit_uid',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "meta_with_vol.to_csv(META_OUT_PATH, index=False)\n",
    "print(f\"\\n✓ Saved metadata: {META_OUT_PATH}\")\n",
    "\n",
    "# ============================================================================\n",
    "# QUALITY CONTROL\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"QUALITY CONTROL STATISTICS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Shape distribution\n",
    "print(f\"\\nVolume shapes (should all be {EXPECTED_SHAPE}):\")\n",
    "ok_df = log_df[log_df['status'] == 'ok']\n",
    "if len(ok_df) > 0:\n",
    "    shape_counts = ok_df['vol_shape'].value_counts()\n",
    "    for shape, count in shape_counts.items():\n",
    "        pct = 100 * count / len(ok_df)\n",
    "        print(f\"  {shape}: {count:4d} ({pct:5.1f}%)\")\n",
    "else:\n",
    "    print(\"  No successful volumes to analyze\")\n",
    "\n",
    "# Success by dataset\n",
    "print(\"\\nSuccess rate by dataset:\")\n",
    "for dataset in ['OASIS2', 'OASIS3']:\n",
    "    mask_ds = log_df['dataset'] == dataset\n",
    "    mask_ok = (log_df['status'] == 'ok') & mask_ds\n",
    "    n_ds = mask_ds.sum()\n",
    "    n_ok = mask_ok.sum()\n",
    "    pct = 100 * n_ok / n_ds if n_ds > 0 else 0\n",
    "    print(f\"  {dataset:10s}: {n_ok:3d}/{n_ds:3d} ({pct:5.1f}%)\")\n",
    "\n",
    "# Intensity stats\n",
    "if len(ok_df) > 0:\n",
    "    print(\"\\nIntensity statistics (successful volumes):\")\n",
    "    print(f\"  Mean: {ok_df['mean'].mean():.4f} ± {ok_df['mean'].std():.4f}\")\n",
    "    print(f\"  Std:  {ok_df['std'].mean():.4f} ± {ok_df['std'].std():.4f}\")\n",
    "\n",
    "# Timing\n",
    "if len(ok_df) > 0:\n",
    "    print(\"\\nTiming statistics:\")\n",
    "    print(f\"  Total:  {elapsed_total/60:.1f} min\")\n",
    "    print(f\"  Avg:    {ok_df['time_sec'].mean():.2f}s per visit\")\n",
    "    print(f\"  Median: {ok_df['time_sec'].median():.2f}s\")\n",
    "\n",
    "# Sample volumes\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"SAMPLE SUCCESSFUL VOLUMES:\")\n",
    "print(\"-\" * 80)\n",
    "for dataset in ['OASIS2', 'OASIS3']:\n",
    "    subset = ok_df[ok_df['dataset'] == dataset]\n",
    "    if len(subset) > 0:\n",
    "        sample = subset.sample(min(3, len(subset)), random_state=42)\n",
    "        print(f\"\\n{dataset}:\")\n",
    "        for _, row in sample.iterrows():\n",
    "            label = \"CN\" if row['diagnosis_binary'] == 0 else \"AD\"\n",
    "            print(f\"  {row['visit_uid']:30s} | {label} | \"\n",
    "                  f\"shape={row['vol_shape']} | \"\n",
    "                  f\"mean={row['mean']:.4f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# FINAL SUMMARY\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"FINAL SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "success_rate = 100 * n_success / n_total if n_total > 0 else 0\n",
    "\n",
    "print(f\"\\n✅ Preprocessing complete\")\n",
    "print(f\"\\n   Processed:   {n_processed}/{n_total}\")\n",
    "print(f\"   Successful:  {n_success} ({success_rate:.1f}%)\")\n",
    "print(f\"   Bad shape:   {n_bad_shape}\")\n",
    "print(f\"   Errors:      {n_failed}\")\n",
    "print(f\"   Skipped:     {n_skipped}\")\n",
    "\n",
    "if success_rate >= 95:\n",
    "    print(f\"\\n✅ High success rate (≥95%) - excellent!\")\n",
    "    print(f\"✅ Ready for downstream tasks\")\n",
    "elif success_rate >= 90:\n",
    "    print(f\"\\n⚠️  Moderate success rate (90-95%)\")\n",
    "    print(f\"   Review failures before proceeding\")\n",
    "else:\n",
    "    print(f\"\\n❌ Low success rate (<90%)\")\n",
    "    print(f\"   Debug failures before proceeding\")\n",
    "\n",
    "print(f\"\\n✅ Output:\")\n",
    "print(f\"   Volumes: {VOLUME_DIR} ({n_success} .npy files)\")\n",
    "print(f\"   Shape:   {EXPECTED_SHAPE} per volume\")\n",
    "print(f\"   Size:    ~{np.prod(EXPECTED_SHAPE) * 4 / 1024 / 1024:.2f} MB per file\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(f\"End time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ============================================================================\n",
    "# VERIFICATION CODE (run in next cell)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"VERIFICATION CODE FOR NEXT CELL\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\"\"\n",
    "# Run this in the next cell to verify results:\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "log = pd.read_csv(\"/kaggle/working/mni_preproc_v2/preprocessing_all_visits_log_v2.csv\")\n",
    "\n",
    "print(\"Status distribution:\")\n",
    "print(log[\"status\"].value_counts())\n",
    "\n",
    "print(\"\\\\nShape distribution (successful volumes):\")\n",
    "ok_log = log[log[\"status\"] == \"ok\"]\n",
    "print(ok_log[\"vol_shape\"].value_counts())\n",
    "\n",
    "print(\"\\\\nSuccess by dataset:\")\n",
    "print(log.groupby([\"dataset\", \"status\"]).size())\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a7aa3ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T19:06:47.074346Z",
     "iopub.status.busy": "2025-11-17T19:06:47.074002Z",
     "iopub.status.idle": "2025-11-17T19:06:52.492715Z",
     "shell.execute_reply": "2025-11-17T19:06:52.491745Z"
    },
    "papermill": {
     "duration": 5.438829,
     "end_time": "2025-11-17T19:06:52.494401",
     "exception": false,
     "start_time": "2025-11-17T19:06:47.055572",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SNIPPET S9: BUILD 2D AXIAL SLICE DATASET\n",
      "================================================================================\n",
      "Start time: 2025-11-17 19:06:47\n",
      "\n",
      "================================================================================\n",
      "CONFIGURATION\n",
      "================================================================================\n",
      "\n",
      "Input metadata: classification_mni_volumes_metadata_v2.csv\n",
      "\n",
      "Output:\n",
      "  Root:       /kaggle/working/mni_slices_v1\n",
      "  Slices:     /kaggle/working/mni_slices_v1/slices\n",
      "  Metadata:   /kaggle/working/mni_slices_v1/slice_level_metadata_v1.csv\n",
      "\n",
      "Slice extraction parameters:\n",
      "  Expected volume shape: (97, 115, 97) (Z,Y,X)\n",
      "  Slices per visit:      32\n",
      "  Intensity threshold:   0.05 (for brain detection)\n",
      "  Brain fraction thresh: 0.01 (min fraction per slice)\n",
      "  View:                  Axial (Z-axis)\n",
      "\n",
      "================================================================================\n",
      "LOADING VISIT-LEVEL METADATA\n",
      "================================================================================\n",
      "\n",
      "Loaded: classification_mni_volumes_metadata_v2.csv\n",
      "  Total rows: 577\n",
      "\n",
      "Filtering by status:\n",
      "  Valid statuses: ['ok', 'skipped_exists']\n",
      "  Valid visits: 577\n",
      "\n",
      "Valid visits distribution:\n",
      "  Total:   577\n",
      "  By split:\n",
      "split\n",
      "trainval    462\n",
      "test        115\n",
      "Name: count, dtype: int64\n",
      "\n",
      "  By dataset × diagnosis:\n",
      "diagnosis_binary  0.0  1.0  All\n",
      "dataset                        \n",
      "OASIS2            206   44  250\n",
      "OASIS3            293   34  327\n",
      "All               499   78  577\n",
      "\n",
      "================================================================================\n",
      "STARTING SLICE EXTRACTION\n",
      "================================================================================\n",
      "\n",
      "Processing 577 visits...\n",
      "Progress every 50 visits\n",
      "--------------------------------------------------------------------------------\n",
      "[ 50/577]   8.7% | Slices: 1600\n",
      "[100/577]  17.3% | Slices: 3200\n",
      "[150/577]  26.0% | Slices: 4800\n",
      "[200/577]  34.7% | Slices: 6400\n",
      "[250/577]  43.3% | Slices: 8000\n",
      "[300/577]  52.0% | Slices: 9600\n",
      "[350/577]  60.7% | Slices: 11200\n",
      "[400/577]  69.3% | Slices: 12800\n",
      "[450/577]  78.0% | Slices: 14400\n",
      "[500/577]  86.7% | Slices: 16000\n",
      "[550/577]  95.3% | Slices: 17600\n",
      "--------------------------------------------------------------------------------\n",
      "✓ Slice extraction complete\n",
      "  Visits processed: 577\n",
      "  Visits skipped:   0\n",
      "  Total slices:     18464\n",
      "\n",
      "================================================================================\n",
      "SAVING SLICE-LEVEL METADATA\n",
      "================================================================================\n",
      "\n",
      "✓ Saved: /kaggle/working/mni_slices_v1/slice_level_metadata_v1.csv\n",
      "  Total rows: 18464\n",
      "  Columns:    15\n",
      "\n",
      "Columns:\n",
      "   1. slice_uid\n",
      "   2. visit_uid\n",
      "   3. subject_id\n",
      "   4. dataset\n",
      "   5. split\n",
      "   6. diagnosis_binary\n",
      "   7. z_index\n",
      "   8. slice_position_norm\n",
      "   9. brain_fraction\n",
      "  10. mni_volume_path\n",
      "  11. slice_path\n",
      "  12. age\n",
      "  13. mmse\n",
      "  14. cdr\n",
      "  15. sex\n",
      "\n",
      "================================================================================\n",
      "QUALITY CONTROL STATISTICS\n",
      "================================================================================\n",
      "\n",
      "1. Overall statistics:\n",
      "   Total slices:     18464\n",
      "   Unique visits:    577\n",
      "   Unique subjects:  347\n",
      "\n",
      "2. Slices per split:\n",
      "   trainval  : 14784 ( 80.1%)\n",
      "   test      :  3680 ( 19.9%)\n",
      "\n",
      "3. Slices per dataset × diagnosis:\n",
      "diagnosis_binary    0.0   1.0    All\n",
      "dataset                             \n",
      "OASIS2             6592  1408   8000\n",
      "OASIS3             9376  1088  10464\n",
      "All               15968  2496  18464\n",
      "\n",
      "4. Slices per visit:\n",
      "   Mean:   32.00\n",
      "   Median: 32\n",
      "   Min:    32\n",
      "   Max:    32\n",
      "\n",
      "   Distribution:\n",
      "     32 slices: 577 visits\n",
      "\n",
      "5. Z-index distribution (spatial coverage):\n",
      "   Min:    0\n",
      "   25%:    22\n",
      "   Median: 45\n",
      "   75%:    68\n",
      "   Max:    96\n",
      "\n",
      "6. Normalized slice position:\n",
      "   Mean:   0.500\n",
      "   Std:    0.298\n",
      "   Range:  [0.000, 1.000]\n",
      "\n",
      "7. Brain fraction statistics:\n",
      "   Mean:   0.4530\n",
      "   Median: 0.4987\n",
      "   Min:    0.0100\n",
      "   Max:    0.7494\n",
      "\n",
      "8. Clinical variable completeness:\n",
      "   age       : 18464 / 18464 (100.0%)\n",
      "   mmse      : 18400 / 18464 ( 99.7%)\n",
      "   cdr       : 18464 / 18464 (100.0%)\n",
      "   sex       :  8000 / 18464 ( 43.3%)\n",
      "\n",
      "================================================================================\n",
      "SAMPLE SLICES (3 per dataset × diagnosis)\n",
      "================================================================================\n",
      "\n",
      "OASIS2 | CN:\n",
      "  OASIS2|OAS2_0070|MR1_z062                | z=62 | pos=0.646 | brain_frac=0.4108\n",
      "  OASIS2|OAS2_0169|MR2_z065                | z=65 | pos=0.677 | brain_frac=0.4619\n",
      "  OASIS2|OAS2_0077|MR2_z090                | z=90 | pos=0.938 | brain_frac=0.2987\n",
      "\n",
      "OASIS2 | AD:\n",
      "  OASIS2|OAS2_0048|MR4_z003                | z= 3 | pos=0.031 | brain_frac=0.6076\n",
      "  OASIS2|OAS2_0106|MR2_z000                | z= 0 | pos=0.000 | brain_frac=0.3626\n",
      "  OASIS2|OAS2_0160|MR2_z028                | z=28 | pos=0.292 | brain_frac=0.6680\n",
      "\n",
      "OASIS3 | CN:\n",
      "  OASIS3|OAS30178|d2443_z058               | z=58 | pos=0.644 | brain_frac=0.5493\n",
      "  OASIS3|OAS30478|d4271_z032               | z=32 | pos=0.360 | brain_frac=0.5734\n",
      "  OASIS3|OAS30479|d1266_z067               | z=67 | pos=0.779 | brain_frac=0.4278\n",
      "\n",
      "OASIS3 | AD:\n",
      "  OASIS3|OAS30388|d0073_z008               | z= 8 | pos=0.093 | brain_frac=0.3874\n",
      "  OASIS3|OAS30078|d0210_z068               | z=68 | pos=0.773 | brain_frac=0.3941\n",
      "  OASIS3|OAS30440|d0163_z077               | z=77 | pos=0.963 | brain_frac=0.1029\n",
      "\n",
      "================================================================================\n",
      "FINAL SUMMARY\n",
      "================================================================================\n",
      "\n",
      "✅ Slice extraction complete\n",
      "\n",
      "   Visits processed:  577/577 (100.0%)\n",
      "   Total slices:      18464\n",
      "   Avg slices/visit:  32.0\n",
      "\n",
      "   Expected slices:   ~18464 (32 × 577)\n",
      "   Actual slices:     18464\n",
      "\n",
      "✅ Class distribution:\n",
      "   CN slices: 15968 (86.5%)\n",
      "   AD slices: 2496 (13.5%)\n",
      "   CN/AD ratio: 6.40:1\n",
      "\n",
      "   ⚠ Class imbalance detected (CN/AD > 3:1)\n",
      "   Will handle in S10 with:\n",
      "   - Class-balanced sampler, OR\n",
      "   - Weighted loss function\n",
      "\n",
      "✅ Output files:\n",
      "   Slice directory:  /kaggle/working/mni_slices_v1/slices (18464 .npy files)\n",
      "   Metadata CSV:     /kaggle/working/mni_slices_v1/slice_level_metadata_v1.csv\n",
      "   Slice dimensions: (115, 97) per file\n",
      "   Total disk usage: ~785.7 MB\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "SNIPPET S9: Build 2D Axial Slice Dataset\n",
    "Extract axial slices from MNI-registered 3D volumes for 2D CNN training.\n",
    "\n",
    "Design decisions:\n",
    "- View: Axial (Z-axis slices)\n",
    "- Slices per visit: 32 (uniformly spaced across brain)\n",
    "- Brain detection: Intensity threshold + spatial coverage\n",
    "- Output: .npy slices (115×97, float32) + metadata CSV\n",
    "\n",
    "Total expected: ~18,432 slices (576 visits × 32 slices)\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"SNIPPET S9: BUILD 2D AXIAL SLICE DATASET\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Start time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURATION (LOCKED)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"CONFIGURATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Input\n",
    "INPUT_MNI_META = \"classification_mni_volumes_metadata_v2.csv\"\n",
    "\n",
    "# Output\n",
    "SLICES_ROOT = Path(\"/kaggle/working/mni_slices_v1\")\n",
    "SLICES_DIR = SLICES_ROOT / \"slices\"\n",
    "SLICE_META_CSV = SLICES_ROOT / \"slice_level_metadata_v1.csv\"\n",
    "\n",
    "# Slice extraction parameters\n",
    "EXPECTED_SHAPE = (97, 115, 97)     # (Z, Y, X) from TemplateFlow MNI\n",
    "N_SLICES_PER_VISIT = 32            # Uniform sampling across brain\n",
    "INTENSITY_THRESH = 0.05            # Threshold for \"brain\" pixels\n",
    "BRAIN_FRAC_THRESH = 0.01           # Min 1% brain pixels per slice\n",
    "\n",
    "# Create output directories\n",
    "SLICES_ROOT.mkdir(exist_ok=True)\n",
    "SLICES_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"\\nInput metadata: {INPUT_MNI_META}\")\n",
    "print(f\"\\nOutput:\")\n",
    "print(f\"  Root:       {SLICES_ROOT}\")\n",
    "print(f\"  Slices:     {SLICES_DIR}\")\n",
    "print(f\"  Metadata:   {SLICE_META_CSV}\")\n",
    "\n",
    "print(f\"\\nSlice extraction parameters:\")\n",
    "print(f\"  Expected volume shape: {EXPECTED_SHAPE} (Z,Y,X)\")\n",
    "print(f\"  Slices per visit:      {N_SLICES_PER_VISIT}\")\n",
    "print(f\"  Intensity threshold:   {INTENSITY_THRESH} (for brain detection)\")\n",
    "print(f\"  Brain fraction thresh: {BRAIN_FRAC_THRESH} (min fraction per slice)\")\n",
    "print(f\"  View:                  Axial (Z-axis)\")\n",
    "\n",
    "# ============================================================================\n",
    "# LOAD VISIT-LEVEL METADATA\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"LOADING VISIT-LEVEL METADATA\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "visit_meta = pd.read_csv(INPUT_MNI_META)\n",
    "\n",
    "print(f\"\\nLoaded: {INPUT_MNI_META}\")\n",
    "print(f\"  Total rows: {len(visit_meta)}\")\n",
    "\n",
    "# Filter to successfully preprocessed volumes\n",
    "if 'status' in visit_meta.columns:\n",
    "    # Use status if available\n",
    "    valid_visits = visit_meta[visit_meta['status'].isin(['ok', 'skipped_exists'])].copy()\n",
    "    print(f\"\\nFiltering by status:\")\n",
    "    print(f\"  Valid statuses: ['ok', 'skipped_exists']\")\n",
    "    print(f\"  Valid visits: {len(valid_visits)}\")\n",
    "elif 'volume_path' in visit_meta.columns:\n",
    "    # Fall back to checking volume_path exists\n",
    "    valid_visits = visit_meta[visit_meta['volume_path'].notna()].copy()\n",
    "    print(f\"\\nFiltering by volume_path not null:\")\n",
    "    print(f\"  Valid visits: {len(valid_visits)}\")\n",
    "else:\n",
    "    # Assume all are valid\n",
    "    valid_visits = visit_meta.copy()\n",
    "    print(f\"\\nNo filtering applied (assuming all valid)\")\n",
    "\n",
    "print(f\"\\nValid visits distribution:\")\n",
    "print(f\"  Total:   {len(valid_visits)}\")\n",
    "print(f\"  By split:\")\n",
    "print(valid_visits['split'].value_counts())\n",
    "print(f\"\\n  By dataset × diagnosis:\")\n",
    "print(pd.crosstab(valid_visits['dataset'], valid_visits['diagnosis_binary'], margins=True))\n",
    "\n",
    "# ============================================================================\n",
    "# BRAIN DETECTION & SLICE EXTRACTION\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STARTING SLICE EXTRACTION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "slice_records = []\n",
    "\n",
    "# Counters\n",
    "n_visits_processed = 0\n",
    "n_visits_skipped = 0\n",
    "n_slices_total = 0\n",
    "\n",
    "print(f\"\\nProcessing {len(valid_visits)} visits...\")\n",
    "print(f\"Progress every 50 visits\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for idx, row in valid_visits.iterrows():\n",
    "    visit_uid = row['visit_uid']\n",
    "    subject_id = row['subject_id']\n",
    "    dataset = row['dataset']\n",
    "    split = row['split']\n",
    "    label = row['diagnosis_binary']\n",
    "    \n",
    "    # Get volume path\n",
    "    if 'volume_path' in row and pd.notna(row['volume_path']):\n",
    "        mni_path = row['volume_path']\n",
    "    else:\n",
    "        # Reconstruct path if not in metadata\n",
    "        mni_path = f\"/kaggle/working/mni_preproc_v2/volumes/{visit_uid}.npy\"\n",
    "    \n",
    "    # Check file exists\n",
    "    if not Path(mni_path).exists():\n",
    "        print(f\"⚠ Volume not found: {visit_uid}\")\n",
    "        n_visits_skipped += 1\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        # Load 3D volume\n",
    "        vol = np.load(mni_path)\n",
    "        \n",
    "        # Verify shape\n",
    "        if vol.shape != EXPECTED_SHAPE:\n",
    "            print(f\"⚠ Shape mismatch {visit_uid}: {vol.shape} != {EXPECTED_SHAPE}\")\n",
    "            n_visits_skipped += 1\n",
    "            continue\n",
    "        \n",
    "        Z, Y, X = vol.shape\n",
    "        \n",
    "        # Compute brain fraction per Z slice\n",
    "        brain_fraction = np.zeros(Z)\n",
    "        for z in range(Z):\n",
    "            slice_2d = vol[z, :, :]\n",
    "            brain_pixels = (slice_2d > INTENSITY_THRESH).sum()\n",
    "            brain_fraction[z] = brain_pixels / (Y * X)\n",
    "        \n",
    "        # Identify valid brain slices\n",
    "        valid_z = np.where(brain_fraction >= BRAIN_FRAC_THRESH)[0]\n",
    "        \n",
    "        if len(valid_z) == 0:\n",
    "            print(f\"⚠ No brain slices for {visit_uid}\")\n",
    "            n_visits_skipped += 1\n",
    "            continue\n",
    "        \n",
    "        z_min = valid_z.min()\n",
    "        z_max = valid_z.max()\n",
    "        \n",
    "        # Select N_SLICES_PER_VISIT uniformly across brain\n",
    "        if len(valid_z) <= N_SLICES_PER_VISIT:\n",
    "            chosen_z = valid_z\n",
    "        else:\n",
    "            # Uniform sampling\n",
    "            indices = np.linspace(0, len(valid_z) - 1, N_SLICES_PER_VISIT)\n",
    "            indices = np.round(indices).astype(int)\n",
    "            chosen_z = valid_z[indices]\n",
    "        \n",
    "        # Extract and save each slice\n",
    "        for z in chosen_z:\n",
    "            slice_2d = vol[z, :, :]\n",
    "            \n",
    "            # Slice UID and path\n",
    "            slice_uid = f\"{visit_uid}_z{z:03d}\"\n",
    "            slice_fname = f\"{slice_uid}.npy\"\n",
    "            slice_path = SLICES_DIR / slice_fname\n",
    "            \n",
    "            # Save slice\n",
    "            np.save(slice_path, slice_2d.astype(np.float32))\n",
    "            \n",
    "            # Compute normalized position within brain\n",
    "            if z_max > z_min:\n",
    "                slice_pos_norm = (z - z_min) / (z_max - z_min)\n",
    "            else:\n",
    "                slice_pos_norm = 0.5\n",
    "            \n",
    "            # Build metadata record\n",
    "            record = {\n",
    "                'slice_uid': slice_uid,\n",
    "                'visit_uid': visit_uid,\n",
    "                'subject_id': subject_id,\n",
    "                'dataset': dataset,\n",
    "                'split': split,\n",
    "                'diagnosis_binary': label,\n",
    "                'z_index': int(z),\n",
    "                'slice_position_norm': float(slice_pos_norm),\n",
    "                'brain_fraction': float(brain_fraction[z]),\n",
    "                'mni_volume_path': mni_path,\n",
    "                'slice_path': str(slice_path)\n",
    "            }\n",
    "            \n",
    "            # Add optional clinical variables if available\n",
    "            for col in ['age', 'mmse', 'cdr', 'sex']:\n",
    "                if col in row and pd.notna(row[col]):\n",
    "                    record[col] = row[col]\n",
    "            \n",
    "            slice_records.append(record)\n",
    "            n_slices_total += 1\n",
    "        \n",
    "        n_visits_processed += 1\n",
    "        \n",
    "        # Progress update\n",
    "        if n_visits_processed % 50 == 0:\n",
    "            pct = 100 * n_visits_processed / len(valid_visits)\n",
    "            print(f\"[{n_visits_processed:3d}/{len(valid_visits)}] {pct:5.1f}% | \"\n",
    "                  f\"Slices: {n_slices_total}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error processing {visit_uid}: {type(e).__name__}: {str(e)[:100]}\")\n",
    "        n_visits_skipped += 1\n",
    "        continue\n",
    "\n",
    "print(\"-\" * 80)\n",
    "print(f\"✓ Slice extraction complete\")\n",
    "print(f\"  Visits processed: {n_visits_processed}\")\n",
    "print(f\"  Visits skipped:   {n_visits_skipped}\")\n",
    "print(f\"  Total slices:     {n_slices_total}\")\n",
    "\n",
    "# ============================================================================\n",
    "# SAVE SLICE-LEVEL METADATA\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SAVING SLICE-LEVEL METADATA\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "slice_meta = pd.DataFrame(slice_records)\n",
    "\n",
    "if len(slice_meta) == 0:\n",
    "    raise ValueError(\"No slices extracted - check volume paths and thresholds\")\n",
    "\n",
    "slice_meta.to_csv(SLICE_META_CSV, index=False)\n",
    "\n",
    "print(f\"\\n✓ Saved: {SLICE_META_CSV}\")\n",
    "print(f\"  Total rows: {len(slice_meta)}\")\n",
    "print(f\"  Columns:    {len(slice_meta.columns)}\")\n",
    "\n",
    "print(\"\\nColumns:\")\n",
    "for i, col in enumerate(slice_meta.columns, 1):\n",
    "    print(f\"  {i:2d}. {col}\")\n",
    "\n",
    "# ============================================================================\n",
    "# QUALITY CONTROL STATISTICS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"QUALITY CONTROL STATISTICS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Overall counts\n",
    "print(f\"\\n1. Overall statistics:\")\n",
    "print(f\"   Total slices:     {len(slice_meta)}\")\n",
    "print(f\"   Unique visits:    {slice_meta['visit_uid'].nunique()}\")\n",
    "print(f\"   Unique subjects:  {slice_meta['subject_id'].nunique()}\")\n",
    "\n",
    "# Slices per split\n",
    "print(f\"\\n2. Slices per split:\")\n",
    "split_counts = slice_meta['split'].value_counts()\n",
    "for split, count in split_counts.items():\n",
    "    pct = 100 * count / len(slice_meta)\n",
    "    print(f\"   {split:10s}: {count:5d} ({pct:5.1f}%)\")\n",
    "\n",
    "# Slices per dataset × diagnosis\n",
    "print(f\"\\n3. Slices per dataset × diagnosis:\")\n",
    "crosstab = pd.crosstab(slice_meta['dataset'], slice_meta['diagnosis_binary'], margins=True)\n",
    "print(crosstab)\n",
    "\n",
    "# Slices per visit\n",
    "print(f\"\\n4. Slices per visit:\")\n",
    "slices_per_visit = slice_meta.groupby('visit_uid').size()\n",
    "print(f\"   Mean:   {slices_per_visit.mean():.2f}\")\n",
    "print(f\"   Median: {slices_per_visit.median():.0f}\")\n",
    "print(f\"   Min:    {slices_per_visit.min()}\")\n",
    "print(f\"   Max:    {slices_per_visit.max()}\")\n",
    "print(f\"\\n   Distribution:\")\n",
    "dist = slices_per_visit.value_counts().sort_index()\n",
    "for n_slices, n_visits in dist.head(10).items():\n",
    "    print(f\"     {n_slices:2d} slices: {n_visits:3d} visits\")\n",
    "\n",
    "# Z-index distribution\n",
    "print(f\"\\n5. Z-index distribution (spatial coverage):\")\n",
    "z_stats = slice_meta['z_index'].describe()\n",
    "print(f\"   Min:    {z_stats['min']:.0f}\")\n",
    "print(f\"   25%:    {z_stats['25%']:.0f}\")\n",
    "print(f\"   Median: {z_stats['50%']:.0f}\")\n",
    "print(f\"   75%:    {z_stats['75%']:.0f}\")\n",
    "print(f\"   Max:    {z_stats['max']:.0f}\")\n",
    "\n",
    "# Slice position distribution\n",
    "print(f\"\\n6. Normalized slice position:\")\n",
    "pos_stats = slice_meta['slice_position_norm'].describe()\n",
    "print(f\"   Mean:   {pos_stats['mean']:.3f}\")\n",
    "print(f\"   Std:    {pos_stats['std']:.3f}\")\n",
    "print(f\"   Range:  [{pos_stats['min']:.3f}, {pos_stats['max']:.3f}]\")\n",
    "\n",
    "# Brain fraction distribution\n",
    "print(f\"\\n7. Brain fraction statistics:\")\n",
    "bf_stats = slice_meta['brain_fraction'].describe()\n",
    "print(f\"   Mean:   {bf_stats['mean']:.4f}\")\n",
    "print(f\"   Median: {bf_stats['50%']:.4f}\")\n",
    "print(f\"   Min:    {bf_stats['min']:.4f}\")\n",
    "print(f\"   Max:    {bf_stats['max']:.4f}\")\n",
    "\n",
    "# Clinical variable completeness\n",
    "print(f\"\\n8. Clinical variable completeness:\")\n",
    "clinical_vars = ['age', 'mmse', 'cdr', 'sex']\n",
    "for var in clinical_vars:\n",
    "    if var in slice_meta.columns:\n",
    "        n_valid = slice_meta[var].notna().sum()\n",
    "        pct = 100 * n_valid / len(slice_meta)\n",
    "        print(f\"   {var:10s}: {n_valid:5d} / {len(slice_meta)} ({pct:5.1f}%)\")\n",
    "\n",
    "# ============================================================================\n",
    "# SAMPLE SLICES\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SAMPLE SLICES (3 per dataset × diagnosis)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for dataset in ['OASIS2', 'OASIS3']:\n",
    "    for diag in [0, 1]:\n",
    "        label_str = \"CN\" if diag == 0 else \"AD\"\n",
    "        mask = (slice_meta['dataset'] == dataset) & (slice_meta['diagnosis_binary'] == diag)\n",
    "        subset = slice_meta[mask]\n",
    "        \n",
    "        if len(subset) == 0:\n",
    "            continue\n",
    "        \n",
    "        sample = subset.sample(min(3, len(subset)), random_state=42)\n",
    "        \n",
    "        print(f\"\\n{dataset} | {label_str}:\")\n",
    "        for _, row in sample.iterrows():\n",
    "            print(f\"  {row['slice_uid']:40s} | \"\n",
    "                  f\"z={row['z_index']:2d} | \"\n",
    "                  f\"pos={row['slice_position_norm']:.3f} | \"\n",
    "                  f\"brain_frac={row['brain_fraction']:.4f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# FINAL SUMMARY\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"FINAL SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Success metrics\n",
    "success_rate = 100 * n_visits_processed / len(valid_visits) if len(valid_visits) > 0 else 0\n",
    "avg_slices = n_slices_total / n_visits_processed if n_visits_processed > 0 else 0\n",
    "\n",
    "print(f\"\\n✅ Slice extraction complete\")\n",
    "print(f\"\\n   Visits processed:  {n_visits_processed}/{len(valid_visits)} ({success_rate:.1f}%)\")\n",
    "print(f\"   Total slices:      {n_slices_total}\")\n",
    "print(f\"   Avg slices/visit:  {avg_slices:.1f}\")\n",
    "\n",
    "# Expected vs actual\n",
    "expected_slices = n_visits_processed * N_SLICES_PER_VISIT\n",
    "print(f\"\\n   Expected slices:   ~{expected_slices} ({N_SLICES_PER_VISIT} × {n_visits_processed})\")\n",
    "print(f\"   Actual slices:     {n_slices_total}\")\n",
    "\n",
    "if n_slices_total < expected_slices * 0.9:\n",
    "    print(f\"   ⚠ Fewer slices than expected (some visits may have <{N_SLICES_PER_VISIT} brain slices)\")\n",
    "\n",
    "# Class balance\n",
    "cn_slices = (slice_meta['diagnosis_binary'] == 0).sum()\n",
    "ad_slices = (slice_meta['diagnosis_binary'] == 1).sum()\n",
    "ratio = cn_slices / ad_slices if ad_slices > 0 else float('inf')\n",
    "\n",
    "print(f\"\\n✅ Class distribution:\")\n",
    "print(f\"   CN slices: {cn_slices} ({100*cn_slices/len(slice_meta):.1f}%)\")\n",
    "print(f\"   AD slices: {ad_slices} ({100*ad_slices/len(slice_meta):.1f}%)\")\n",
    "print(f\"   CN/AD ratio: {ratio:.2f}:1\")\n",
    "\n",
    "if ratio > 3:\n",
    "    print(f\"\\n   ⚠ Class imbalance detected (CN/AD > 3:1)\")\n",
    "    print(f\"   Will handle in S10 with:\")\n",
    "    print(f\"   - Class-balanced sampler, OR\")\n",
    "    print(f\"   - Weighted loss function\")\n",
    "\n",
    "print(f\"\\n✅ Output files:\")\n",
    "print(f\"   Slice directory:  {SLICES_DIR} ({n_slices_total} .npy files)\")\n",
    "print(f\"   Metadata CSV:     {SLICE_META_CSV}\")\n",
    "print(f\"   Slice dimensions: (115, 97) per file\")\n",
    "print(f\"   Total disk usage: ~{n_slices_total * 115 * 97 * 4 / 1024 / 1024:.1f} MB\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d301233",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T19:06:52.533496Z",
     "iopub.status.busy": "2025-11-17T19:06:52.533247Z",
     "iopub.status.idle": "2025-11-17T19:13:03.369212Z",
     "shell.execute_reply": "2025-11-17T19:13:03.367972Z"
    },
    "papermill": {
     "duration": 370.855974,
     "end_time": "2025-11-17T19:13:03.370494",
     "exception": false,
     "start_time": "2025-11-17T19:06:52.514520",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SNIPPET S10d: PROPER IMAGENET-PRETRAINED RESNET18\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "CONFIGURATION\n",
      "================================================================================\n",
      "Device: cuda\n",
      "GPU: Tesla T4\n",
      "\n",
      "Hyperparameters:\n",
      "  Epochs:     30\n",
      "  Batch size: 32\n",
      "  LR:         0.0001\n",
      "  Patience:   8\n",
      "\n",
      "================================================================================\n",
      "LOADING METADATA\n",
      "================================================================================\n",
      "\n",
      "Split sizes:\n",
      "  Train: 11872\n",
      "  Val:   2912\n",
      "  Test:  3680\n",
      "✓ No subject leakage\n",
      "\n",
      "================================================================================\n",
      "DEFINING TRANSFORMS\n",
      "================================================================================\n",
      "✓ Transforms defined with ImageNet normalization\n",
      "✓ Datasets created with RGB conversion\n",
      "\n",
      "================================================================================\n",
      "CREATING BALANCED SAMPLER\n",
      "================================================================================\n",
      "\n",
      "Class distribution:\n",
      "  CN: 10240 slices\n",
      "  AD: 1632 slices\n",
      "  Ratio: 6.27:1\n",
      "\n",
      "Balanced sampler weights:\n",
      "  CN weight: 0.0001\n",
      "  AD weight: 0.0006\n",
      "\n",
      "✓ DataLoaders created (train batches: 371)\n",
      "\n",
      "================================================================================\n",
      "MODEL INITIALIZATION\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
      "100%|██████████| 44.7M/44.7M [00:00<00:00, 156MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ ResNet18 with ImageNet weights\n",
      "  Parameters: 11,177,025\n",
      "\n",
      "Loss function:\n",
      "  Raw CN/AD ratio: 6.27\n",
      "  Clamped pos_weight: 3.000\n",
      "  Using BCEWithLogitsLoss\n",
      "\n",
      "================================================================================\n",
      "TRAINING\n",
      "================================================================================\n",
      "\n",
      "Target: Beat trivial baseline (ACC=0.878, BalACC=0.5, AUC=0.5)\n",
      "--------------------------------------------------------------------------------\n",
      "[Epoch 01/30] time=21.1s | lr=1.00e-04\n",
      "  train_loss=1.0369 | val_loss=1.0653\n",
      "  val_slice_acc=0.4842 | val_visit_acc=0.4835\n",
      "  val_visit_auc=0.8738 | CN_acc=0.4191 | AD_acc=0.8750\n",
      "  ✓ New best: 0.4835\n",
      "[Epoch 02/30] time=19.4s | lr=1.00e-04\n",
      "  train_loss=0.7561 | val_loss=1.0439\n",
      "  val_slice_acc=0.6535 | val_visit_acc=0.8022\n",
      "  val_visit_auc=0.8284 | CN_acc=0.6607 | AD_acc=0.6106\n",
      "  ✓ New best: 0.8022\n",
      "[Epoch 03/30] time=19.7s | lr=1.00e-04\n",
      "  train_loss=0.5895 | val_loss=1.0500\n",
      "  val_slice_acc=0.6992 | val_visit_acc=0.8681\n",
      "  val_visit_auc=0.8215 | CN_acc=0.7167 | AD_acc=0.5938\n",
      "  ✓ New best: 0.8681\n",
      "[Epoch 04/30] time=20.1s | lr=1.00e-04\n",
      "  train_loss=0.4639 | val_loss=1.3425\n",
      "  val_slice_acc=0.7510 | val_visit_acc=0.9121\n",
      "  val_visit_auc=0.8511 | CN_acc=0.7957 | AD_acc=0.4832\n",
      "  ✓ New best: 0.9121\n",
      "[Epoch 05/30] time=20.7s | lr=1.00e-04\n",
      "  train_loss=0.3793 | val_loss=1.3865\n",
      "  val_slice_acc=0.7012 | val_visit_acc=0.8791\n",
      "  val_visit_auc=0.8215 | CN_acc=0.7324 | AD_acc=0.5144\n",
      "[Epoch 06/30] time=21.3s | lr=1.00e-04\n",
      "  train_loss=0.3265 | val_loss=1.3060\n",
      "  val_slice_acc=0.7435 | val_visit_acc=0.9011\n",
      "  val_visit_auc=0.8659 | CN_acc=0.7748 | AD_acc=0.5553\n",
      "[Epoch 07/30] time=21.9s | lr=1.00e-04\n",
      "  train_loss=0.3007 | val_loss=1.7633\n",
      "  val_slice_acc=0.7665 | val_visit_acc=0.8791\n",
      "  val_visit_auc=0.8412 | CN_acc=0.8225 | AD_acc=0.4303\n",
      "[Epoch 08/30] time=21.6s | lr=1.00e-04\n",
      "  train_loss=0.2658 | val_loss=2.0540\n",
      "  val_slice_acc=0.7898 | val_visit_acc=0.8681\n",
      "  val_visit_auc=0.7899 | CN_acc=0.8738 | AD_acc=0.2861\n",
      "[Epoch 09/30] time=21.1s | lr=1.00e-04\n",
      "  train_loss=0.2405 | val_loss=1.7719\n",
      "  val_slice_acc=0.7823 | val_visit_acc=0.9231\n",
      "  val_visit_auc=0.8935 | CN_acc=0.8273 | AD_acc=0.5120\n",
      "  ✓ New best: 0.9231\n",
      "[Epoch 10/30] time=21.2s | lr=1.00e-04\n",
      "  train_loss=0.1956 | val_loss=1.9409\n",
      "  val_slice_acc=0.8029 | val_visit_acc=0.9011\n",
      "  val_visit_auc=0.8639 | CN_acc=0.8774 | AD_acc=0.3558\n",
      "[Epoch 11/30] time=21.4s | lr=1.00e-04\n",
      "  train_loss=0.1979 | val_loss=1.9747\n",
      "  val_slice_acc=0.7394 | val_visit_acc=0.9011\n",
      "  val_visit_auc=0.8649 | CN_acc=0.7889 | AD_acc=0.4423\n",
      "[Epoch 12/30] time=21.4s | lr=1.00e-04\n",
      "  train_loss=0.1851 | val_loss=2.4363\n",
      "  val_slice_acc=0.7936 | val_visit_acc=0.8462\n",
      "  val_visit_auc=0.8491 | CN_acc=0.8774 | AD_acc=0.2909\n",
      "[Epoch 13/30] time=21.3s | lr=1.00e-04\n",
      "  train_loss=0.1873 | val_loss=1.7279\n",
      "  val_slice_acc=0.7922 | val_visit_acc=0.8901\n",
      "  val_visit_auc=0.8018 | CN_acc=0.8566 | AD_acc=0.4062\n",
      "[Epoch 14/30] time=21.2s | lr=1.00e-04\n",
      "  train_loss=0.1603 | val_loss=2.3383\n",
      "  val_slice_acc=0.7751 | val_visit_acc=0.8462\n",
      "  val_visit_auc=0.8097 | CN_acc=0.8474 | AD_acc=0.3413\n",
      "[Epoch 15/30] time=21.3s | lr=5.00e-05\n",
      "  train_loss=0.0991 | val_loss=2.4869\n",
      "  val_slice_acc=0.8177 | val_visit_acc=0.8791\n",
      "  val_visit_auc=0.8452 | CN_acc=0.8998 | AD_acc=0.3245\n",
      "[Epoch 16/30] time=21.4s | lr=5.00e-05\n",
      "  train_loss=0.0908 | val_loss=2.6400\n",
      "  val_slice_acc=0.8307 | val_visit_acc=0.8681\n",
      "  val_visit_auc=0.7909 | CN_acc=0.9375 | AD_acc=0.1899\n",
      "[Epoch 17/30] time=21.2s | lr=5.00e-05\n",
      "  train_loss=0.0813 | val_loss=2.7586\n",
      "  val_slice_acc=0.8334 | val_visit_acc=0.8571\n",
      "  val_visit_auc=0.7959 | CN_acc=0.9403 | AD_acc=0.1923\n",
      "\n",
      "⚠ Early stopping (no improvement for 8 epochs)\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "✓ Model saved: /kaggle/working/resnet18_fold0_proper.pth\n",
      "✓ History saved: /kaggle/working/training_history_fold0_proper.csv\n",
      "\n",
      "================================================================================\n",
      "TEST EVALUATION\n",
      "================================================================================\n",
      "\n",
      "Test results (threshold=0.5):\n",
      "  Loss:         2.3635\n",
      "  Slice ACC:    0.7011\n",
      "  Visit ACC:    0.7478\n",
      "  Visit AUC:    0.6308\n",
      "  CN ACC:       0.7550\n",
      "  AD ACC:       0.3125\n",
      "\n",
      "Comparison with baseline:\n",
      "  Trivial baseline: ACC=0.878, AUC=0.5\n",
      "  Current model:    ACC=0.748, AUC=0.631\n",
      "\n",
      "⚠️  Weak AD signal (AUC 0.55-0.65)\n",
      "   Consider: longer training, better architecture\n",
      "\n",
      "================================================================================\n",
      "SNIPPET S10d COMPLETE\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "SNIPPET S10d: Proper ImageNet-Pretrained ResNet18 (Fold 0)\n",
    "CRITICAL FIXES from S10b:\n",
    "1. ImageNet normalization (matches pretrained weights)\n",
    "2. Clamped pos_weight (avoid extreme gradients)\n",
    "3. Balanced sampler (better than pos_weight alone)\n",
    "4. Longer training (30 epochs)\n",
    "5. Enhanced monitoring\n",
    "\n",
    "Goal: Beat trivial baseline (0.878 ACC, 0.5 BalACC)\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import time\n",
    "import copy\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"SNIPPET S10d: PROPER IMAGENET-PRETRAINED RESNET18\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURATION\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"CONFIGURATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "SLICE_META_CSV = \"/kaggle/working/mni_slices_v1/slice_level_metadata_v1.csv\"\n",
    "VISIT_SPLIT_CSV = \"classification_visit_metadata_with_splits.csv\"\n",
    "MODEL_OUT_PATH = \"/kaggle/working/resnet18_fold0_proper.pth\"\n",
    "HISTORY_CSV = \"/kaggle/working/training_history_fold0_proper.csv\"\n",
    "\n",
    "FOLD_ID = 0\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 30                # Increased from 20\n",
    "LR = 1e-4\n",
    "WEIGHT_DECAY = 1e-4\n",
    "GRAD_CLIP = 1.0\n",
    "IMG_SIZE = (128, 128)\n",
    "EARLY_STOP_PATIENCE = 8        # Increased from 5\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {DEVICE}\")\n",
    "\n",
    "if DEVICE.type == \"cuda\":\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if DEVICE.type == \"cuda\":\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "print(f\"\\nHyperparameters:\")\n",
    "print(f\"  Epochs:     {NUM_EPOCHS}\")\n",
    "print(f\"  Batch size: {BATCH_SIZE}\")\n",
    "print(f\"  LR:         {LR}\")\n",
    "print(f\"  Patience:   {EARLY_STOP_PATIENCE}\")\n",
    "\n",
    "# ============================================================================\n",
    "# LOAD METADATA\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"LOADING METADATA\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "slice_meta = pd.read_csv(SLICE_META_CSV)\n",
    "visit_meta_splits = pd.read_csv(VISIT_SPLIT_CSV)\n",
    "\n",
    "slice_meta = slice_meta.merge(\n",
    "    visit_meta_splits[[\"visit_uid\", \"cv_fold\", \"split\"]],\n",
    "    on=\"visit_uid\",\n",
    "    how=\"left\",\n",
    "    suffixes=(\"_slice\", \"_visit\")\n",
    ")\n",
    "\n",
    "if \"split_visit\" in slice_meta.columns:\n",
    "    slice_meta[\"split\"] = slice_meta[\"split_visit\"]\n",
    "\n",
    "train_slices = slice_meta[\n",
    "    (slice_meta[\"split\"] == \"trainval\") &\n",
    "    (slice_meta[\"cv_fold\"] != FOLD_ID)\n",
    "].copy()\n",
    "\n",
    "val_slices = slice_meta[\n",
    "    (slice_meta[\"split\"] == \"trainval\") &\n",
    "    (slice_meta[\"cv_fold\"] == FOLD_ID)\n",
    "].copy()\n",
    "\n",
    "test_slices = slice_meta[slice_meta[\"split\"] == \"test\"].copy()\n",
    "\n",
    "print(f\"\\nSplit sizes:\")\n",
    "print(f\"  Train: {len(train_slices)}\")\n",
    "print(f\"  Val:   {len(val_slices)}\")\n",
    "print(f\"  Test:  {len(test_slices)}\")\n",
    "\n",
    "# Subject leakage check\n",
    "train_subjects = set(train_slices[\"subject_id\"].unique())\n",
    "val_subjects = set(val_slices[\"subject_id\"].unique())\n",
    "test_subjects = set(test_slices[\"subject_id\"].unique())\n",
    "\n",
    "if (train_subjects & val_subjects) or (train_subjects & test_subjects) or (val_subjects & test_subjects):\n",
    "    raise ValueError(\"❌ Subject leakage detected!\")\n",
    "else:\n",
    "    print(\"✓ No subject leakage\")\n",
    "\n",
    "# ============================================================================\n",
    "# TRANSFORMS (PROPER IMAGENET NORMALIZATION)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"DEFINING TRANSFORMS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# *** CRITICAL: ImageNet normalization for pretrained weights ***\n",
    "imagenet_normalize = transforms.Normalize(\n",
    "    mean=[0.485, 0.456, 0.406],\n",
    "    std=[0.229, 0.224, 0.225]\n",
    ")\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize(IMG_SIZE),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=10),\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.1),  # Mild augmentation\n",
    "    transforms.ToTensor(),\n",
    "    imagenet_normalize,\n",
    "])\n",
    "\n",
    "eval_transform = transforms.Compose([\n",
    "    transforms.Resize(IMG_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    imagenet_normalize,\n",
    "])\n",
    "\n",
    "print(\"✓ Transforms defined with ImageNet normalization\")\n",
    "\n",
    "# ============================================================================\n",
    "# DATASET (RGB CONVERSION BEFORE TRANSFORMS)\n",
    "# ============================================================================\n",
    "\n",
    "class SliceDataset(Dataset):\n",
    "    \"\"\"Dataset with proper RGB conversion and ImageNet normalization\"\"\"\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        slice_path = row[\"slice_path\"]\n",
    "        label = float(row[\"diagnosis_binary\"])\n",
    "        visit_uid = row[\"visit_uid\"]\n",
    "\n",
    "        # Load slice\n",
    "        arr = np.load(slice_path).astype(np.float32)\n",
    "        img_np = (arr * 255.0).clip(0, 255).astype(np.uint8)\n",
    "\n",
    "        # *** CRITICAL: Convert to RGB BEFORE transforms ***\n",
    "        img = Image.fromarray(img_np).convert(\"RGB\")\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        label = torch.tensor(label, dtype=torch.float32)\n",
    "        return img, label, visit_uid\n",
    "\n",
    "train_dataset = SliceDataset(train_slices, transform=train_transform)\n",
    "val_dataset = SliceDataset(val_slices, transform=eval_transform)\n",
    "test_dataset = SliceDataset(test_slices, transform=eval_transform)\n",
    "\n",
    "print(\"✓ Datasets created with RGB conversion\")\n",
    "\n",
    "# ============================================================================\n",
    "# BALANCED SAMPLER (BETTER THAN POS_WEIGHT ALONE)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"CREATING BALANCED SAMPLER\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "train_labels = train_slices[\"diagnosis_binary\"].values.astype(int)\n",
    "class_counts = np.bincount(train_labels)\n",
    "class_weights = 1.0 / class_counts\n",
    "sample_weights = class_weights[train_labels]\n",
    "\n",
    "print(f\"\\nClass distribution:\")\n",
    "print(f\"  CN: {class_counts[0]} slices\")\n",
    "print(f\"  AD: {class_counts[1]} slices\")\n",
    "print(f\"  Ratio: {class_counts[0]/class_counts[1]:.2f}:1\")\n",
    "\n",
    "print(f\"\\nBalanced sampler weights:\")\n",
    "print(f\"  CN weight: {class_weights[0]:.4f}\")\n",
    "print(f\"  AD weight: {class_weights[1]:.4f}\")\n",
    "\n",
    "sampler = WeightedRandomSampler(\n",
    "    weights=sample_weights,\n",
    "    num_samples=len(sample_weights),\n",
    "    replacement=True,\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    sampler=sampler,           # Balanced sampling\n",
    "    shuffle=False,             # Cannot use shuffle with sampler\n",
    "    num_workers=2,\n",
    "    pin_memory=(DEVICE.type == \"cuda\"),\n",
    "    drop_last=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "\n",
    "print(f\"\\n✓ DataLoaders created (train batches: {len(train_loader)})\")\n",
    "\n",
    "# ============================================================================\n",
    "# MODEL INITIALIZATION\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"MODEL INITIALIZATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "def create_model():\n",
    "    try:\n",
    "        weights = models.ResNet18_Weights.IMAGENET1K_V1\n",
    "        model = models.resnet18(weights=weights)\n",
    "    except AttributeError:\n",
    "        model = models.resnet18(pretrained=True)\n",
    "    \n",
    "    num_features = model.fc.in_features\n",
    "    model.fc = nn.Sequential(\n",
    "        nn.Dropout(p=0.5),\n",
    "        nn.Linear(num_features, 1)\n",
    "    )\n",
    "    return model\n",
    "\n",
    "model = create_model().to(DEVICE)\n",
    "\n",
    "print(f\"✓ ResNet18 with ImageNet weights\")\n",
    "print(f\"  Parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "# ============================================================================\n",
    "# LOSS FUNCTION (CLAMPED POS_WEIGHT)\n",
    "# ============================================================================\n",
    "\n",
    "# Calculate raw ratio\n",
    "n_cn = float(class_counts[0])\n",
    "n_ad = float(class_counts[1])\n",
    "raw_ratio = n_cn / n_ad\n",
    "\n",
    "# Clamp to avoid extreme gradients\n",
    "clamped_ratio = min(raw_ratio, 3.0)\n",
    "\n",
    "pos_weight = torch.tensor([clamped_ratio], device=DEVICE)\n",
    "\n",
    "print(f\"\\nLoss function:\")\n",
    "print(f\"  Raw CN/AD ratio: {raw_ratio:.2f}\")\n",
    "print(f\"  Clamped pos_weight: {pos_weight.item():.3f}\")\n",
    "print(f\"  Using BCEWithLogitsLoss\")\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='max', factor=0.5, patience=4, verbose=True\n",
    ")\n",
    "\n",
    "# ============================================================================\n",
    "# TRAINING FUNCTIONS\n",
    "# ============================================================================\n",
    "\n",
    "def train_one_epoch(model, loader, optimizer, criterion, device, grad_clip=None):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    n_batches = 0\n",
    "    \n",
    "    for images, labels, _ in loader:\n",
    "        images = images.to(device, non_blocking=True)\n",
    "        labels = labels.to(device, non_blocking=True)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        logits = model(images).squeeze(1)\n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        if grad_clip is not None:\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
    "        \n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        n_batches += 1\n",
    "    \n",
    "    return running_loss / max(n_batches, 1)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_model(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    all_logits = []\n",
    "    all_labels = []\n",
    "    all_visit_uids = []\n",
    "    total_loss = 0.0\n",
    "    n_batches = 0\n",
    "    \n",
    "    for images, labels, visit_uids in loader:\n",
    "        images = images.to(device, non_blocking=True)\n",
    "        labels = labels.to(device, non_blocking=True)\n",
    "        \n",
    "        logits = model(images).squeeze(1)\n",
    "        loss = criterion(logits, labels)\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        n_batches += 1\n",
    "        \n",
    "        all_logits.append(logits.cpu())\n",
    "        all_labels.append(labels.cpu())\n",
    "        all_visit_uids.extend(visit_uids)\n",
    "    \n",
    "    if n_batches == 0:\n",
    "        return math.nan, math.nan, math.nan, {}\n",
    "    \n",
    "    avg_loss = total_loss / n_batches\n",
    "    logits = torch.cat(all_logits).numpy()\n",
    "    labels = torch.cat(all_labels).numpy()\n",
    "    probs = 1 / (1 + np.exp(-logits))\n",
    "    preds = (probs >= 0.5).astype(np.float32)\n",
    "    \n",
    "    slice_acc = (preds == labels).mean()\n",
    "    \n",
    "    cn_mask = labels == 0\n",
    "    ad_mask = labels == 1\n",
    "    cn_acc = (preds[cn_mask] == labels[cn_mask]).mean() if cn_mask.sum() > 0 else 0.0\n",
    "    ad_acc = (preds[ad_mask] == labels[ad_mask]).mean() if ad_mask.sum() > 0 else 0.0\n",
    "    \n",
    "    df = pd.DataFrame({\"visit_uid\": all_visit_uids, \"label\": labels, \"prob\": probs})\n",
    "    visit_group = df.groupby(\"visit_uid\")\n",
    "    visit_prob = visit_group[\"prob\"].mean()\n",
    "    visit_label = visit_group[\"label\"].first()\n",
    "    visit_pred = (visit_prob >= 0.5).astype(np.float32)\n",
    "    visit_acc = (visit_pred.values == visit_label.values).mean()\n",
    "    \n",
    "    # Calculate ROC-AUC at visit level\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    try:\n",
    "        visit_auc = roc_auc_score(visit_label.values, visit_prob.values)\n",
    "    except:\n",
    "        visit_auc = 0.5\n",
    "    \n",
    "    return avg_loss, slice_acc, visit_acc, {\n",
    "        \"slice_cn_acc\": cn_acc, \n",
    "        \"slice_ad_acc\": ad_acc,\n",
    "        \"visit_auc\": visit_auc\n",
    "    }\n",
    "\n",
    "# ============================================================================\n",
    "# TRAINING LOOP\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"TRAINING\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "history = []\n",
    "best_val_visit_acc = 0.0\n",
    "best_state_dict = None\n",
    "epochs_no_improve = 0\n",
    "\n",
    "print(f\"\\nTarget: Beat trivial baseline (ACC=0.878, BalACC=0.5, AUC=0.5)\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    t0 = time.time()\n",
    "    \n",
    "    train_loss = train_one_epoch(model, train_loader, optimizer, criterion, DEVICE, GRAD_CLIP)\n",
    "    val_loss, val_slice_acc, val_visit_acc, val_metrics = evaluate_model(model, val_loader, criterion, DEVICE)\n",
    "    \n",
    "    dt = time.time() - t0\n",
    "    current_lr = optimizer.param_groups[0][\"lr\"]\n",
    "    \n",
    "    print(f\"[Epoch {epoch:02d}/{NUM_EPOCHS}] time={dt:.1f}s | lr={current_lr:.2e}\")\n",
    "    print(f\"  train_loss={train_loss:.4f} | val_loss={val_loss:.4f}\")\n",
    "    print(f\"  val_slice_acc={val_slice_acc:.4f} | val_visit_acc={val_visit_acc:.4f}\")\n",
    "    print(f\"  val_visit_auc={val_metrics['visit_auc']:.4f} | CN_acc={val_metrics['slice_cn_acc']:.4f} | AD_acc={val_metrics['slice_ad_acc']:.4f}\")\n",
    "    \n",
    "    history.append({\n",
    "        \"epoch\": epoch, \"train_loss\": train_loss, \"val_loss\": val_loss,\n",
    "        \"val_slice_acc\": val_slice_acc, \"val_visit_acc\": val_visit_acc,\n",
    "        \"val_cn_acc\": val_metrics[\"slice_cn_acc\"], \"val_ad_acc\": val_metrics[\"slice_ad_acc\"],\n",
    "        \"val_visit_auc\": val_metrics[\"visit_auc\"], \"lr\": current_lr\n",
    "    })\n",
    "    \n",
    "    scheduler.step(val_visit_acc)\n",
    "    \n",
    "    if not math.isnan(val_visit_acc) and val_visit_acc > best_val_visit_acc:\n",
    "        best_val_visit_acc = val_visit_acc\n",
    "        best_state_dict = copy.deepcopy(model.state_dict())\n",
    "        epochs_no_improve = 0\n",
    "        print(f\"  ✓ New best: {best_val_visit_acc:.4f}\")\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "    \n",
    "    if epochs_no_improve >= EARLY_STOP_PATIENCE:\n",
    "        print(f\"\\n⚠ Early stopping (no improvement for {EARLY_STOP_PATIENCE} epochs)\")\n",
    "        break\n",
    "\n",
    "print(\"-\" * 80)\n",
    "\n",
    "if best_state_dict is not None:\n",
    "    torch.save(best_state_dict, MODEL_OUT_PATH)\n",
    "    print(f\"\\n✓ Model saved: {MODEL_OUT_PATH}\")\n",
    "\n",
    "pd.DataFrame(history).to_csv(HISTORY_CSV, index=False)\n",
    "print(f\"✓ History saved: {HISTORY_CSV}\")\n",
    "\n",
    "# ============================================================================\n",
    "# TEST EVALUATION\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"TEST EVALUATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if best_state_dict is not None:\n",
    "    model.load_state_dict(best_state_dict)\n",
    "\n",
    "test_loss, test_slice_acc, test_visit_acc, test_metrics = evaluate_model(model, test_loader, criterion, DEVICE)\n",
    "\n",
    "print(f\"\\nTest results (threshold=0.5):\")\n",
    "print(f\"  Loss:         {test_loss:.4f}\")\n",
    "print(f\"  Slice ACC:    {test_slice_acc:.4f}\")\n",
    "print(f\"  Visit ACC:    {test_visit_acc:.4f}\")\n",
    "print(f\"  Visit AUC:    {test_metrics['visit_auc']:.4f}\")\n",
    "print(f\"  CN ACC:       {test_metrics['slice_cn_acc']:.4f}\")\n",
    "print(f\"  AD ACC:       {test_metrics['slice_ad_acc']:.4f}\")\n",
    "\n",
    "print(f\"\\nComparison with baseline:\")\n",
    "print(f\"  Trivial baseline: ACC=0.878, AUC=0.5\")\n",
    "print(f\"  Current model:    ACC={test_visit_acc:.3f}, AUC={test_metrics['visit_auc']:.3f}\")\n",
    "\n",
    "if test_metrics['visit_auc'] > 0.65:\n",
    "    print(f\"\\n✅ Model shows AD signal (AUC > 0.65)\")\n",
    "    print(f\"   Proceed to threshold optimization (S10c)\")\n",
    "elif test_metrics['visit_auc'] > 0.55:\n",
    "    print(f\"\\n⚠️  Weak AD signal (AUC 0.55-0.65)\")\n",
    "    print(f\"   Consider: longer training, better architecture\")\n",
    "else:\n",
    "    print(f\"\\n❌ No AD signal (AUC ≤ 0.55)\")\n",
    "    print(f\"   Need: architecture change (3D CNN, multi-scale)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SNIPPET S10d COMPLETE\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be881e90",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T19:13:03.411023Z",
     "iopub.status.busy": "2025-11-17T19:13:03.410790Z",
     "iopub.status.idle": "2025-11-17T19:13:12.252356Z",
     "shell.execute_reply": "2025-11-17T19:13:12.251569Z"
    },
    "papermill": {
     "duration": 8.863496,
     "end_time": "2025-11-17T19:13:12.253700",
     "exception": false,
     "start_time": "2025-11-17T19:13:03.390204",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SNIPPET S10c_proper: THRESHOLD OPTIMIZATION\n",
      "================================================================================\n",
      "Device: cuda\n",
      "\n",
      "================================================================================\n",
      "LOADING MODEL\n",
      "================================================================================\n",
      "✓ Model loaded: /kaggle/working/resnet18_fold0_proper.pth\n",
      "\n",
      "================================================================================\n",
      "LOADING METADATA\n",
      "================================================================================\n",
      "\n",
      "Data loaded:\n",
      "  Val slices:  2912\n",
      "  Test slices: 3680\n",
      "\n",
      "================================================================================\n",
      "DEFINING TRANSFORMS & DATASET\n",
      "================================================================================\n",
      "Transform pipeline:\n",
      "  1. Resize to (128, 128)\n",
      "  2. ToTensor\n",
      "  3. ImageNet normalization (MATCHES S10d training)\n",
      "✓ Datasets created (consistent with S10d)\n",
      "\n",
      "================================================================================\n",
      "GENERATING VISIT-LEVEL PREDICTIONS\n",
      "================================================================================\n",
      "Computing validation predictions...\n",
      "  Val visits: 91\n",
      "Computing test predictions...\n",
      "  Test visits: 115\n",
      "\n",
      "================================================================================\n",
      "TRIVIAL BASELINE COMPUTATION\n",
      "================================================================================\n",
      "\n",
      "Test set composition:\n",
      "  CN visits: 101 (87.8%)\n",
      "  AD visits: 14 (12.2%)\n",
      "\n",
      "Trivial 'Always CN' baseline:\n",
      "  Accuracy:     0.8783\n",
      "  Balanced ACC: 0.5000\n",
      "  ROC-AUC:      0.5000\n",
      "\n",
      "⚠️  Model MUST beat these numbers to be useful!\n",
      "\n",
      "================================================================================\n",
      "THRESHOLD OPTIMIZATION (VALIDATION SET)\n",
      "================================================================================\n",
      "\n",
      "✓ Optimal threshold: 0.350\n",
      "  (Maximizes balanced accuracy on validation)\n",
      "\n",
      "Validation metrics at optimal threshold:\n",
      "  Accuracy:     0.8901\n",
      "  Balanced ACC: 0.8397\n",
      "  CN accuracy:  0.9103\n",
      "  AD accuracy:  0.7692\n",
      "\n",
      "================================================================================\n",
      "PLOTTING THRESHOLD CURVES\n",
      "================================================================================\n",
      "✓ Saved: /kaggle/working/threshold_optimization_proper.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1800x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "FINAL TEST SET EVALUATION\n",
      "================================================================================\n",
      "\n",
      "Test results (threshold=0.350):\n",
      "  Accuracy:         0.6870\n",
      "  Balanced ACC:     0.5757\n",
      "  ROC-AUC:          0.6308\n",
      "\n",
      "Per-class accuracy:\n",
      "  CN accuracy:      0.7228\n",
      "  AD accuracy:      0.4286\n",
      "\n",
      "Confusion matrix:\n",
      "                Predicted\n",
      "                CN    AD\n",
      "  Actual  CN     73   28\n",
      "          AD      8    6\n",
      "\n",
      "Detailed metrics:\n",
      "  Sensitivity (AD Recall): 0.4286\n",
      "  Specificity (CN Recall): 0.7228\n",
      "  Precision:               0.1765\n",
      "  F1-Score:                0.2500\n",
      "\n",
      "================================================================================\n",
      "MODEL vs BASELINE COMPARISON\n",
      "================================================================================\n",
      "\n",
      "Model performance:\n",
      "  Accuracy:     0.6870\n",
      "  Balanced ACC: 0.5757\n",
      "  ROC-AUC:      0.6308\n",
      "\n",
      "Trivial baseline:\n",
      "  Accuracy:     0.8783\n",
      "  Balanced ACC: 0.5000\n",
      "  ROC-AUC:      0.5000\n",
      "\n",
      "Improvement over baseline:\n",
      "  Accuracy:     -0.1913\n",
      "  Balanced ACC: +0.0757\n",
      "  ROC-AUC:      +0.1308\n",
      "\n",
      "================================================================================\n",
      "PERFORMANCE ASSESSMENT\n",
      "================================================================================\n",
      "\n",
      "❌ ASSESSMENT: FAILED\n",
      "\n",
      "Model performs worse than trivial baseline\n",
      "REQUIRED ACTIONS:\n",
      "  1. Train on ALL trainval (not just fold 0)\n",
      "  2. Increase to 40-50 epochs\n",
      "  3. Try EfficientNet-B0 or DenseNet121\n",
      "  4. Consider 3D CNN or multi-scale inputs\n",
      "\n",
      "================================================================================\n",
      "PLOTTING PROBABILITY DISTRIBUTIONS\n",
      "================================================================================\n",
      "✓ Saved: /kaggle/working/probability_distributions_proper.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1400x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "FINAL SUMMARY\n",
      "================================================================================\n",
      "\n",
      "✅ Threshold optimization complete\n",
      "   Optimal threshold: 0.350\n",
      "\n",
      "📊 Test set performance:\n",
      "   Accuracy:      0.6870 (baseline: 0.8783)\n",
      "   Balanced ACC:  0.5757 (baseline: 0.5000)\n",
      "   ROC-AUC:       0.6308 (baseline: 0.5000)\n",
      "   CN accuracy:   0.7228\n",
      "   AD accuracy:   0.4286\n",
      "\n",
      "================================================================================\n",
      "SNIPPET S10c_proper COMPLETE\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "SNIPPET S10c_proper: Threshold Optimization for S10d Model\n",
    "Find optimal classification threshold on validation set,\n",
    "      evaluate on test set, and compare against trivial baseline.\n",
    "\n",
    "Requirements: Must run after S10d training completes\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, balanced_accuracy_score,\n",
    "    confusion_matrix, roc_auc_score, roc_curve,\n",
    "    classification_report\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"SNIPPET S10c_proper: THRESHOLD OPTIMIZATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURATION (ALIGNED WITH S10d)\n",
    "# ============================================================================\n",
    "\n",
    "MODEL_PATH = \"/kaggle/working/resnet18_fold0_proper.pth\"\n",
    "SLICE_META_CSV = \"/kaggle/working/mni_slices_v1/slice_level_metadata_v1.csv\"\n",
    "VISIT_SPLIT_CSV = \"classification_visit_metadata_with_splits.csv\"\n",
    "\n",
    "FOLD_ID = 0\n",
    "BATCH_SIZE = 32\n",
    "IMG_SIZE = (128, 128)\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {DEVICE}\")\n",
    "\n",
    "# ============================================================================\n",
    "# LOAD MODEL (IDENTICAL TO S10d)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"LOADING MODEL\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "def create_model():\n",
    "    \"\"\"Same architecture as S10d\"\"\"\n",
    "    try:\n",
    "        weights = models.ResNet18_Weights.IMAGENET1K_V1\n",
    "        model = models.resnet18(weights=weights)\n",
    "    except AttributeError:\n",
    "        model = models.resnet18(pretrained=True)\n",
    "    \n",
    "    num_features = model.fc.in_features\n",
    "    model.fc = nn.Sequential(\n",
    "        nn.Dropout(p=0.5),\n",
    "        nn.Linear(num_features, 1)\n",
    "    )\n",
    "    return model\n",
    "\n",
    "model = create_model().to(DEVICE)\n",
    "state_dict = torch.load(MODEL_PATH, map_location=DEVICE)\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval()\n",
    "\n",
    "print(f\"✓ Model loaded: {MODEL_PATH}\")\n",
    "\n",
    "# ============================================================================\n",
    "# LOAD METADATA\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"LOADING METADATA\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "slice_meta = pd.read_csv(SLICE_META_CSV)\n",
    "visit_meta_splits = pd.read_csv(VISIT_SPLIT_CSV)\n",
    "\n",
    "slice_meta = slice_meta.merge(\n",
    "    visit_meta_splits[[\"visit_uid\", \"cv_fold\", \"split\"]],\n",
    "    on=\"visit_uid\",\n",
    "    how=\"left\",\n",
    "    suffixes=(\"_slice\", \"_visit\")\n",
    ")\n",
    "\n",
    "if \"split_visit\" in slice_meta.columns:\n",
    "    slice_meta[\"split\"] = slice_meta[\"split_visit\"]\n",
    "\n",
    "val_slices = slice_meta[\n",
    "    (slice_meta[\"split\"] == \"trainval\") &\n",
    "    (slice_meta[\"cv_fold\"] == FOLD_ID)\n",
    "].copy()\n",
    "\n",
    "test_slices = slice_meta[slice_meta[\"split\"] == \"test\"].copy()\n",
    "\n",
    "print(f\"\\nData loaded:\")\n",
    "print(f\"  Val slices:  {len(val_slices)}\")\n",
    "print(f\"  Test slices: {len(test_slices)}\")\n",
    "\n",
    "# ============================================================================\n",
    "# TRANSFORMS & DATASET (IDENTICAL TO S10d)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"DEFINING TRANSFORMS & DATASET\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "imagenet_normalize = transforms.Normalize(\n",
    "    mean=[0.485, 0.456, 0.406],\n",
    "    std=[0.229, 0.224, 0.225]\n",
    ")\n",
    "\n",
    "eval_transform = transforms.Compose([\n",
    "    transforms.Resize(IMG_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    imagenet_normalize,\n",
    "])\n",
    "\n",
    "print(\"Transform pipeline:\")\n",
    "print(\"  1. Resize to (128, 128)\")\n",
    "print(\"  2. ToTensor\")\n",
    "print(\"  3. ImageNet normalization (MATCHES S10d training)\")\n",
    "\n",
    "class SliceDataset(Dataset):\n",
    "    \"\"\"Same dataset as S10d evaluation\"\"\"\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        slice_path = row[\"slice_path\"]\n",
    "        label = float(row[\"diagnosis_binary\"])\n",
    "        visit_uid = row[\"visit_uid\"]\n",
    "        \n",
    "        arr = np.load(slice_path).astype(np.float32)\n",
    "        img_np = (arr * 255.0).clip(0, 255).astype(np.uint8)\n",
    "        \n",
    "        # CRITICAL: Same RGB conversion as S10d\n",
    "        img = Image.fromarray(img_np).convert(\"RGB\")\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        \n",
    "        label = torch.tensor(label, dtype=torch.float32)\n",
    "        return img, label, visit_uid\n",
    "\n",
    "val_dataset = SliceDataset(val_slices, transform=eval_transform)\n",
    "test_dataset = SliceDataset(test_slices, transform=eval_transform)\n",
    "\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "\n",
    "print(\"✓ Datasets created (consistent with S10d)\")\n",
    "\n",
    "# ============================================================================\n",
    "# VISIT-LEVEL PREDICTION\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"GENERATING VISIT-LEVEL PREDICTIONS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "@torch.no_grad()\n",
    "def get_visit_predictions(model, loader, device):\n",
    "    \"\"\"\n",
    "    Aggregate slice predictions to visit level\n",
    "    Returns DataFrame: [visit_uid, true_label, prob_mean, n_slices]\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_logits = []\n",
    "    all_labels = []\n",
    "    all_visit_uids = []\n",
    "    \n",
    "    for images, labels, visit_uids in loader:\n",
    "        images = images.to(device, non_blocking=True)\n",
    "        logits = model(images).squeeze(1)\n",
    "        \n",
    "        all_logits.append(logits.cpu())\n",
    "        all_labels.append(labels.cpu())\n",
    "        all_visit_uids.extend(visit_uids)\n",
    "    \n",
    "    logits = torch.cat(all_logits).numpy()\n",
    "    labels = torch.cat(all_labels).numpy()\n",
    "    probs = 1.0 / (1.0 + np.exp(-logits))\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        \"visit_uid\": all_visit_uids,\n",
    "        \"true_label\": labels,\n",
    "        \"prob\": probs\n",
    "    })\n",
    "    \n",
    "    visit_df = df.groupby(\"visit_uid\").agg({\n",
    "        \"true_label\": \"first\",\n",
    "        \"prob\": [\"mean\", \"count\"]\n",
    "    }).reset_index()\n",
    "    \n",
    "    visit_df.columns = [\"visit_uid\", \"true_label\", \"prob_mean\", \"n_slices\"]\n",
    "    return visit_df\n",
    "\n",
    "print(\"Computing validation predictions...\")\n",
    "val_visits = get_visit_predictions(model, val_loader, DEVICE)\n",
    "print(f\"  Val visits: {len(val_visits)}\")\n",
    "\n",
    "print(\"Computing test predictions...\")\n",
    "test_visits = get_visit_predictions(model, test_loader, DEVICE)\n",
    "print(f\"  Test visits: {len(test_visits)}\")\n",
    "\n",
    "# ============================================================================\n",
    "# BASELINE COMPARISON\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"TRIVIAL BASELINE COMPUTATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "test_labels = test_visits[\"true_label\"].astype(int).values\n",
    "n_cn_test = (test_labels == 0).sum()\n",
    "n_ad_test = (test_labels == 1).sum()\n",
    "cn_rate_test = n_cn_test / len(test_labels)\n",
    "\n",
    "baseline_acc = cn_rate_test  # \"Always CN\" accuracy\n",
    "baseline_bal_acc = 0.5        # Random for one class\n",
    "\n",
    "print(f\"\\nTest set composition:\")\n",
    "print(f\"  CN visits: {n_cn_test} ({100*cn_rate_test:.1f}%)\")\n",
    "print(f\"  AD visits: {n_ad_test} ({100*(1-cn_rate_test):.1f}%)\")\n",
    "\n",
    "print(f\"\\nTrivial 'Always CN' baseline:\")\n",
    "print(f\"  Accuracy:     {baseline_acc:.4f}\")\n",
    "print(f\"  Balanced ACC: {baseline_bal_acc:.4f}\")\n",
    "print(f\"  ROC-AUC:      {baseline_bal_acc:.4f}\")\n",
    "\n",
    "print(f\"\\n⚠️  Model MUST beat these numbers to be useful!\")\n",
    "\n",
    "# ============================================================================\n",
    "# THRESHOLD OPTIMIZATION ON VALIDATION\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"THRESHOLD OPTIMIZATION (VALIDATION SET)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "thresholds = np.linspace(0.1, 0.9, 81)\n",
    "results = []\n",
    "\n",
    "labels_val = val_visits[\"true_label\"].astype(int).values\n",
    "probs_val = val_visits[\"prob_mean\"].values\n",
    "\n",
    "for thr in thresholds:\n",
    "    preds_val = (probs_val >= thr).astype(int)\n",
    "    acc = accuracy_score(labels_val, preds_val)\n",
    "    bal_acc = balanced_accuracy_score(labels_val, preds_val)\n",
    "    \n",
    "    cm = confusion_matrix(labels_val, preds_val, labels=[0, 1])\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    cn_acc = tn / (tn + fp) if (tn + fp) > 0 else 0.0\n",
    "    ad_acc = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "    \n",
    "    results.append({\n",
    "        \"threshold\": thr,\n",
    "        \"accuracy\": acc,\n",
    "        \"balanced_accuracy\": bal_acc,\n",
    "        \"cn_accuracy\": cn_acc,\n",
    "        \"ad_accuracy\": ad_acc\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "best_idx = results_df[\"balanced_accuracy\"].idxmax()\n",
    "best_thr = results_df.loc[best_idx, \"threshold\"]\n",
    "best_bal_acc = results_df.loc[best_idx, \"balanced_accuracy\"]\n",
    "\n",
    "print(f\"\\n✓ Optimal threshold: {best_thr:.3f}\")\n",
    "print(f\"  (Maximizes balanced accuracy on validation)\")\n",
    "\n",
    "print(f\"\\nValidation metrics at optimal threshold:\")\n",
    "print(f\"  Accuracy:     {results_df.loc[best_idx, 'accuracy']:.4f}\")\n",
    "print(f\"  Balanced ACC: {best_bal_acc:.4f}\")\n",
    "print(f\"  CN accuracy:  {results_df.loc[best_idx, 'cn_accuracy']:.4f}\")\n",
    "print(f\"  AD accuracy:  {results_df.loc[best_idx, 'ad_accuracy']:.4f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# VISUALIZATION: THRESHOLD CURVES\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"PLOTTING THRESHOLD CURVES\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Plot 1: Overall metrics\n",
    "ax = axes[0]\n",
    "ax.plot(results_df[\"threshold\"], results_df[\"accuracy\"], \n",
    "        'b-', linewidth=2, label='Accuracy', alpha=0.7)\n",
    "ax.plot(results_df[\"threshold\"], results_df[\"balanced_accuracy\"], \n",
    "        'r-', linewidth=2.5, label='Balanced Accuracy')\n",
    "ax.axvline(best_thr, color='k', linestyle='--', linewidth=1.5,\n",
    "           label=f'Optimal: {best_thr:.3f}')\n",
    "ax.axhline(baseline_acc, color='orange', linestyle=':', linewidth=2,\n",
    "           label=f'Baseline (always CN): {baseline_acc:.3f}')\n",
    "ax.axhline(0.5, color='gray', linestyle=':', alpha=0.5)\n",
    "ax.set_xlabel('Threshold', fontsize=12)\n",
    "ax.set_ylabel('Accuracy', fontsize=12)\n",
    "ax.set_title('Validation: Accuracy vs Threshold', fontsize=13, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.legend(fontsize=9)\n",
    "\n",
    "# Plot 2: Per-class accuracy\n",
    "ax = axes[1]\n",
    "ax.plot(results_df[\"threshold\"], results_df[\"cn_accuracy\"], \n",
    "        'g-', linewidth=2, label='CN Accuracy')\n",
    "ax.plot(results_df[\"threshold\"], results_df[\"ad_accuracy\"], \n",
    "        'r-', linewidth=2, label='AD Accuracy')\n",
    "ax.axvline(best_thr, color='k', linestyle='--', linewidth=1.5,\n",
    "           label=f'Optimal: {best_thr:.3f}')\n",
    "ax.set_xlabel('Threshold', fontsize=12)\n",
    "ax.set_ylabel('Per-Class Accuracy', fontsize=12)\n",
    "ax.set_title('Per-Class Performance', fontsize=13, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.legend(fontsize=9)\n",
    "\n",
    "# Plot 3: Trade-off curve\n",
    "ax = axes[2]\n",
    "ax.plot(results_df[\"cn_accuracy\"], results_df[\"ad_accuracy\"], \n",
    "        'b-', linewidth=2, alpha=0.7)\n",
    "ax.scatter(results_df.loc[best_idx, 'cn_accuracy'], \n",
    "           results_df.loc[best_idx, 'ad_accuracy'],\n",
    "           color='red', s=100, zorder=5, label=f'Optimal (thr={best_thr:.3f})')\n",
    "ax.plot([0, 1], [0, 1], 'k--', alpha=0.3, label='Perfect balance')\n",
    "ax.set_xlabel('CN Accuracy', fontsize=12)\n",
    "ax.set_ylabel('AD Accuracy', fontsize=12)\n",
    "ax.set_title('CN-AD Trade-off Curve', fontsize=13, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.legend(fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('/kaggle/working/threshold_optimization_proper.png', dpi=150, bbox_inches='tight')\n",
    "print(\"✓ Saved: /kaggle/working/threshold_optimization_proper.png\")\n",
    "plt.show()\n",
    "\n",
    "# ============================================================================\n",
    "# FINAL TEST SET EVALUATION\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"FINAL TEST SET EVALUATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "probs_test = test_visits[\"prob_mean\"].values\n",
    "preds_test = (probs_test >= best_thr).astype(int)\n",
    "\n",
    "test_acc = accuracy_score(test_labels, preds_test)\n",
    "test_bal_acc = balanced_accuracy_score(test_labels, preds_test)\n",
    "test_auc = roc_auc_score(test_labels, probs_test)\n",
    "\n",
    "cm = confusion_matrix(test_labels, preds_test, labels=[0, 1])\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "cn_acc_test = tn / (tn + fp) if (tn + fp) > 0 else 0.0\n",
    "ad_acc_test = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "\n",
    "sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "specificity = tn / (tn + fp) if (tn + fp) > 0 else 0.0\n",
    "precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "f1 = 2 * tp / (2 * tp + fp + fn) if (2 * tp + fp + fn) > 0 else 0.0\n",
    "\n",
    "print(f\"\\nTest results (threshold={best_thr:.3f}):\")\n",
    "print(f\"  Accuracy:         {test_acc:.4f}\")\n",
    "print(f\"  Balanced ACC:     {test_bal_acc:.4f}\")\n",
    "print(f\"  ROC-AUC:          {test_auc:.4f}\")\n",
    "\n",
    "print(f\"\\nPer-class accuracy:\")\n",
    "print(f\"  CN accuracy:      {cn_acc_test:.4f}\")\n",
    "print(f\"  AD accuracy:      {ad_acc_test:.4f}\")\n",
    "\n",
    "print(f\"\\nConfusion matrix:\")\n",
    "print(f\"                Predicted\")\n",
    "print(f\"                CN    AD\")\n",
    "print(f\"  Actual  CN    {tn:3d}  {fp:3d}\")\n",
    "print(f\"          AD    {fn:3d}  {tp:3d}\")\n",
    "\n",
    "print(f\"\\nDetailed metrics:\")\n",
    "print(f\"  Sensitivity (AD Recall): {sensitivity:.4f}\")\n",
    "print(f\"  Specificity (CN Recall): {specificity:.4f}\")\n",
    "print(f\"  Precision:               {precision:.4f}\")\n",
    "print(f\"  F1-Score:                {f1:.4f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# COMPARISON WITH BASELINE\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"MODEL vs BASELINE COMPARISON\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\\nModel performance:\")\n",
    "print(f\"  Accuracy:     {test_acc:.4f}\")\n",
    "print(f\"  Balanced ACC: {test_bal_acc:.4f}\")\n",
    "print(f\"  ROC-AUC:      {test_auc:.4f}\")\n",
    "\n",
    "print(f\"\\nTrivial baseline:\")\n",
    "print(f\"  Accuracy:     {baseline_acc:.4f}\")\n",
    "print(f\"  Balanced ACC: {baseline_bal_acc:.4f}\")\n",
    "print(f\"  ROC-AUC:      {baseline_bal_acc:.4f}\")\n",
    "\n",
    "acc_improvement = test_acc - baseline_acc\n",
    "bal_improvement = test_bal_acc - baseline_bal_acc\n",
    "auc_improvement = test_auc - baseline_bal_acc\n",
    "\n",
    "print(f\"\\nImprovement over baseline:\")\n",
    "print(f\"  Accuracy:     {acc_improvement:+.4f}\")\n",
    "print(f\"  Balanced ACC: {bal_improvement:+.4f}\")\n",
    "print(f\"  ROC-AUC:      {auc_improvement:+.4f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# PERFORMANCE ASSESSMENT\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"PERFORMANCE ASSESSMENT\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if test_acc < baseline_acc * 0.95:\n",
    "    assessment = \"FAILED\"\n",
    "    color = \"❌\"\n",
    "    recommendation = [\n",
    "        \"Model performs worse than trivial baseline\",\n",
    "        \"REQUIRED ACTIONS:\",\n",
    "        \"  1. Train on ALL trainval (not just fold 0)\",\n",
    "        \"  2. Increase to 40-50 epochs\",\n",
    "        \"  3. Try EfficientNet-B0 or DenseNet121\",\n",
    "        \"  4. Consider 3D CNN or multi-scale inputs\"\n",
    "    ]\n",
    "elif test_auc < 0.60:\n",
    "    assessment = \"POOR\"\n",
    "    color = \"❌\"\n",
    "    recommendation = [\n",
    "        \"Model barely separates CN from AD (AUC < 0.60)\",\n",
    "        \"REQUIRED ACTIONS:\",\n",
    "        \"  1. Train on all trainval subjects\",\n",
    "        \"  2. Ensemble folds 0-4\",\n",
    "        \"  3. Upgrade architecture (EfficientNet-B0)\"\n",
    "    ]\n",
    "elif test_auc < 0.70:\n",
    "    assessment = \"WEAK\"\n",
    "    color = \"⚠️\"\n",
    "    recommendation = [\n",
    "        \"Model shows some AD signal but needs improvement\",\n",
    "        \"RECOMMENDED ACTIONS:\",\n",
    "        \"  1. Train on all trainval (not just fold 0)\",\n",
    "        \"  2. Ensemble 5 folds\",\n",
    "        \"  3. Try longer training (40 epochs)\"\n",
    "    ]\n",
    "elif test_bal_acc < 0.75:\n",
    "    assessment = \"MODERATE\"\n",
    "    color = \"⚠️\"\n",
    "    recommendation = [\n",
    "        \"Model has reasonable performance but below target\",\n",
    "        \"RECOMMENDED ACTIONS:\",\n",
    "        \"  1. Ensemble folds 0-4 (+5-10% typical boost)\",\n",
    "        \"  2. Add multi-scale inputs\",\n",
    "        \"  3. Consider EfficientNet-B0\"\n",
    "    ]\n",
    "elif test_bal_acc < 0.85:\n",
    "    assessment = \"GOOD\"\n",
    "    color = \"✅\"\n",
    "    recommendation = [\n",
    "        \"Model meets minimum research-grade criteria\",\n",
    "        \"OPTIONAL IMPROVEMENTS:\",\n",
    "        \"  1. Ensemble for stability\",\n",
    "        \"  2. Ready for Grad-CAM analysis (S11)\"\n",
    "    ]\n",
    "else:\n",
    "    assessment = \"EXCELLENT\"\n",
    "    color = \"🎉\"\n",
    "    recommendation = [\n",
    "        \"Model exceeds research-grade performance!\",\n",
    "        \"NEXT STEPS:\",\n",
    "        \"  1. Proceed to Grad-CAM (S11)\",\n",
    "        \"  2. Hippocampus overlap analysis\",\n",
    "        \"  3. Multi-site validation\"\n",
    "    ]\n",
    "\n",
    "print(f\"\\n{color} ASSESSMENT: {assessment}\")\n",
    "print(f\"\\n\" + \"\\n\".join(recommendation))\n",
    "\n",
    "# ============================================================================\n",
    "# PROBABILITY DISTRIBUTIONS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"PLOTTING PROBABILITY DISTRIBUTIONS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "for ax, (name, visits_df) in zip(axes, [(\"Validation\", val_visits), (\"Test\", test_visits)]):\n",
    "    cn_probs = visits_df[visits_df[\"true_label\"] == 0][\"prob_mean\"]\n",
    "    ad_probs = visits_df[visits_df[\"true_label\"] == 1][\"prob_mean\"]\n",
    "    \n",
    "    ax.hist(cn_probs, bins=25, alpha=0.6, label=f'CN (n={len(cn_probs)})', \n",
    "            color='green', edgecolor='black')\n",
    "    ax.hist(ad_probs, bins=25, alpha=0.6, label=f'AD (n={len(ad_probs)})', \n",
    "            color='red', edgecolor='black')\n",
    "    ax.axvline(best_thr, color='k', linestyle='--', linewidth=2,\n",
    "               label=f'Threshold={best_thr:.3f}')\n",
    "    ax.set_xlabel('Predicted Probability (AD)', fontsize=12)\n",
    "    ax.set_ylabel('Count', fontsize=12)\n",
    "    ax.set_title(f'{name} Set', fontsize=13, fontweight='bold')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('/kaggle/working/probability_distributions_proper.png', dpi=150, bbox_inches='tight')\n",
    "print(\"✓ Saved: /kaggle/working/probability_distributions_proper.png\")\n",
    "plt.show()\n",
    "\n",
    "# ============================================================================\n",
    "# SUMMARY\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"FINAL SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\\n✅ Threshold optimization complete\")\n",
    "print(f\"   Optimal threshold: {best_thr:.3f}\")\n",
    "\n",
    "print(f\"\\n📊 Test set performance:\")\n",
    "print(f\"   Accuracy:      {test_acc:.4f} (baseline: {baseline_acc:.4f})\")\n",
    "print(f\"   Balanced ACC:  {test_bal_acc:.4f} (baseline: {baseline_bal_acc:.4f})\")\n",
    "print(f\"   ROC-AUC:       {test_auc:.4f} (baseline: {baseline_bal_acc:.4f})\")\n",
    "print(f\"   CN accuracy:   {cn_acc_test:.4f}\")\n",
    "print(f\"   AD accuracy:   {ad_acc_test:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SNIPPET S10c_proper COMPLETE\")\n",
    "print(\"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5273e58f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T19:13:12.303987Z",
     "iopub.status.busy": "2025-11-17T19:13:12.303733Z",
     "iopub.status.idle": "2025-11-17T19:17:09.483913Z",
     "shell.execute_reply": "2025-11-17T19:17:09.482880Z"
    },
    "papermill": {
     "duration": 237.205279,
     "end_time": "2025-11-17T19:17:09.485289",
     "exception": false,
     "start_time": "2025-11-17T19:13:12.280010",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SNIPPET S11: VISIT-LEVEL ATTENTION RESNET18 (FOLD 0)\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "CONFIGURATION\n",
      "================================================================================\n",
      "\n",
      "Device: cuda\n",
      "GPU: Tesla T4\n",
      "GPU Memory: 15.8 GB\n",
      "\n",
      "Hyperparameters:\n",
      "  Batch size:  8 visits/batch\n",
      "  Epochs:      30\n",
      "  LR:          0.0001\n",
      "  Weight decay: 0.0001\n",
      "  Patience:    8\n",
      "\n",
      "================================================================================\n",
      "LOADING & GROUPING METADATA\n",
      "================================================================================\n",
      "✓ Fixed slices per visit: 32\n",
      "\n",
      "Slice counts:\n",
      "  Train: 11872\n",
      "  Val:   2912\n",
      "  Test:  3680\n",
      "\n",
      "Visit counts:\n",
      "  Train: 371\n",
      "  Val:   91\n",
      "  Test:  115\n",
      "\n",
      "✓ No subject leakage at visit level\n",
      "\n",
      "Class distribution (visit-level):\n",
      "  Train: CN=320, AD= 51 (ratio 6.27:1)\n",
      "  Val  : CN= 78, AD= 13 (ratio 6.00:1)\n",
      "  Test : CN=101, AD= 14 (ratio 7.21:1)\n",
      "\n",
      "================================================================================\n",
      "DEFINING TRANSFORMS & DATASET\n",
      "================================================================================\n",
      "✓ Visit datasets created\n",
      "\n",
      "================================================================================\n",
      "CREATING BALANCED SAMPLER\n",
      "================================================================================\n",
      "\n",
      "Visit-level class weights:\n",
      "  CN weight: 0.0031\n",
      "  AD weight: 0.0196\n",
      "\n",
      "✓ DataLoaders created\n",
      "  Train batches: 47\n",
      "  Val batches:   12\n",
      "  Test batches:  15\n",
      "\n",
      "================================================================================\n",
      "MODEL ARCHITECTURE\n",
      "================================================================================\n",
      "\n",
      "✓ Visit-level attention model initialized\n",
      "  Total parameters:     11,242,818\n",
      "  Trainable parameters: 11,242,818\n",
      "  Feature dimension:    512\n",
      "  Attention hidden:     128\n",
      "\n",
      "================================================================================\n",
      "LOSS & OPTIMIZER\n",
      "================================================================================\n",
      "\n",
      "Class weighting:\n",
      "  Raw CN/AD ratio: 6.27\n",
      "  Clamped pos_weight: 3.000\n",
      "\n",
      "✓ Optimizer: Adam (lr=0.0001, weight_decay=0.0001)\n",
      "✓ Scheduler: ReduceLROnPlateau (patience=4)\n",
      "\n",
      "================================================================================\n",
      "TRAINING\n",
      "================================================================================\n",
      "\n",
      "Training for up to 30 epochs...\n",
      "Target: Beat S10d baseline (AUC ~0.6)\n",
      "--------------------------------------------------------------------------------\n",
      "[Epoch 01/30] time=17.8s lr=1.00e-04\n",
      "  train_loss=0.9005 | val_loss=1.3877\n",
      "  val_acc=0.3297 | val_bal_acc=0.6090 | val_auc=0.8836\n",
      "  val_CN_acc=0.2179 | val_AD_acc=1.0000\n",
      "  ✓ New best val_bal_acc: 0.6090\n",
      "[Epoch 02/30] time=18.2s lr=1.00e-04\n",
      "  train_loss=0.6783 | val_loss=0.6774\n",
      "  val_acc=0.8242 | val_bal_acc=0.8333 | val_auc=0.8807\n",
      "  val_CN_acc=0.8205 | val_AD_acc=0.8462\n",
      "  ✓ New best val_bal_acc: 0.8333\n",
      "[Epoch 03/30] time=18.1s lr=1.00e-04\n",
      "  train_loss=0.4426 | val_loss=0.9770\n",
      "  val_acc=0.9011 | val_bal_acc=0.6859 | val_auc=0.8402\n",
      "  val_CN_acc=0.9872 | val_AD_acc=0.3846\n",
      "[Epoch 04/30] time=18.0s lr=1.00e-04\n",
      "  train_loss=0.6217 | val_loss=1.1543\n",
      "  val_acc=0.8901 | val_bal_acc=0.7436 | val_auc=0.9241\n",
      "  val_CN_acc=0.9487 | val_AD_acc=0.5385\n",
      "[Epoch 05/30] time=18.1s lr=1.00e-04\n",
      "  train_loss=0.5646 | val_loss=1.3235\n",
      "  val_acc=0.7912 | val_bal_acc=0.8462 | val_auc=0.9290\n",
      "  val_CN_acc=0.7692 | val_AD_acc=0.9231\n",
      "  ✓ New best val_bal_acc: 0.8462\n",
      "[Epoch 06/30] time=18.1s lr=1.00e-04\n",
      "  train_loss=0.3170 | val_loss=1.8519\n",
      "  val_acc=0.7582 | val_bal_acc=0.8269 | val_auc=0.9359\n",
      "  val_CN_acc=0.7308 | val_AD_acc=0.9231\n",
      "[Epoch 07/30] time=17.8s lr=1.00e-04\n",
      "  train_loss=0.2168 | val_loss=0.9815\n",
      "  val_acc=0.9121 | val_bal_acc=0.8205 | val_auc=0.9517\n",
      "  val_CN_acc=0.9487 | val_AD_acc=0.6923\n",
      "[Epoch 08/30] time=17.8s lr=1.00e-04\n",
      "  train_loss=0.1255 | val_loss=1.9499\n",
      "  val_acc=0.8571 | val_bal_acc=0.6923 | val_auc=0.9423\n",
      "  val_CN_acc=0.9231 | val_AD_acc=0.4615\n",
      "[Epoch 09/30] time=18.0s lr=1.00e-04\n",
      "  train_loss=0.2011 | val_loss=1.8689\n",
      "  val_acc=0.8462 | val_bal_acc=0.7821 | val_auc=0.9241\n",
      "  val_CN_acc=0.8718 | val_AD_acc=0.6923\n",
      "[Epoch 10/30] time=18.1s lr=1.00e-04\n",
      "  train_loss=0.6040 | val_loss=1.1383\n",
      "  val_acc=0.8791 | val_bal_acc=0.8013 | val_auc=0.9122\n",
      "  val_CN_acc=0.9103 | val_AD_acc=0.6923\n",
      "[Epoch 11/30] time=18.1s lr=5.00e-05\n",
      "  train_loss=0.2687 | val_loss=1.3436\n",
      "  val_acc=0.8462 | val_bal_acc=0.8141 | val_auc=0.9418\n",
      "  val_CN_acc=0.8590 | val_AD_acc=0.7692\n",
      "[Epoch 12/30] time=17.9s lr=5.00e-05\n",
      "  train_loss=0.1741 | val_loss=1.7806\n",
      "  val_acc=0.8571 | val_bal_acc=0.8205 | val_auc=0.9216\n",
      "  val_CN_acc=0.8718 | val_AD_acc=0.7692\n",
      "[Epoch 13/30] time=18.0s lr=5.00e-05\n",
      "  train_loss=0.0193 | val_loss=1.8217\n",
      "  val_acc=0.9121 | val_bal_acc=0.8205 | val_auc=0.9310\n",
      "  val_CN_acc=0.9487 | val_AD_acc=0.6923\n",
      "\n",
      "⚠ Early stopping (no improvement for 8 epochs)\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "✓ Best model saved: /kaggle/working/visit_attention_resnet18_fold0.pth\n",
      "  Best val balanced ACC: 0.8462\n",
      "✓ Training history saved: /kaggle/working/training_history_visit_attention_fold0.csv\n",
      "\n",
      "================================================================================\n",
      "TEST EVALUATION (VISIT-LEVEL)\n",
      "================================================================================\n",
      "\n",
      "Test results:\n",
      "  Loss:         2.0962\n",
      "  Accuracy:     0.7217\n",
      "  Balanced ACC: 0.7185\n",
      "  ROC-AUC:      0.7822\n",
      "  CN accuracy:  0.7228\n",
      "  AD accuracy:  0.7143\n",
      "\n",
      "Comparison with trivial baseline:\n",
      "  Baseline: ACC=0.878, AUC=0.500\n",
      "  S11 Model: ACC=0.722, AUC=0.782\n",
      "\n",
      "✅ GOOD: Model shows strong AD signal (AUC > 0.70)\n",
      "   Ready for threshold optimization & Grad-CAM\n",
      "\n",
      "================================================================================\n",
      "SNIPPET S11 COMPLETE\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "SNIPPET S11: Visit-Level Attention ResNet18 (Fold 0)\n",
    "Architecture:\n",
    "- ResNet18 encoder per slice → 512-dim features\n",
    "- Attention mechanism over slices → weighted aggregation\n",
    "- Single visit-level logit\n",
    "\n",
    "Key improvements over S10:\n",
    "- Native visit-level training (no slice averaging)\n",
    "- Attention learns which slices matter\n",
    "- Better handles variable slice importance\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import time\n",
    "import copy\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, balanced_accuracy_score\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"SNIPPET S11: VISIT-LEVEL ATTENTION RESNET18 (FOLD 0)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURATION\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"CONFIGURATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "SLICE_META_CSV = \"/kaggle/working/mni_slices_v1/slice_level_metadata_v1.csv\"\n",
    "VISIT_SPLIT_CSV = \"classification_visit_metadata_with_splits.csv\"\n",
    "MODEL_OUT_PATH = \"/kaggle/working/visit_attention_resnet18_fold0.pth\"\n",
    "HISTORY_CSV = \"/kaggle/working/training_history_visit_attention_fold0.csv\"\n",
    "\n",
    "FOLD_ID = 0\n",
    "BATCH_SIZE = 8              # Visit-level batches (8 visits × 32 slices)\n",
    "NUM_EPOCHS = 30\n",
    "LR = 1e-4\n",
    "WEIGHT_DECAY = 1e-4\n",
    "GRAD_CLIP = 1.0\n",
    "IMG_SIZE = (128, 128)\n",
    "EARLY_STOP_PATIENCE = 8\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"\\nDevice: {DEVICE}\")\n",
    "\n",
    "if DEVICE.type == \"cuda\":\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if DEVICE.type == \"cuda\":\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "print(f\"\\nHyperparameters:\")\n",
    "print(f\"  Batch size:  {BATCH_SIZE} visits/batch\")\n",
    "print(f\"  Epochs:      {NUM_EPOCHS}\")\n",
    "print(f\"  LR:          {LR}\")\n",
    "print(f\"  Weight decay: {WEIGHT_DECAY}\")\n",
    "print(f\"  Patience:    {EARLY_STOP_PATIENCE}\")\n",
    "\n",
    "# ============================================================================\n",
    "# LOAD & GROUP METADATA (VISIT-LEVEL)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"LOADING & GROUPING METADATA\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "slice_meta = pd.read_csv(SLICE_META_CSV)\n",
    "visit_meta_splits = pd.read_csv(VISIT_SPLIT_CSV)\n",
    "\n",
    "slice_meta = slice_meta.merge(\n",
    "    visit_meta_splits[[\"visit_uid\", \"cv_fold\", \"split\"]],\n",
    "    on=\"visit_uid\",\n",
    "    how=\"left\",\n",
    "    suffixes=(\"_slice\", \"_visit\")\n",
    ")\n",
    "\n",
    "if \"split_visit\" in slice_meta.columns:\n",
    "    slice_meta[\"split\"] = slice_meta[\"split_visit\"]\n",
    "\n",
    "# Verify fixed slices per visit\n",
    "counts_per_visit = slice_meta.groupby(\"visit_uid\").size()\n",
    "NUM_SLICES_PER_VISIT = counts_per_visit.iloc[0]\n",
    "\n",
    "if counts_per_visit.nunique() != 1:\n",
    "    print(f\"⚠️ Warning: Variable slices per visit (range: {counts_per_visit.min()}-{counts_per_visit.max()})\")\n",
    "else:\n",
    "    print(f\"✓ Fixed slices per visit: {NUM_SLICES_PER_VISIT}\")\n",
    "\n",
    "# Build train/val/test slice tables\n",
    "train_df = slice_meta[\n",
    "    (slice_meta[\"split\"] == \"trainval\") &\n",
    "    (slice_meta[\"cv_fold\"] != FOLD_ID)\n",
    "].copy()\n",
    "\n",
    "val_df = slice_meta[\n",
    "    (slice_meta[\"split\"] == \"trainval\") &\n",
    "    (slice_meta[\"cv_fold\"] == FOLD_ID)\n",
    "].copy()\n",
    "\n",
    "test_df = slice_meta[slice_meta[\"split\"] == \"test\"].copy()\n",
    "\n",
    "print(f\"\\nSlice counts:\")\n",
    "print(f\"  Train: {len(train_df)}\")\n",
    "print(f\"  Val:   {len(val_df)}\")\n",
    "print(f\"  Test:  {len(test_df)}\")\n",
    "\n",
    "# Group by visit\n",
    "def make_visit_table(df):\n",
    "    \"\"\"Group slices by visit_uid\"\"\"\n",
    "    grouped = df.groupby(\"visit_uid\")\n",
    "    rows = []\n",
    "    for vid, sub in grouped:\n",
    "        paths = sub.sort_values(\"z_index\")[\"slice_path\"].tolist()  # Sort by z-index\n",
    "        label = float(sub[\"diagnosis_binary\"].iloc[0])\n",
    "        rows.append({\n",
    "            \"visit_uid\": vid,\n",
    "            \"slice_paths\": paths,\n",
    "            \"label\": label,\n",
    "            \"n_slices\": len(paths)\n",
    "        })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "train_visits = make_visit_table(train_df)\n",
    "val_visits = make_visit_table(val_df)\n",
    "test_visits = make_visit_table(test_df)\n",
    "\n",
    "print(f\"\\nVisit counts:\")\n",
    "print(f\"  Train: {len(train_visits)}\")\n",
    "print(f\"  Val:   {len(val_visits)}\")\n",
    "print(f\"  Test:  {len(test_visits)}\")\n",
    "\n",
    "# Subject leakage check\n",
    "train_subj = set(train_df[\"subject_id\"].unique())\n",
    "val_subj = set(val_df[\"subject_id\"].unique())\n",
    "test_subj = set(test_df[\"subject_id\"].unique())\n",
    "\n",
    "if (train_subj & val_subj) or (train_subj & test_subj) or (val_subj & test_subj):\n",
    "    raise ValueError(\"❌ Subject leakage detected!\")\n",
    "else:\n",
    "    print(\"\\n✓ No subject leakage at visit level\")\n",
    "\n",
    "# Class distribution\n",
    "print(f\"\\nClass distribution (visit-level):\")\n",
    "for name, df in [(\"Train\", train_visits), (\"Val\", val_visits), (\"Test\", test_visits)]:\n",
    "    cn = (df[\"label\"] == 0).sum()\n",
    "    ad = (df[\"label\"] == 1).sum()\n",
    "    ratio = cn / ad if ad > 0 else float('inf')\n",
    "    print(f\"  {name:5s}: CN={cn:3d}, AD={ad:3d} (ratio {ratio:.2f}:1)\")\n",
    "\n",
    "# ============================================================================\n",
    "# TRANSFORMS & VISIT DATASET\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"DEFINING TRANSFORMS & DATASET\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "imagenet_normalize = transforms.Normalize(\n",
    "    mean=[0.485, 0.456, 0.406],\n",
    "    std=[0.229, 0.224, 0.225]\n",
    ")\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize(IMG_SIZE),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=10),\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    imagenet_normalize,\n",
    "])\n",
    "\n",
    "eval_transform = transforms.Compose([\n",
    "    transforms.Resize(IMG_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    imagenet_normalize,\n",
    "])\n",
    "\n",
    "class VisitDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset that returns entire visit (all slices)\n",
    "    Output: [num_slices, 3, H, W], label, visit_uid\n",
    "    \"\"\"\n",
    "    def __init__(self, visit_table, transform=None):\n",
    "        self.df = visit_table.reset_index(drop=True)\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        slice_paths = row[\"slice_paths\"]\n",
    "        label = float(row[\"label\"])\n",
    "        visit_uid = row[\"visit_uid\"]\n",
    "        \n",
    "        imgs = []\n",
    "        for p in slice_paths:\n",
    "            arr = np.load(p).astype(np.float32)\n",
    "            img_np = (arr * 255.0).clip(0, 255).astype(np.uint8)\n",
    "            img = Image.fromarray(img_np).convert(\"RGB\")\n",
    "            \n",
    "            if self.transform is not None:\n",
    "                img = self.transform(img)\n",
    "            \n",
    "            imgs.append(img)\n",
    "        \n",
    "        # Stack to [num_slices, C, H, W]\n",
    "        imgs = torch.stack(imgs, dim=0)\n",
    "        label = torch.tensor(label, dtype=torch.float32)\n",
    "        \n",
    "        return imgs, label, visit_uid\n",
    "\n",
    "train_dataset = VisitDataset(train_visits, transform=train_transform)\n",
    "val_dataset = VisitDataset(val_visits, transform=eval_transform)\n",
    "test_dataset = VisitDataset(test_visits, transform=eval_transform)\n",
    "\n",
    "print(\"✓ Visit datasets created\")\n",
    "\n",
    "# ============================================================================\n",
    "# BALANCED SAMPLER (VISIT-LEVEL)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"CREATING BALANCED SAMPLER\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "train_labels = train_visits[\"label\"].values.astype(int)\n",
    "visit_class_counts = np.bincount(train_labels)\n",
    "visit_class_weights = 1.0 / visit_class_counts\n",
    "sample_weights = visit_class_weights[train_labels]\n",
    "\n",
    "print(f\"\\nVisit-level class weights:\")\n",
    "print(f\"  CN weight: {visit_class_weights[0]:.4f}\")\n",
    "print(f\"  AD weight: {visit_class_weights[1]:.4f}\")\n",
    "\n",
    "sampler = WeightedRandomSampler(\n",
    "    weights=sample_weights,\n",
    "    num_samples=len(sample_weights),\n",
    "    replacement=True,\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    sampler=sampler,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    pin_memory=(DEVICE.type == \"cuda\"),\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    pin_memory=(DEVICE.type == \"cuda\"),\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    pin_memory=(DEVICE.type == \"cuda\"),\n",
    ")\n",
    "\n",
    "print(f\"\\n✓ DataLoaders created\")\n",
    "print(f\"  Train batches: {len(train_loader)}\")\n",
    "print(f\"  Val batches:   {len(val_loader)}\")\n",
    "print(f\"  Test batches:  {len(test_loader)}\")\n",
    "\n",
    "# ============================================================================\n",
    "# MODEL: RESNET18 ENCODER + ATTENTION\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"MODEL ARCHITECTURE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "def create_resnet_encoder():\n",
    "    \"\"\"\n",
    "    Create ResNet18 feature extractor\n",
    "    Returns encoder and feature dimension\n",
    "    \"\"\"\n",
    "    try:\n",
    "        weights = models.ResNet18_Weights.IMAGENET1K_V1\n",
    "        base = models.resnet18(weights=weights)\n",
    "    except AttributeError:\n",
    "        base = models.resnet18(pretrained=True)\n",
    "    \n",
    "    # Remove final fc layer, keep up to avgpool\n",
    "    modules = list(base.children())[:-1]  # Output: [N, 512, 1, 1]\n",
    "    encoder = nn.Sequential(*modules)\n",
    "    feat_dim = 512\n",
    "    \n",
    "    return encoder, feat_dim\n",
    "\n",
    "\n",
    "class VisitAttentionModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Visit-level attention model\n",
    "    \n",
    "    Architecture:\n",
    "    1. ResNet18 encoder per slice → [B*S, 512]\n",
    "    2. Attention MLP → [B, S, 1] attention scores\n",
    "    3. Weighted sum → [B, 512] visit features\n",
    "    4. Classifier → [B] logit\n",
    "    \"\"\"\n",
    "    def __init__(self, feat_dim=512, attention_hidden=128):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Shared encoder for all slices\n",
    "        self.encoder, feat_dim = create_resnet_encoder()\n",
    "        \n",
    "        # Attention mechanism\n",
    "        self.attn_mlp = nn.Sequential(\n",
    "            nn.Linear(feat_dim, attention_hidden),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(attention_hidden, 1)\n",
    "        )\n",
    "        \n",
    "        # Visit-level classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(feat_dim, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: [B, S, C, H, W] batch of visits\n",
    "        \n",
    "        Returns:\n",
    "            logits: [B] visit-level logits\n",
    "            attn_weights: [B, S] attention weights per slice\n",
    "        \"\"\"\n",
    "        B, S, C, H, W = x.shape\n",
    "        \n",
    "        # Flatten batch and slices for encoder\n",
    "        x = x.view(B * S, C, H, W)\n",
    "        \n",
    "        # Extract features per slice\n",
    "        feats = self.encoder(x)  # [B*S, 512, 1, 1]\n",
    "        feats = feats.view(B, S, -1)  # [B, S, 512]\n",
    "        \n",
    "        # Compute attention scores\n",
    "        attn_scores = self.attn_mlp(feats)  # [B, S, 1]\n",
    "        attn_weights = torch.softmax(attn_scores, dim=1)  # Softmax over slices\n",
    "        \n",
    "        # Weighted sum over slices\n",
    "        visit_feat = (attn_weights * feats).sum(dim=1)  # [B, 512]\n",
    "        \n",
    "        # Classification\n",
    "        logits = self.classifier(visit_feat).squeeze(1)  # [B]\n",
    "        \n",
    "        return logits, attn_weights.squeeze(-1)  # [B], [B, S]\n",
    "\n",
    "model = VisitAttentionModel().to(DEVICE)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"\\n✓ Visit-level attention model initialized\")\n",
    "print(f\"  Total parameters:     {total_params:,}\")\n",
    "print(f\"  Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"  Feature dimension:    512\")\n",
    "print(f\"  Attention hidden:     128\")\n",
    "\n",
    "# ============================================================================\n",
    "# LOSS & OPTIMIZER\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"LOSS & OPTIMIZER\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Visit-level class weighting\n",
    "n_cn = float(visit_class_counts[0])\n",
    "n_ad = float(visit_class_counts[1])\n",
    "raw_ratio = n_cn / n_ad\n",
    "clamped_ratio = min(raw_ratio, 3.0)\n",
    "\n",
    "pos_weight = torch.tensor([clamped_ratio], device=DEVICE)\n",
    "\n",
    "print(f\"\\nClass weighting:\")\n",
    "print(f\"  Raw CN/AD ratio: {raw_ratio:.2f}\")\n",
    "print(f\"  Clamped pos_weight: {pos_weight.item():.3f}\")\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='max', factor=0.5, patience=4, verbose=True\n",
    ")\n",
    "\n",
    "print(f\"\\n✓ Optimizer: Adam (lr={LR}, weight_decay={WEIGHT_DECAY})\")\n",
    "print(f\"✓ Scheduler: ReduceLROnPlateau (patience=4)\")\n",
    "\n",
    "# ============================================================================\n",
    "# TRAINING & EVALUATION FUNCTIONS\n",
    "# ============================================================================\n",
    "\n",
    "def train_one_epoch(model, loader, optimizer, criterion, device, grad_clip=None):\n",
    "    \"\"\"Train for one epoch\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    n_batches = 0\n",
    "    \n",
    "    for visit_imgs, labels, _ in loader:\n",
    "        visit_imgs = visit_imgs.to(device, non_blocking=True)\n",
    "        labels = labels.to(device, non_blocking=True)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        logits, _ = model(visit_imgs)\n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        if grad_clip is not None:\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        n_batches += 1\n",
    "    \n",
    "    return total_loss / max(n_batches, 1)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_model(model, loader, criterion, device):\n",
    "    \"\"\"Evaluate model on visit-level metrics\"\"\"\n",
    "    model.eval()\n",
    "    all_logits = []\n",
    "    all_labels = []\n",
    "    total_loss = 0.0\n",
    "    n_batches = 0\n",
    "    \n",
    "    for visit_imgs, labels, _ in loader:\n",
    "        visit_imgs = visit_imgs.to(device, non_blocking=True)\n",
    "        labels = labels.to(device, non_blocking=True)\n",
    "        \n",
    "        logits, _ = model(visit_imgs)\n",
    "        loss = criterion(logits, labels)\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        n_batches += 1\n",
    "        \n",
    "        all_logits.append(logits.cpu())\n",
    "        all_labels.append(labels.cpu())\n",
    "    \n",
    "    if n_batches == 0:\n",
    "        return math.nan, math.nan, 0.5, 0.5, 0.0, 0.0\n",
    "    \n",
    "    logits = torch.cat(all_logits).numpy()\n",
    "    labels = torch.cat(all_labels).numpy()\n",
    "    probs = 1.0 / (1.0 + np.exp(-logits))\n",
    "    preds = (probs >= 0.5).astype(int)\n",
    "    \n",
    "    avg_loss = total_loss / n_batches\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    bal_acc = balanced_accuracy_score(labels, preds)\n",
    "    \n",
    "    try:\n",
    "        auc = roc_auc_score(labels, probs)\n",
    "    except:\n",
    "        auc = 0.5\n",
    "    \n",
    "    # Per-class accuracy\n",
    "    cn_mask = labels == 0\n",
    "    ad_mask = labels == 1\n",
    "    cn_acc = (preds[cn_mask] == labels[cn_mask]).mean() if cn_mask.sum() > 0 else 0.0\n",
    "    ad_acc = (preds[ad_mask] == labels[ad_mask]).mean() if ad_mask.sum() > 0 else 0.0\n",
    "    \n",
    "    return avg_loss, acc, bal_acc, auc, cn_acc, ad_acc\n",
    "\n",
    "# ============================================================================\n",
    "# TRAINING LOOP\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"TRAINING\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "history = []\n",
    "best_val_bal_acc = 0.0\n",
    "best_state = None\n",
    "epochs_no_improve = 0\n",
    "\n",
    "print(f\"\\nTraining for up to {NUM_EPOCHS} epochs...\")\n",
    "print(f\"Target: Beat S10d baseline (AUC ~0.6)\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    t0 = time.time()\n",
    "    \n",
    "    train_loss = train_one_epoch(model, train_loader, optimizer, criterion, DEVICE, GRAD_CLIP)\n",
    "    val_loss, val_acc, val_bal_acc, val_auc, val_cn_acc, val_ad_acc = eval_model(\n",
    "        model, val_loader, criterion, DEVICE\n",
    "    )\n",
    "    \n",
    "    dt = time.time() - t0\n",
    "    lr = optimizer.param_groups[0][\"lr\"]\n",
    "    \n",
    "    print(f\"[Epoch {epoch:02d}/{NUM_EPOCHS}] time={dt:.1f}s lr={lr:.2e}\")\n",
    "    print(f\"  train_loss={train_loss:.4f} | val_loss={val_loss:.4f}\")\n",
    "    print(f\"  val_acc={val_acc:.4f} | val_bal_acc={val_bal_acc:.4f} | val_auc={val_auc:.4f}\")\n",
    "    print(f\"  val_CN_acc={val_cn_acc:.4f} | val_AD_acc={val_ad_acc:.4f}\")\n",
    "    \n",
    "    history.append({\n",
    "        \"epoch\": epoch,\n",
    "        \"train_loss\": train_loss,\n",
    "        \"val_loss\": val_loss,\n",
    "        \"val_acc\": val_acc,\n",
    "        \"val_bal_acc\": val_bal_acc,\n",
    "        \"val_auc\": val_auc,\n",
    "        \"val_CN_acc\": val_cn_acc,\n",
    "        \"val_AD_acc\": val_ad_acc,\n",
    "        \"lr\": lr\n",
    "    })\n",
    "    \n",
    "    scheduler.step(val_bal_acc)\n",
    "    \n",
    "    if not math.isnan(val_bal_acc) and val_bal_acc > best_val_bal_acc:\n",
    "        best_val_bal_acc = val_bal_acc\n",
    "        best_state = copy.deepcopy(model.state_dict())\n",
    "        epochs_no_improve = 0\n",
    "        print(f\"  ✓ New best val_bal_acc: {best_val_bal_acc:.4f}\")\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve >= EARLY_STOP_PATIENCE:\n",
    "            print(f\"\\n⚠ Early stopping (no improvement for {EARLY_STOP_PATIENCE} epochs)\")\n",
    "            break\n",
    "\n",
    "print(\"-\" * 80)\n",
    "\n",
    "if best_state is not None:\n",
    "    model.load_state_dict(best_state)\n",
    "    torch.save(best_state, MODEL_OUT_PATH)\n",
    "    print(f\"\\n✓ Best model saved: {MODEL_OUT_PATH}\")\n",
    "    print(f\"  Best val balanced ACC: {best_val_bal_acc:.4f}\")\n",
    "\n",
    "pd.DataFrame(history).to_csv(HISTORY_CSV, index=False)\n",
    "print(f\"✓ Training history saved: {HISTORY_CSV}\")\n",
    "\n",
    "# ============================================================================\n",
    "# TEST EVALUATION\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"TEST EVALUATION (VISIT-LEVEL)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "test_loss, test_acc, test_bal_acc, test_auc, test_cn_acc, test_ad_acc = eval_model(\n",
    "    model, test_loader, criterion, DEVICE\n",
    ")\n",
    "\n",
    "print(f\"\\nTest results:\")\n",
    "print(f\"  Loss:         {test_loss:.4f}\")\n",
    "print(f\"  Accuracy:     {test_acc:.4f}\")\n",
    "print(f\"  Balanced ACC: {test_bal_acc:.4f}\")\n",
    "print(f\"  ROC-AUC:      {test_auc:.4f}\")\n",
    "print(f\"  CN accuracy:  {test_cn_acc:.4f}\")\n",
    "print(f\"  AD accuracy:  {test_ad_acc:.4f}\")\n",
    "\n",
    "# Comparison with baseline\n",
    "baseline_acc = 0.878\n",
    "baseline_auc = 0.5\n",
    "\n",
    "print(f\"\\nComparison with trivial baseline:\")\n",
    "print(f\"  Baseline: ACC={baseline_acc:.3f}, AUC={baseline_auc:.3f}\")\n",
    "print(f\"  S11 Model: ACC={test_acc:.3f}, AUC={test_auc:.3f}\")\n",
    "\n",
    "if test_auc > 0.70:\n",
    "    print(f\"\\n✅ GOOD: Model shows strong AD signal (AUC > 0.70)\")\n",
    "    print(f\"   Ready for threshold optimization & Grad-CAM\")\n",
    "elif test_auc > 0.60:\n",
    "    print(f\"\\n⚠️ MODERATE: Model shows some AD signal (AUC 0.60-0.70)\")\n",
    "    print(f\"   Consider: ensemble folds or train on all trainval\")\n",
    "else:\n",
    "    print(f\"\\n❌ WEAK: Model needs improvement (AUC ≤ 0.60)\")\n",
    "    print(f\"   Need: more data, better architecture, or ensemble\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SNIPPET S11 COMPLETE\")\n",
    "print(\"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ecafbaca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T19:17:09.535400Z",
     "iopub.status.busy": "2025-11-17T19:17:09.535128Z",
     "iopub.status.idle": "2025-11-17T19:25:30.433984Z",
     "shell.execute_reply": "2025-11-17T19:25:30.432839Z"
    },
    "papermill": {
     "duration": 500.925533,
     "end_time": "2025-11-17T19:25:30.435496",
     "exception": false,
     "start_time": "2025-11-17T19:17:09.509963",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SNIPPET S12: VISIT-LEVEL ATTENTION + EFFICIENTNET-B0 (FOLD 0)\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "CONFIGURATION\n",
      "================================================================================\n",
      "\n",
      "Device: cuda\n",
      "GPU: Tesla T4\n",
      "Memory: 15.8 GB\n",
      "\n",
      "Hyperparameters:\n",
      "  Backbone:    EfficientNet-B0 (1280-dim features)\n",
      "  Batch size:  8 visits\n",
      "  Epochs:      30\n",
      "  LR:          0.0001\n",
      "  Patience:    8\n",
      "\n",
      "================================================================================\n",
      "LOADING & GROUPING METADATA\n",
      "================================================================================\n",
      "\n",
      "Slice counts:\n",
      "  Train: 11872\n",
      "  Val:   2912\n",
      "  Test:  3680\n",
      "✓ Fixed slices per visit: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-7f5810bc.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b0_rwightman-7f5810bc.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Visit counts:\n",
      "  Train: 371\n",
      "  Val:   91\n",
      "  Test:  115\n",
      "✓ No subject leakage\n",
      "\n",
      "Class distribution (visit-level):\n",
      "  Train: CN=320, AD= 51 (ratio 6.27:1)\n",
      "  Val  : CN= 78, AD= 13 (ratio 6.00:1)\n",
      "  Test : CN=101, AD= 14 (ratio 7.21:1)\n",
      "\n",
      "================================================================================\n",
      "DEFINING TRANSFORMS & DATASET\n",
      "================================================================================\n",
      "✓ Visit datasets created\n",
      "\n",
      "================================================================================\n",
      "CREATING BALANCED SAMPLER\n",
      "================================================================================\n",
      "\n",
      "Visit-level class weights:\n",
      "  CN weight: 0.0031\n",
      "  AD weight: 0.0196\n",
      "\n",
      "✓ DataLoaders created\n",
      "  Train batches: 47\n",
      "  Val batches:   12\n",
      "  Test batches:  15\n",
      "\n",
      "================================================================================\n",
      "MODEL ARCHITECTURE\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20.5M/20.5M [00:00<00:00, 152MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ EfficientNet-B0 attention model initialized\n",
      "  Total parameters:     4,172,925\n",
      "  Trainable parameters: 4,172,925\n",
      "  Feature dimension:    1280\n",
      "  Attention hidden:     128\n",
      "\n",
      "================================================================================\n",
      "LOSS & OPTIMIZER\n",
      "================================================================================\n",
      "\n",
      "Class weighting:\n",
      "  Raw CN/AD ratio: 6.27\n",
      "  Clamped pos_weight: 3.000\n",
      "\n",
      "✓ Optimizer: Adam (lr=0.0001, weight_decay=0.0001)\n",
      "✓ Scheduler: ReduceLROnPlateau (patience=4)\n",
      "\n",
      "================================================================================\n",
      "TRAINING\n",
      "================================================================================\n",
      "\n",
      "Training for up to 30 epochs...\n",
      "Target: Val AUC ≥ 0.80, Balanced ACC ≥ 0.72, AD Recall ≥ 0.65\n",
      "--------------------------------------------------------------------------------\n",
      "[Epoch 01/30] time=24.9s lr=1.00e-04\n",
      "  train_loss=1.2303 | val_loss=0.9214\n",
      "  val_acc=0.3736 | val_bal_acc=0.6026 | val_auc=0.6558\n",
      "  val_CN_acc=0.2821 | val_AD_acc=0.9231\n",
      "  ✓ New best val_bal_acc: 0.6026\n",
      "[Epoch 02/30] time=25.0s lr=1.00e-04\n",
      "  train_loss=0.9361 | val_loss=1.1205\n",
      "  val_acc=0.4286 | val_bal_acc=0.6346 | val_auc=0.7239\n",
      "  val_CN_acc=0.3462 | val_AD_acc=0.9231\n",
      "  ✓ New best val_bal_acc: 0.6346\n",
      "[Epoch 03/30] time=24.8s lr=1.00e-04\n",
      "  train_loss=0.7196 | val_loss=0.9368\n",
      "  val_acc=0.6923 | val_bal_acc=0.6923 | val_auc=0.7742\n",
      "  val_CN_acc=0.6923 | val_AD_acc=0.6923\n",
      "  ✓ New best val_bal_acc: 0.6923\n",
      "[Epoch 04/30] time=24.9s lr=1.00e-04\n",
      "  train_loss=0.4939 | val_loss=1.3314\n",
      "  val_acc=0.7033 | val_bal_acc=0.6987 | val_auc=0.7653\n",
      "  val_CN_acc=0.7051 | val_AD_acc=0.6923\n",
      "  ✓ New best val_bal_acc: 0.6987\n",
      "[Epoch 05/30] time=24.7s lr=1.00e-04\n",
      "  train_loss=0.6069 | val_loss=0.8289\n",
      "  val_acc=0.7802 | val_bal_acc=0.7115 | val_auc=0.8284\n",
      "  val_CN_acc=0.8077 | val_AD_acc=0.6154\n",
      "  ✓ New best val_bal_acc: 0.7115\n",
      "[Epoch 06/30] time=25.0s lr=1.00e-04\n",
      "  train_loss=0.4651 | val_loss=1.3959\n",
      "  val_acc=0.7143 | val_bal_acc=0.7372 | val_auc=0.8097\n",
      "  val_CN_acc=0.7051 | val_AD_acc=0.7692\n",
      "  ✓ New best val_bal_acc: 0.7372\n",
      "[Epoch 07/30] time=24.9s lr=1.00e-04\n",
      "  train_loss=0.6372 | val_loss=1.1285\n",
      "  val_acc=0.7692 | val_bal_acc=0.7051 | val_auc=0.8511\n",
      "  val_CN_acc=0.7949 | val_AD_acc=0.6154\n",
      "[Epoch 08/30] time=24.6s lr=1.00e-04\n",
      "  train_loss=0.4496 | val_loss=1.3744\n",
      "  val_acc=0.7582 | val_bal_acc=0.7308 | val_auc=0.8294\n",
      "  val_CN_acc=0.7692 | val_AD_acc=0.6923\n",
      "[Epoch 09/30] time=24.6s lr=1.00e-04\n",
      "  train_loss=0.5117 | val_loss=1.4721\n",
      "  val_acc=0.9011 | val_bal_acc=0.7500 | val_auc=0.8817\n",
      "  val_CN_acc=0.9615 | val_AD_acc=0.5385\n",
      "  ✓ New best val_bal_acc: 0.7500\n",
      "[Epoch 10/30] time=24.8s lr=1.00e-04\n",
      "  train_loss=0.3404 | val_loss=0.8342\n",
      "  val_acc=0.8901 | val_bal_acc=0.7756 | val_auc=0.9270\n",
      "  val_CN_acc=0.9359 | val_AD_acc=0.6154\n",
      "  ✓ New best val_bal_acc: 0.7756\n",
      "[Epoch 11/30] time=24.9s lr=1.00e-04\n",
      "  train_loss=0.3451 | val_loss=1.2218\n",
      "  val_acc=0.7802 | val_bal_acc=0.8397 | val_auc=0.8876\n",
      "  val_CN_acc=0.7564 | val_AD_acc=0.9231\n",
      "  ✓ New best val_bal_acc: 0.8397\n",
      "[Epoch 12/30] time=24.9s lr=1.00e-04\n",
      "  train_loss=0.4272 | val_loss=0.9186\n",
      "  val_acc=0.8571 | val_bal_acc=0.8846 | val_auc=0.9043\n",
      "  val_CN_acc=0.8462 | val_AD_acc=0.9231\n",
      "  ✓ New best val_bal_acc: 0.8846\n",
      "[Epoch 13/30] time=24.9s lr=1.00e-04\n",
      "  train_loss=0.3221 | val_loss=1.1417\n",
      "  val_acc=0.8791 | val_bal_acc=0.8013 | val_auc=0.8994\n",
      "  val_CN_acc=0.9103 | val_AD_acc=0.6923\n",
      "[Epoch 14/30] time=24.9s lr=1.00e-04\n",
      "  train_loss=0.2892 | val_loss=1.1856\n",
      "  val_acc=0.8681 | val_bal_acc=0.7628 | val_auc=0.9073\n",
      "  val_CN_acc=0.9103 | val_AD_acc=0.6154\n",
      "[Epoch 15/30] time=25.0s lr=1.00e-04\n",
      "  train_loss=0.0644 | val_loss=1.6755\n",
      "  val_acc=0.8681 | val_bal_acc=0.6667 | val_auc=0.8955\n",
      "  val_CN_acc=0.9487 | val_AD_acc=0.3846\n",
      "[Epoch 16/30] time=24.8s lr=1.00e-04\n",
      "  train_loss=0.3029 | val_loss=1.5034\n",
      "  val_acc=0.8791 | val_bal_acc=0.7372 | val_auc=0.9043\n",
      "  val_CN_acc=0.9359 | val_AD_acc=0.5385\n",
      "[Epoch 17/30] time=24.9s lr=1.00e-04\n",
      "  train_loss=0.2692 | val_loss=1.4929\n",
      "  val_acc=0.9011 | val_bal_acc=0.8141 | val_auc=0.8817\n",
      "  val_CN_acc=0.9359 | val_AD_acc=0.6923\n",
      "[Epoch 18/30] time=24.9s lr=5.00e-05\n",
      "  train_loss=0.1767 | val_loss=1.2645\n",
      "  val_acc=0.8901 | val_bal_acc=0.8397 | val_auc=0.8856\n",
      "  val_CN_acc=0.9103 | val_AD_acc=0.7692\n",
      "[Epoch 19/30] time=25.0s lr=5.00e-05\n",
      "  train_loss=0.1196 | val_loss=2.0365\n",
      "  val_acc=0.8681 | val_bal_acc=0.6346 | val_auc=0.9083\n",
      "  val_CN_acc=0.9615 | val_AD_acc=0.3077\n",
      "[Epoch 20/30] time=24.9s lr=5.00e-05\n",
      "  train_loss=0.0453 | val_loss=1.7351\n",
      "  val_acc=0.8791 | val_bal_acc=0.7372 | val_auc=0.9152\n",
      "  val_CN_acc=0.9359 | val_AD_acc=0.5385\n",
      "\n",
      "⚠ Early stopping (no improvement for 8 epochs)\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "✓ Best model saved: /kaggle/working/visit_attention_effnetb0_fold0.pth\n",
      "  Best val balanced ACC: 0.8846\n",
      "✓ Training history saved: /kaggle/working/training_history_effnetb0_fold0.csv\n",
      "\n",
      "================================================================================\n",
      "TEST EVALUATION (VISIT-LEVEL)\n",
      "================================================================================\n",
      "\n",
      "Test results:\n",
      "  Loss:         1.9341\n",
      "  Accuracy:     0.7478\n",
      "  Balanced ACC: 0.6411\n",
      "  ROC-AUC:      0.6605\n",
      "  CN accuracy:  0.7822\n",
      "  AD accuracy:  0.5000\n",
      "\n",
      "================================================================================\n",
      "PERFORMANCE COMPARISON\n",
      "================================================================================\n",
      "\n",
      "Baseline (always CN):\n",
      "  ACC: 0.878, AUC: 0.500\n",
      "\n",
      "S11 (ResNet18 + Attention):\n",
      "  AUC: 0.783, Balanced ACC: 0.718\n",
      "\n",
      "S12 (EfficientNet-B0 + Attention):\n",
      "  AUC: 0.661, Balanced ACC: 0.641\n",
      "\n",
      "Improvement over S11:\n",
      "  AUC:          -0.1225\n",
      "  Balanced ACC: -0.0769\n",
      "\n",
      "⚠️ REGRESSION: S12 worse than S11\n",
      "   Consider: hyperparameter tuning or revert to S11\n",
      "\n",
      "================================================================================\n",
      "SNIPPET S12 COMPLETE\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "SNIPPET S12: Visit-Level Attention with EfficientNet-B0 (Fold 0)\n",
    "Author: Research Team\n",
    "Date: 2025-11-17\n",
    "\n",
    "Architecture upgrade from S11:\n",
    "- EfficientNet-B0 encoder (1280-dim features vs ResNet18's 512)\n",
    "- Same attention mechanism over slices\n",
    "- Better feature representation for AD detection\n",
    "\n",
    "Target performance:\n",
    "- Val AUC ≥ 0.80\n",
    "- Val Balanced ACC ≥ 0.72\n",
    "- AD Recall ≥ 0.65\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import time\n",
    "import copy\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, accuracy_score, balanced_accuracy_score,\n",
    "    confusion_matrix\n",
    ")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"SNIPPET S12: VISIT-LEVEL ATTENTION + EFFICIENTNET-B0 (FOLD 0)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURATION\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"CONFIGURATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "SLICE_META_CSV = \"/kaggle/working/mni_slices_v1/slice_level_metadata_v1.csv\"\n",
    "VISIT_SPLIT_CSV = \"classification_visit_metadata_with_splits.csv\"\n",
    "MODEL_OUT_PATH = \"/kaggle/working/visit_attention_effnetb0_fold0.pth\"\n",
    "HISTORY_CSV = \"/kaggle/working/training_history_effnetb0_fold0.csv\"\n",
    "\n",
    "FOLD_ID = 0\n",
    "BATCH_SIZE = 8              # Visit-level batches\n",
    "NUM_EPOCHS = 30\n",
    "LR = 1e-4\n",
    "WEIGHT_DECAY = 1e-4\n",
    "GRAD_CLIP = 1.0\n",
    "IMG_SIZE = (128, 128)\n",
    "EARLY_STOP_PATIENCE = 8\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"\\nDevice: {DEVICE}\")\n",
    "\n",
    "if DEVICE.type == \"cuda\":\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if DEVICE.type == \"cuda\":\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "print(f\"\\nHyperparameters:\")\n",
    "print(f\"  Backbone:    EfficientNet-B0 (1280-dim features)\")\n",
    "print(f\"  Batch size:  {BATCH_SIZE} visits\")\n",
    "print(f\"  Epochs:      {NUM_EPOCHS}\")\n",
    "print(f\"  LR:          {LR}\")\n",
    "print(f\"  Patience:    {EARLY_STOP_PATIENCE}\")\n",
    "\n",
    "# ============================================================================\n",
    "# LOAD & GROUP METADATA\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"LOADING & GROUPING METADATA\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "slice_meta = pd.read_csv(SLICE_META_CSV)\n",
    "visit_meta_splits = pd.read_csv(VISIT_SPLIT_CSV)\n",
    "\n",
    "slice_meta = slice_meta.merge(\n",
    "    visit_meta_splits[[\"visit_uid\", \"cv_fold\", \"split\"]],\n",
    "    on=\"visit_uid\",\n",
    "    how=\"left\",\n",
    "    suffixes=(\"_slice\", \"_visit\")\n",
    ")\n",
    "\n",
    "if \"split_visit\" in slice_meta.columns:\n",
    "    slice_meta[\"split\"] = slice_meta[\"split_visit\"]\n",
    "\n",
    "# Build train/val/test\n",
    "train_df = slice_meta[\n",
    "    (slice_meta[\"split\"] == \"trainval\") &\n",
    "    (slice_meta[\"cv_fold\"] != FOLD_ID)\n",
    "].copy()\n",
    "\n",
    "val_df = slice_meta[\n",
    "    (slice_meta[\"split\"] == \"trainval\") &\n",
    "    (slice_meta[\"cv_fold\"] == FOLD_ID)\n",
    "].copy()\n",
    "\n",
    "test_df = slice_meta[slice_meta[\"split\"] == \"test\"].copy()\n",
    "\n",
    "print(f\"\\nSlice counts:\")\n",
    "print(f\"  Train: {len(train_df)}\")\n",
    "print(f\"  Val:   {len(val_df)}\")\n",
    "print(f\"  Test:  {len(test_df)}\")\n",
    "\n",
    "# Verify fixed slices per visit\n",
    "counts_per_visit = slice_meta.groupby(\"visit_uid\").size()\n",
    "NUM_SLICES_PER_VISIT = counts_per_visit.iloc[0]\n",
    "\n",
    "if counts_per_visit.nunique() != 1:\n",
    "    print(f\"⚠️ Warning: Variable slices per visit\")\n",
    "else:\n",
    "    print(f\"✓ Fixed slices per visit: {NUM_SLICES_PER_VISIT}\")\n",
    "\n",
    "# Group by visit\n",
    "def make_visit_table(df):\n",
    "    \"\"\"Group slices by visit_uid\"\"\"\n",
    "    grouped = df.groupby(\"visit_uid\")\n",
    "    rows = []\n",
    "    for vid, sub in grouped:\n",
    "        paths = sub.sort_values(\"z_index\")[\"slice_path\"].tolist()\n",
    "        label = float(sub[\"diagnosis_binary\"].iloc[0])\n",
    "        rows.append({\n",
    "            \"visit_uid\": vid,\n",
    "            \"slice_paths\": paths,\n",
    "            \"label\": label,\n",
    "            \"n_slices\": len(paths)\n",
    "        })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "train_visits = make_visit_table(train_df)\n",
    "val_visits = make_visit_table(val_df)\n",
    "test_visits = make_visit_table(test_df)\n",
    "\n",
    "print(f\"\\nVisit counts:\")\n",
    "print(f\"  Train: {len(train_visits)}\")\n",
    "print(f\"  Val:   {len(val_visits)}\")\n",
    "print(f\"  Test:  {len(test_visits)}\")\n",
    "\n",
    "# Subject leakage check\n",
    "train_subj = set(train_df[\"subject_id\"].unique())\n",
    "val_subj = set(val_df[\"subject_id\"].unique())\n",
    "test_subj = set(test_df[\"subject_id\"].unique())\n",
    "\n",
    "if (train_subj & val_subj) or (train_subj & test_subj) or (val_subj & test_subj):\n",
    "    raise ValueError(\"❌ Subject leakage detected!\")\n",
    "else:\n",
    "    print(\"✓ No subject leakage\")\n",
    "\n",
    "# Class distribution\n",
    "print(f\"\\nClass distribution (visit-level):\")\n",
    "for name, df in [(\"Train\", train_visits), (\"Val\", val_visits), (\"Test\", test_visits)]:\n",
    "    cn = (df[\"label\"] == 0).sum()\n",
    "    ad = (df[\"label\"] == 1).sum()\n",
    "    ratio = cn / ad if ad > 0 else float('inf')\n",
    "    print(f\"  {name:5s}: CN={cn:3d}, AD={ad:3d} (ratio {ratio:.2f}:1)\")\n",
    "\n",
    "# ============================================================================\n",
    "# TRANSFORMS & DATASET\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"DEFINING TRANSFORMS & DATASET\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "imagenet_normalize = transforms.Normalize(\n",
    "    mean=[0.485, 0.456, 0.406],\n",
    "    std=[0.229, 0.224, 0.225]\n",
    ")\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize(IMG_SIZE),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=10),\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    imagenet_normalize,\n",
    "])\n",
    "\n",
    "eval_transform = transforms.Compose([\n",
    "    transforms.Resize(IMG_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    imagenet_normalize,\n",
    "])\n",
    "\n",
    "class VisitDataset(Dataset):\n",
    "    \"\"\"Returns entire visit (all slices): [num_slices, 3, H, W]\"\"\"\n",
    "    def __init__(self, visit_table, transform=None):\n",
    "        self.df = visit_table.reset_index(drop=True)\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        slice_paths = row[\"slice_paths\"]\n",
    "        label = float(row[\"label\"])\n",
    "        visit_uid = row[\"visit_uid\"]\n",
    "        \n",
    "        imgs = []\n",
    "        for p in slice_paths:\n",
    "            arr = np.load(p).astype(np.float32)\n",
    "            img_np = (arr * 255.0).clip(0, 255).astype(np.uint8)\n",
    "            img = Image.fromarray(img_np).convert(\"RGB\")\n",
    "            \n",
    "            if self.transform is not None:\n",
    "                img = self.transform(img)\n",
    "            \n",
    "            imgs.append(img)\n",
    "        \n",
    "        imgs = torch.stack(imgs, dim=0)  # [S, 3, H, W]\n",
    "        label = torch.tensor(label, dtype=torch.float32)\n",
    "        \n",
    "        return imgs, label, visit_uid\n",
    "\n",
    "train_dataset = VisitDataset(train_visits, transform=train_transform)\n",
    "val_dataset = VisitDataset(val_visits, transform=eval_transform)\n",
    "test_dataset = VisitDataset(test_visits, transform=eval_transform)\n",
    "\n",
    "print(\"✓ Visit datasets created\")\n",
    "\n",
    "# ============================================================================\n",
    "# BALANCED SAMPLER\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"CREATING BALANCED SAMPLER\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "train_labels = train_visits[\"label\"].values.astype(int)\n",
    "visit_class_counts = np.bincount(train_labels)\n",
    "visit_class_weights = 1.0 / visit_class_counts\n",
    "sample_weights = visit_class_weights[train_labels]\n",
    "\n",
    "print(f\"\\nVisit-level class weights:\")\n",
    "print(f\"  CN weight: {visit_class_weights[0]:.4f}\")\n",
    "print(f\"  AD weight: {visit_class_weights[1]:.4f}\")\n",
    "\n",
    "sampler = WeightedRandomSampler(\n",
    "    weights=sample_weights,\n",
    "    num_samples=len(sample_weights),\n",
    "    replacement=True,\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    sampler=sampler,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    pin_memory=(DEVICE.type == \"cuda\"),\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    pin_memory=(DEVICE.type == \"cuda\"),\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    pin_memory=(DEVICE.type == \"cuda\"),\n",
    ")\n",
    "\n",
    "print(f\"\\n✓ DataLoaders created\")\n",
    "print(f\"  Train batches: {len(train_loader)}\")\n",
    "print(f\"  Val batches:   {len(val_loader)}\")\n",
    "print(f\"  Test batches:  {len(test_loader)}\")\n",
    "\n",
    "# ============================================================================\n",
    "# MODEL: EFFICIENTNET-B0 + ATTENTION\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"MODEL ARCHITECTURE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "def create_effnet_backbone():\n",
    "    \"\"\"\n",
    "    Create EfficientNet-B0 feature extractor\n",
    "    Returns encoder and feature dimension\n",
    "    \"\"\"\n",
    "    try:\n",
    "        weights = models.EfficientNet_B0_Weights.IMAGENET1K_V1\n",
    "        effnet = models.efficientnet_b0(weights=weights)\n",
    "    except AttributeError:\n",
    "        effnet = models.efficientnet_b0(pretrained=True)\n",
    "    \n",
    "    # EfficientNet-B0 classifier: Sequential(Dropout(0.2), Linear(1280 -> 1000))\n",
    "    feature_dim = effnet.classifier[1].in_features  # 1280\n",
    "    \n",
    "    # Replace classifier with identity to get features\n",
    "    effnet.classifier = nn.Identity()\n",
    "    \n",
    "    return effnet, feature_dim\n",
    "\n",
    "\n",
    "class VisitAttentionEffNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Visit-level attention with EfficientNet-B0 encoder\n",
    "    \n",
    "    Architecture:\n",
    "    1. EfficientNet-B0 encoder per slice → [B*S, 1280]\n",
    "    2. Attention MLP → [B, S, 1] attention scores\n",
    "    3. Weighted sum → [B, 1280] visit features\n",
    "    4. Classifier → [B] logit\n",
    "    \"\"\"\n",
    "    def __init__(self, effnet_backbone, feature_dim, attn_hidden=128):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.backbone = effnet_backbone\n",
    "        self.feature_dim = feature_dim\n",
    "        \n",
    "        # Attention mechanism\n",
    "        self.att_fc = nn.Linear(feature_dim, attn_hidden)\n",
    "        self.att_vec = nn.Linear(attn_hidden, 1, bias=False)\n",
    "        \n",
    "        # Visit-level classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(feature_dim, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: [B, S, C, H, W] batch of visits\n",
    "        \n",
    "        Returns:\n",
    "            logits: [B] visit-level logits\n",
    "            alpha: [B, S] attention weights (optional, for visualization)\n",
    "        \"\"\"\n",
    "        B, S, C, H, W = x.shape\n",
    "        \n",
    "        # Flatten batch and slices\n",
    "        x = x.view(B * S, C, H, W)\n",
    "        \n",
    "        # Extract features per slice\n",
    "        feats = self.backbone(x)  # [B*S, 1280]\n",
    "        feats = feats.view(B, S, self.feature_dim)  # [B, S, 1280]\n",
    "        \n",
    "        # Compute attention scores\n",
    "        att = torch.tanh(self.att_fc(feats))  # [B, S, 128]\n",
    "        att = self.att_vec(att).squeeze(-1)   # [B, S]\n",
    "        alpha = torch.softmax(att, dim=1)     # Softmax over slices\n",
    "        \n",
    "        # Weighted sum over slices\n",
    "        alpha_expanded = alpha.unsqueeze(-1)  # [B, S, 1]\n",
    "        context = (alpha_expanded * feats).sum(dim=1)  # [B, 1280]\n",
    "        \n",
    "        # Classification\n",
    "        logits = self.classifier(context).squeeze(1)  # [B]\n",
    "        \n",
    "        return logits\n",
    "\n",
    "# Create model\n",
    "effnet_backbone, feature_dim = create_effnet_backbone()\n",
    "model = VisitAttentionEffNet(effnet_backbone, feature_dim).to(DEVICE)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"\\n✓ EfficientNet-B0 attention model initialized\")\n",
    "print(f\"  Total parameters:     {total_params:,}\")\n",
    "print(f\"  Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"  Feature dimension:    {feature_dim}\")\n",
    "print(f\"  Attention hidden:     128\")\n",
    "\n",
    "# ============================================================================\n",
    "# LOSS & OPTIMIZER\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"LOSS & OPTIMIZER\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Visit-level class weighting\n",
    "n_cn = float(visit_class_counts[0])\n",
    "n_ad = float(visit_class_counts[1])\n",
    "raw_ratio = n_cn / n_ad\n",
    "clamped_ratio = min(raw_ratio, 3.0)\n",
    "\n",
    "pos_weight = torch.tensor([clamped_ratio], device=DEVICE)\n",
    "\n",
    "print(f\"\\nClass weighting:\")\n",
    "print(f\"  Raw CN/AD ratio: {raw_ratio:.2f}\")\n",
    "print(f\"  Clamped pos_weight: {pos_weight.item():.3f}\")\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='max', factor=0.5, patience=4, verbose=True\n",
    ")\n",
    "\n",
    "print(f\"\\n✓ Optimizer: Adam (lr={LR}, weight_decay={WEIGHT_DECAY})\")\n",
    "print(f\"✓ Scheduler: ReduceLROnPlateau (patience=4)\")\n",
    "\n",
    "# ============================================================================\n",
    "# TRAINING & EVALUATION FUNCTIONS\n",
    "# ============================================================================\n",
    "\n",
    "def train_one_epoch(model, loader, optimizer, criterion, device, grad_clip=None):\n",
    "    \"\"\"Train for one epoch\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    n_batches = 0\n",
    "    \n",
    "    for visit_imgs, labels, _ in loader:\n",
    "        visit_imgs = visit_imgs.to(device, non_blocking=True)\n",
    "        labels = labels.to(device, non_blocking=True)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        logits = model(visit_imgs)\n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        if grad_clip is not None:\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        n_batches += 1\n",
    "    \n",
    "    return total_loss / max(n_batches, 1)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_model(model, loader, criterion, device):\n",
    "    \"\"\"Evaluate on visit-level metrics\"\"\"\n",
    "    model.eval()\n",
    "    all_logits = []\n",
    "    all_labels = []\n",
    "    total_loss = 0.0\n",
    "    n_batches = 0\n",
    "    \n",
    "    for visit_imgs, labels, _ in loader:\n",
    "        visit_imgs = visit_imgs.to(device, non_blocking=True)\n",
    "        labels = labels.to(device, non_blocking=True)\n",
    "        \n",
    "        logits = model(visit_imgs)\n",
    "        loss = criterion(logits, labels)\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        n_batches += 1\n",
    "        \n",
    "        all_logits.append(logits.cpu())\n",
    "        all_labels.append(labels.cpu())\n",
    "    \n",
    "    if n_batches == 0:\n",
    "        return math.nan, math.nan, 0.5, 0.5, 0.0, 0.0\n",
    "    \n",
    "    avg_loss = total_loss / n_batches\n",
    "    logits = torch.cat(all_logits).numpy()\n",
    "    labels = torch.cat(all_labels).numpy()\n",
    "    probs = 1.0 / (1.0 + np.exp(-logits))\n",
    "    preds = (probs >= 0.5).astype(int)\n",
    "    \n",
    "    acc = accuracy_score(labels, preds)\n",
    "    bal_acc = balanced_accuracy_score(labels, preds)\n",
    "    \n",
    "    try:\n",
    "        auc = roc_auc_score(labels, probs)\n",
    "    except:\n",
    "        auc = 0.5\n",
    "    \n",
    "    # Per-class accuracy\n",
    "    cm = confusion_matrix(labels, preds, labels=[0, 1])\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    cn_acc = tn / (tn + fp) if (tn + fp) > 0 else 0.0\n",
    "    ad_acc = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "    \n",
    "    return avg_loss, acc, bal_acc, auc, cn_acc, ad_acc\n",
    "\n",
    "# ============================================================================\n",
    "# TRAINING LOOP\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"TRAINING\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "history = []\n",
    "best_val_bal_acc = 0.0\n",
    "best_state = None\n",
    "epochs_no_improve = 0\n",
    "\n",
    "print(f\"\\nTraining for up to {NUM_EPOCHS} epochs...\")\n",
    "print(f\"Target: Val AUC ≥ 0.80, Balanced ACC ≥ 0.72, AD Recall ≥ 0.65\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    t0 = time.time()\n",
    "    \n",
    "    train_loss = train_one_epoch(model, train_loader, optimizer, criterion, DEVICE, GRAD_CLIP)\n",
    "    val_loss, val_acc, val_bal_acc, val_auc, val_cn_acc, val_ad_acc = eval_model(\n",
    "        model, val_loader, criterion, DEVICE\n",
    "    )\n",
    "    \n",
    "    dt = time.time() - t0\n",
    "    lr = optimizer.param_groups[0][\"lr\"]\n",
    "    \n",
    "    print(f\"[Epoch {epoch:02d}/{NUM_EPOCHS}] time={dt:.1f}s lr={lr:.2e}\")\n",
    "    print(f\"  train_loss={train_loss:.4f} | val_loss={val_loss:.4f}\")\n",
    "    print(f\"  val_acc={val_acc:.4f} | val_bal_acc={val_bal_acc:.4f} | val_auc={val_auc:.4f}\")\n",
    "    print(f\"  val_CN_acc={val_cn_acc:.4f} | val_AD_acc={val_ad_acc:.4f}\")\n",
    "    \n",
    "    history.append({\n",
    "        \"epoch\": epoch,\n",
    "        \"train_loss\": train_loss,\n",
    "        \"val_loss\": val_loss,\n",
    "        \"val_acc\": val_acc,\n",
    "        \"val_bal_acc\": val_bal_acc,\n",
    "        \"val_auc\": val_auc,\n",
    "        \"val_CN_acc\": val_cn_acc,\n",
    "        \"val_AD_acc\": val_ad_acc,\n",
    "        \"lr\": lr\n",
    "    })\n",
    "    \n",
    "    scheduler.step(val_bal_acc)\n",
    "    \n",
    "    if not math.isnan(val_bal_acc) and val_bal_acc > best_val_bal_acc:\n",
    "        best_val_bal_acc = val_bal_acc\n",
    "        best_state = copy.deepcopy(model.state_dict())\n",
    "        epochs_no_improve = 0\n",
    "        print(f\"  ✓ New best val_bal_acc: {best_val_bal_acc:.4f}\")\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve >= EARLY_STOP_PATIENCE:\n",
    "            print(f\"\\n⚠ Early stopping (no improvement for {EARLY_STOP_PATIENCE} epochs)\")\n",
    "            break\n",
    "\n",
    "print(\"-\" * 80)\n",
    "\n",
    "if best_state is not None:\n",
    "    model.load_state_dict(best_state)\n",
    "    torch.save(best_state, MODEL_OUT_PATH)\n",
    "    print(f\"\\n✓ Best model saved: {MODEL_OUT_PATH}\")\n",
    "    print(f\"  Best val balanced ACC: {best_val_bal_acc:.4f}\")\n",
    "\n",
    "pd.DataFrame(history).to_csv(HISTORY_CSV, index=False)\n",
    "print(f\"✓ Training history saved: {HISTORY_CSV}\")\n",
    "\n",
    "# ============================================================================\n",
    "# TEST EVALUATION\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"TEST EVALUATION (VISIT-LEVEL)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "test_loss, test_acc, test_bal_acc, test_auc, test_cn_acc, test_ad_acc = eval_model(\n",
    "    model, test_loader, criterion, DEVICE\n",
    ")\n",
    "\n",
    "print(f\"\\nTest results:\")\n",
    "print(f\"  Loss:         {test_loss:.4f}\")\n",
    "print(f\"  Accuracy:     {test_acc:.4f}\")\n",
    "print(f\"  Balanced ACC: {test_bal_acc:.4f}\")\n",
    "print(f\"  ROC-AUC:      {test_auc:.4f}\")\n",
    "print(f\"  CN accuracy:  {test_cn_acc:.4f}\")\n",
    "print(f\"  AD accuracy:  {test_ad_acc:.4f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# COMPARISON WITH S11 & BASELINE\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"PERFORMANCE COMPARISON\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "baseline_acc = 0.878\n",
    "s11_auc = 0.783  # From your S11 results\n",
    "s11_bal_acc = 0.718\n",
    "\n",
    "print(f\"\\nBaseline (always CN):\")\n",
    "print(f\"  ACC: {baseline_acc:.3f}, AUC: 0.500\")\n",
    "\n",
    "print(f\"\\nS11 (ResNet18 + Attention):\")\n",
    "print(f\"  AUC: {s11_auc:.3f}, Balanced ACC: {s11_bal_acc:.3f}\")\n",
    "\n",
    "print(f\"\\nS12 (EfficientNet-B0 + Attention):\")\n",
    "print(f\"  AUC: {test_auc:.3f}, Balanced ACC: {test_bal_acc:.3f}\")\n",
    "\n",
    "improvement_auc = test_auc - s11_auc\n",
    "improvement_bal = test_bal_acc - s11_bal_acc\n",
    "\n",
    "print(f\"\\nImprovement over S11:\")\n",
    "print(f\"  AUC:          {improvement_auc:+.4f}\")\n",
    "print(f\"  Balanced ACC: {improvement_bal:+.4f}\")\n",
    "\n",
    "if test_auc >= 0.80 and test_bal_acc >= 0.72:\n",
    "    print(f\"\\n🎉 EXCELLENT: S12 meets all targets!\")\n",
    "    print(f\"   Ready for attention visualization & Grad-CAM\")\n",
    "elif test_auc > s11_auc and test_bal_acc > s11_bal_acc:\n",
    "    print(f\"\\n✅ IMPROVEMENT: S12 beats S11\")\n",
    "    print(f\"   Consider: ensemble or threshold tuning\")\n",
    "else:\n",
    "    print(f\"\\n⚠️ REGRESSION: S12 worse than S11\")\n",
    "    print(f\"   Consider: hyperparameter tuning or revert to S11\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SNIPPET S12 COMPLETE\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3025b0",
   "metadata": {
    "papermill": {
     "duration": 0.024724,
     "end_time": "2025-11-17T19:25:30.486457",
     "exception": false,
     "start_time": "2025-11-17T19:25:30.461733",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "> Primary experiment end, now combining two datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f4a841f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T19:25:30.537746Z",
     "iopub.status.busy": "2025-11-17T19:25:30.537483Z",
     "iopub.status.idle": "2025-11-17T19:25:31.057204Z",
     "shell.execute_reply": "2025-11-17T19:25:31.056189Z"
    },
    "papermill": {
     "duration": 0.547334,
     "end_time": "2025-11-17T19:25:31.058558",
     "exception": false,
     "start_time": "2025-11-17T19:25:30.511224",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SNIPPET S13_FIXED: COMBINED OASIS-2 + OASIS-3 SPLITS (MULTI-SITE)\n",
      "================================================================================\n",
      "Date: 2025-11-17 19:25:30\n",
      "\n",
      "================================================================================\n",
      "CONFIGURATION\n",
      "================================================================================\n",
      "\n",
      "Split parameters:\n",
      "  Test fraction: 20.0%\n",
      "  CV folds:      5\n",
      "  Random seed:   42\n",
      "\n",
      "================================================================================\n",
      "STEP 1: LOADING SLICE METADATA\n",
      "================================================================================\n",
      "Total slices loaded: 18,464\n",
      "Columns: ['slice_uid', 'visit_uid', 'subject_id', 'dataset', 'split', 'diagnosis_binary', 'z_index', 'slice_position_norm', 'brain_fraction', 'mni_volume_path', 'slice_path', 'age', 'mmse', 'cdr', 'sex']\n",
      "\n",
      "⚠️  Found legacy columns from previous runs: ['split']\n",
      "   These will be dropped and replaced with new splits\n",
      "\n",
      "✓ Found 'dataset' column from S9\n",
      "\n",
      "Cleaned slices: 18,464\n",
      "\n",
      "Slice distribution:\n",
      "diagnosis_binary      0     1    All\n",
      "site                                \n",
      "O2                 6592  1408   8000\n",
      "O3                 9376  1088  10464\n",
      "All               15968  2496  18464\n",
      "\n",
      "================================================================================\n",
      "STEP 2: BUILDING VISIT-LEVEL METADATA\n",
      "================================================================================\n",
      "\n",
      "Total visits: 577\n",
      "Unique subjects: 347\n",
      "\n",
      "Visit-level distribution:\n",
      "diagnosis_binary    0   1  All\n",
      "site                          \n",
      "O2                206  44  250\n",
      "O3                293  34  327\n",
      "All               499  78  577\n",
      "\n",
      "✓ All visits have exactly 32 slices\n",
      "\n",
      "================================================================================\n",
      "STEP 3: DEFINING LOCKED TEST SET\n",
      "================================================================================\n",
      "\n",
      "Subject-level statistics:\n",
      "  Total subjects: 347\n",
      "\n",
      "Stratification groups:\n",
      "strata\n",
      "O2_0     86\n",
      "O2_1     26\n",
      "O3_0    202\n",
      "O3_1     33\n",
      "Name: count, dtype: int64\n",
      "\n",
      "✓ Split created:\n",
      "  Train/Val subjects: 277 (80%)\n",
      "  Test subjects:      70 (20%)\n",
      "\n",
      "Test set composition:\n",
      "diagnosis_binary   0   1  All\n",
      "site                         \n",
      "O2                17   5   22\n",
      "O3                41   7   48\n",
      "All               58  12   70\n",
      "\n",
      "✓ Locked test subjects saved: /kaggle/working/test_subjects_LOCKED_20251117.csv\n",
      "  ⚠️  DO NOT MODIFY - GROUND TRUTH\n",
      "\n",
      "================================================================================\n",
      "STEP 4: ASSIGNING 5-FOLD CV\n",
      "================================================================================\n",
      "\n",
      "Train/Val subjects: 277\n",
      "\n",
      "Fold 0:  56 subjects\n",
      "diagnosis_binary   0  1\n",
      "site                   \n",
      "O2                14  4\n",
      "O3                33  5\n",
      "\n",
      "Fold 1:  56 subjects\n",
      "diagnosis_binary   0  1\n",
      "site                   \n",
      "O2                14  4\n",
      "O3                32  6\n",
      "\n",
      "Fold 2:  55 subjects\n",
      "diagnosis_binary   0  1\n",
      "site                   \n",
      "O2                14  4\n",
      "O3                32  5\n",
      "\n",
      "Fold 3:  55 subjects\n",
      "diagnosis_binary   0  1\n",
      "site                   \n",
      "O2                14  4\n",
      "O3                32  5\n",
      "\n",
      "Fold 4:  55 subjects\n",
      "diagnosis_binary   0  1\n",
      "site                   \n",
      "O2                13  5\n",
      "O3                32  5\n",
      "\n",
      "✓ CV fold assignment complete\n",
      "\n",
      "================================================================================\n",
      "STEP 5: PROPAGATING SPLITS TO SLICE LEVEL\n",
      "================================================================================\n",
      "⚠️  Dropping legacy column 'split' from slice metadata\n",
      "✓ Dropped 1 legacy columns\n",
      "\n",
      "✓ Merge complete\n",
      "  Total slices: 18,464\n",
      "\n",
      "Slice-level split distribution:\n",
      "split\n",
      "trainval    14720\n",
      "test         3744\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Slice-level CV fold distribution (train/val only):\n",
      "cv_fold\n",
      "0    3168\n",
      "1    2848\n",
      "2    2752\n",
      "3    3136\n",
      "4    2816\n",
      "Name: count, dtype: int64\n",
      "\n",
      "✓ Outputs saved:\n",
      "  1. /kaggle/working/combined_visit_metadata_with_splits.csv\n",
      "  2. /kaggle/working/combined_slice_level_metadata_with_splits.csv\n",
      "\n",
      "================================================================================\n",
      "STEP 6: COMPREHENSIVE QC\n",
      "================================================================================\n",
      "\n",
      "1. Subject leakage check:\n",
      "   Train/Val: 277 subjects\n",
      "   Test:      70 subjects\n",
      "   Overlap:   0\n",
      "   ✅ No subject leakage\n",
      "\n",
      "2. Fold completeness:\n",
      "   Fold 0:  56 subj,   99 visits (CN= 83, AD=16)\n",
      "   Fold 1:  56 subj,   89 visits (CN= 78, AD=11)\n",
      "   Fold 2:  55 subj,   86 visits (CN= 75, AD=11)\n",
      "   Fold 3:  55 subj,   98 visits (CN= 86, AD=12)\n",
      "   Fold 4:  55 subj,   88 visits (CN= 74, AD=14)\n",
      "\n",
      "3. Test set quality:\n",
      "   Test visits: 117\n",
      "   CN: 103 (88.0%)\n",
      "   AD:  14 (12.0%)\n",
      "\n",
      "4. Subject uniqueness in folds:\n",
      "   ✅ All subjects in exactly one fold\n",
      "\n",
      "================================================================================\n",
      "SNIPPET S13_FIXED COMPLETE\n",
      "================================================================================\n",
      "\n",
      "✅ Multi-site dataset created successfully\n",
      "\n",
      "📊 Summary:\n",
      "   Subjects:  347 total\n",
      "     Train/Val: 277 (80%)\n",
      "     Test:      70 (20%)\n",
      "   Visits:    577 total\n",
      "   Slices:    18,464 total\n",
      "\n",
      "📁 Output files:\n",
      "   1. /kaggle/working/combined_visit_metadata_with_splits.csv\n",
      "   2. /kaggle/working/combined_slice_level_metadata_with_splits.csv\n",
      "   3. /kaggle/working/test_subjects_LOCKED_20251117.csv\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "SNIPPET S13_FIXED: Combined OASIS-2 + OASIS-3 Splits (Multi-Site)\n",
    "\n",
    "CRITICAL FIX: Drop legacy 'split' and 'cv_fold' columns before merge\n",
    "to avoid KeyError from Pandas creating split_x, split_y\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, StratifiedKFold\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"SNIPPET S13_FIXED: COMBINED OASIS-2 + OASIS-3 SPLITS (MULTI-SITE)\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURATION\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"CONFIGURATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Input paths\n",
    "SLICE_META_PATH = \"/kaggle/working/mni_slices_v1/slice_level_metadata_v1.csv\"\n",
    "\n",
    "# Output paths\n",
    "OUTPUT_ROOT = \"/kaggle/working\"\n",
    "OUT_VISIT_CSV = f\"{OUTPUT_ROOT}/combined_visit_metadata_with_splits.csv\"\n",
    "OUT_SLICE_CSV = f\"{OUTPUT_ROOT}/combined_slice_level_metadata_with_splits.csv\"\n",
    "OUT_TEST_SUBJS = f\"{OUTPUT_ROOT}/test_subjects_LOCKED_{datetime.now().strftime('%Y%m%d')}.csv\"\n",
    "\n",
    "# Split parameters\n",
    "TARGET_TEST_FRACTION = 0.20\n",
    "N_FOLDS = 5\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "print(f\"\\nSplit parameters:\")\n",
    "print(f\"  Test fraction: {TARGET_TEST_FRACTION:.1%}\")\n",
    "print(f\"  CV folds:      {N_FOLDS}\")\n",
    "print(f\"  Random seed:   {RANDOM_STATE}\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 1: LOAD & TAG SLICES\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STEP 1: LOADING SLICE METADATA\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "df_slices = pd.read_csv(SLICE_META_PATH)\n",
    "\n",
    "print(f\"Total slices loaded: {len(df_slices):,}\")\n",
    "print(f\"Columns: {list(df_slices.columns)}\")\n",
    "\n",
    "# Check for legacy columns\n",
    "legacy_cols = [\"split\", \"cv_fold\"]\n",
    "found_legacy = [col for col in legacy_cols if col in df_slices.columns]\n",
    "if found_legacy:\n",
    "    print(f\"\\n⚠️  Found legacy columns from previous runs: {found_legacy}\")\n",
    "    print(f\"   These will be dropped and replaced with new splits\")\n",
    "\n",
    "# Determine site from 'dataset' column (from S9)\n",
    "if \"dataset\" in df_slices.columns:\n",
    "    print(\"\\n✓ Found 'dataset' column from S9\")\n",
    "    df_slices[\"site\"] = df_slices[\"dataset\"].replace({\"OASIS2\": \"O2\", \"OASIS3\": \"O3\"})\n",
    "else:\n",
    "    raise ValueError(\"Missing 'dataset' column - ensure S9 was run correctly\")\n",
    "\n",
    "# Verify required columns\n",
    "required_cols = [\"subject_id\", \"visit_uid\", \"diagnosis_binary\", \"slice_path\"]\n",
    "missing = [c for c in required_cols if c not in df_slices.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"Missing required columns: {missing}\")\n",
    "\n",
    "# Clean data\n",
    "initial_count = len(df_slices)\n",
    "df_slices = df_slices.dropna(subset=[\"subject_id\", \"visit_uid\", \"diagnosis_binary\"])\n",
    "df_slices[\"diagnosis_binary\"] = df_slices[\"diagnosis_binary\"].astype(int)\n",
    "\n",
    "if len(df_slices) < initial_count:\n",
    "    print(f\"⚠️  Dropped {initial_count - len(df_slices)} rows with missing data\")\n",
    "\n",
    "print(f\"\\nCleaned slices: {len(df_slices):,}\")\n",
    "print(\"\\nSlice distribution:\")\n",
    "site_diag_counts = pd.crosstab(df_slices[\"site\"], df_slices[\"diagnosis_binary\"], margins=True)\n",
    "print(site_diag_counts)\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 2: BUILD VISIT-LEVEL METADATA\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STEP 2: BUILDING VISIT-LEVEL METADATA\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Aggregation dictionary\n",
    "agg_dict = {\n",
    "    \"diagnosis_binary\": \"first\",\n",
    "    \"site\": \"first\",\n",
    "    \"slice_path\": \"count\"\n",
    "}\n",
    "\n",
    "# Add optional columns if they exist\n",
    "optional_cols = [\"cdr\", \"mmse\", \"age\", \"sex\"]\n",
    "for col in optional_cols:\n",
    "    if col in df_slices.columns:\n",
    "        agg_dict[col] = \"first\"\n",
    "\n",
    "# Group by visit\n",
    "df_visits = (\n",
    "    df_slices\n",
    "    .groupby([\"subject_id\", \"visit_uid\"], as_index=False)\n",
    "    .agg(agg_dict)\n",
    "    .rename(columns={\"slice_path\": \"n_slices\"})\n",
    ")\n",
    "\n",
    "print(f\"\\nTotal visits: {len(df_visits):,}\")\n",
    "print(f\"Unique subjects: {df_visits['subject_id'].nunique():,}\")\n",
    "\n",
    "print(\"\\nVisit-level distribution:\")\n",
    "print(pd.crosstab(df_visits[\"site\"], df_visits[\"diagnosis_binary\"], margins=True))\n",
    "\n",
    "# Check slices per visit consistency\n",
    "slices_per_visit = df_visits[\"n_slices\"]\n",
    "if slices_per_visit.nunique() == 1:\n",
    "    print(f\"\\n✓ All visits have exactly {slices_per_visit.iloc[0]} slices\")\n",
    "else:\n",
    "    print(f\"\\n⚠️  Variable slices per visit: {slices_per_visit.min()}-{slices_per_visit.max()}\")\n",
    "    print(f\"   Distribution:\")\n",
    "    print(slices_per_visit.value_counts().head(10))\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 3: SUBJECT-LEVEL TABLE & LOCKED TEST SPLIT\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STEP 3: DEFINING LOCKED TEST SET\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Build subject-level table\n",
    "df_subjects = (\n",
    "    df_visits\n",
    "    .groupby(\"subject_id\")\n",
    "    .agg({\n",
    "        \"diagnosis_binary\": \"first\",\n",
    "        \"site\": lambda x: x.value_counts().idxmax(),\n",
    "        \"visit_uid\": \"count\"\n",
    "    })\n",
    "    .rename(columns={\"visit_uid\": \"n_visits\"})\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "print(f\"\\nSubject-level statistics:\")\n",
    "print(f\"  Total subjects: {len(df_subjects):,}\")\n",
    "\n",
    "# Create stratification labels (site + diagnosis)\n",
    "df_subjects[\"strata\"] = (\n",
    "    df_subjects[\"site\"].astype(str) + \"_\" + \n",
    "    df_subjects[\"diagnosis_binary\"].astype(str)\n",
    ")\n",
    "\n",
    "print(f\"\\nStratification groups:\")\n",
    "print(df_subjects[\"strata\"].value_counts().sort_index())\n",
    "\n",
    "# Stratified train/test split\n",
    "X = df_subjects[[\"subject_id\"]].values\n",
    "y = df_subjects[\"strata\"].values\n",
    "\n",
    "sss = StratifiedShuffleSplit(\n",
    "    n_splits=1,\n",
    "    test_size=TARGET_TEST_FRACTION,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "trainval_idx, test_idx = next(sss.split(X, y))\n",
    "\n",
    "trainval_subjects = df_subjects.iloc[trainval_idx][\"subject_id\"].tolist()\n",
    "test_subjects = df_subjects.iloc[test_idx][\"subject_id\"].tolist()\n",
    "\n",
    "print(f\"\\n✓ Split created:\")\n",
    "print(f\"  Train/Val subjects: {len(trainval_subjects):,} ({100*(1-TARGET_TEST_FRACTION):.0f}%)\")\n",
    "print(f\"  Test subjects:      {len(test_subjects):,} ({100*TARGET_TEST_FRACTION:.0f}%)\")\n",
    "\n",
    "# Verify stratification\n",
    "df_test_subs = df_subjects[df_subjects[\"subject_id\"].isin(test_subjects)]\n",
    "print(f\"\\nTest set composition:\")\n",
    "print(pd.crosstab(df_test_subs[\"site\"], df_test_subs[\"diagnosis_binary\"], margins=True))\n",
    "\n",
    "# Save locked test subjects\n",
    "test_df = pd.DataFrame({\n",
    "    \"subject_id\": test_subjects,\n",
    "    \"locked_date\": datetime.now().strftime('%Y-%m-%d')\n",
    "})\n",
    "test_df.to_csv(OUT_TEST_SUBJS, index=False)\n",
    "print(f\"\\n✓ Locked test subjects saved: {OUT_TEST_SUBJS}\")\n",
    "print(f\"  ⚠️  DO NOT MODIFY - GROUND TRUTH\")\n",
    "\n",
    "# Mark split in visit table\n",
    "df_visits[\"split\"] = np.where(\n",
    "    df_visits[\"subject_id\"].isin(test_subjects),\n",
    "    \"test\",\n",
    "    \"trainval\"\n",
    ")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 4: ASSIGN 5-FOLD CV ON TRAINVAL SUBJECTS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STEP 4: ASSIGNING 5-FOLD CV\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "df_sub_trainval = df_subjects[df_subjects[\"subject_id\"].isin(trainval_subjects)].copy()\n",
    "\n",
    "print(f\"\\nTrain/Val subjects: {len(df_sub_trainval):,}\")\n",
    "\n",
    "X_tv = df_sub_trainval[[\"subject_id\"]].values\n",
    "y_tv = df_sub_trainval[\"strata\"].values\n",
    "\n",
    "skf = StratifiedKFold(\n",
    "    n_splits=N_FOLDS,\n",
    "    shuffle=True,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "fold_assignments = {}\n",
    "\n",
    "for fold_id, (train_idx, val_idx) in enumerate(skf.split(X_tv, y_tv)):\n",
    "    fold_subjects = df_sub_trainval.iloc[val_idx][\"subject_id\"].tolist()\n",
    "    for sid in fold_subjects:\n",
    "        fold_assignments[sid] = fold_id\n",
    "    \n",
    "    fold_df = df_sub_trainval.iloc[val_idx]\n",
    "    print(f\"\\nFold {fold_id}: {len(fold_subjects):3d} subjects\")\n",
    "    print(pd.crosstab(fold_df[\"site\"], fold_df[\"diagnosis_binary\"]))\n",
    "\n",
    "# Assign cv_fold to visits\n",
    "def get_fold(sid, split):\n",
    "    if split == \"test\":\n",
    "        return -1\n",
    "    return fold_assignments.get(sid, -1)\n",
    "\n",
    "df_visits[\"cv_fold\"] = df_visits.apply(\n",
    "    lambda row: get_fold(row[\"subject_id\"], row[\"split\"]),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# QC: verify fold assignments\n",
    "bad_folds = df_visits[\n",
    "    (df_visits[\"split\"] == \"trainval\") & \n",
    "    (~df_visits[\"cv_fold\"].isin(range(N_FOLDS)))\n",
    "]\n",
    "if len(bad_folds) > 0:\n",
    "    raise ValueError(f\"Found {len(bad_folds)} train/val visits with invalid cv_fold!\")\n",
    "\n",
    "print(f\"\\n✓ CV fold assignment complete\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 5: PROPAGATE SPLITS TO SLICE LEVEL (FIXED)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STEP 5: PROPAGATING SPLITS TO SLICE LEVEL\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# 🔥 CRITICAL FIX: Drop legacy split/cv_fold columns before merge\n",
    "legacy_cols_to_drop = []\n",
    "for col in [\"split\", \"cv_fold\"]:\n",
    "    if col in df_slices.columns:\n",
    "        legacy_cols_to_drop.append(col)\n",
    "        print(f\"⚠️  Dropping legacy column '{col}' from slice metadata\")\n",
    "\n",
    "if legacy_cols_to_drop:\n",
    "    df_slices = df_slices.drop(columns=legacy_cols_to_drop)\n",
    "    print(f\"✓ Dropped {len(legacy_cols_to_drop)} legacy columns\")\n",
    "\n",
    "# Now merge cleanly\n",
    "df_slices_with_splits = df_slices.merge(\n",
    "    df_visits[[\"visit_uid\", \"split\", \"cv_fold\"]],\n",
    "    on=\"visit_uid\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "print(f\"\\n✓ Merge complete\")\n",
    "print(f\"  Total slices: {len(df_slices_with_splits):,}\")\n",
    "\n",
    "# Verify merge worked\n",
    "if \"split\" not in df_slices_with_splits.columns:\n",
    "    raise ValueError(\"❌ 'split' column missing after merge - check logic!\")\n",
    "\n",
    "print(f\"\\nSlice-level split distribution:\")\n",
    "print(df_slices_with_splits[\"split\"].value_counts())\n",
    "\n",
    "print(f\"\\nSlice-level CV fold distribution (train/val only):\")\n",
    "trainval_slices = df_slices_with_splits[df_slices_with_splits[\"split\"] == \"trainval\"]\n",
    "print(trainval_slices[\"cv_fold\"].value_counts().sort_index())\n",
    "\n",
    "# Save outputs\n",
    "df_visits.to_csv(OUT_VISIT_CSV, index=False)\n",
    "df_slices_with_splits.to_csv(OUT_SLICE_CSV, index=False)\n",
    "\n",
    "print(f\"\\n✓ Outputs saved:\")\n",
    "print(f\"  1. {OUT_VISIT_CSV}\")\n",
    "print(f\"  2. {OUT_SLICE_CSV}\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 6: COMPREHENSIVE QC\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STEP 6: COMPREHENSIVE QC\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Check 1: Subject leakage\n",
    "subs_test = set(test_subjects)\n",
    "subs_trainval = set(trainval_subjects)\n",
    "overlap = subs_test & subs_trainval\n",
    "\n",
    "print(f\"\\n1. Subject leakage check:\")\n",
    "print(f\"   Train/Val: {len(subs_trainval):,} subjects\")\n",
    "print(f\"   Test:      {len(subs_test):,} subjects\")\n",
    "print(f\"   Overlap:   {len(overlap)}\")\n",
    "\n",
    "if len(overlap) != 0:\n",
    "    raise ValueError(\"❌ CRITICAL: Subject leakage detected!\")\n",
    "else:\n",
    "    print(f\"   ✅ No subject leakage\")\n",
    "\n",
    "# Check 2: Fold completeness\n",
    "print(f\"\\n2. Fold completeness:\")\n",
    "for fold_id in range(N_FOLDS):\n",
    "    fold_visits = df_visits[\n",
    "        (df_visits[\"split\"] == \"trainval\") & \n",
    "        (df_visits[\"cv_fold\"] == fold_id)\n",
    "    ]\n",
    "    n_cn = (fold_visits[\"diagnosis_binary\"] == 0).sum()\n",
    "    n_ad = (fold_visits[\"diagnosis_binary\"] == 1).sum()\n",
    "    n_subj = fold_visits[\"subject_id\"].nunique()\n",
    "    print(f\"   Fold {fold_id}: {n_subj:3d} subj, {len(fold_visits):4d} visits (CN={n_cn:3d}, AD={n_ad:2d})\")\n",
    "    \n",
    "    if n_cn == 0 or n_ad == 0:\n",
    "        print(f\"   ⚠️  WARNING: Fold {fold_id} missing one class!\")\n",
    "\n",
    "# Check 3: Test set quality\n",
    "print(f\"\\n3. Test set quality:\")\n",
    "test_visits = df_visits[df_visits[\"split\"] == \"test\"]\n",
    "test_cn = (test_visits[\"diagnosis_binary\"] == 0).sum()\n",
    "test_ad = (test_visits[\"diagnosis_binary\"] == 1).sum()\n",
    "print(f\"   Test visits: {len(test_visits):,}\")\n",
    "print(f\"   CN: {test_cn:3d} ({100*test_cn/len(test_visits):.1f}%)\")\n",
    "print(f\"   AD: {test_ad:3d} ({100*test_ad/len(test_visits):.1f}%)\")\n",
    "\n",
    "if test_cn == 0 or test_ad == 0:\n",
    "    raise ValueError(\"❌ CRITICAL: Test set missing one class!\")\n",
    "\n",
    "# Check 4: Subject uniqueness\n",
    "print(f\"\\n4. Subject uniqueness in folds:\")\n",
    "unique_check_passed = True\n",
    "for sid in trainval_subjects[:10]:  # Check first 10 as sample\n",
    "    subject_folds = df_visits[\n",
    "        (df_visits[\"subject_id\"] == sid) & \n",
    "        (df_visits[\"split\"] == \"trainval\")\n",
    "    ][\"cv_fold\"].unique()\n",
    "    \n",
    "    if len(subject_folds) != 1:\n",
    "        print(f\"   ❌ Subject {sid} in multiple folds: {subject_folds}\")\n",
    "        unique_check_passed = False\n",
    "\n",
    "if unique_check_passed:\n",
    "    print(f\"   ✅ All subjects in exactly one fold\")\n",
    "\n",
    "# ============================================================================\n",
    "# FINAL SUMMARY\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SNIPPET S13_FIXED COMPLETE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\\n✅ Multi-site dataset created successfully\")\n",
    "\n",
    "print(f\"\\n📊 Summary:\")\n",
    "print(f\"   Subjects:  {len(df_subjects):,} total\")\n",
    "print(f\"     Train/Val: {len(trainval_subjects):,} ({100*(1-TARGET_TEST_FRACTION):.0f}%)\")\n",
    "print(f\"     Test:      {len(test_subjects):,} ({100*TARGET_TEST_FRACTION:.0f}%)\")\n",
    "print(f\"   Visits:    {len(df_visits):,} total\")\n",
    "print(f\"   Slices:    {len(df_slices_with_splits):,} total\")\n",
    "\n",
    "print(f\"\\n📁 Output files:\")\n",
    "print(f\"   1. {OUT_VISIT_CSV}\")\n",
    "print(f\"   2. {OUT_SLICE_CSV}\")\n",
    "print(f\"   3. {OUT_TEST_SUBJS}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "623eb45f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T19:25:31.111043Z",
     "iopub.status.busy": "2025-11-17T19:25:31.110759Z",
     "iopub.status.idle": "2025-11-17T19:29:49.548247Z",
     "shell.execute_reply": "2025-11-17T19:29:49.547291Z"
    },
    "papermill": {
     "duration": 258.464846,
     "end_time": "2025-11-17T19:29:49.549528",
     "exception": false,
     "start_time": "2025-11-17T19:25:31.084682",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SNIPPET S14: MULTI-SITE RESNET18 + VISIT-LEVEL ATTENTION (FOLD 0)\n",
      "================================================================================\n",
      "Date: 2025-11-17 19:25:31\n",
      "\n",
      "Device: cuda\n",
      "\n",
      "================================================================================\n",
      "STEP 1: LOADING SLICE METADATA\n",
      "================================================================================\n",
      "\n",
      "Total slices: 18,464\n",
      "\n",
      "Slice distribution:\n",
      "diagnosis_binary      0     1    All\n",
      "split                               \n",
      "test               3296   448   3744\n",
      "trainval          12672  2048  14720\n",
      "All               15968  2496  18464\n",
      "\n",
      "================================================================================\n",
      "STEP 2: BUILDING VISIT-LEVEL TABLE\n",
      "================================================================================\n",
      "\n",
      "Total visits: 577\n",
      "Visits with exactly 32 slices: 577\n",
      "\n",
      "Split sizes:\n",
      "  Train: 361 visits\n",
      "  Val:    99 visits\n",
      "  Test:  117 visits\n",
      "\n",
      "Train: CN=313, AD=48 (ratio 6.52:1)\n",
      "\n",
      "Val: CN= 83, AD=16 (ratio 5.19:1)\n",
      "\n",
      "Test: CN=103, AD=14 (ratio 7.36:1)\n",
      "\n",
      "================================================================================\n",
      "STEP 3: DATASET & TRANSFORMS\n",
      "================================================================================\n",
      "\n",
      "✓ Datasets created\n",
      "\n",
      "================================================================================\n",
      "STEP 4: DATALOADERS\n",
      "================================================================================\n",
      "\n",
      "Train: CN=313, AD=48\n",
      "Raw ratio: 6.52\n",
      "Clamped pos_weight: 3.000\n",
      "\n",
      "✓ DataLoaders created\n",
      "\n",
      "================================================================================\n",
      "STEP 5: MODEL\n",
      "================================================================================\n",
      "\n",
      "✓ Model initialized\n",
      "  Parameters: 11,242,818\n",
      "\n",
      "================================================================================\n",
      "STEP 7: TRAINING\n",
      "================================================================================\n",
      "\n",
      "Training for up to 30 epochs...\n",
      "Target: Val AUC ≥ 0.80, Bal ACC ≥ 0.72, AD Recall ≥ 0.65\n",
      "--------------------------------------------------------------------------------\n",
      "[Epoch 01/30] time=24.6s lr=1.00e-04\n",
      "  train_loss=0.8833 | val_loss=0.6948\n",
      "  val_acc=0.7071 | val_bal_acc=0.7496 | val_auc=0.8449\n",
      "  val_CN_acc=0.6867 | val_AD_acc=0.8125\n",
      "  ✓ New best: 0.7496\n",
      "[Epoch 02/30] time=15.2s lr=1.00e-04\n",
      "  train_loss=0.7149 | val_loss=0.7195\n",
      "  val_acc=0.8485 | val_bal_acc=0.5312 | val_auc=0.8223\n",
      "  val_CN_acc=1.0000 | val_AD_acc=0.0625\n",
      "[Epoch 03/30] time=15.1s lr=1.00e-04\n",
      "  train_loss=0.6540 | val_loss=0.6343\n",
      "  val_acc=0.8687 | val_bal_acc=0.7703 | val_auc=0.8479\n",
      "  val_CN_acc=0.9157 | val_AD_acc=0.6250\n",
      "  ✓ New best: 0.7703\n",
      "[Epoch 04/30] time=15.2s lr=1.00e-04\n",
      "  train_loss=0.5658 | val_loss=0.5881\n",
      "  val_acc=0.8081 | val_bal_acc=0.7846 | val_auc=0.8592\n",
      "  val_CN_acc=0.8193 | val_AD_acc=0.7500\n",
      "  ✓ New best: 0.7846\n",
      "[Epoch 05/30] time=15.2s lr=1.00e-04\n",
      "  train_loss=0.3617 | val_loss=0.5157\n",
      "  val_acc=0.8889 | val_bal_acc=0.7824 | val_auc=0.9164\n",
      "  val_CN_acc=0.9398 | val_AD_acc=0.6250\n",
      "[Epoch 06/30] time=15.2s lr=1.00e-04\n",
      "  train_loss=0.3940 | val_loss=0.6087\n",
      "  val_acc=0.8182 | val_bal_acc=0.8159 | val_auc=0.8569\n",
      "  val_CN_acc=0.8193 | val_AD_acc=0.8125\n",
      "  ✓ New best: 0.8159\n",
      "[Epoch 07/30] time=15.2s lr=1.00e-04\n",
      "  train_loss=0.2540 | val_loss=0.6227\n",
      "  val_acc=0.9091 | val_bal_acc=0.7692 | val_auc=0.9104\n",
      "  val_CN_acc=0.9759 | val_AD_acc=0.5625\n",
      "[Epoch 08/30] time=15.2s lr=1.00e-04\n",
      "  train_loss=0.1469 | val_loss=0.6721\n",
      "  val_acc=0.8485 | val_bal_acc=0.8592 | val_auc=0.8577\n",
      "  val_CN_acc=0.8434 | val_AD_acc=0.8750\n",
      "  ✓ New best: 0.8592\n",
      "[Epoch 09/30] time=15.3s lr=1.00e-04\n",
      "  train_loss=0.2198 | val_loss=1.0833\n",
      "  val_acc=0.7677 | val_bal_acc=0.6596 | val_auc=0.6581\n",
      "  val_CN_acc=0.8193 | val_AD_acc=0.5000\n",
      "[Epoch 10/30] time=15.3s lr=1.00e-04\n",
      "  train_loss=0.1253 | val_loss=0.8966\n",
      "  val_acc=0.9192 | val_bal_acc=0.7752 | val_auc=0.8878\n",
      "  val_CN_acc=0.9880 | val_AD_acc=0.5625\n",
      "[Epoch 11/30] time=15.3s lr=5.00e-05\n",
      "  train_loss=0.1131 | val_loss=0.8914\n",
      "  val_acc=0.8687 | val_bal_acc=0.6694 | val_auc=0.8825\n",
      "  val_CN_acc=0.9639 | val_AD_acc=0.3750\n",
      "[Epoch 12/30] time=15.2s lr=5.00e-05\n",
      "  train_loss=0.0656 | val_loss=1.1477\n",
      "  val_acc=0.8687 | val_bal_acc=0.6947 | val_auc=0.8178\n",
      "  val_CN_acc=0.9518 | val_AD_acc=0.4375\n",
      "[Epoch 13/30] time=15.4s lr=5.00e-05\n",
      "  train_loss=0.0197 | val_loss=1.5801\n",
      "  val_acc=0.8586 | val_bal_acc=0.6130 | val_auc=0.8554\n",
      "  val_CN_acc=0.9759 | val_AD_acc=0.2500\n",
      "[Epoch 14/30] time=15.2s lr=5.00e-05\n",
      "  train_loss=0.0440 | val_loss=1.3383\n",
      "  val_acc=0.8687 | val_bal_acc=0.6442 | val_auc=0.8441\n",
      "  val_CN_acc=0.9759 | val_AD_acc=0.3125\n",
      "[Epoch 15/30] time=15.1s lr=5.00e-05\n",
      "  train_loss=0.0200 | val_loss=1.4862\n",
      "  val_acc=0.8586 | val_bal_acc=0.6130 | val_auc=0.8931\n",
      "  val_CN_acc=0.9759 | val_AD_acc=0.2500\n",
      "[Epoch 16/30] time=15.3s lr=2.50e-05\n",
      "  train_loss=0.0271 | val_loss=1.2668\n",
      "  val_acc=0.8990 | val_bal_acc=0.7127 | val_auc=0.8449\n",
      "  val_CN_acc=0.9880 | val_AD_acc=0.4375\n",
      "\n",
      "⚠ Early stopping\n",
      "\n",
      "✓ History saved: /kaggle/working/training_history_multisite_resnet18_fold0.csv\n",
      "Best epoch: 8, val_bal_acc=0.8592\n",
      "\n",
      "================================================================================\n",
      "STEP 8: TEST EVALUATION\n",
      "================================================================================\n",
      "\n",
      "Test composition: CN=103, AD=14\n",
      "\n",
      "Test results:\n",
      "  Accuracy:     0.7265\n",
      "  Balanced ACC: 0.5978\n",
      "  ROC-AUC:      0.6761\n",
      "  CN accuracy:  0.7670\n",
      "  AD accuracy:  0.4286\n",
      "\n",
      "Baseline (always CN): 0.8803\n",
      "Improvement: -0.1538\n",
      "\n",
      "================================================================================\n",
      "SNIPPET S14 COMPLETE\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "SNIPPET S14: Multi-Site ResNet18 + Visit-Level Attention (Fold 0)\n",
    "Train visit-level attention model on combined OASIS-2 + OASIS-3\n",
    "\n",
    "Targets (Validation, Fold 0):\n",
    "  - Val AUC          ≥ 0.80\n",
    "  - Val Balanced ACC ≥ 0.72\n",
    "  - Val AD Recall    ≥ 0.65\n",
    "\n",
    "Targets (Test, Multi-site):\n",
    "  - Test AUC         ≥ 0.70\n",
    "  - Test Balanced ACC ≥ 0.65\n",
    "  - AD Recall        ≥ 0.45\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score,\n",
    "    accuracy_score,\n",
    "    balanced_accuracy_score,\n",
    "    confusion_matrix\n",
    ")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"SNIPPET S14: MULTI-SITE RESNET18 + VISIT-LEVEL ATTENTION (FOLD 0)\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURATION & SEEDING\n",
    "# ============================================================================\n",
    "\n",
    "SLICE_META_CSV = \"/kaggle/working/combined_slice_level_metadata_with_splits.csv\"\n",
    "MODEL_PATH = \"/kaggle/working/multisite_visit_attention_resnet18_fold0.pth\"\n",
    "HIST_PATH = \"/kaggle/working/training_history_multisite_resnet18_fold0.csv\"\n",
    "\n",
    "FOLD_ID = 0\n",
    "N_SLICES_PER_VISIT = 32\n",
    "IMG_SIZE = (128, 128)\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "NUM_EPOCHS = 30\n",
    "LR = 1e-4\n",
    "WEIGHT_DECAY = 1e-5\n",
    "PATIENCE = 8\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"\\nDevice: {DEVICE}\")\n",
    "\n",
    "def set_seed(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = False\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "set_seed(RANDOM_STATE)\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 1: LOAD SLICE METADATA\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STEP 1: LOADING SLICE METADATA\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "slice_meta = pd.read_csv(SLICE_META_CSV)\n",
    "\n",
    "required_cols = [\n",
    "    \"subject_id\", \"visit_uid\", \"diagnosis_binary\",\n",
    "    \"slice_path\", \"split\", \"cv_fold\", \"z_index\"\n",
    "]\n",
    "missing = [c for c in required_cols if c not in slice_meta.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"Missing required columns: {missing}\")\n",
    "\n",
    "initial_count = len(slice_meta)\n",
    "slice_meta = slice_meta.dropna(subset=[\"subject_id\", \"visit_uid\", \"diagnosis_binary\"])\n",
    "slice_meta[\"diagnosis_binary\"] = slice_meta[\"diagnosis_binary\"].astype(int)\n",
    "slice_meta[\"cv_fold\"] = slice_meta[\"cv_fold\"].astype(int)\n",
    "\n",
    "if len(slice_meta) < initial_count:\n",
    "    print(f\"⚠️ Dropped {initial_count - len(slice_meta)} rows with missing data\")\n",
    "\n",
    "print(f\"\\nTotal slices: {len(slice_meta):,}\")\n",
    "print(\"\\nSlice distribution:\")\n",
    "print(pd.crosstab(slice_meta[\"split\"], slice_meta[\"diagnosis_binary\"], margins=True))\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 2: BUILD VISIT-LEVEL TABLE & SPLITS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STEP 2: BUILDING VISIT-LEVEL TABLE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "visit_agg = (\n",
    "    slice_meta\n",
    "    .groupby([\"subject_id\", \"visit_uid\", \"split\", \"cv_fold\"], as_index=False)\n",
    "    .agg({\n",
    "        \"diagnosis_binary\": \"first\",\n",
    "        \"slice_path\": \"count\"\n",
    "    })\n",
    "    .rename(columns={\"slice_path\": \"n_slices\"})\n",
    ")\n",
    "\n",
    "print(f\"\\nTotal visits: {len(visit_agg):,}\")\n",
    "\n",
    "# Enforce fixed slices per visit\n",
    "valid_visits = visit_agg[visit_agg[\"n_slices\"] == N_SLICES_PER_VISIT].copy()\n",
    "print(f\"Visits with exactly {N_SLICES_PER_VISIT} slices: {len(valid_visits):,}\")\n",
    "\n",
    "if len(valid_visits) < len(visit_agg):\n",
    "    print(f\"⚠️ Dropped {len(visit_agg) - len(valid_visits)} visits\")\n",
    "\n",
    "# Split\n",
    "train_visits = valid_visits[\n",
    "    (valid_visits[\"split\"] == \"trainval\") & \n",
    "    (valid_visits[\"cv_fold\"] != FOLD_ID)\n",
    "].copy()\n",
    "\n",
    "val_visits = valid_visits[\n",
    "    (valid_visits[\"split\"] == \"trainval\") & \n",
    "    (valid_visits[\"cv_fold\"] == FOLD_ID)\n",
    "].copy()\n",
    "\n",
    "test_visits = valid_visits[valid_visits[\"split\"] == \"test\"].copy()\n",
    "\n",
    "print(f\"\\nSplit sizes:\")\n",
    "print(f\"  Train: {len(train_visits):3d} visits\")\n",
    "print(f\"  Val:   {len(val_visits):3d} visits\")\n",
    "print(f\"  Test:  {len(test_visits):3d} visits\")\n",
    "\n",
    "for name, df in [(\"Train\", train_visits), (\"Val\", val_visits), (\"Test\", test_visits)]:\n",
    "    if len(df) > 0:\n",
    "        cn = (df[\"diagnosis_binary\"] == 0).sum()\n",
    "        ad = (df[\"diagnosis_binary\"] == 1).sum()\n",
    "        print(f\"\\n{name}: CN={cn:3d}, AD={ad:2d} (ratio {cn/ad if ad > 0 else np.inf:.2f}:1)\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 3: DATASET & TRANSFORMS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STEP 3: DATASET & TRANSFORMS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "imagenet_normalize = transforms.Normalize(\n",
    "    mean=[0.485, 0.456, 0.406],\n",
    "    std=[0.229, 0.224, 0.225]\n",
    ")\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize(IMG_SIZE),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    imagenet_normalize,\n",
    "])\n",
    "\n",
    "eval_transform = transforms.Compose([\n",
    "    transforms.Resize(IMG_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    imagenet_normalize,\n",
    "])\n",
    "\n",
    "class VisitDataset(Dataset):\n",
    "    def __init__(self, visits_df, slices_df, transform=None):\n",
    "        self.visits_df = visits_df.reset_index(drop=True)\n",
    "        self.transform = transform\n",
    "        grouped = slices_df.groupby(\"visit_uid\")\n",
    "        self.visit_to_slices = {vid: g.sort_values(\"z_index\") for vid, g in grouped}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.visits_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.visits_df.iloc[idx]\n",
    "        visit_uid = row[\"visit_uid\"]\n",
    "        label = float(row[\"diagnosis_binary\"])\n",
    "\n",
    "        if visit_uid not in self.visit_to_slices:\n",
    "            raise KeyError(f\"visit_uid {visit_uid} not found\")\n",
    "\n",
    "        slice_rows = self.visit_to_slices[visit_uid]\n",
    "\n",
    "        imgs = []\n",
    "        for _, srow in slice_rows.iterrows():\n",
    "            arr = np.load(srow[\"slice_path\"]).astype(np.float32)\n",
    "            img_np = (arr * 255.0).clip(0, 255).astype(np.uint8)\n",
    "            img = Image.fromarray(img_np).convert(\"RGB\")\n",
    "            if self.transform is not None:\n",
    "                img = self.transform(img)\n",
    "            imgs.append(img)\n",
    "\n",
    "        images = torch.stack(imgs, dim=0)\n",
    "        label = torch.tensor(label, dtype=torch.float32)\n",
    "        return images, label, visit_uid\n",
    "\n",
    "train_dataset = VisitDataset(train_visits, slice_meta, transform=train_transform)\n",
    "val_dataset = VisitDataset(val_visits, slice_meta, transform=eval_transform)\n",
    "test_dataset = VisitDataset(test_visits, slice_meta, transform=eval_transform)\n",
    "\n",
    "print(f\"\\n✓ Datasets created\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 4: DATALOADERS & CLASS WEIGHTS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STEP 4: DATALOADERS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "train_labels = train_visits[\"diagnosis_binary\"].values\n",
    "n_train_cn = (train_labels == 0).sum()\n",
    "n_train_ad = (train_labels == 1).sum()\n",
    "\n",
    "print(f\"\\nTrain: CN={n_train_cn}, AD={n_train_ad}\")\n",
    "\n",
    "if n_train_ad == 0:\n",
    "    raise ValueError(\"No AD visits in training!\")\n",
    "\n",
    "raw_pos_weight = n_train_cn / n_train_ad\n",
    "pos_weight = min(raw_pos_weight, 3.0)\n",
    "\n",
    "print(f\"Raw ratio: {raw_pos_weight:.2f}\")\n",
    "print(f\"Clamped pos_weight: {pos_weight:.3f}\")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "print(f\"\\n✓ DataLoaders created\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 5: MODEL\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STEP 5: MODEL\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "class ResNet18VisitAttention(nn.Module):\n",
    "    def __init__(self, attention_hidden=128, pretrained=True):\n",
    "        super().__init__()\n",
    "        try:\n",
    "            weights = models.ResNet18_Weights.IMAGENET1K_V1 if pretrained else None\n",
    "            backbone = models.resnet18(weights=weights)\n",
    "        except AttributeError:\n",
    "            backbone = models.resnet18(pretrained=pretrained)\n",
    "\n",
    "        modules = list(backbone.children())[:-1]\n",
    "        self.backbone = nn.Sequential(*modules)\n",
    "        self.feature_dim = backbone.fc.in_features\n",
    "\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(self.feature_dim, attention_hidden),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(attention_hidden, 1)\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Linear(self.feature_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, N, C, H, W = x.shape\n",
    "        x = x.view(B * N, C, H, W)\n",
    "        feats = self.backbone(x)\n",
    "        feats = feats.view(B, N, self.feature_dim)\n",
    "\n",
    "        attn_scores = self.attention(feats)\n",
    "        attn_weights = torch.softmax(attn_scores, dim=1)\n",
    "\n",
    "        visit_feat = torch.sum(attn_weights * feats, dim=1)\n",
    "        logits = self.classifier(visit_feat).squeeze(1)\n",
    "\n",
    "        return logits, attn_weights.squeeze(-1)\n",
    "\n",
    "model = ResNet18VisitAttention(attention_hidden=128, pretrained=True).to(DEVICE)\n",
    "\n",
    "print(f\"\\n✓ Model initialized\")\n",
    "print(f\"  Parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 6: LOSS, OPTIMIZER, SCHEDULER\n",
    "# ============================================================================\n",
    "\n",
    "pos_weight_tensor = torch.tensor([pos_weight], dtype=torch.float32, device=DEVICE)\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight_tensor)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.5, patience=4, verbose=True)\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 7: TRAINING\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STEP 7: TRAINING\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "history = []\n",
    "best_val_bal_acc = -np.inf\n",
    "best_epoch = -1\n",
    "epochs_no_improve = 0\n",
    "\n",
    "print(f\"\\nTraining for up to {NUM_EPOCHS} epochs...\")\n",
    "print(\"Target: Val AUC ≥ 0.80, Bal ACC ≥ 0.72, AD Recall ≥ 0.65\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Train\n",
    "    model.train()\n",
    "    train_losses = []\n",
    "    for images, labels, _ in train_loader:\n",
    "        images = images.to(DEVICE, non_blocking=True)\n",
    "        labels = labels.to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits, _ = model(images)\n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_losses.append(loss.item())\n",
    "\n",
    "    train_loss = np.mean(train_losses) if train_losses else np.nan\n",
    "\n",
    "    # Validate\n",
    "    model.eval()\n",
    "    val_losses = []\n",
    "    all_val_labels = []\n",
    "    all_val_probs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels, _ in val_loader:\n",
    "            images = images.to(DEVICE, non_blocking=True)\n",
    "            labels = labels.to(DEVICE)\n",
    "\n",
    "            logits, _ = model(images)\n",
    "            loss = criterion(logits, labels)\n",
    "\n",
    "            val_losses.append(loss.item())\n",
    "            probs = torch.sigmoid(logits)\n",
    "            all_val_labels.extend(labels.cpu().numpy())\n",
    "            all_val_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "    val_loss = np.mean(val_losses) if val_losses else np.nan\n",
    "    all_val_labels = np.array(all_val_labels)\n",
    "    all_val_probs = np.array(all_val_probs)\n",
    "\n",
    "    try:\n",
    "        val_auc = roc_auc_score(all_val_labels, all_val_probs)\n",
    "    except:\n",
    "        val_auc = np.nan\n",
    "\n",
    "    val_preds = (all_val_probs >= 0.5).astype(int)\n",
    "    val_acc = accuracy_score(all_val_labels, val_preds)\n",
    "    val_bal_acc = balanced_accuracy_score(all_val_labels, val_preds)\n",
    "\n",
    "    cm = confusion_matrix(all_val_labels, val_preds, labels=[0, 1])\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    val_cn_acc = tn / (tn + fp) if (tn + fp) > 0 else 0.0\n",
    "    val_ad_acc = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "\n",
    "    lr_now = optimizer.param_groups[0][\"lr\"]\n",
    "    elapsed = time.time() - t0\n",
    "\n",
    "    print(f\"[Epoch {epoch:02d}/{NUM_EPOCHS}] time={elapsed:.1f}s lr={lr_now:.2e}\")\n",
    "    print(f\"  train_loss={train_loss:.4f} | val_loss={val_loss:.4f}\")\n",
    "    print(f\"  val_acc={val_acc:.4f} | val_bal_acc={val_bal_acc:.4f} | val_auc={val_auc:.4f}\")\n",
    "    print(f\"  val_CN_acc={val_cn_acc:.4f} | val_AD_acc={val_ad_acc:.4f}\")\n",
    "\n",
    "    history.append({\n",
    "        \"epoch\": epoch, \"train_loss\": train_loss, \"val_loss\": val_loss,\n",
    "        \"val_acc\": val_acc, \"val_bal_acc\": val_bal_acc, \"val_auc\": val_auc,\n",
    "        \"val_CN_acc\": val_cn_acc, \"val_AD_acc\": val_ad_acc, \"lr\": lr_now,\n",
    "    })\n",
    "\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    if val_bal_acc > best_val_bal_acc:\n",
    "        best_val_bal_acc = val_bal_acc\n",
    "        best_epoch = epoch\n",
    "        epochs_no_improve = 0\n",
    "        torch.save(model.state_dict(), MODEL_PATH)\n",
    "        print(f\"  ✓ New best: {best_val_bal_acc:.4f}\")\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "\n",
    "    if epochs_no_improve >= PATIENCE:\n",
    "        print(f\"\\n⚠ Early stopping\")\n",
    "        break\n",
    "\n",
    "pd.DataFrame(history).to_csv(HIST_PATH, index=False)\n",
    "print(f\"\\n✓ History saved: {HIST_PATH}\")\n",
    "print(f\"Best epoch: {best_epoch}, val_bal_acc={best_val_bal_acc:.4f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 8: TEST EVALUATION\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STEP 8: TEST EVALUATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "best_model = ResNet18VisitAttention(attention_hidden=128, pretrained=False).to(DEVICE)\n",
    "best_model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n",
    "best_model.eval()\n",
    "\n",
    "test_labels = []\n",
    "test_probs = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels, _ in test_loader:\n",
    "        images = images.to(DEVICE, non_blocking=True)\n",
    "        logits, _ = best_model(images)\n",
    "        probs = torch.sigmoid(logits)\n",
    "        test_labels.extend(labels.cpu().numpy())\n",
    "        test_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "test_labels = np.array(test_labels)\n",
    "test_probs = np.array(test_probs)\n",
    "test_preds = (test_probs >= 0.5).astype(int)\n",
    "\n",
    "try:\n",
    "    test_auc = roc_auc_score(test_labels, test_probs)\n",
    "except:\n",
    "    test_auc = np.nan\n",
    "\n",
    "test_acc = accuracy_score(test_labels, test_preds)\n",
    "test_bal_acc = balanced_accuracy_score(test_labels, test_preds)\n",
    "cm = confusion_matrix(test_labels, test_preds, labels=[0, 1])\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "cn_acc = tn / (tn + fp) if (tn + fp) > 0 else 0.0\n",
    "ad_acc = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "\n",
    "n_cn = (test_labels == 0).sum()\n",
    "n_ad = (test_labels == 1).sum()\n",
    "baseline_acc = n_cn / len(test_labels)\n",
    "\n",
    "print(f\"\\nTest composition: CN={n_cn}, AD={n_ad}\")\n",
    "print(f\"\\nTest results:\")\n",
    "print(f\"  Accuracy:     {test_acc:.4f}\")\n",
    "print(f\"  Balanced ACC: {test_bal_acc:.4f}\")\n",
    "print(f\"  ROC-AUC:      {test_auc:.4f}\")\n",
    "print(f\"  CN accuracy:  {cn_acc:.4f}\")\n",
    "print(f\"  AD accuracy:  {ad_acc:.4f}\")\n",
    "\n",
    "print(f\"\\nBaseline (always CN): {baseline_acc:.4f}\")\n",
    "print(f\"Improvement: {test_acc - baseline_acc:+.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SNIPPET S14 COMPLETE\")\n",
    "print(\"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0de329dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T19:29:49.604637Z",
     "iopub.status.busy": "2025-11-17T19:29:49.604412Z",
     "iopub.status.idle": "2025-11-17T20:09:20.918155Z",
     "shell.execute_reply": "2025-11-17T20:09:20.917284Z"
    },
    "papermill": {
     "duration": 2371.342731,
     "end_time": "2025-11-17T20:09:20.919409",
     "exception": false,
     "start_time": "2025-11-17T19:29:49.576678",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SNIPPET S15: MULTI-SITE EFFICIENTNET-B0 5-FOLD CV\n",
      "================================================================================\n",
      "Date: 2025-11-17 19:29:49\n",
      "\n",
      "Device: cuda\n",
      "GPU: Tesla T4\n",
      "Memory: 15.8 GB\n",
      "\n",
      "Configuration:\n",
      "  Folds:      5\n",
      "  Batch size: 8\n",
      "  Epochs:     30\n",
      "  LR:         0.0001\n",
      "  Patience:   8\n",
      "\n",
      "================================================================================\n",
      "STEP 1: LOADING METADATA\n",
      "================================================================================\n",
      "\n",
      "Total slices (trainval): 14,720\n",
      "Unique visits: 460\n",
      "\n",
      "================================================================================\n",
      "STEP 2: BUILDING VISIT-LEVEL TABLE\n",
      "================================================================================\n",
      "\n",
      "Total visits: 460\n",
      "Visits with 32 slices: 460\n",
      "\n",
      "Per-fold distribution:\n",
      "  Fold 0:  99 visits (CN= 83, AD=16)\n",
      "  Fold 1:  89 visits (CN= 78, AD=11)\n",
      "  Fold 2:  86 visits (CN= 75, AD=11)\n",
      "  Fold 3:  98 visits (CN= 86, AD=12)\n",
      "  Fold 4:  88 visits (CN= 74, AD=14)\n",
      "\n",
      "================================================================================\n",
      "STEP 3: DEFINING TRANSFORMS\n",
      "================================================================================\n",
      "✓ Transforms defined\n",
      "\n",
      "================================================================================\n",
      "STEP 4: DEFINING VISIT DATASET\n",
      "================================================================================\n",
      "✓ Dataset class defined\n",
      "\n",
      "================================================================================\n",
      "STEP 5: MODEL DEFINITION\n",
      "================================================================================\n",
      "✓ Model class defined\n",
      "\n",
      "================================================================================\n",
      "STEP 6: 5-FOLD CROSS-VALIDATION\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "FOLD 0\n",
      "================================================================================\n",
      "\n",
      "Split sizes:\n",
      "  Train: 361 visits\n",
      "  Val:    99 visits\n",
      "\n",
      "Train: CN=313, AD=48\n",
      "pos_weight: 3.000\n",
      "\n",
      "Training fold 0...\n",
      "------------------------------------------------------------\n",
      "[Epoch 01] 28.1s | loss: 0.7652/0.7597 | auc: 0.8321 | bal_acc: 0.5000 | AD_acc: 0.0000\n",
      "[Epoch 05] 23.6s | loss: 0.5612/0.6822 | auc: 0.8419 | bal_acc: 0.7752 | AD_acc: 0.5625\n",
      "[Epoch 10] 23.7s | loss: 0.3230/0.5617 | auc: 0.8923 | bal_acc: 0.8532 | AD_acc: 0.8750\n",
      "[Epoch 15] 23.6s | loss: 0.1407/1.0152 | auc: 0.8893 | bal_acc: 0.7944 | AD_acc: 0.6250\n",
      "[Epoch 20] 23.5s | loss: 0.0441/0.7419 | auc: 0.9066 | bal_acc: 0.7884 | AD_acc: 0.6250\n",
      "[Epoch 25] 23.5s | loss: 0.0701/0.9087 | auc: 0.8660 | bal_acc: 0.7462 | AD_acc: 0.6250\n",
      "  Early stopping at epoch 27\n",
      "------------------------------------------------------------\n",
      "✓ Fold 0 complete\n",
      "  Best val_bal_acc: 0.8761 at epoch 19\n",
      "  Best val_auc:     0.9232\n",
      "  Best val_AD_acc:  0.8125\n",
      "\n",
      "================================================================================\n",
      "FOLD 1\n",
      "================================================================================\n",
      "\n",
      "Split sizes:\n",
      "  Train: 371 visits\n",
      "  Val:    89 visits\n",
      "\n",
      "Train: CN=318, AD=53\n",
      "pos_weight: 3.000\n",
      "\n",
      "Training fold 1...\n",
      "------------------------------------------------------------\n",
      "[Epoch 01] 25.0s | loss: 0.8045/0.7047 | auc: 0.6340 | bal_acc: 0.5000 | AD_acc: 0.0000\n",
      "[Epoch 05] 23.9s | loss: 0.5270/1.1084 | auc: 0.5944 | bal_acc: 0.5484 | AD_acc: 0.5455\n",
      "[Epoch 10] 23.9s | loss: 0.3103/0.9907 | auc: 0.7110 | bal_acc: 0.7284 | AD_acc: 0.6364\n",
      "[Epoch 15] 23.8s | loss: 0.1566/1.3803 | auc: 0.6830 | bal_acc: 0.5082 | AD_acc: 0.2727\n",
      "  Early stopping at epoch 18\n",
      "------------------------------------------------------------\n",
      "✓ Fold 1 complete\n",
      "  Best val_bal_acc: 0.7284 at epoch 10\n",
      "  Best val_auc:     0.7110\n",
      "  Best val_AD_acc:  0.6364\n",
      "\n",
      "================================================================================\n",
      "FOLD 2\n",
      "================================================================================\n",
      "\n",
      "Split sizes:\n",
      "  Train: 374 visits\n",
      "  Val:    86 visits\n",
      "\n",
      "Train: CN=321, AD=53\n",
      "pos_weight: 3.000\n",
      "\n",
      "Training fold 2...\n",
      "------------------------------------------------------------\n",
      "[Epoch 01] 26.6s | loss: 0.8278/0.7627 | auc: 0.6255 | bal_acc: 0.5000 | AD_acc: 0.0000\n",
      "[Epoch 05] 24.0s | loss: 0.4697/0.7185 | auc: 0.8061 | bal_acc: 0.7236 | AD_acc: 0.7273\n",
      "[Epoch 10] 24.0s | loss: 0.2701/0.7367 | auc: 0.8327 | bal_acc: 0.7527 | AD_acc: 0.5455\n",
      "[Epoch 15] 23.8s | loss: 0.1134/0.8200 | auc: 0.8630 | bal_acc: 0.7006 | AD_acc: 0.4545\n",
      "[Epoch 20] 23.9s | loss: 0.0433/0.8273 | auc: 0.8824 | bal_acc: 0.7461 | AD_acc: 0.5455\n",
      "  Early stopping at epoch 20\n",
      "------------------------------------------------------------\n",
      "✓ Fold 2 complete\n",
      "  Best val_bal_acc: 0.7970 at epoch 12\n",
      "  Best val_auc:     0.8558\n",
      "  Best val_AD_acc:  0.7273\n",
      "\n",
      "================================================================================\n",
      "FOLD 3\n",
      "================================================================================\n",
      "\n",
      "Split sizes:\n",
      "  Train: 362 visits\n",
      "  Val:    98 visits\n",
      "\n",
      "Train: CN=310, AD=52\n",
      "pos_weight: 3.000\n",
      "\n",
      "Training fold 3...\n",
      "------------------------------------------------------------\n",
      "[Epoch 01] 24.6s | loss: 0.7721/0.6735 | auc: 0.6773 | bal_acc: 0.5000 | AD_acc: 0.0000\n",
      "[Epoch 05] 23.6s | loss: 0.4458/0.7048 | auc: 0.8266 | bal_acc: 0.7297 | AD_acc: 0.7500\n",
      "[Epoch 10] 23.6s | loss: 0.1134/0.9041 | auc: 0.8391 | bal_acc: 0.6793 | AD_acc: 0.4167\n",
      "  Early stopping at epoch 13\n",
      "------------------------------------------------------------\n",
      "✓ Fold 3 complete\n",
      "  Best val_bal_acc: 0.7297 at epoch 5\n",
      "  Best val_auc:     0.8266\n",
      "  Best val_AD_acc:  0.7500\n",
      "\n",
      "================================================================================\n",
      "FOLD 4\n",
      "================================================================================\n",
      "\n",
      "Split sizes:\n",
      "  Train: 372 visits\n",
      "  Val:    88 visits\n",
      "\n",
      "Train: CN=322, AD=50\n",
      "pos_weight: 3.000\n",
      "\n",
      "Training fold 4...\n",
      "------------------------------------------------------------\n",
      "[Epoch 01] 25.9s | loss: 0.7770/0.9737 | auc: 0.6255 | bal_acc: 0.5000 | AD_acc: 0.0000\n",
      "[Epoch 05] 24.0s | loss: 0.4005/1.5798 | auc: 0.5502 | bal_acc: 0.6004 | AD_acc: 0.2143\n",
      "[Epoch 10] 23.9s | loss: 0.1545/2.1538 | auc: 0.7539 | bal_acc: 0.5579 | AD_acc: 0.1429\n",
      "[Epoch 15] 24.0s | loss: 0.0959/1.8185 | auc: 0.7046 | bal_acc: 0.6245 | AD_acc: 0.3571\n",
      "[Epoch 20] 23.8s | loss: 0.0724/2.2798 | auc: 0.7307 | bal_acc: 0.6448 | AD_acc: 0.3571\n",
      "  Early stopping at epoch 21\n",
      "------------------------------------------------------------\n",
      "✓ Fold 4 complete\n",
      "  Best val_bal_acc: 0.7452 at epoch 13\n",
      "  Best val_auc:     0.7722\n",
      "  Best val_AD_acc:  0.5714\n",
      "\n",
      "================================================================================\n",
      "CROSS-VALIDATION RESULTS\n",
      "================================================================================\n",
      "\n",
      "✓ Results saved: /kaggle/working/effnetb0_multisite_cv_results.csv\n",
      "\n",
      "Metric          Mean     Std      Min      Max     \n",
      "-------------------------------------------------------\n",
      "val_auc          0.8177  0.0723  0.7110  0.9232\n",
      "val_acc          0.8287  0.0691  0.7143  0.9192\n",
      "val_bal_acc      0.7753  0.0563  0.7284  0.8761\n",
      "val_cn_acc       0.8510  0.0822  0.7093  0.9398\n",
      "val_ad_acc       0.6995  0.0854  0.5714  0.8125\n",
      "\n",
      "================================================================================\n",
      "PERFORMANCE ASSESSMENT\n",
      "================================================================================\n",
      "\n",
      "Mean metrics (5-fold CV):\n",
      "  AUC:         0.8177\n",
      "  Balanced ACC: 0.7753\n",
      "  AD Recall:    0.6995\n",
      "\n",
      "Targets:\n",
      "  AUC:          ≥ 0.90\n",
      "  Balanced ACC: ≥ 0.80\n",
      "  AD Recall:    ≥ 0.70\n",
      "\n",
      "⚠️ MODERATE: Below targets but reasonable\n",
      "   Next: Tune hyperparameters (LR, epochs, augmentation)\n",
      "\n",
      "================================================================================\n",
      "SNIPPET S15 COMPLETE\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "SNIPPET S15: Multi-Site EfficientNet-B0 + Visit-Level Attention (5-Fold CV)\n",
    "Author: Research Team\n",
    "Date: 2025-11-17\n",
    "\n",
    "Goal: Train EfficientNet-B0 with 5-fold CV on combined OASIS-2 + OASIS-3\n",
    "\n",
    "Targets (Mean over 5 folds):\n",
    "  - Val AUC          ≥ 0.90\n",
    "  - Val Balanced ACC ≥ 0.80\n",
    "  - Val AD Recall    ≥ 0.70\n",
    "\n",
    "Strategy: Do NOT touch test set until model meets validation targets\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score,\n",
    "    accuracy_score,\n",
    "    balanced_accuracy_score,\n",
    "    confusion_matrix\n",
    ")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"SNIPPET S15: MULTI-SITE EFFICIENTNET-B0 5-FOLD CV\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURATION\n",
    "# ============================================================================\n",
    "\n",
    "SLICE_META_CSV = \"/kaggle/working/combined_slice_level_metadata_with_splits.csv\"\n",
    "OUTPUT_ROOT = \"/kaggle/working\"\n",
    "CV_RESULTS_CSV = f\"{OUTPUT_ROOT}/effnetb0_multisite_cv_results.csv\"\n",
    "\n",
    "N_SLICES_PER_VISIT = 32\n",
    "IMG_SIZE = (128, 128)\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "NUM_EPOCHS = 30\n",
    "LR = 1e-4\n",
    "WEIGHT_DECAY = 1e-5\n",
    "PATIENCE = 8\n",
    "N_FOLDS = 5\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"\\nDevice: {DEVICE}\")\n",
    "\n",
    "if DEVICE.type == \"cuda\":\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "\n",
    "def set_seed(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = False\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "set_seed(RANDOM_STATE)\n",
    "\n",
    "print(f\"\\nConfiguration:\")\n",
    "print(f\"  Folds:      {N_FOLDS}\")\n",
    "print(f\"  Batch size: {BATCH_SIZE}\")\n",
    "print(f\"  Epochs:     {NUM_EPOCHS}\")\n",
    "print(f\"  LR:         {LR}\")\n",
    "print(f\"  Patience:   {PATIENCE}\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 1: LOAD & FILTER METADATA\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STEP 1: LOADING METADATA\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "df_all = pd.read_csv(SLICE_META_CSV)\n",
    "\n",
    "required_cols = [\n",
    "    \"subject_id\", \"visit_uid\", \"diagnosis_binary\",\n",
    "    \"slice_path\", \"split\", \"cv_fold\", \"z_index\"\n",
    "]\n",
    "missing = [c for c in required_cols if c not in df_all.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"Missing columns: {missing}\")\n",
    "\n",
    "# Filter to trainval only\n",
    "df_tv = df_all[df_all[\"split\"] == \"trainval\"].copy()\n",
    "df_tv[\"diagnosis_binary\"] = df_tv[\"diagnosis_binary\"].astype(int)\n",
    "df_tv[\"cv_fold\"] = df_tv[\"cv_fold\"].astype(int)\n",
    "\n",
    "print(f\"\\nTotal slices (trainval): {len(df_tv):,}\")\n",
    "print(f\"Unique visits: {df_tv['visit_uid'].nunique():,}\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 2: BUILD VISIT-LEVEL TABLE\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STEP 2: BUILDING VISIT-LEVEL TABLE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "visits_tv = (\n",
    "    df_tv\n",
    "    .groupby([\"subject_id\", \"visit_uid\", \"cv_fold\"], as_index=False)\n",
    "    .agg({\n",
    "        \"diagnosis_binary\": \"first\",\n",
    "        \"slice_path\": \"count\"\n",
    "    })\n",
    "    .rename(columns={\"slice_path\": \"n_slices\"})\n",
    ")\n",
    "\n",
    "print(f\"\\nTotal visits: {len(visits_tv):,}\")\n",
    "\n",
    "# Filter to complete visits\n",
    "valid_visits = visits_tv[visits_tv[\"n_slices\"] == N_SLICES_PER_VISIT].copy()\n",
    "print(f\"Visits with {N_SLICES_PER_VISIT} slices: {len(valid_visits):,}\")\n",
    "\n",
    "if len(valid_visits) < len(visits_tv):\n",
    "    print(f\"⚠️ Dropped {len(visits_tv) - len(valid_visits)} incomplete visits\")\n",
    "\n",
    "# Per-fold distribution\n",
    "print(f\"\\nPer-fold distribution:\")\n",
    "for fold_id in range(N_FOLDS):\n",
    "    fold_visits = valid_visits[valid_visits[\"cv_fold\"] == fold_id]\n",
    "    cn = (fold_visits[\"diagnosis_binary\"] == 0).sum()\n",
    "    ad = (fold_visits[\"diagnosis_binary\"] == 1).sum()\n",
    "    print(f\"  Fold {fold_id}: {len(fold_visits):3d} visits (CN={cn:3d}, AD={ad:2d})\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 3: TRANSFORMS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STEP 3: DEFINING TRANSFORMS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "imagenet_normalize = transforms.Normalize(\n",
    "    mean=[0.485, 0.456, 0.406],\n",
    "    std=[0.229, 0.224, 0.225]\n",
    ")\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize(IMG_SIZE),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    imagenet_normalize,\n",
    "])\n",
    "\n",
    "eval_transform = transforms.Compose([\n",
    "    transforms.Resize(IMG_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    imagenet_normalize,\n",
    "])\n",
    "\n",
    "print(\"✓ Transforms defined\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 4: VISIT DATASET\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STEP 4: DEFINING VISIT DATASET\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "class VisitDataset(Dataset):\n",
    "    \"\"\"Visit-level dataset with multi-site support\"\"\"\n",
    "    def __init__(self, visits_df, slices_df, transform=None):\n",
    "        self.visits_df = visits_df.reset_index(drop=True)\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Pre-build mapping\n",
    "        grouped = slices_df.groupby(\"visit_uid\")\n",
    "        self.visit_to_slices = {\n",
    "            vid: g.sort_values(\"z_index\") \n",
    "            for vid, g in grouped\n",
    "        }\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.visits_df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.visits_df.iloc[idx]\n",
    "        visit_uid = row[\"visit_uid\"]\n",
    "        label = float(row[\"diagnosis_binary\"])\n",
    "        \n",
    "        if visit_uid not in self.visit_to_slices:\n",
    "            raise KeyError(f\"visit_uid {visit_uid} not found\")\n",
    "        \n",
    "        slice_rows = self.visit_to_slices[visit_uid]\n",
    "        \n",
    "        imgs = []\n",
    "        for _, srow in slice_rows.iterrows():\n",
    "            arr = np.load(srow[\"slice_path\"]).astype(np.float32)\n",
    "            img_np = (arr * 255.0).clip(0, 255).astype(np.uint8)\n",
    "            img = Image.fromarray(img_np).convert(\"RGB\")\n",
    "            \n",
    "            if self.transform is not None:\n",
    "                img = self.transform(img)\n",
    "            \n",
    "            imgs.append(img)\n",
    "        \n",
    "        images = torch.stack(imgs, dim=0)\n",
    "        label = torch.tensor(label, dtype=torch.float32)\n",
    "        \n",
    "        return images, label, visit_uid\n",
    "\n",
    "print(\"✓ Dataset class defined\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 5: MODEL DEFINITION\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STEP 5: MODEL DEFINITION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "def create_effnet_backbone():\n",
    "    \"\"\"Create EfficientNet-B0 feature extractor\"\"\"\n",
    "    try:\n",
    "        weights = models.EfficientNet_B0_Weights.IMAGENET1K_V1\n",
    "        effnet = models.efficientnet_b0(weights=weights)\n",
    "    except AttributeError:\n",
    "        effnet = models.efficientnet_b0(pretrained=True)\n",
    "    \n",
    "    feature_dim = effnet.classifier[1].in_features  # 1280\n",
    "    effnet.classifier = nn.Identity()\n",
    "    \n",
    "    return effnet, feature_dim\n",
    "\n",
    "\n",
    "class EffNetB0VisitAttention(nn.Module):\n",
    "    \"\"\"EfficientNet-B0 + visit-level attention\"\"\"\n",
    "    def __init__(self, effnet_backbone, feature_dim, attn_hidden=128):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.backbone = effnet_backbone\n",
    "        self.feature_dim = feature_dim\n",
    "        \n",
    "        # Attention mechanism\n",
    "        self.att_fc = nn.Linear(feature_dim, attn_hidden)\n",
    "        self.att_vec = nn.Linear(attn_hidden, 1, bias=False)\n",
    "        \n",
    "        # Classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(feature_dim, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: [B, N, C, H, W]\n",
    "        Returns:\n",
    "            logits: [B]\n",
    "            attn_weights: [B, N]\n",
    "        \"\"\"\n",
    "        B, N, C, H, W = x.shape\n",
    "        \n",
    "        x = x.view(B * N, C, H, W)\n",
    "        feats = self.backbone(x)  # [B*N, 1280]\n",
    "        feats = feats.view(B, N, self.feature_dim)  # [B, N, 1280]\n",
    "        \n",
    "        att = torch.tanh(self.att_fc(feats))  # [B, N, 128]\n",
    "        att = self.att_vec(att).squeeze(-1)   # [B, N]\n",
    "        alpha = torch.softmax(att, dim=1)      # [B, N]\n",
    "        \n",
    "        alpha_expanded = alpha.unsqueeze(-1)  # [B, N, 1]\n",
    "        context = (alpha_expanded * feats).sum(dim=1)  # [B, 1280]\n",
    "        \n",
    "        logits = self.classifier(context).squeeze(1)  # [B]\n",
    "        \n",
    "        return logits, alpha\n",
    "\n",
    "print(\"✓ Model class defined\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 6: 5-FOLD TRAINING LOOP\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STEP 6: 5-FOLD CROSS-VALIDATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "fold_results = []\n",
    "\n",
    "for fold_id in range(N_FOLDS):\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(f\"FOLD {fold_id}\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Split data\n",
    "    train_visits = valid_visits[valid_visits[\"cv_fold\"] != fold_id].copy()\n",
    "    val_visits = valid_visits[valid_visits[\"cv_fold\"] == fold_id].copy()\n",
    "    \n",
    "    print(f\"\\nSplit sizes:\")\n",
    "    print(f\"  Train: {len(train_visits):3d} visits\")\n",
    "    print(f\"  Val:   {len(val_visits):3d} visits\")\n",
    "    \n",
    "    # Class distribution\n",
    "    train_labels = train_visits[\"diagnosis_binary\"].values\n",
    "    n_cn = (train_labels == 0).sum()\n",
    "    n_ad = (train_labels == 1).sum()\n",
    "    \n",
    "    print(f\"\\nTrain: CN={n_cn}, AD={n_ad}\")\n",
    "    \n",
    "    if n_ad == 0:\n",
    "        print(f\"⚠️ Skipping fold {fold_id} (no AD in training)\")\n",
    "        continue\n",
    "    \n",
    "    # Datasets\n",
    "    train_dataset = VisitDataset(train_visits, df_tv, train_transform)\n",
    "    val_dataset = VisitDataset(val_visits, df_tv, eval_transform)\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, batch_size=BATCH_SIZE, shuffle=True,\n",
    "        num_workers=2, pin_memory=True\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset, batch_size=BATCH_SIZE, shuffle=False,\n",
    "        num_workers=2, pin_memory=True\n",
    "    )\n",
    "    \n",
    "    # Loss weighting\n",
    "    raw_pos_weight = n_cn / n_ad\n",
    "    pos_weight = min(raw_pos_weight, 3.0)\n",
    "    print(f\"pos_weight: {pos_weight:.3f}\")\n",
    "    \n",
    "    # Model\n",
    "    effnet_backbone, feature_dim = create_effnet_backbone()\n",
    "    model = EffNetB0VisitAttention(effnet_backbone, feature_dim).to(DEVICE)\n",
    "    \n",
    "    pos_weight_tensor = torch.tensor([pos_weight], device=DEVICE)\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight_tensor)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode=\"min\", factor=0.5, patience=4, verbose=False\n",
    "    )\n",
    "    \n",
    "    # Training\n",
    "    best_val_bal_acc = -np.inf\n",
    "    best_metrics = None\n",
    "    epochs_no_improve = 0\n",
    "    \n",
    "    print(f\"\\nTraining fold {fold_id}...\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    for epoch in range(1, NUM_EPOCHS + 1):\n",
    "        t0 = time.time()\n",
    "        \n",
    "        # Train\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        for images, labels, _ in train_loader:\n",
    "            images = images.to(DEVICE, non_blocking=True)\n",
    "            labels = labels.to(DEVICE)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            logits, _ = model(images)\n",
    "            loss = criterion(logits, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_losses.append(loss.item())\n",
    "        \n",
    "        train_loss = np.mean(train_losses)\n",
    "        \n",
    "        # Validate\n",
    "        model.eval()\n",
    "        val_losses = []\n",
    "        all_labels = []\n",
    "        all_probs = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, labels, _ in val_loader:\n",
    "                images = images.to(DEVICE, non_blocking=True)\n",
    "                labels = labels.to(DEVICE)\n",
    "                \n",
    "                logits, _ = model(images)\n",
    "                loss = criterion(logits, labels)\n",
    "                \n",
    "                val_losses.append(loss.item())\n",
    "                probs = torch.sigmoid(logits)\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "                all_probs.extend(probs.cpu().numpy())\n",
    "        \n",
    "        val_loss = np.mean(val_losses)\n",
    "        all_labels = np.array(all_labels)\n",
    "        all_probs = np.array(all_probs)\n",
    "        \n",
    "        # Metrics\n",
    "        try:\n",
    "            val_auc = roc_auc_score(all_labels, all_probs)\n",
    "        except:\n",
    "            val_auc = np.nan\n",
    "        \n",
    "        val_preds = (all_probs >= 0.5).astype(int)\n",
    "        val_acc = accuracy_score(all_labels, val_preds)\n",
    "        val_bal_acc = balanced_accuracy_score(all_labels, val_preds)\n",
    "        \n",
    "        cm = confusion_matrix(all_labels, val_preds, labels=[0, 1])\n",
    "        tn, fp, fn, tp = cm.ravel()\n",
    "        val_cn_acc = tn / (tn + fp) if (tn + fp) > 0 else 0.0\n",
    "        val_ad_acc = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "        \n",
    "        elapsed = time.time() - t0\n",
    "        \n",
    "        if epoch % 5 == 0 or epoch == 1:\n",
    "            print(f\"[Epoch {epoch:02d}] {elapsed:.1f}s | \"\n",
    "                  f\"loss: {train_loss:.4f}/{val_loss:.4f} | \"\n",
    "                  f\"auc: {val_auc:.4f} | bal_acc: {val_bal_acc:.4f} | \"\n",
    "                  f\"AD_acc: {val_ad_acc:.4f}\")\n",
    "        \n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        # Early stopping\n",
    "        if val_bal_acc > best_val_bal_acc:\n",
    "            best_val_bal_acc = val_bal_acc\n",
    "            best_metrics = {\n",
    "                \"epoch\": epoch,\n",
    "                \"val_auc\": val_auc,\n",
    "                \"val_acc\": val_acc,\n",
    "                \"val_bal_acc\": val_bal_acc,\n",
    "                \"val_cn_acc\": val_cn_acc,\n",
    "                \"val_ad_acc\": val_ad_acc\n",
    "            }\n",
    "            \n",
    "            model_path = f\"{OUTPUT_ROOT}/effnetb0_multisite_fold{fold_id}.pth\"\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "        \n",
    "        if epochs_no_improve >= PATIENCE:\n",
    "            print(f\"  Early stopping at epoch {epoch}\")\n",
    "            break\n",
    "    \n",
    "    print(\"-\" * 60)\n",
    "    print(f\"✓ Fold {fold_id} complete\")\n",
    "    print(f\"  Best val_bal_acc: {best_val_bal_acc:.4f} at epoch {best_metrics['epoch']}\")\n",
    "    print(f\"  Best val_auc:     {best_metrics['val_auc']:.4f}\")\n",
    "    print(f\"  Best val_AD_acc:  {best_metrics['val_ad_acc']:.4f}\")\n",
    "    \n",
    "    # Store results\n",
    "    fold_results.append({\n",
    "        \"fold\": fold_id,\n",
    "        **best_metrics\n",
    "    })\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 7: AGGREGATE & SAVE RESULTS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"CROSS-VALIDATION RESULTS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "results_df = pd.DataFrame(fold_results)\n",
    "results_df.to_csv(CV_RESULTS_CSV, index=False)\n",
    "\n",
    "print(f\"\\n✓ Results saved: {CV_RESULTS_CSV}\")\n",
    "\n",
    "# Compute statistics\n",
    "metrics = [\"val_auc\", \"val_acc\", \"val_bal_acc\", \"val_cn_acc\", \"val_ad_acc\"]\n",
    "\n",
    "print(f\"\\n{'Metric':<15} {'Mean':<8} {'Std':<8} {'Min':<8} {'Max':<8}\")\n",
    "print(\"-\" * 55)\n",
    "\n",
    "summary = {}\n",
    "for metric in metrics:\n",
    "    values = results_df[metric].values\n",
    "    mean_val = np.mean(values)\n",
    "    std_val = np.std(values)\n",
    "    min_val = np.min(values)\n",
    "    max_val = np.max(values)\n",
    "    \n",
    "    summary[metric] = {\"mean\": mean_val, \"std\": std_val}\n",
    "    \n",
    "    print(f\"{metric:<15} {mean_val:>7.4f} {std_val:>7.4f} {min_val:>7.4f} {max_val:>7.4f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 8: DECISION CRITERIA\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"PERFORMANCE ASSESSMENT\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "mean_auc = summary[\"val_auc\"][\"mean\"]\n",
    "mean_bal_acc = summary[\"val_bal_acc\"][\"mean\"]\n",
    "mean_ad_recall = summary[\"val_ad_acc\"][\"mean\"]\n",
    "\n",
    "print(f\"\\nMean metrics (5-fold CV):\")\n",
    "print(f\"  AUC:         {mean_auc:.4f}\")\n",
    "print(f\"  Balanced ACC: {mean_bal_acc:.4f}\")\n",
    "print(f\"  AD Recall:    {mean_ad_recall:.4f}\")\n",
    "\n",
    "print(f\"\\nTargets:\")\n",
    "print(f\"  AUC:          ≥ 0.90\")\n",
    "print(f\"  Balanced ACC: ≥ 0.80\")\n",
    "print(f\"  AD Recall:    ≥ 0.70\")\n",
    "\n",
    "if mean_auc >= 0.90 and mean_bal_acc >= 0.80 and mean_ad_recall >= 0.70:\n",
    "    print(f\"\\n🎉 SUCCESS: All targets met!\")\n",
    "    print(f\"   Next: Test set evaluation & XAI analysis\")\n",
    "elif mean_auc >= 0.85 and mean_bal_acc >= 0.75:\n",
    "    print(f\"\\n✅ GOOD: Close to targets\")\n",
    "    print(f\"   Consider: Ensemble or proceed to test\")\n",
    "elif mean_auc >= 0.75:\n",
    "    print(f\"\\n⚠️ MODERATE: Below targets but reasonable\")\n",
    "    print(f\"   Next: Tune hyperparameters (LR, epochs, augmentation)\")\n",
    "else:\n",
    "    print(f\"\\n❌ NEEDS IMPROVEMENT: Significantly below targets\")\n",
    "    print(f\"   Next: Architecture review or data augmentation\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SNIPPET S15 COMPLETE\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e3da959e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T20:09:20.977431Z",
     "iopub.status.busy": "2025-11-17T20:09:20.976642Z",
     "iopub.status.idle": "2025-11-17T21:15:45.437234Z",
     "shell.execute_reply": "2025-11-17T21:15:45.436313Z"
    },
    "papermill": {
     "duration": 3984.519713,
     "end_time": "2025-11-17T21:15:45.467808",
     "exception": false,
     "start_time": "2025-11-17T20:09:20.948095",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SNIPPET S16: TUNED EFFICIENTNET-B0 5-FOLD CV\n",
      "================================================================================\n",
      "Date: 2025-11-17 20:09:21\n",
      "\n",
      "Device: cuda\n",
      "GPU: Tesla T4\n",
      "\n",
      "Configuration (TUNED):\n",
      "  Resolution:  160×160 (↑ from 128)\n",
      "  LR:          5e-05 (↓ from 1e-4)\n",
      "  Patience:    10 (↑ from 8)\n",
      "  Dropout:     0.3 classifier, 0.2 attention\n",
      "\n",
      "================================================================================\n",
      "STEP 1: LOADING METADATA\n",
      "================================================================================\n",
      "Trainval slices: 14,720\n",
      "Valid visits: 460\n",
      "\n",
      "================================================================================\n",
      "STEP 2: DEFINING TRANSFORMS (TUNED)\n",
      "================================================================================\n",
      "✓ Transforms defined\n",
      "  Train: RandomResizedCrop(160×160)\n",
      "  Eval:  Resize(180) → CenterCrop(160)\n",
      "\n",
      "================================================================================\n",
      "STEP 4: MODEL DEFINITION (TUNED)\n",
      "================================================================================\n",
      "✓ Model defined with enhanced regularization\n",
      "\n",
      "================================================================================\n",
      "STEP 5: 5-FOLD CROSS-VALIDATION\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "FOLD 0\n",
      "================================================================================\n",
      "Train: 361, Val: 99\n",
      "Training fold 0...\n",
      "------------------------------------------------------------\n",
      "[Epoch 01] 45.5s | loss: 0.7696/0.8120 | auc: 0.7139 | bal_acc: 0.5000 | AD_acc: 0.0000\n",
      "[Epoch 05] 38.2s | loss: 0.5921/0.6530 | auc: 0.8547 | bal_acc: 0.6562 | AD_acc: 0.3125\n",
      "[Epoch 10] 38.2s | loss: 0.3952/0.9320 | auc: 0.8840 | bal_acc: 0.6250 | AD_acc: 0.2500\n",
      "[Epoch 15] 38.2s | loss: 0.2226/0.7831 | auc: 0.9014 | bal_acc: 0.8005 | AD_acc: 0.6250\n",
      "[Epoch 20] 38.0s | loss: 0.0950/0.8782 | auc: 0.9104 | bal_acc: 0.7380 | AD_acc: 0.5000\n",
      "[Epoch 25] 38.0s | loss: 0.2239/0.9063 | auc: 0.9081 | bal_acc: 0.7380 | AD_acc: 0.5000\n",
      "[Epoch 30] 38.1s | loss: 0.1406/0.9933 | auc: 0.8923 | bal_acc: 0.7380 | AD_acc: 0.5000\n",
      "------------------------------------------------------------\n",
      "✓ Fold 0 complete\n",
      "  Best: bal_acc=0.8136, auc=0.8818, AD_acc=0.6875\n",
      "\n",
      "================================================================================\n",
      "FOLD 1\n",
      "================================================================================\n",
      "Train: 371, Val: 89\n",
      "Training fold 1...\n",
      "------------------------------------------------------------\n",
      "[Epoch 01] 40.5s | loss: 0.8371/0.7554 | auc: 0.5536 | bal_acc: 0.4872 | AD_acc: 0.0000\n",
      "[Epoch 05] 38.8s | loss: 0.5354/0.7768 | auc: 0.6317 | bal_acc: 0.5146 | AD_acc: 0.2727\n",
      "[Epoch 10] 38.9s | loss: 0.3433/0.9145 | auc: 0.6783 | bal_acc: 0.6515 | AD_acc: 0.6364\n",
      "[Epoch 15] 38.7s | loss: 0.2377/1.0977 | auc: 0.7366 | bal_acc: 0.5659 | AD_acc: 0.2727\n",
      "[Epoch 20] 38.6s | loss: 0.2669/1.0982 | auc: 0.7238 | bal_acc: 0.6049 | AD_acc: 0.3636\n",
      "  Early stopping at epoch 21\n",
      "------------------------------------------------------------\n",
      "✓ Fold 1 complete\n",
      "  Best: bal_acc=0.6707, auc=0.7436, AD_acc=0.6364\n",
      "\n",
      "================================================================================\n",
      "FOLD 2\n",
      "================================================================================\n",
      "Train: 374, Val: 86\n",
      "Training fold 2...\n",
      "------------------------------------------------------------\n",
      "[Epoch 01] 43.1s | loss: 0.8306/0.7585 | auc: 0.6618 | bal_acc: 0.5000 | AD_acc: 0.0000\n",
      "[Epoch 05] 38.9s | loss: 0.5282/0.5765 | auc: 0.8788 | bal_acc: 0.8479 | AD_acc: 0.9091\n",
      "[Epoch 10] 39.0s | loss: 0.2729/0.7435 | auc: 0.8267 | bal_acc: 0.7248 | AD_acc: 0.6364\n",
      "[Epoch 15] 39.0s | loss: 0.1612/1.2138 | auc: 0.8206 | bal_acc: 0.7006 | AD_acc: 0.4545\n",
      "  Early stopping at epoch 15\n",
      "------------------------------------------------------------\n",
      "✓ Fold 2 complete\n",
      "  Best: bal_acc=0.8479, auc=0.8788, AD_acc=0.9091\n",
      "\n",
      "================================================================================\n",
      "FOLD 3\n",
      "================================================================================\n",
      "Train: 362, Val: 98\n",
      "Training fold 3...\n",
      "------------------------------------------------------------\n",
      "[Epoch 01] 39.5s | loss: 0.8364/0.7192 | auc: 0.6279 | bal_acc: 0.5000 | AD_acc: 0.0000\n",
      "[Epoch 05] 38.0s | loss: 0.5070/0.5471 | auc: 0.8236 | bal_acc: 0.6986 | AD_acc: 0.5833\n",
      "[Epoch 10] 38.2s | loss: 0.4266/0.6131 | auc: 0.8324 | bal_acc: 0.7112 | AD_acc: 0.6667\n",
      "[Epoch 15] 38.0s | loss: 0.2256/1.0009 | auc: 0.7975 | bal_acc: 0.6202 | AD_acc: 0.3333\n",
      "[Epoch 20] 38.0s | loss: 0.1159/0.8944 | auc: 0.8062 | bal_acc: 0.7035 | AD_acc: 0.5000\n",
      "  Early stopping at epoch 21\n",
      "------------------------------------------------------------\n",
      "✓ Fold 3 complete\n",
      "  Best: bal_acc=0.7762, auc=0.8508, AD_acc=0.7500\n",
      "\n",
      "================================================================================\n",
      "FOLD 4\n",
      "================================================================================\n",
      "Train: 372, Val: 88\n",
      "Training fold 4...\n",
      "------------------------------------------------------------\n",
      "[Epoch 01] 41.4s | loss: 0.8007/0.8257 | auc: 0.7114 | bal_acc: 0.5357 | AD_acc: 0.0714\n",
      "[Epoch 05] 39.1s | loss: 0.4564/0.6756 | auc: 0.8272 | bal_acc: 0.7963 | AD_acc: 0.7143\n",
      "[Epoch 10] 38.9s | loss: 0.2437/0.9612 | auc: 0.8629 | bal_acc: 0.6873 | AD_acc: 0.4286\n",
      "[Epoch 15] 38.9s | loss: 0.1299/1.2762 | auc: 0.8562 | bal_acc: 0.6940 | AD_acc: 0.4286\n",
      "  Early stopping at epoch 16\n",
      "------------------------------------------------------------\n",
      "✓ Fold 4 complete\n",
      "  Best: bal_acc=0.8031, auc=0.8591, AD_acc=0.7143\n",
      "\n",
      "================================================================================\n",
      "CROSS-VALIDATION RESULTS (TUNED)\n",
      "================================================================================\n",
      "\n",
      "✓ Results saved: /kaggle/working/effnetb0_multisite_cv_results_tuned.csv\n",
      "\n",
      "Metric          Mean     Std      Min      Max     \n",
      "-------------------------------------------------------\n",
      "val_auc          0.8428  0.0510  0.7436  0.8818\n",
      "val_acc          0.8115  0.0691  0.6966  0.8990\n",
      "val_bal_acc      0.7823  0.0603  0.6707  0.8479\n",
      "val_cn_acc       0.8252  0.0825  0.7051  0.9398\n",
      "val_ad_acc       0.7394  0.0926  0.6364  0.9091\n",
      "\n",
      "================================================================================\n",
      "COMPARISON: S15 vs S16\n",
      "================================================================================\n",
      "\n",
      "Metric          S15 (Base)   S16 (Tuned)  Δ       \n",
      "--------------------------------------------------\n",
      "AUC                  0.8500      0.8428 -0.0072\n",
      "Balanced ACC         0.7800      0.7823 +0.0023\n",
      "AD Recall            0.7200      0.7394 +0.0194\n",
      "\n",
      "================================================================================\n",
      "PERFORMANCE ASSESSMENT\n",
      "================================================================================\n",
      "\n",
      "S16 Mean metrics (5-fold CV):\n",
      "  AUC:          0.8428\n",
      "  Balanced ACC: 0.7823\n",
      "  AD Recall:    0.7394\n",
      "\n",
      "Targets:\n",
      "  AUC:          ≥ 0.87\n",
      "  Balanced ACC: ≥ 0.82\n",
      "  AD Recall:    ≥ 0.75\n",
      "\n",
      "⚠️ BELOW TARGET\n",
      "\n",
      "Options:\n",
      "  1. Accept current performance, focus on XAI\n",
      "  2. Try architectural changes (not recommended)\n",
      "\n",
      "================================================================================\n",
      "SNIPPET S16 COMPLETE\n",
      "================================================================================\n",
      "\n",
      "Decision: REVIEW\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "SNIPPET S16: Tuned Multi-Site EfficientNet-B0 5-Fold CV\n",
    "Improvements over S15:\n",
    "1. Higher resolution (160×160 vs 128×128)\n",
    "2. Stronger augmentation (RandomResizedCrop)\n",
    "3. More regularization (dropout 0.3 in classifier, 0.2 in attention)\n",
    "4. Lower LR (5e-5 vs 1e-4)\n",
    "5. Higher patience (10 vs 8)\n",
    "\n",
    "Targets (Mean over 5 folds):\n",
    "  - Val AUC          ≥ 0.87\n",
    "  - Val Balanced ACC ≥ 0.82\n",
    "  - Val AD Recall    ≥ 0.75\n",
    "\n",
    "If targets not met: Accept classification ceiling and focus on XAI novelties\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score,\n",
    "    accuracy_score,\n",
    "    balanced_accuracy_score,\n",
    "    confusion_matrix\n",
    ")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"SNIPPET S16: TUNED EFFICIENTNET-B0 5-FOLD CV\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURATION (TUNED)\n",
    "# ============================================================================\n",
    "\n",
    "SLICE_META_CSV = \"/kaggle/working/combined_slice_level_metadata_with_splits.csv\"\n",
    "OUTPUT_ROOT = \"/kaggle/working\"\n",
    "CV_RESULTS_CSV = f\"{OUTPUT_ROOT}/effnetb0_multisite_cv_results_tuned.csv\"\n",
    "\n",
    "N_SLICES_PER_VISIT = 32\n",
    "IMG_SIZE = 160  # INCREASED from 128\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "NUM_EPOCHS = 30\n",
    "LR = 5e-5  # REDUCED from 1e-4\n",
    "WEIGHT_DECAY = 1e-5\n",
    "PATIENCE = 10  # INCREASED from 8\n",
    "N_FOLDS = 5\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"\\nDevice: {DEVICE}\")\n",
    "\n",
    "if DEVICE.type == \"cuda\":\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "def set_seed(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = False\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "set_seed(RANDOM_STATE)\n",
    "\n",
    "print(f\"\\nConfiguration (TUNED):\")\n",
    "print(f\"  Resolution:  {IMG_SIZE}×{IMG_SIZE} (↑ from 128)\")\n",
    "print(f\"  LR:          {LR} (↓ from 1e-4)\")\n",
    "print(f\"  Patience:    {PATIENCE} (↑ from 8)\")\n",
    "print(f\"  Dropout:     0.3 classifier, 0.2 attention\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 1: LOAD METADATA\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STEP 1: LOADING METADATA\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "df_all = pd.read_csv(SLICE_META_CSV)\n",
    "\n",
    "df_tv = df_all[df_all[\"split\"] == \"trainval\"].copy()\n",
    "df_tv[\"diagnosis_binary\"] = df_tv[\"diagnosis_binary\"].astype(int)\n",
    "df_tv[\"cv_fold\"] = df_tv[\"cv_fold\"].astype(int)\n",
    "\n",
    "print(f\"Trainval slices: {len(df_tv):,}\")\n",
    "\n",
    "visits_tv = (\n",
    "    df_tv\n",
    "    .groupby([\"subject_id\", \"visit_uid\", \"cv_fold\"], as_index=False)\n",
    "    .agg({\n",
    "        \"diagnosis_binary\": \"first\",\n",
    "        \"slice_path\": \"count\"\n",
    "    })\n",
    "    .rename(columns={\"slice_path\": \"n_slices\"})\n",
    ")\n",
    "\n",
    "valid_visits = visits_tv[visits_tv[\"n_slices\"] == N_SLICES_PER_VISIT].copy()\n",
    "print(f\"Valid visits: {len(valid_visits):,}\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 2: TRANSFORMS (TUNED)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STEP 2: DEFINING TRANSFORMS (TUNED)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "imagenet_normalize = transforms.Normalize(\n",
    "    mean=[0.485, 0.456, 0.406],\n",
    "    std=[0.229, 0.224, 0.225]\n",
    ")\n",
    "\n",
    "# STRONGER AUGMENTATION\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(\n",
    "        size=(IMG_SIZE, IMG_SIZE),\n",
    "        scale=(0.8, 1.0),\n",
    "        ratio=(0.9, 1.1)\n",
    "    ),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    imagenet_normalize,\n",
    "])\n",
    "\n",
    "eval_transform = transforms.Compose([\n",
    "    transforms.Resize(int(IMG_SIZE * 1.125)),  # 180 for 160\n",
    "    transforms.CenterCrop(IMG_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    imagenet_normalize,\n",
    "])\n",
    "\n",
    "print(\"✓ Transforms defined\")\n",
    "print(f\"  Train: RandomResizedCrop({IMG_SIZE}×{IMG_SIZE})\")\n",
    "print(f\"  Eval:  Resize(180) → CenterCrop({IMG_SIZE})\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 3: DATASET\n",
    "# ============================================================================\n",
    "\n",
    "class VisitDataset(Dataset):\n",
    "    def __init__(self, visits_df, slices_df, transform=None):\n",
    "        self.visits_df = visits_df.reset_index(drop=True)\n",
    "        self.transform = transform\n",
    "        \n",
    "        grouped = slices_df.groupby(\"visit_uid\")\n",
    "        self.visit_to_slices = {\n",
    "            vid: g.sort_values(\"z_index\") \n",
    "            for vid, g in grouped\n",
    "        }\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.visits_df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.visits_df.iloc[idx]\n",
    "        visit_uid = row[\"visit_uid\"]\n",
    "        label = float(row[\"diagnosis_binary\"])\n",
    "        \n",
    "        slice_rows = self.visit_to_slices[visit_uid]\n",
    "        \n",
    "        imgs = []\n",
    "        for _, srow in slice_rows.iterrows():\n",
    "            arr = np.load(srow[\"slice_path\"]).astype(np.float32)\n",
    "            img_np = (arr * 255.0).clip(0, 255).astype(np.uint8)\n",
    "            img = Image.fromarray(img_np).convert(\"RGB\")\n",
    "            \n",
    "            if self.transform is not None:\n",
    "                img = self.transform(img)\n",
    "            \n",
    "            imgs.append(img)\n",
    "        \n",
    "        images = torch.stack(imgs, dim=0)\n",
    "        label = torch.tensor(label, dtype=torch.float32)\n",
    "        \n",
    "        return images, label, visit_uid\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 4: MODEL (TUNED WITH MORE DROPOUT)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STEP 4: MODEL DEFINITION (TUNED)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "def create_effnet_backbone():\n",
    "    try:\n",
    "        weights = models.EfficientNet_B0_Weights.IMAGENET1K_V1\n",
    "        effnet = models.efficientnet_b0(weights=weights)\n",
    "    except AttributeError:\n",
    "        effnet = models.efficientnet_b0(pretrained=True)\n",
    "    \n",
    "    feature_dim = effnet.classifier[1].in_features\n",
    "    effnet.classifier = nn.Identity()\n",
    "    \n",
    "    return effnet, feature_dim\n",
    "\n",
    "\n",
    "class EffNetB0VisitAttentionTuned(nn.Module):\n",
    "    \"\"\"Tuned with more dropout\"\"\"\n",
    "    def __init__(self, effnet_backbone, feature_dim, attn_hidden=128):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.backbone = effnet_backbone\n",
    "        self.feature_dim = feature_dim\n",
    "        \n",
    "        # Attention with dropout\n",
    "        self.att_fc = nn.Linear(feature_dim, attn_hidden)\n",
    "        self.att_dropout = nn.Dropout(p=0.2)  # NEW\n",
    "        self.att_vec = nn.Linear(attn_hidden, 1, bias=False)\n",
    "        \n",
    "        # Classifier with more dropout\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=0.3),  # INCREASED from 0.5\n",
    "            nn.Linear(feature_dim, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        B, N, C, H, W = x.shape\n",
    "        \n",
    "        x = x.view(B * N, C, H, W)\n",
    "        feats = self.backbone(x)\n",
    "        feats = feats.view(B, N, self.feature_dim)\n",
    "        \n",
    "        # Attention with dropout\n",
    "        att = torch.tanh(self.att_fc(feats))\n",
    "        att = self.att_dropout(att)  # NEW\n",
    "        att = self.att_vec(att).squeeze(-1)\n",
    "        alpha = torch.softmax(att, dim=1)\n",
    "        \n",
    "        alpha_expanded = alpha.unsqueeze(-1)\n",
    "        context = (alpha_expanded * feats).sum(dim=1)\n",
    "        \n",
    "        logits = self.classifier(context).squeeze(1)\n",
    "        \n",
    "        return logits, alpha\n",
    "\n",
    "print(\"✓ Model defined with enhanced regularization\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 5: 5-FOLD CV\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STEP 5: 5-FOLD CROSS-VALIDATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "fold_results = []\n",
    "\n",
    "for fold_id in range(N_FOLDS):\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(f\"FOLD {fold_id}\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    train_visits = valid_visits[valid_visits[\"cv_fold\"] != fold_id].copy()\n",
    "    val_visits = valid_visits[valid_visits[\"cv_fold\"] == fold_id].copy()\n",
    "    \n",
    "    print(f\"Train: {len(train_visits)}, Val: {len(val_visits)}\")\n",
    "    \n",
    "    train_labels = train_visits[\"diagnosis_binary\"].values\n",
    "    n_cn = (train_labels == 0).sum()\n",
    "    n_ad = (train_labels == 1).sum()\n",
    "    \n",
    "    if n_ad == 0:\n",
    "        print(f\"⚠️ Skipping fold {fold_id}\")\n",
    "        continue\n",
    "    \n",
    "    train_dataset = VisitDataset(train_visits, df_tv, train_transform)\n",
    "    val_dataset = VisitDataset(val_visits, df_tv, eval_transform)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
    "    \n",
    "    raw_pos_weight = n_cn / n_ad\n",
    "    pos_weight = min(raw_pos_weight, 3.0)\n",
    "    \n",
    "    effnet_backbone, feature_dim = create_effnet_backbone()\n",
    "    model = EffNetB0VisitAttentionTuned(effnet_backbone, feature_dim).to(DEVICE)\n",
    "    \n",
    "    pos_weight_tensor = torch.tensor([pos_weight], device=DEVICE)\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight_tensor)\n",
    "    \n",
    "    # TUNED OPTIMIZER\n",
    "    optimizer = torch.optim.Adam(\n",
    "        model.parameters(),\n",
    "        lr=LR,  # 5e-5\n",
    "        weight_decay=WEIGHT_DECAY\n",
    "    )\n",
    "    \n",
    "    # TUNED SCHEDULER\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer,\n",
    "        mode=\"min\",\n",
    "        factor=0.5,\n",
    "        patience=5,  # INCREASED\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    best_val_bal_acc = -np.inf\n",
    "    best_metrics = None\n",
    "    epochs_no_improve = 0\n",
    "    \n",
    "    print(f\"Training fold {fold_id}...\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    for epoch in range(1, NUM_EPOCHS + 1):\n",
    "        t0 = time.time()\n",
    "        \n",
    "        # Train\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        for images, labels, _ in train_loader:\n",
    "            images = images.to(DEVICE, non_blocking=True)\n",
    "            labels = labels.to(DEVICE)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            logits, _ = model(images)\n",
    "            loss = criterion(logits, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_losses.append(loss.item())\n",
    "        \n",
    "        train_loss = np.mean(train_losses)\n",
    "        \n",
    "        # Validate\n",
    "        model.eval()\n",
    "        val_losses = []\n",
    "        all_labels = []\n",
    "        all_probs = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, labels, _ in val_loader:\n",
    "                images = images.to(DEVICE, non_blocking=True)\n",
    "                labels = labels.to(DEVICE)\n",
    "                \n",
    "                logits, _ = model(images)\n",
    "                loss = criterion(logits, labels)\n",
    "                \n",
    "                val_losses.append(loss.item())\n",
    "                probs = torch.sigmoid(logits)\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "                all_probs.extend(probs.cpu().numpy())\n",
    "        \n",
    "        val_loss = np.mean(val_losses)\n",
    "        all_labels = np.array(all_labels)\n",
    "        all_probs = np.array(all_probs)\n",
    "        \n",
    "        try:\n",
    "            val_auc = roc_auc_score(all_labels, all_probs)\n",
    "        except:\n",
    "            val_auc = np.nan\n",
    "        \n",
    "        val_preds = (all_probs >= 0.5).astype(int)\n",
    "        val_acc = accuracy_score(all_labels, val_preds)\n",
    "        val_bal_acc = balanced_accuracy_score(all_labels, val_preds)\n",
    "        \n",
    "        cm = confusion_matrix(all_labels, val_preds, labels=[0, 1])\n",
    "        tn, fp, fn, tp = cm.ravel()\n",
    "        val_cn_acc = tn / (tn + fp) if (tn + fp) > 0 else 0.0\n",
    "        val_ad_acc = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "        \n",
    "        elapsed = time.time() - t0\n",
    "        \n",
    "        if epoch % 5 == 0 or epoch == 1:\n",
    "            print(f\"[Epoch {epoch:02d}] {elapsed:.1f}s | \"\n",
    "                  f\"loss: {train_loss:.4f}/{val_loss:.4f} | \"\n",
    "                  f\"auc: {val_auc:.4f} | bal_acc: {val_bal_acc:.4f} | \"\n",
    "                  f\"AD_acc: {val_ad_acc:.4f}\")\n",
    "        \n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        if val_bal_acc > best_val_bal_acc:\n",
    "            best_val_bal_acc = val_bal_acc\n",
    "            best_metrics = {\n",
    "                \"epoch\": epoch,\n",
    "                \"val_auc\": val_auc,\n",
    "                \"val_acc\": val_acc,\n",
    "                \"val_bal_acc\": val_bal_acc,\n",
    "                \"val_cn_acc\": val_cn_acc,\n",
    "                \"val_ad_acc\": val_ad_acc\n",
    "            }\n",
    "            \n",
    "            model_path = f\"{OUTPUT_ROOT}/effnetb0_multisite_tuned_fold{fold_id}.pth\"\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "        \n",
    "        if epochs_no_improve >= PATIENCE:\n",
    "            print(f\"  Early stopping at epoch {epoch}\")\n",
    "            break\n",
    "    \n",
    "    print(\"-\" * 60)\n",
    "    print(f\"✓ Fold {fold_id} complete\")\n",
    "    print(f\"  Best: bal_acc={best_val_bal_acc:.4f}, auc={best_metrics['val_auc']:.4f}, AD_acc={best_metrics['val_ad_acc']:.4f}\")\n",
    "    \n",
    "    fold_results.append({\n",
    "        \"fold\": fold_id,\n",
    "        **best_metrics\n",
    "    })\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 6: AGGREGATE RESULTS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"CROSS-VALIDATION RESULTS (TUNED)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "results_df = pd.DataFrame(fold_results)\n",
    "results_df.to_csv(CV_RESULTS_CSV, index=False)\n",
    "\n",
    "print(f\"\\n✓ Results saved: {CV_RESULTS_CSV}\")\n",
    "\n",
    "metrics = [\"val_auc\", \"val_acc\", \"val_bal_acc\", \"val_cn_acc\", \"val_ad_acc\"]\n",
    "\n",
    "print(f\"\\n{'Metric':<15} {'Mean':<8} {'Std':<8} {'Min':<8} {'Max':<8}\")\n",
    "print(\"-\" * 55)\n",
    "\n",
    "summary = {}\n",
    "for metric in metrics:\n",
    "    values = results_df[metric].values\n",
    "    mean_val = np.mean(values)\n",
    "    std_val = np.std(values)\n",
    "    min_val = np.min(values)\n",
    "    max_val = np.max(values)\n",
    "    \n",
    "    summary[metric] = {\"mean\": mean_val, \"std\": std_val}\n",
    "    \n",
    "    print(f\"{metric:<15} {mean_val:>7.4f} {std_val:>7.4f} {min_val:>7.4f} {max_val:>7.4f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 7: COMPARISON WITH S15\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"COMPARISON: S15 vs S16\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# You'll fill these in manually after running S15\n",
    "s15_results = {\n",
    "    \"val_auc\": 0.850,      # PLACEHOLDER\n",
    "    \"val_bal_acc\": 0.780,  # PLACEHOLDER\n",
    "    \"val_ad_acc\": 0.720    # PLACEHOLDER\n",
    "}\n",
    "\n",
    "mean_auc = summary[\"val_auc\"][\"mean\"]\n",
    "mean_bal_acc = summary[\"val_bal_acc\"][\"mean\"]\n",
    "mean_ad_recall = summary[\"val_ad_acc\"][\"mean\"]\n",
    "\n",
    "print(f\"\\n{'Metric':<15} {'S15 (Base)':<12} {'S16 (Tuned)':<12} {'Δ':<8}\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"{'AUC':<15} {s15_results['val_auc']:>11.4f} {mean_auc:>11.4f} {mean_auc - s15_results['val_auc']:>+7.4f}\")\n",
    "print(f\"{'Balanced ACC':<15} {s15_results['val_bal_acc']:>11.4f} {mean_bal_acc:>11.4f} {mean_bal_acc - s15_results['val_bal_acc']:>+7.4f}\")\n",
    "print(f\"{'AD Recall':<15} {s15_results['val_ad_acc']:>11.4f} {mean_ad_recall:>11.4f} {mean_ad_recall - s15_results['val_ad_acc']:>+7.4f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 8: DECISION CRITERIA\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"PERFORMANCE ASSESSMENT\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\\nS16 Mean metrics (5-fold CV):\")\n",
    "print(f\"  AUC:          {mean_auc:.4f}\")\n",
    "print(f\"  Balanced ACC: {mean_bal_acc:.4f}\")\n",
    "print(f\"  AD Recall:    {mean_ad_recall:.4f}\")\n",
    "\n",
    "print(f\"\\nTargets:\")\n",
    "print(f\"  AUC:          ≥ 0.87\")\n",
    "print(f\"  Balanced ACC: ≥ 0.82\")\n",
    "print(f\"  AD Recall:    ≥ 0.75\")\n",
    "\n",
    "if mean_auc >= 0.87 and mean_bal_acc >= 0.82 and mean_ad_recall >= 0.75:\n",
    "    print(f\"\\n🎉 SUCCESS: All targets met!\")\n",
    "    print(f\"\\nNext step: S17 (Test set evaluation + ensemble)\")\n",
    "    decision = \"SUCCESS\"\n",
    "elif mean_auc >= 0.85 and mean_bal_acc >= 0.78:\n",
    "    print(f\"\\n✅ NEAR TARGET: Close enough to proceed\")\n",
    "    print(f\"\\nNext step: S17 (Test set evaluation)\")\n",
    "    print(f\"  Focus on XAI novelties rather than pushing classification further\")\n",
    "    decision = \"ACCEPTABLE\"\n",
    "else:\n",
    "    print(f\"\\n⚠️ BELOW TARGET\")\n",
    "    print(f\"\\nOptions:\")\n",
    "    print(f\"  1. Accept current performance, focus on XAI\")\n",
    "    print(f\"  2. Try architectural changes (not recommended)\")\n",
    "    decision = \"REVIEW\"\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SNIPPET S16 COMPLETE\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nDecision: {decision}\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 1980,
     "sourceId": 3398,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8690252,
     "sourceId": 13667832,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8691044,
     "sourceId": 13668930,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8746096,
     "sourceId": 13745173,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8747805,
     "sourceId": 13747487,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 8717.399995,
   "end_time": "2025-11-17T21:15:48.733738",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-17T18:50:31.333743",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
