{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tousifo/ml_notebooks/blob/main/als_pro_act.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# -------------------------------\n",
        "# 1. Load all relevant CSV tables\n",
        "# -------------------------------\n",
        "alsfrs_df = pd.read_csv('PROACT_ALSFRS.csv')\n",
        "fvc_df = pd.read_csv('PROACT_FVC.csv')\n",
        "vitals_df = pd.read_csv('PROACT_VITALSIGNS.csv')\n",
        "labs_df = pd.read_csv('PROACT_LABS.csv')\n",
        "onset_df = pd.read_csv('PROACT_ALSHISTORY.csv')\n",
        "riluzole_df = pd.read_csv('PROACT_RILUZOLE.csv')\n",
        "demographics_df = pd.read_csv('PROACT_DEMOGRAPHICS.csv')\n",
        "\n",
        "# -------------------------------\n",
        "# 2. Compute ALSFRS (convert ALSFRS-R to original if needed)\n",
        "# -------------------------------\n",
        "def convert_alsfrs_row(row):\n",
        "    if pd.notna(row.get('ALSFRS_Total')):\n",
        "        return row['ALSFRS_Total']\n",
        "    total = 0\n",
        "    for q in range(1, 10):\n",
        "        val = row.get(f'Q{q}', np.nan)\n",
        "        if pd.notna(val):\n",
        "            total += val\n",
        "    # Handle Q10 (respiratory)\n",
        "    if pd.notna(row.get('Q10_Respiratory')):\n",
        "        total += row['Q10_Respiratory']\n",
        "    elif pd.notna(row.get('R_1_Dyspnea')):\n",
        "        total += row.get('R_1_Dyspnea')\n",
        "    return total\n",
        "\n",
        "alsfrs_df['ALSFRS_Total_orig'] = alsfrs_df.apply(convert_alsfrs_row, axis=1)\n",
        "\n",
        "# -------------------------------\n",
        "# 3. Identify valid patients\n",
        "# -------------------------------\n",
        "months_start, months_end = 3, 12\n",
        "min_records_start, min_records_end = 2, 2\n",
        "days_start, days_end = months_start * 30, months_end * 30\n",
        "\n",
        "alsfrs_counts = alsfrs_df.groupby('subject_id')['ALSFRS_Delta'].agg(\n",
        "    records_before_start=lambda x: (x <= days_start).sum(),\n",
        "    records_after_end=lambda x: (x >= days_end).sum()\n",
        ")\n",
        "\n",
        "valid_patients_df = alsfrs_counts[\n",
        "    (alsfrs_counts['records_before_start'] >= min_records_start) &\n",
        "    (alsfrs_counts['records_after_end'] >= min_records_end)\n",
        "]\n",
        "valid_patients = sorted(valid_patients_df.index.tolist())\n",
        "\n",
        "print(f\"✅ Valid patients: {len(valid_patients)}\")\n",
        "\n",
        "# -------------------------------\n",
        "# 4. Compute ALSFRS slope (3–12 months)\n",
        "# -------------------------------\n",
        "slope_targets = {}\n",
        "for pid in valid_patients:\n",
        "    patient_data = alsfrs_df[alsfrs_df['subject_id'] == pid].copy()\n",
        "    patient_data.sort_values('ALSFRS_Delta', inplace=True)\n",
        "    t1 = patient_data[patient_data['ALSFRS_Delta'] > 90]\n",
        "    t2 = patient_data[patient_data['ALSFRS_Delta'] >= 365]\n",
        "    if len(t1) > 0 and len(t2) > 0:\n",
        "        t1_record = t1.iloc[0]\n",
        "        t2_record = t2.iloc[0]\n",
        "        delta_days = t2_record['ALSFRS_Delta'] - t1_record['ALSFRS_Delta']\n",
        "        if delta_days > 0:\n",
        "            slope = (t2_record['ALSFRS_Total_orig'] - t1_record['ALSFRS_Total_orig']) / (delta_days / 30.0)\n",
        "            slope_targets[pid] = slope\n",
        "\n",
        "target_df = pd.Series(slope_targets, name='ALSFRS_slope_3to12m')\n",
        "print(\"✅ ALSFRS slope computed for\", len(target_df), \"patients\")\n",
        "print(target_df.describe())\n",
        "\n",
        "# -------------------------------\n",
        "# 5. Helper: summarize all numeric columns in a time-series table\n",
        "# -------------------------------\n",
        "def summarize_timeseries(df, time_col, value_col):\n",
        "    grp = df.groupby('subject_id')\n",
        "    summary = pd.DataFrame({\n",
        "        'min': grp[value_col].min(),\n",
        "        'max': grp[value_col].max(),\n",
        "        'median': grp[value_col].median(),\n",
        "        'std': grp[value_col].std(),\n",
        "        'first': grp.apply(lambda g: g.sort_values(time_col)[value_col].iloc[0], include_groups=False),\n",
        "        'last': grp.apply(lambda g: g.sort_values(time_col)[value_col].iloc[-1], include_groups=False)\n",
        "    })\n",
        "    time_first = grp[time_col].min()\n",
        "    time_last = grp[time_col].max()\n",
        "    time_diff_months = (time_last - time_first) / 30.0\n",
        "    summary['slope'] = (summary['last'] - summary['first']) / time_diff_months\n",
        "    summary.loc[time_diff_months == 0, 'slope'] = np.nan\n",
        "    return summary\n",
        "\n",
        "def summarize_all_numeric(df, time_col):\n",
        "    numeric_cols = df.select_dtypes(include=['number']).columns.drop([time_col, 'subject_id'], errors='ignore') # Exclude subject_id\n",
        "    summaries = {}\n",
        "    for col in numeric_cols:\n",
        "        summaries[col] = summarize_timeseries(df, time_col, col)\n",
        "        summaries[col].columns = [f'{col}_{c}' for c in summaries[col].columns]\n",
        "    return summaries\n",
        "\n",
        "# -------------------------------\n",
        "# 6. Subset to first 90 days and summarize automatically\n",
        "# -------------------------------\n",
        "alsfrs_3m = alsfrs_df[alsfrs_df['subject_id'].isin(valid_patients) & (alsfrs_df['ALSFRS_Delta'] <= 90)]\n",
        "fvc_df['FVC'] = fvc_df[['Subject_Liters_Trial_1','Subject_Liters_Trial_2','Subject_Liters_Trial_3']].max(axis=1)\n",
        "fvc_3m = fvc_df[fvc_df['subject_id'].isin(valid_patients) & (fvc_df['Forced_Vital_Capacity_Delta'] <= 90)]\n",
        "vitals_3m = vitals_df[vitals_df['subject_id'].isin(valid_patients) & (vitals_df['Vital_Signs_Delta'] <= 90)]\n",
        "labs_3m = labs_df[labs_df['subject_id'].isin(valid_patients) & (labs_df['Laboratory_Delta'] <= 90)]\n",
        "\n",
        "alsfrs_features = summarize_all_numeric(alsfrs_3m, 'ALSFRS_Delta')\n",
        "fvc_features = summarize_all_numeric(fvc_3m, 'Forced_Vital_Capacity_Delta')\n",
        "vitals_features = summarize_all_numeric(vitals_3m, 'Vital_Signs_Delta')\n",
        "labs_features = summarize_all_numeric(labs_3m, 'Laboratory_Delta')\n",
        "\n",
        "\n",
        "# -------------------------------\n",
        "# 7. Merge all features\n",
        "# -------------------------------\n",
        "features_df = pd.DataFrame(index=valid_patients)\n",
        "\n",
        "# Select relevant columns from static tables and set index\n",
        "onset_static = onset_df.drop_duplicates(subset='subject_id', keep='first').set_index('subject_id')[['Site_of_Onset', 'Onset_Delta', 'Diagnosis_Delta']]\n",
        "riluzole_static = riluzole_df.drop_duplicates(subset='subject_id', keep='first').set_index('subject_id')[['Subject_used_Riluzole', 'Riluzole_use_Delta']]\n",
        "demographics_static = demographics_df.drop_duplicates(subset='subject_id', keep='first').set_index('subject_id')[['Age', 'Sex']]\n",
        "\n",
        "\n",
        "# Join static tables with suffixes\n",
        "features_df = features_df.join(onset_static, how='left')\n",
        "features_df = features_df.join(riluzole_static, how='left', rsuffix='_rilu')\n",
        "features_df = features_df.join(demographics_static, how='left', rsuffix='_demo')\n",
        "\n",
        "\n",
        "# Add dynamic (summarized) features\n",
        "for group in [alsfrs_features, fvc_features, vitals_features, labs_features]:\n",
        "    for feat_df in group.values():\n",
        "        features_df = features_df.join(feat_df, how='left')\n",
        "\n",
        "\n",
        "# Add slope target\n",
        "features_df = features_df.join(target_df, how='left')\n",
        "\n",
        "# -------------------------------\n",
        "# 8. Clean up\n",
        "# -------------------------------\n",
        "features_df = features_df.dropna(axis=1, how='all')\n",
        "features_df = features_df.loc[:, features_df.nunique() > 1]\n",
        "\n",
        "print(f\"✅ Final features shape: {features_df.shape}\")\n",
        "print(features_df.head(3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TgwkVE8D4wRY",
        "outputId": "b9559510-9c75-4336-d25e-f0e6bf70e2f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Valid patients: 2442\n",
            "✅ ALSFRS slope computed for 2439 patients\n",
            "count    2439.000000\n",
            "mean       -0.388076\n",
            "std         0.496497\n",
            "min        -3.100000\n",
            "25%        -0.638298\n",
            "50%        -0.218978\n",
            "75%         0.000000\n",
            "max         1.052632\n",
            "Name: ALSFRS_slope_3to12m, dtype: float64\n",
            "✅ Final features shape: (2442, 330)\n",
            "      Site_of_Onset  Onset_Delta  Diagnosis_Delta Subject_used_Riluzole  \\\n",
            "121     Onset: Limb          NaN              NaN                   Yes   \n",
            "1009   Onset: Other       -324.0            -63.0                   Yes   \n",
            "1036  Onset: Bulbar          NaN              NaN                   NaN   \n",
            "\n",
            "      Riluzole_use_Delta   Age     Sex  Q1_Speech_min  Q1_Speech_max  \\\n",
            "121                  0.0  52.0  Female            4.0            4.0   \n",
            "1009                 0.0  51.0    Male            4.0            4.0   \n",
            "1036                 NaN  67.0  Female            3.0            3.0   \n",
            "\n",
            "      Q1_Speech_median  ...  Standing_BP_Diastolic_max  \\\n",
            "121                4.0  ...                        NaN   \n",
            "1009               4.0  ...                        NaN   \n",
            "1036               3.0  ...                        NaN   \n",
            "\n",
            "      Standing_BP_Diastolic_median  Standing_BP_Diastolic_first  \\\n",
            "121                            NaN                          NaN   \n",
            "1009                           NaN                          NaN   \n",
            "1036                           NaN                          NaN   \n",
            "\n",
            "      Standing_BP_Diastolic_last  Standing_BP_Systolic_min  \\\n",
            "121                          NaN                       NaN   \n",
            "1009                         NaN                       NaN   \n",
            "1036                         NaN                       NaN   \n",
            "\n",
            "      Standing_BP_Systolic_max  Standing_BP_Systolic_median  \\\n",
            "121                        NaN                          NaN   \n",
            "1009                       NaN                          NaN   \n",
            "1036                       NaN                          NaN   \n",
            "\n",
            "      Standing_BP_Systolic_first  Standing_BP_Systolic_last  \\\n",
            "121                          NaN                        NaN   \n",
            "1009                         NaN                        NaN   \n",
            "1036                         NaN                        NaN   \n",
            "\n",
            "      ALSFRS_slope_3to12m  \n",
            "121             -1.058824  \n",
            "1009             0.000000  \n",
            "1036                  NaN  \n",
            "\n",
            "[3 rows x 330 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features_df.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "8FvNDrtz7VbD",
        "outputId": "ca2b00a3-41aa-4755-c743-49555e49fd7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Site_of_Onset  Onset_Delta  Diagnosis_Delta Subject_used_Riluzole  \\\n",
              "121     Onset: Limb          NaN              NaN                   Yes   \n",
              "1009   Onset: Other       -324.0            -63.0                   Yes   \n",
              "1036  Onset: Bulbar          NaN              NaN                   NaN   \n",
              "\n",
              "      Riluzole_use_Delta   Age     Sex  Q1_Speech_min  Q1_Speech_max  \\\n",
              "121                  0.0  52.0  Female            4.0            4.0   \n",
              "1009                 0.0  51.0    Male            4.0            4.0   \n",
              "1036                 NaN  67.0  Female            3.0            3.0   \n",
              "\n",
              "      Q1_Speech_median  ...  Standing_BP_Diastolic_max  \\\n",
              "121                4.0  ...                        NaN   \n",
              "1009               4.0  ...                        NaN   \n",
              "1036               3.0  ...                        NaN   \n",
              "\n",
              "      Standing_BP_Diastolic_median  Standing_BP_Diastolic_first  \\\n",
              "121                            NaN                          NaN   \n",
              "1009                           NaN                          NaN   \n",
              "1036                           NaN                          NaN   \n",
              "\n",
              "      Standing_BP_Diastolic_last  Standing_BP_Systolic_min  \\\n",
              "121                          NaN                       NaN   \n",
              "1009                         NaN                       NaN   \n",
              "1036                         NaN                       NaN   \n",
              "\n",
              "      Standing_BP_Systolic_max  Standing_BP_Systolic_median  \\\n",
              "121                        NaN                          NaN   \n",
              "1009                       NaN                          NaN   \n",
              "1036                       NaN                          NaN   \n",
              "\n",
              "      Standing_BP_Systolic_first  Standing_BP_Systolic_last  \\\n",
              "121                          NaN                        NaN   \n",
              "1009                         NaN                        NaN   \n",
              "1036                         NaN                        NaN   \n",
              "\n",
              "      ALSFRS_slope_3to12m  \n",
              "121             -1.058824  \n",
              "1009             0.000000  \n",
              "1036                  NaN  \n",
              "\n",
              "[3 rows x 330 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1e1c7279-4172-46e0-a26f-f4713e68d3dc\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Site_of_Onset</th>\n",
              "      <th>Onset_Delta</th>\n",
              "      <th>Diagnosis_Delta</th>\n",
              "      <th>Subject_used_Riluzole</th>\n",
              "      <th>Riluzole_use_Delta</th>\n",
              "      <th>Age</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Q1_Speech_min</th>\n",
              "      <th>Q1_Speech_max</th>\n",
              "      <th>Q1_Speech_median</th>\n",
              "      <th>...</th>\n",
              "      <th>Standing_BP_Diastolic_max</th>\n",
              "      <th>Standing_BP_Diastolic_median</th>\n",
              "      <th>Standing_BP_Diastolic_first</th>\n",
              "      <th>Standing_BP_Diastolic_last</th>\n",
              "      <th>Standing_BP_Systolic_min</th>\n",
              "      <th>Standing_BP_Systolic_max</th>\n",
              "      <th>Standing_BP_Systolic_median</th>\n",
              "      <th>Standing_BP_Systolic_first</th>\n",
              "      <th>Standing_BP_Systolic_last</th>\n",
              "      <th>ALSFRS_slope_3to12m</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>121</th>\n",
              "      <td>Onset: Limb</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Yes</td>\n",
              "      <td>0.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>Female</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-1.058824</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1009</th>\n",
              "      <td>Onset: Other</td>\n",
              "      <td>-324.0</td>\n",
              "      <td>-63.0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>0.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>Male</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1036</th>\n",
              "      <td>Onset: Bulbar</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>67.0</td>\n",
              "      <td>Female</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3 rows × 330 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1e1c7279-4172-46e0-a26f-f4713e68d3dc')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1e1c7279-4172-46e0-a26f-f4713e68d3dc button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1e1c7279-4172-46e0-a26f-f4713e68d3dc');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-5379d122-6b1e-4b76-a510-bcf8e827eaa7\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5379d122-6b1e-4b76-a510-bcf8e827eaa7')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-5379d122-6b1e-4b76-a510-bcf8e827eaa7 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "features_df"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ua5B00YFOE8p"
      },
      "outputs": [],
      "source": [
        "# import pandas as pd\n",
        "\n",
        "# # Load CSV files (assuming they are in the working directory or mounted drive)\n",
        "# alsfrs_df = pd.read_csv('PROACT_ALSFRS.csv')\n",
        "# fvc_df = pd.read_csv('PROACT_FVC.csv')\n",
        "# vitals_df = pd.read_csv('PROACT_VITALSIGNS.csv')\n",
        "# labs_df = pd.read_csv('PROACT_LABS.csv')\n",
        "# onset_df = pd.read_csv('PROACT_ALSHISTORY.csv')\n",
        "# riluzole_df = pd.read_csv('PROACT_RILUZOLE.csv')\n",
        "# # (Load other tables like Demographics if available)\n",
        "# demographics_df = pd.read_csv('PROACT_DEMOGRAPHICS.csv')\n",
        "\n",
        "# # Convert ALSFRS-R to ALSFRS (original 0-40 scale) according to guidelines:contentReference[oaicite:5]{index=5}.\n",
        "# def convert_alsfrs_row(row):\n",
        "#     # If original ALSFRS total is present, use it\n",
        "#     if pd.notna(row['ALSFRS_Total']):\n",
        "#         return row['ALSFRS_Total']\n",
        "#     # Otherwise, use ALSFRS-R values to compute original total\n",
        "#     total = 0\n",
        "#     # Sum questions 1–9 (same in ALSFRS and ALSFRS-R)\n",
        "#     for q in range(1, 10):\n",
        "#         total += row.get(f'Q{q}_{alsfrs_df.columns[1+ (q-1)]}', 0)  # using actual Q# columns\n",
        "#     # For Q10, use R_1_Dyspnea if available (ALSFRS-R) or Q10_Respiratory if original\n",
        "#     if pd.notna(row.get('Q10_Respiratory')):\n",
        "#         total += row['Q10_Respiratory']\n",
        "#     elif pd.notna(row.get('R_1_Dyspnea')):\n",
        "#         total += row.get('R_1_Dyspnea', 0) # Added default value 0 for get\n",
        "#     # Merge Q5a and Q5b (if one is NaN, use the other)\n",
        "#     # (Already counted in sum above if present; ensure not double-counted)\n",
        "#     return total\n",
        "\n",
        "# alsfrs_df['ALSFRS_Total_orig'] = alsfrs_df.apply(convert_alsfrs_row, axis=1)\n",
        "\n",
        "# # Determine patients with required ALSFRS timeline\n",
        "# # ALSFRS_Delta is time (days) since first ALSFRS (baseline)\n",
        "\n",
        "# # Define the number of months and minimum records\n",
        "# months_start = 3  # First threshold in months\n",
        "# months_end = 12   # Second threshold in months\n",
        "# min_records_start = 2 # Minimum records before months_start\n",
        "# min_records_end = 2   # Minimum records after months_end\n",
        "\n",
        "# days_start = months_start * 30 # Convert months to days\n",
        "# days_end = months_end * 30   # Convert months to days\n",
        "\n",
        "# # Group by patient and count records within the specified timeframes\n",
        "# alsfrs_counts = alsfrs_df.groupby('subject_id')['ALSFRS_Delta'].agg(\n",
        "#     records_before_start=lambda x: (x <= days_start).sum(),\n",
        "#     records_after_end=lambda x: (x >= days_end).sum()\n",
        "# )\n",
        "\n",
        "# # Filter patients based on minimum record counts\n",
        "# valid_patients_df = alsfrs_counts[(alsfrs_counts['records_before_start'] >= min_records_start) &\n",
        "#                                   (alsfrs_counts['records_after_end'] >= min_records_end)]\n",
        "\n",
        "# valid_patients = sorted(valid_patients_df.index.tolist())\n",
        "\n",
        "# print(f\"Patients with ≥{min_records_start} ALSFRS in first {months_start} mo and ≥{min_records_end} after {months_end} mo: {len(valid_patients)}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# alsfrs_counts = alsfrs_df.groupby('subject_id')['ALSFRS_Delta'].agg(\n",
        "#     count_first_3m=lambda x: (x <= 90).sum(),\n",
        "#     count_after_12m=lambda x: (x >= 365).sum()\n",
        "# )\n",
        "\n",
        "# # Filter for patients with at least 2 records in each window\n",
        "# valid_patients_df = alsfrs_counts[(alsfrs_counts['count_first_3m'] >= 2) & (alsfrs_counts['count_after_12m'] >= 2)]\n",
        "# valid_patients = sorted(valid_patients_df.index.tolist())\n",
        "\n",
        "# print(f\"Patients with ≥2 ALSFRS in first 3 mo and ≥2 after 12 mo: {len(valid_patients)}\")"
      ],
      "metadata": {
        "id": "w9Oh2f19s2m2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Count records with at least 2 ALSFRS in the first 3 months\n",
        "# count_at_least_2_first_3m = alsfrs_counts[alsfrs_counts['count_first_3m'] >= 2].shape[0]\n",
        "# print(f\"Number of records with ≥2 ALSFRS in first 3 months: {count_at_least_2_first_3m}\")\n",
        "\n",
        "# # Count records with at least 2 ALSFRS after 12 months\n",
        "# count_at_least_2_after_12m = alsfrs_counts[alsfrs_counts['count_after_12m'] >= 2].shape[0]\n",
        "# print(f\"Number of records with ≥2 ALSFRS after 12 months: {count_at_least_2_after_12m}\")"
      ],
      "metadata": {
        "id": "LreaJOlXtFSD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Compute ALSFRS slope (points/month) for each valid patient\n",
        "# slope_targets = {}\n",
        "# for pid in valid_patients:\n",
        "#     patient_data = alsfrs_df[alsfrs_df['subject_id'] == pid].copy()\n",
        "#     patient_data.sort_values('ALSFRS_Delta', inplace=True)\n",
        "#     # t1: first ALSFRS after 3 months (90 days), t2: first ALSFRS after 12 months (365 days)\n",
        "#     t1_record = patient_data[patient_data['ALSFRS_Delta'] > 90].iloc[0]\n",
        "#     t2_record = patient_data[patient_data['ALSFRS_Delta'] >= 365].iloc[0]\n",
        "#     # Calculate slope in ALSFRS points per month\n",
        "#     delta_days = t2_record['ALSFRS_Delta'] - t1_record['ALSFRS_Delta']\n",
        "#     if delta_days > 0:\n",
        "#         slope = (t2_record['ALSFRS_Total_orig'] - t1_record['ALSFRS_Total_orig']) / (delta_days / 30.0)\n",
        "#         slope_targets[pid] = slope\n",
        "# target_df = pd.Series(slope_targets, name='ALSFRS_slope_3to12m')\n",
        "# print(target_df.describe())  # inspect target distribution\n"
      ],
      "metadata": {
        "id": "fQuVa6F4OM9_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import numpy as np\n",
        "\n",
        "# # Helper to compute summary stats for a given patient series\n",
        "# def summarize_timeseries(df, time_col, value_col):\n",
        "#     grp = df.groupby('subject_id')\n",
        "#     summary = pd.DataFrame({\n",
        "#         'min': grp[value_col].min(),\n",
        "#         'max': grp[value_col].max(),\n",
        "#         'median': grp[value_col].median(),\n",
        "#         'std': grp[value_col].std(),\n",
        "#         'first': grp.apply(lambda g: g.sort_values(time_col)[value_col].iloc[0]),\n",
        "#         'last': grp.apply(lambda g: g.sort_values(time_col)[value_col].iloc[-1])\n",
        "#     })\n",
        "#     # Compute slope = (last - first) / (time_diff in months)\n",
        "#     time_first = grp[time_col].min()\n",
        "#     time_last = grp[time_col].max()\n",
        "#     time_diff_months = (time_last - time_first) / 30.0\n",
        "#     summary['slope'] = (summary['last'] - summary['first']) / time_diff_months\n",
        "#     # If only one observation, slope will be NaN (time_diff=0) as per guidelines\n",
        "#     summary.loc[time_diff_months == 0, 'slope'] = np.nan\n",
        "#     return summary\n",
        "\n",
        "# # Filter data to first 90 days\n",
        "# alsfrs_3m = alsfrs_df[alsfrs_df['subject_id'].isin(valid_patients) & (alsfrs_df['ALSFRS_Delta'] <= 90)]\n",
        "# fvc_df['FVC'] = fvc_df[['Subject_Liters_Trial_1','Subject_Liters_Trial_2','Subject_Liters_Trial_3']].max(axis=1)\n",
        "# fvc_3m = fvc_df[fvc_df['subject_id'].isin(valid_patients) & (fvc_df['Forced_Vital_Capacity_Delta'] <= 90)]\n",
        "# vitals_3m = vitals_df[vitals_df['subject_id'].isin(valid_patients) & (vitals_df['Vital_Signs_Delta'] <= 90)]\n",
        "# labs_3m = labs_df[labs_df['subject_id'].isin(valid_patients) & (labs_df['Laboratory_Delta'] <= 90)]\n",
        "\n",
        "# # Compute summaries for ALSFRS (using ALSFRS_Total_orig)\n",
        "# alsfrs_summary = summarize_timeseries(alsfrs_3m, 'ALSFRS_Delta', 'ALSFRS_Total_orig')\n",
        "# alsfrs_summary.columns = [f'ALSFRS_{col}' for col in alsfrs_summary.columns]\n",
        "\n",
        "# # Compute summaries for FVC (using max FVC per visit)\n",
        "# fvc_summary = summarize_timeseries(fvc_3m, 'Forced_Vital_Capacity_Delta', 'FVC')\n",
        "# fvc_summary.columns = [f'FVC_{col}' for col in fvc_summary.columns]\n",
        "\n",
        "# # Vital signs: Weight, Blood Pressure (Sys/Dia), Pulse, Respiratory Rate\n",
        "# vital_features = {}\n",
        "# for feat in ['Weight', 'Blood_Pressure_Systolic', 'Blood_Pressure_Diastolic', 'Pulse', 'Respiratory_Rate']:\n",
        "#     sub_df = vitals_3m[vitals_3m[feat].notna()]\n",
        "#     vital_features[feat] = summarize_timeseries(sub_df, 'Vital_Signs_Delta', feat)\n",
        "#     vital_features[feat].columns = [f'{feat}_{col}' for col in vital_features[feat].columns]\n",
        "\n",
        "# # Lab tests: select top lab features (based on data availability >70%)\n",
        "# top_lab_tests = ['ALT(SGPT)','AST(SGOT)','Creatinine','Albumin','Hemoglobin','White Blood Cell (WBC)']\n",
        "# lab_features = {}\n",
        "# for test in top_lab_tests:\n",
        "#     sub_df = labs_3m[labs_3m['Test_Name'] == test].copy()\n",
        "#     # Convert lab results to numeric (coerce non-numeric to NaN)\n",
        "#     sub_df['Test_Result'] = pd.to_numeric(sub_df['Test_Result'], errors='coerce')\n",
        "#     sub_df = sub_df[sub_df['Test_Result'].notna()]\n",
        "#     lab_features[test] = summarize_timeseries(sub_df, 'Laboratory_Delta', 'Test_Result')\n",
        "#     prefix = ''.join(ch for ch in test if ch.isalnum() or ch == '_')\n",
        "#     lab_features[test].columns = [f'{prefix}_{col}' for col in lab_features[test].columns]\n",
        "\n",
        "# # Compile all features into one DataFrame\n",
        "# features_df = pd.DataFrame(index=valid_patients)\n",
        "# # Static features: onset delta (time from onset to baseline), onset site, riluzole usage\n",
        "# # Onset delta (in months)\n",
        "# onset_df = onset_df.drop_duplicates(subset='subject_id', keep='first')  # one record per patient\n",
        "# features_df['Onset_Delta_months'] = -onset_df.set_index('subject_id')['Onset_Delta'] / 30.0  # negative stored, make positive months\n",
        "# # Onset site (bulbar vs limb etc.)\n",
        "# features_df = features_df.join(pd.get_dummies(onset_df.set_index('subject_id')['Site_of_Onset'], prefix='Site'))\n",
        "# # Riluzole usage (Yes=1, No=0)\n",
        "# riluzole_usage = riluzole_df.drop_duplicates('subject_id').set_index('subject_id')['Subject_used_Riluzole'].map({'Yes':1, 'No':0})\n",
        "# features_df['Riluzole'] = riluzole_usage\n",
        "# features_df.fillna({'Riluzole': 0}, inplace=True)  # assume missing as No\n",
        "\n",
        "# # Demographics\n",
        "# demographics_df = demographics_df.drop_duplicates(subset='subject_id', keep='first').copy()\n",
        "# features_df = features_df.join(demographics_df.set_index('subject_id')[['Age', 'Sex']], how='left')\n",
        "# features_df = features_df.join(pd.get_dummies(demographics_df.set_index('subject_id')['Sex'], prefix='Sex'), how='left')\n",
        "\n",
        "# # Merge longitudinal summary features\n",
        "# features_df = features_df.join(alsfrs_summary, how='left')\n",
        "# features_df = features_df.join(fvc_summary, how='left')\n",
        "# for feat_df in vital_features.values():\n",
        "#     features_df = features_df.join(feat_df, how='left')\n",
        "# for lab_df in lab_features.values():\n",
        "#     features_df = features_df.join(lab_df, how='left')\n",
        "\n",
        "# print(\"Total feature columns before cleaning:\", features_df.shape[1])\n",
        "# features_df.head(3)\n"
      ],
      "metadata": {
        "id": "74JjK--WOURp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop features with >30% missing\n",
        "missing_frac = features_df.isna().mean()\n",
        "drop_cols = missing_frac[missing_frac > 0.30].index\n",
        "features_df.drop(columns=drop_cols, inplace=True)\n",
        "print(f\"Dropped {len(drop_cols)} features due to >30% missing data\")\n",
        "\n",
        "# Impute remaining missing values\n",
        "for col in features_df.columns:\n",
        "    if features_df[col].isna().any():\n",
        "        if features_df[col].dtype in [np.float64, np.int64]:\n",
        "            # continuous: use median\n",
        "            features_df[col].fillna(features_df[col].median(), inplace=True)\n",
        "        else:\n",
        "            # discrete/categorical: use mode\n",
        "            features_df[col].fillna(features_df[col].mode()[0], inplace=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1Wc8ochOZ-z",
        "outputId": "cd6774d4-4b3f-4ba4-a15c-ca148eb9c61b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dropped 202 features due to >30% missing data\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4145066154.py:15: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  features_df[col].fillna(features_df[col].mode()[0], inplace=True)\n",
            "/tmp/ipython-input-4145066154.py:12: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  features_df[col].fillna(features_df[col].median(), inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Align X and y on common patient IDs (prevents KeyError) ---\n",
        "common_ids = features_df.index.intersection(target_df.index)\n",
        "\n",
        "X = features_df.loc[common_ids].copy()\n",
        "y = target_df.loc[common_ids].copy()\n",
        "\n",
        "# Drop the original 'Sex' column and the 'Sex_demo' column if they exist\n",
        "X = X.drop(columns=['Sex', 'Sex_demo'], errors='ignore')\n",
        "\n",
        "# Handle categorical features (Site_of_Onset)\n",
        "# One-hot encode 'Site_of_Onset'\n",
        "X = pd.get_dummies(X, columns=['Site_of_Onset'], prefix='Site', dummy_na=False)\n",
        "\n",
        "# Convert 'Subject_used_Riluzole' to numerical (1 for Yes, 0 for No)\n",
        "if 'Subject_used_Riluzole' in X.columns:\n",
        "    X['Subject_used_Riluzole'] = X['Subject_used_Riluzole'].map({'Yes': 1, 'No': 0})\n",
        "\n",
        "\n",
        "# (Optional) sanity checks\n",
        "print(\"X shape (before split):\", X.shape)\n",
        "print(\"y shape (before split):\", y.shape)\n",
        "assert X.index.equals(y.index), \"Indices are not aligned!\"\n",
        "\n",
        "# --- Train/test split (split X and y together) ---\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.20, random_state=42\n",
        ")\n",
        "\n",
        "# --- Scale features (fit on train, transform test) ---\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = pd.DataFrame(\n",
        "    scaler.fit_transform(X_train),\n",
        "    index=X_train.index, columns=X_train.columns\n",
        ")\n",
        "X_test_scaled = pd.DataFrame(\n",
        "    scaler.transform(X_test),\n",
        "    index=X_test.index, columns=X_test.columns\n",
        ")\n",
        "\n",
        "print(\"X_train_scaled:\", X_train_scaled.shape, \"| X_test_scaled:\", X_test_scaled.shape)\n",
        "print(\"y_train:\", y_train.shape, \"| y_test:\", y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6PBS6VHbOjaT",
        "outputId": "9590c89e-3d25-4b43-dfcb-0ace6530d1c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X shape (before split): (2439, 131)\n",
            "y shape (before split): (2439,)\n",
            "X_train_scaled: (1951, 131) | X_test_scaled: (488, 131)\n",
            "y_train: (1951,) | y_test: (488,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "rf = RandomForestRegressor(n_estimators=100, random_state=0)\n",
        "rf.fit(X_train_scaled, y_train)\n",
        "importances = pd.Series(rf.feature_importances_, index=X_train_scaled.columns).sort_values(ascending=False)\n",
        "top_features_rf = importances.head(10).index.tolist()\n",
        "\n",
        "# Pearson correlation absolute values\n",
        "corr = X_train_scaled.corrwith(y_train).abs().sort_values(ascending=False)\n",
        "top_features_corr = corr.head(10).index.tolist()\n",
        "\n",
        "# Combine and choose top 8 features (taking into account both methods)\n",
        "candidate_features = list(dict.fromkeys(top_features_rf + top_features_corr))\n",
        "selected_features = candidate_features[:16]\n",
        "print(\"Top features selected for QNN:\", selected_features)\n",
        "# Reduce feature sets to selected features\n",
        "X_train_sel = X_train_scaled[selected_features]\n",
        "X_test_sel = X_test_scaled[selected_features]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2cqfZeqoOoCu",
        "outputId": "4a4678ce-4731-43d4-f778-8abc0a7d2b2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top features selected for QNN: ['ALSFRS_slope_3to12m', 'Blood_Pressure_Systolic_slope', 'Q1_Speech_slope', 'Blood_Pressure_Systolic_first', 'Q5a_Cutting_without_Gastrostomy_slope', 'Blood_Pressure_Systolic_std', 'ALSFRS_Total_orig_median', 'Q9_Climbing_Stairs_slope', 'Pulse_slope', 'Pulse_std', 'ALSFRS_Total_orig_first', 'ALSFRS_Total_orig_max', 'ALSFRS_Total_orig_last', 'ALSFRS_Total_orig_min', 'ALSFRS_Total_orig_std', 'Subject_used_Riluzole']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(selected_features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jhaJHX39uYM5",
        "outputId": "757c9db4-8532-4529-f67c-00a38e4488b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pennylane  # Install PennyLane for quantum modeling\n",
        "import pennylane as qml\n",
        "import numpy as np\n",
        "\n",
        "n_qubits = len(selected_features)  # number of qubits = number of selected features\n",
        "dev = qml.device('default.qubit', wires=n_qubits)\n",
        "\n",
        "# Define the variational quantum circuit (ansatz)\n",
        "@qml.qnode(dev)\n",
        "def quantum_model(feature_vector, weights):\n",
        "    # Encode features as rotations (angle encoding using Ry rotations)\n",
        "    for i in range(n_qubits):\n",
        "        qml.RY(feature_vector[i], wires=i)\n",
        "    # Variational layers\n",
        "    # weights shape: (L, n_qubits), where L = number of layers\n",
        "    for layer in weights:\n",
        "        # Apply a trainable rotation on each qubit\n",
        "        for i in range(n_qubits):\n",
        "            qml.RY(layer[i], wires=i)\n",
        "        # Apply entangling CNOT gates (chain topology)\n",
        "        for i in range(n_qubits - 1):\n",
        "            qml.CNOT(wires=[i, i+1])\n",
        "    # Return expectation of PauliZ on first qubit as prediction\n",
        "    return qml.expval(qml.PauliZ(0))\n",
        "\n",
        "# Initialize trainable weights (e.g., 2 layers of rotations)\n",
        "layers = 2\n",
        "np.random.seed(0)\n",
        "weights = 0.01 * np.random.randn(layers, n_qubits)\n",
        "\n",
        "# Normalize target slopes to [-1,1] for training\n",
        "y_min, y_max = y_train.min(), y_train.max()\n",
        "y_train_norm = 2 * (y_train - y_min) / (y_max - y_min) - 1\n",
        "y_test_norm = 2 * (y_test - y_min) / (y_max - y_min) - 1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXRsmwjbOuFv",
        "outputId": "8ddf4bc8-44a9-4ea4-cec1-1b3226e31015"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pennylane\n",
            "  Downloading pennylane-0.43.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from pennylane) (1.16.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from pennylane) (3.5)\n",
            "Collecting rustworkx>=0.14.0 (from pennylane)\n",
            "  Downloading rustworkx-0.17.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: autograd in /usr/local/lib/python3.12/dist-packages (from pennylane) (1.8.0)\n",
            "Collecting appdirs (from pennylane)\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting autoray==0.8.0 (from pennylane)\n",
            "  Downloading autoray-0.8.0-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.12/dist-packages (from pennylane) (5.5.2)\n",
            "Collecting pennylane-lightning>=0.43 (from pennylane)\n",
            "  Downloading pennylane_lightning-0.43.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from pennylane) (2.32.4)\n",
            "Requirement already satisfied: tomlkit in /usr/local/lib/python3.12/dist-packages (from pennylane) (0.13.3)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.12/dist-packages (from pennylane) (4.15.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from pennylane) (25.0)\n",
            "Collecting diastatic-malt (from pennylane)\n",
            "  Downloading diastatic_malt-2.15.2-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from pennylane) (2.0.2)\n",
            "Collecting scipy-openblas32>=0.3.26 (from pennylane-lightning>=0.43->pennylane)\n",
            "  Downloading scipy_openblas32-0.3.30.0.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.1/57.1 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: astunparse in /usr/local/lib/python3.12/dist-packages (from diastatic-malt->pennylane) (1.6.3)\n",
            "Requirement already satisfied: gast in /usr/local/lib/python3.12/dist-packages (from diastatic-malt->pennylane) (0.6.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.12/dist-packages (from diastatic-malt->pennylane) (3.1.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->pennylane) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->pennylane) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->pennylane) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->pennylane) (2025.10.5)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse->diastatic-malt->pennylane) (0.45.1)\n",
            "Requirement already satisfied: six<2.0,>=1.6.1 in /usr/local/lib/python3.12/dist-packages (from astunparse->diastatic-malt->pennylane) (1.17.0)\n",
            "Downloading pennylane-0.43.0-py3-none-any.whl (5.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m76.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading autoray-0.8.0-py3-none-any.whl (934 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m934.3/934.3 kB\u001b[0m \u001b[31m61.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pennylane_lightning-0.43.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m92.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rustworkx-0.17.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m83.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Downloading diastatic_malt-2.15.2-py3-none-any.whl (167 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy_openblas32-0.3.30.0.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m118.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: appdirs, scipy-openblas32, rustworkx, autoray, diastatic-malt, pennylane-lightning, pennylane\n",
            "Successfully installed appdirs-1.4.4 autoray-0.8.0 diastatic-malt-2.15.2 pennylane-0.43.0 pennylane-lightning-0.43.0 rustworkx-0.17.1 scipy-openblas32-0.3.30.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- QNN training (PennyLane-compatible) ---\n",
        "\n",
        "from pennylane import numpy as pnp\n",
        "\n",
        "# Optimizer: use 'stepsize' (not 'learning_rate')\n",
        "opt = qml.AdamOptimizer(stepsize=0.1)\n",
        "batch_size = 32\n",
        "num_epochs = 10\n",
        "\n",
        "# Convert data to PennyLane numpy for autograd compatibility\n",
        "X_train_array = pnp.array(X_train_sel.values, dtype=float)\n",
        "# Make sure y aligns with X_train_sel index\n",
        "y_train_array = pnp.array(y_train_norm.loc[X_train_sel.index].values, dtype=float)\n",
        "\n",
        "# Ensure weights are a trainable pnp array\n",
        "weights = pnp.array(weights, requires_grad=True)\n",
        "\n",
        "for epoch in range(1, num_epochs + 1):\n",
        "    # Shuffle training data\n",
        "    perm = pnp.random.permutation(len(X_train_array))\n",
        "    X_train_array = X_train_array[perm]\n",
        "    y_train_array = y_train_array[perm]\n",
        "\n",
        "    # Mini-batch gradient descent\n",
        "    for i in range(0, len(X_train_array), batch_size):\n",
        "        X_batch = X_train_array[i:i + batch_size]\n",
        "        y_batch = y_train_array[i:i + batch_size]\n",
        "\n",
        "        # Batch cost must use pnp ops so PennyLane can differentiate\n",
        "        def batch_cost(w):\n",
        "            preds = pnp.stack([quantum_model(x, w) for x in X_batch])\n",
        "            return pnp.mean((preds - y_batch) ** 2)\n",
        "\n",
        "        # Update weights\n",
        "        weights = opt.step(batch_cost, weights)\n",
        "\n",
        "    # Monitor training loss\n",
        "    if epoch % 10 == 0:\n",
        "        train_preds = pnp.stack([quantum_model(x, weights) for x in X_train_array])\n",
        "        train_loss = pnp.mean((train_preds - y_train_array) ** 2)\n",
        "        print(f\"Epoch {epoch}: Training MSE = {train_loss:.4f}\")\n"
      ],
      "metadata": {
        "id": "tpl7fJF9O1XU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfa198c3-14e0-4d93-a55b-7967dc994055"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10: Training MSE = 0.0847\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate on test set\n",
        "test_preds_norm = np.array([quantum_model(x, weights) for x in X_test_sel.values], dtype=float)\n",
        "# Invert normalization to original scale\n",
        "test_preds = 0.5 * (test_preds_norm + 1) * (y_max - y_min) + y_min\n",
        "\n",
        "# Calculate performance metrics\n",
        "from math import sqrt\n",
        "test_true = y_test.values\n",
        "rmsd = sqrt(((test_preds - test_true)**2).mean())  # Root Mean Squared Deviation:contentReference[oaicite:19]{index=19}\n",
        "pcc = np.corrcoef(test_preds, test_true)[0, 1]     # Pearson Correlation Coefficient:contentReference[oaicite:20]{index=20}\n",
        "\n",
        "print(f\"Test RMSD: {rmsd:.3f} ALSFRS points/month\")\n",
        "print(f\"Test PCC:  {pcc:.3f}\")\n"
      ],
      "metadata": {
        "id": "KNLWWhY9O6pa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2517962-cb76-4aaa-be52-a723bf25cf86"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test RMSD: 0.580 ALSFRS points/month\n",
            "Test PCC:  0.706\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Classify patients based on predicted slope\n",
        "pred_fast = test_preds <= -1.0   # boolean array for fast progressors\n",
        "true_fast = test_true <= -1.0\n",
        "# Compute classification metrics (e.g., accuracy or confusion matrix)\n",
        "accuracy = (pred_fast == true_fast).mean()\n",
        "print(f\"Fast progressor classification accuracy: {accuracy:.2%}\")\n",
        "print(f\"Predicted fast progressors: {pred_fast.sum()} / {len(pred_fast)}\")\n"
      ],
      "metadata": {
        "id": "kaJnKBh0PDiC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1fdf497-077f-422c-9cf7-2b0d1eaa393b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fast progressor classification accuracy: 89.96%\n",
            "Predicted fast progressors: 90 / 488\n"
          ]
        }
      ]
    }
  ]
}