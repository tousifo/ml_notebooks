{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tousifo/ml_notebooks/blob/main/MedMNIST_QNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BToV6a-J5of3",
        "outputId": "fc024d63-ee92-4aca-d547-b880d3c664c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/115.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.9/115.9 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing device: cuda\n",
            "\n",
            "--- Loading Datasets (with Augmentations) ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 206M/206M [02:47<00:00, 1.22MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PathMNIST: train=89996, val=10004, test=7180, classes=9, channels=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 19.7M/19.7M [00:17<00:00, 1.12MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DermaMNIST: train=7007, val=1003, test=2005, classes=7, channels=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 35.5M/35.5M [00:34<00:00, 1.03MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BloodMNIST: train=11959, val=1712, test=3421, classes=8, channels=3\n",
            "\n",
            "All datasets with advanced augmentations are ready.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Snippet 1 (Third User Correction): Data Pipeline with Augmentations\n",
        "\n",
        "# --- Install ---\n",
        "!pip install medmnist --quiet\n",
        "\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import medmnist\n",
        "\n",
        "# Device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# --- Histopathology-Friendly Augmentations ---\n",
        "aug_train = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomVerticalFlip(p=0.5),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.03),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5,0.5,0.5],[0.5,0.5,0.5]),\n",
        "])\n",
        "\n",
        "eval_tfm = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5,0.5,0.5],[0.5,0.5,0.5]),\n",
        "])\n",
        "\n",
        "# --- Data Loading ---\n",
        "DATASET_NAMES = ['PathMNIST', 'DermaMNIST', 'BloodMNIST']\n",
        "datasets, dataloaders = {}, {}\n",
        "print(\"\\n--- Loading Datasets (with Augmentations) ---\")\n",
        "\n",
        "for name in DATASET_NAMES:\n",
        "    info = medmnist.INFO[name.lower()]\n",
        "    DataClass = getattr(medmnist, info['python_class'])\n",
        "    n_channels = info.get('n_channels', 3)\n",
        "\n",
        "    # Use the appropriate transform for each split\n",
        "    train_ds = DataClass(split='train', transform=aug_train, download=True)\n",
        "    val_ds   = DataClass(split='val',   transform=eval_tfm, download=True)\n",
        "    test_ds  = DataClass(split='test',  transform=eval_tfm, download=True)\n",
        "\n",
        "    datasets[name] = {'train': train_ds, 'val': val_ds, 'test': test_ds}\n",
        "\n",
        "    dataloaders[name] = {\n",
        "        'train': DataLoader(train_ds, batch_size=64, shuffle=True,  num_workers=2, pin_memory=True),\n",
        "        'val':   DataLoader(val_ds,   batch_size=128, shuffle=False, num_workers=2, pin_memory=True),\n",
        "        'test':  DataLoader(test_ds,  batch_size=128, shuffle=False, num_workers=2, pin_memory=True),\n",
        "    }\n",
        "\n",
        "    print(f\"{name}: train={len(train_ds)}, val={len(val_ds)}, test={len(test_ds)}, \"\n",
        "          f\"classes={len(train_ds.info['label'])}, channels={n_channels}\")\n",
        "\n",
        "print(\"\\nAll datasets with advanced augmentations are ready.\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9abWN0T8FwR",
        "outputId": "fc36c7e4-34d0-446f-8ce4-01cf038a6bcc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.1/57.1 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m54.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m930.8/930.8 kB\u001b[0m \u001b[31m46.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m91.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m78.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m62.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hTrainable QTF model ready (re-uploading + dual-basis readout).\n"
          ]
        }
      ],
      "source": [
        "# Snippet 2 (Third User Correction): The Trainable Quantum Model\n",
        "\n",
        "# --- Install ---\n",
        "!pip install pennylane --quiet\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import pennylane as qml\n",
        "\n",
        "# --- Trainable QLayer with data re-uploading & dual-basis readout ---\n",
        "n_qubits = 8\n",
        "layers = 2  # re-uploading depth\n",
        "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
        "\n",
        "@qml.qnode(dev, interface='torch', diff_method='backprop')\n",
        "def trainable_qnode(inputs, theta_rz, theta_ry):\n",
        "    # inputs: (B, 8) -- TorchLayer handles batching\n",
        "    # First embedding\n",
        "    qml.AngleEmbedding(inputs, wires=range(n_qubits), rotation='Y')\n",
        "\n",
        "    for l in range(layers):\n",
        "        # Variational block\n",
        "        for i in range(n_qubits):\n",
        "            qml.RZ(theta_rz[l, i], wires=i)\n",
        "            qml.RY(theta_ry[l, i], wires=i)\n",
        "        # Ring entanglement\n",
        "        for i in range(n_qubits - 1):\n",
        "            qml.CNOT(wires=[i, i+1])\n",
        "        qml.CNOT(wires=[n_qubits-1, 0])\n",
        "\n",
        "        # Re-upload the same 8 features (gives richer gradients)\n",
        "        qml.AngleEmbedding(inputs, wires=range(n_qubits), rotation='Y')\n",
        "\n",
        "    # Read out in two Pauli bases -> 16 quantum features\n",
        "    z_feats = [qml.expval(qml.PauliZ(i)) for i in range(n_qubits)]\n",
        "    x_feats = [qml.expval(qml.PauliX(i)) for i in range(n_qubits)]\n",
        "    return z_feats + x_feats\n",
        "\n",
        "weight_shapes = {\n",
        "    \"theta_rz\": (layers, n_qubits),\n",
        "    \"theta_ry\": (layers, n_qubits),\n",
        "}\n",
        "\n",
        "class QTFClassifier(nn.Module):\n",
        "    def __init__(self, q_feature_map, weight_shapes, n_classes=9, in_channels=3):\n",
        "        super().__init__()\n",
        "        self.feature_extractor = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, 16, 3, padding=1),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.Conv2d(16, 32, 3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(32 * 7 * 7, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(128, n_qubits)   # -> 8 features\n",
        "        )\n",
        "\n",
        "        # Trainable quantum layer (outputs 16-dim: Z and X on 8 qubits)\n",
        "        self.q_layer = qml.qnn.TorchLayer(q_feature_map, weight_shapes=weight_shapes)\n",
        "\n",
        "        # Final head now expects 16 inputs\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(2 * n_qubits, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(64, n_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        feats = self.feature_extractor(x)         # (B, 8), float32\n",
        "        qfeats = self.q_layer(feats)              # (B, 16)\n",
        "        qfeats = qfeats.to(feats.dtype)           # keep dtypes consistent\n",
        "        logits = self.classifier(qfeats)\n",
        "        return logits\n",
        "\n",
        "print(\"Trainable QTF model ready (re-uploading + dual-basis readout).\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VDpihpCt9IPQ",
        "outputId": "8c5b1411-c77c-4a98-9646-50add3afef25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using CrossEntropyLoss with label smoothing.\n",
            "\n",
            "Starting final training run on PathMNIST for 25 epochs...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/25 [train]: 100%|██████████| 1407/1407 [03:43<00:00,  6.29it/s]\n",
            "Epoch 1/25 [val]: 100%|██████████| 79/79 [00:06<00:00, 11.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: train_loss=2.0873 train_acc=0.1922 val_loss=1.9960 val_acc=0.2219\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/25 [train]: 100%|██████████| 1407/1407 [03:40<00:00,  6.39it/s]\n",
            "Epoch 2/25 [val]: 100%|██████████| 79/79 [00:06<00:00, 11.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2: train_loss=2.0149 train_acc=0.2249 val_loss=2.0113 val_acc=0.2382\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/25 [train]: 100%|██████████| 1407/1407 [03:40<00:00,  6.39it/s]\n",
            "Epoch 3/25 [val]: 100%|██████████| 79/79 [00:06<00:00, 11.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3: train_loss=2.0729 train_acc=0.2003 val_loss=2.0501 val_acc=0.2082\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/25 [train]: 100%|██████████| 1407/1407 [03:42<00:00,  6.33it/s]\n",
            "Epoch 4/25 [val]: 100%|██████████| 79/79 [00:06<00:00, 12.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4: train_loss=2.1392 train_acc=0.1692 val_loss=2.0416 val_acc=0.2184\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/25 [train]: 100%|██████████| 1407/1407 [03:41<00:00,  6.34it/s]\n",
            "Epoch 5/25 [val]: 100%|██████████| 79/79 [00:06<00:00, 12.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5: train_loss=2.0619 train_acc=0.2048 val_loss=1.9291 val_acc=0.2836\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/25 [train]: 100%|██████████| 1407/1407 [03:41<00:00,  6.36it/s]\n",
            "Epoch 6/25 [val]: 100%|██████████| 79/79 [00:07<00:00, 11.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6: train_loss=1.9482 train_acc=0.2512 val_loss=1.8422 val_acc=0.2982\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/25 [train]: 100%|██████████| 1407/1407 [03:47<00:00,  6.18it/s]\n",
            "Epoch 7/25 [val]: 100%|██████████| 79/79 [00:06<00:00, 12.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7: train_loss=1.8476 train_acc=0.2908 val_loss=1.8060 val_acc=0.3079\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/25 [train]: 100%|██████████| 1407/1407 [03:37<00:00,  6.46it/s]\n",
            "Epoch 8/25 [val]: 100%|██████████| 79/79 [00:06<00:00, 13.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8: train_loss=1.8656 train_acc=0.2993 val_loss=1.8099 val_acc=0.3154\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/25 [train]: 100%|██████████| 1407/1407 [03:39<00:00,  6.40it/s]\n",
            "Epoch 9/25 [val]: 100%|██████████| 79/79 [00:06<00:00, 13.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9: train_loss=1.6731 train_acc=0.3921 val_loss=1.3948 val_acc=0.5093\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/25 [train]: 100%|██████████| 1407/1407 [03:39<00:00,  6.40it/s]\n",
            "Epoch 10/25 [val]: 100%|██████████| 79/79 [00:06<00:00, 13.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10: train_loss=1.4145 train_acc=0.5004 val_loss=1.2273 val_acc=0.5756\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/25 [train]: 100%|██████████| 1407/1407 [03:39<00:00,  6.42it/s]\n",
            "Epoch 11/25 [val]: 100%|██████████| 79/79 [00:06<00:00, 13.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11: train_loss=1.2592 train_acc=0.5705 val_loss=1.1396 val_acc=0.6265\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12/25 [train]: 100%|██████████| 1407/1407 [03:36<00:00,  6.49it/s]\n",
            "Epoch 12/25 [val]: 100%|██████████| 79/79 [00:06<00:00, 13.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12: train_loss=1.1275 train_acc=0.6331 val_loss=0.9433 val_acc=0.7150\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13/25 [train]: 100%|██████████| 1407/1407 [03:38<00:00,  6.43it/s]\n",
            "Epoch 13/25 [val]: 100%|██████████| 79/79 [00:06<00:00, 12.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13: train_loss=1.0420 train_acc=0.6740 val_loss=1.0003 val_acc=0.6783\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14/25 [train]: 100%|██████████| 1407/1407 [03:38<00:00,  6.43it/s]\n",
            "Epoch 14/25 [val]: 100%|██████████| 79/79 [00:06<00:00, 12.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14: train_loss=0.9880 train_acc=0.7014 val_loss=0.9428 val_acc=0.7051\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15/25 [train]: 100%|██████████| 1407/1407 [03:40<00:00,  6.39it/s]\n",
            "Epoch 15/25 [val]: 100%|██████████| 79/79 [00:06<00:00, 12.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15: train_loss=0.9582 train_acc=0.7155 val_loss=0.9064 val_acc=0.7190\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16/25 [train]: 100%|██████████| 1407/1407 [03:42<00:00,  6.31it/s]\n",
            "Epoch 16/25 [val]: 100%|██████████| 79/79 [00:06<00:00, 11.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16: train_loss=0.9287 train_acc=0.7297 val_loss=0.8381 val_acc=0.7630\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17/25 [train]: 100%|██████████| 1407/1407 [03:37<00:00,  6.47it/s]\n",
            "Epoch 17/25 [val]: 100%|██████████| 79/79 [00:06<00:00, 11.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17: train_loss=0.9046 train_acc=0.7394 val_loss=0.7995 val_acc=0.7828\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18/25 [train]: 100%|██████████| 1407/1407 [03:37<00:00,  6.46it/s]\n",
            "Epoch 18/25 [val]: 100%|██████████| 79/79 [00:06<00:00, 11.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18: train_loss=0.8831 train_acc=0.7505 val_loss=0.7721 val_acc=0.7948\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19/25 [train]: 100%|██████████| 1407/1407 [03:39<00:00,  6.42it/s]\n",
            "Epoch 19/25 [val]: 100%|██████████| 79/79 [00:06<00:00, 11.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19: train_loss=0.8572 train_acc=0.7634 val_loss=0.8291 val_acc=0.7625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20/25 [train]: 100%|██████████| 1407/1407 [03:39<00:00,  6.42it/s]\n",
            "Epoch 20/25 [val]: 100%|██████████| 79/79 [00:06<00:00, 11.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20: train_loss=0.8378 train_acc=0.7741 val_loss=0.7967 val_acc=0.7673\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 21/25 [train]: 100%|██████████| 1407/1407 [03:48<00:00,  6.17it/s]\n",
            "Epoch 21/25 [val]: 100%|██████████| 79/79 [00:06<00:00, 12.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21: train_loss=0.8245 train_acc=0.7789 val_loss=0.7508 val_acc=0.8028\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 22/25 [train]: 100%|██████████| 1407/1407 [03:57<00:00,  5.93it/s]\n",
            "Epoch 22/25 [val]: 100%|██████████| 79/79 [00:07<00:00, 11.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22: train_loss=0.8125 train_acc=0.7842 val_loss=0.7456 val_acc=0.8010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 23/25 [train]: 100%|██████████| 1407/1407 [03:49<00:00,  6.14it/s]\n",
            "Epoch 23/25 [val]: 100%|██████████| 79/79 [00:06<00:00, 11.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23: train_loss=0.8041 train_acc=0.7898 val_loss=0.7685 val_acc=0.7837\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 24/25 [train]: 100%|██████████| 1407/1407 [03:40<00:00,  6.37it/s]\n",
            "Epoch 24/25 [val]: 100%|██████████| 79/79 [00:06<00:00, 11.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24: train_loss=0.7977 train_acc=0.7923 val_loss=0.7431 val_acc=0.8006\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 25/25 [train]: 100%|██████████| 1407/1407 [03:40<00:00,  6.39it/s]\n",
            "Epoch 25/25 [val]: 100%|██████████| 79/79 [00:07<00:00, 11.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25: train_loss=0.7950 train_acc=0.7936 val_loss=0.7484 val_acc=0.7970\n",
            "\n",
            "Training complete. Best validation accuracy: 0.8028\n",
            "Loaded best model weights. Ready to begin Phase 2: Explainable AI.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Snippet 3 (Third User Correction): The Advanced Training Loop\n",
        "\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "\n",
        "# --- Setup ---\n",
        "dataset_name = 'PathMNIST'\n",
        "info = medmnist.INFO[dataset_name.lower()]\n",
        "in_channels = info.get('n_channels', 3)\n",
        "n_classes = len(info['label'])\n",
        "\n",
        "# --- Build Model ---\n",
        "# This instantiates our final, trainable QTFClassifier\n",
        "model = QTFClassifier(q_feature_map=trainable_qnode,\n",
        "                      weight_shapes=weight_shapes,\n",
        "                      n_classes=n_classes,\n",
        "                      in_channels=in_channels).to(device)\n",
        "\n",
        "# --- Optimizer, Loss, and Scheduler ---\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=2e-3, weight_decay=1e-4)\n",
        "\n",
        "# Label smoothing (with a fallback for older torch versions)\n",
        "try:\n",
        "    loss_fn = nn.CrossEntropyLoss(label_smoothing=0.05)\n",
        "    print(\"Using CrossEntropyLoss with label smoothing.\")\n",
        "except TypeError:\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "    print(\"Using standard CrossEntropyLoss (label smoothing not supported).\")\n",
        "\n",
        "# Cosine annealing scheduler for robust convergence\n",
        "scheduler = CosineAnnealingLR(optimizer, T_max=25, eta_min=1e-5)\n",
        "\n",
        "# --- DataLoaders ---\n",
        "train_loader = dataloaders[dataset_name]['train']\n",
        "val_loader = dataloaders[dataset_name]['val']\n",
        "\n",
        "def labels_to_indices(y):\n",
        "    if y.ndim == 2 and y.size(1) > 1:\n",
        "        return y.argmax(dim=1)\n",
        "    return y.view(-1).long()\n",
        "\n",
        "# --- Full Training & Validation Loop ---\n",
        "num_epochs = 25\n",
        "best_val = 0.0\n",
        "print(f\"\\nStarting final training run on {dataset_name} for {num_epochs} epochs...\")\n",
        "\n",
        "for epoch in range(1, num_epochs + 1):\n",
        "    # ---- Train ----\n",
        "    model.train()\n",
        "    train_loss, train_correct, train_total = 0, 0, 0\n",
        "    for x, y in tqdm(train_loader, desc=f\"Epoch {epoch}/{num_epochs} [train]\"):\n",
        "        x = x.to(device, non_blocking=True)\n",
        "        y = labels_to_indices(y).to(device, non_blocking=True)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(x)\n",
        "        loss = loss_fn(logits, y)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item() * x.size(0)\n",
        "        train_correct += (logits.argmax(1) == y).sum().item()\n",
        "        train_total += x.size(0)\n",
        "    tr_loss = train_loss / train_total\n",
        "    tr_acc = train_correct / train_total\n",
        "\n",
        "    # ---- Validate ----\n",
        "    model.eval()\n",
        "    val_correct, val_total, val_loss = 0, 0, 0\n",
        "    with torch.no_grad():\n",
        "        for x, y in tqdm(val_loader, desc=f\"Epoch {epoch}/{num_epochs} [val]\"):\n",
        "            x = x.to(device, non_blocking=True)\n",
        "            y = labels_to_indices(y).to(device, non_blocking=True)\n",
        "            logits = model(x)\n",
        "            loss = loss_fn(logits, y)\n",
        "            val_loss += loss.item() * x.size(0)\n",
        "            val_correct += (logits.argmax(1) == y).sum().item()\n",
        "            val_total += x.size(0)\n",
        "    v_loss = val_loss / val_total\n",
        "    v_acc = val_correct / val_total\n",
        "\n",
        "    print(f\"Epoch {epoch}: train_loss={tr_loss:.4f} train_acc={tr_acc:.4f} \"\n",
        "          f\"val_loss={v_loss:.4f} val_acc={v_acc:.4f}\")\n",
        "\n",
        "    # Step the scheduler\n",
        "    scheduler.step()\n",
        "\n",
        "    # Save the best model\n",
        "    if v_acc > best_val:\n",
        "        best_val = v_acc\n",
        "        best_state = {k: v.cpu() for k, v in model.state_dict().items()}\n",
        "\n",
        "print(f\"\\nTraining complete. Best validation accuracy: {best_val:.4f}\")\n",
        "\n",
        "# Load the best performing model state for our XAI phase\n",
        "if 'best_state' in locals():\n",
        "    model.load_state_dict(best_state)\n",
        "    print(\"Loaded best model weights. Ready to begin Phase 2: Explainable AI.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN1XOnjHzyO/llrG2Y3IilE",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}