{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tousifo/ml_notebooks/blob/main/MedMNIST_QNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BToV6a-J5of3",
        "outputId": "dae06491-c360-412e-e747-44cbeece107f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n",
            "--- Library Versions ---\n",
            "Torch: 2.8.0+cu126\n",
            "MedMNIST: 3.0.2\n",
            "\n",
            "--- Loading Datasets (train/val/test) ---\n",
            "PathMNIST: train=89996, val=10004, test=7180, classes=9, channels=3\n",
            "DermaMNIST: train=7007, val=1003, test=2005, classes=7, channels=3\n",
            "BloodMNIST: train=11959, val=1712, test=3421, classes=8, channels=3\n",
            "\n",
            "All datasets ready.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Snippet 1 (User Corrected): Data Loading and Preprocessing\n",
        "\n",
        "# --- Install ---\n",
        "!pip install medmnist --quiet\n",
        "\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import medmnist\n",
        "import numpy as np\n",
        "\n",
        "# Device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "print(\"--- Library Versions ---\")\n",
        "print(f\"Torch: {torch.__version__}\")\n",
        "print(f\"MedMNIST: {medmnist.__version__}\\n\")\n",
        "\n",
        "DATASET_NAMES = ['PathMNIST', 'DermaMNIST', 'BloodMNIST']\n",
        "datasets, dataloaders = {}, {}\n",
        "\n",
        "print(\"--- Loading Datasets (train/val/test) ---\")\n",
        "for name in DATASET_NAMES:\n",
        "    info = medmnist.INFO[name.lower()]\n",
        "    DataClass = getattr(medmnist, info['python_class'])\n",
        "    n_channels = info.get('n_channels', 3)\n",
        "\n",
        "    # Channel-aware normalization\n",
        "    if n_channels == 1:\n",
        "        mean, std = [0.5], [0.5]\n",
        "    else:\n",
        "        mean, std = [0.5, 0.5, 0.5], [0.5, 0.5, 0.5]\n",
        "\n",
        "    tfm = transforms.Compose([transforms.ToTensor(),\n",
        "                              transforms.Normalize(mean=mean, std=std)])\n",
        "\n",
        "    # Use TRUE splits; do not train on test\n",
        "    train_ds = DataClass(split='train', transform=tfm, download=True)\n",
        "    val_ds   = DataClass(split='val',   transform=tfm, download=True)\n",
        "    test_ds  = DataClass(split='test',  transform=tfm, download=True)\n",
        "\n",
        "    datasets[name] = {'train': train_ds, 'val': val_ds, 'test': test_ds}\n",
        "\n",
        "    # Reasonable batch sizes\n",
        "    dataloaders[name] = {\n",
        "        'train': DataLoader(train_ds, batch_size=64, shuffle=True,  num_workers=2, pin_memory=True),\n",
        "        'val':   DataLoader(val_ds,   batch_size=128, shuffle=False, num_workers=2, pin_memory=True),\n",
        "        'test':  DataLoader(test_ds,  batch_size=128, shuffle=False, num_workers=2, pin_memory=True),\n",
        "    }\n",
        "\n",
        "    print(f\"{name}: train={len(train_ds)}, val={len(val_ds)}, test={len(test_ds)}, \"\n",
        "          f\"classes={len(train_ds.info['label'])}, channels={n_channels}\")\n",
        "\n",
        "print(\"\\nAll datasets ready.\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9abWN0T8FwR",
        "outputId": "05b220e7-4428-4a99-e53e-5421a3b84d22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Patched Quantum Transfer Learning architecture defined successfully.\n"
          ]
        }
      ],
      "source": [
        "# Snippet 2 (Second User Correction): The Patched Model Architecture\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import pennylane as qml\n",
        "\n",
        "# No changes to the qnode, it remains the same\n",
        "n_qubits = 8\n",
        "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
        "\n",
        "@qml.qnode(dev, interface='torch', diff_method='backprop')\n",
        "def quantum_feature_map(inputs):\n",
        "    qml.templates.AngleEmbedding(inputs, wires=range(n_qubits), rotation='Y')\n",
        "    for i in range(n_qubits - 1):\n",
        "        qml.CNOT(wires=[i, i + 1])\n",
        "    qml.CNOT(wires=[n_qubits - 1, 0])\n",
        "    return [qml.expval(qml.PauliZ(i)) for i in range(n_qubits)]\n",
        "\n",
        "# --- Corrected QTFClassifier ---\n",
        "# Incorporating the user-provided patch for PennyLane version compatibility\n",
        "\n",
        "class QTFClassifier(nn.Module):\n",
        "    def __init__(self, q_feature_map, n_classes=9, in_channels=3):\n",
        "        super().__init__()\n",
        "        self.feature_extractor = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=in_channels, out_channels=16, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(16, 32, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(32 * 7 * 7, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, n_qubits)\n",
        "        )\n",
        "        # PATCH: Removed the unsupported 'dtype' argument\n",
        "        self.q_feature_map = qml.qnn.TorchLayer(q_feature_map, weight_shapes={})\n",
        "        self.classifier = nn.Linear(n_qubits, n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        feats = self.feature_extractor(x)\n",
        "        qfeats = self.q_feature_map(feats)\n",
        "        # PATCH: Manually cast dtype to ensure compatibility\n",
        "        qfeats = qfeats.to(feats.dtype)\n",
        "        logits = self.classifier(qfeats)\n",
        "        return logits\n",
        "\n",
        "print(\"Patched Quantum Transfer Learning architecture defined successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VDpihpCt9IPQ",
        "outputId": "082d2508-4021-4343-f5a0-f1b134efb816"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on PathMNIST for 10 epochs...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 [train]:   0%|          | 0/1407 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "Epoch 1/10 [train]: 100%|██████████| 1407/1407 [02:20<00:00,  9.98it/s]\n",
            "Epoch 1/10 [val]: 100%|██████████| 79/79 [00:07<00:00, 11.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: train_loss=1.5969  train_acc=0.4014  val_loss=1.3190  val_acc=0.4790\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/10 [train]: 100%|██████████| 1407/1407 [03:11<00:00,  7.34it/s]\n",
            "Epoch 2/10 [val]: 100%|██████████| 79/79 [00:14<00:00,  5.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2: train_loss=1.2045  train_acc=0.5556  val_loss=1.0715  val_acc=0.6021\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/10 [train]: 100%|██████████| 1407/1407 [03:40<00:00,  6.39it/s]\n",
            "Epoch 3/10 [val]: 100%|██████████| 79/79 [00:19<00:00,  4.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3: train_loss=0.9879  train_acc=0.6245  val_loss=0.9315  val_acc=0.6409\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/10 [train]: 100%|██████████| 1407/1407 [04:01<00:00,  5.84it/s]\n",
            "Epoch 4/10 [val]: 100%|██████████| 79/79 [00:16<00:00,  4.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4: train_loss=0.8799  train_acc=0.6656  val_loss=0.8170  val_acc=0.6942\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/10 [train]: 100%|██████████| 1407/1407 [03:44<00:00,  6.27it/s]\n",
            "Epoch 5/10 [val]: 100%|██████████| 79/79 [00:15<00:00,  5.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5: train_loss=0.8021  train_acc=0.7027  val_loss=0.7725  val_acc=0.7169\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/10 [train]: 100%|██████████| 1407/1407 [03:49<00:00,  6.13it/s]\n",
            "Epoch 6/10 [val]: 100%|██████████| 79/79 [00:17<00:00,  4.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6: train_loss=0.7375  train_acc=0.7308  val_loss=0.8024  val_acc=0.7186\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/10 [train]: 100%|██████████| 1407/1407 [03:56<00:00,  5.94it/s]\n",
            "Epoch 7/10 [val]: 100%|██████████| 79/79 [00:19<00:00,  4.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7: train_loss=0.6888  train_acc=0.7485  val_loss=0.6705  val_acc=0.7684\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/10 [train]: 100%|██████████| 1407/1407 [03:56<00:00,  5.95it/s]\n",
            "Epoch 8/10 [val]: 100%|██████████| 79/79 [00:17<00:00,  4.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8: train_loss=0.6503  train_acc=0.7640  val_loss=0.6090  val_acc=0.7791\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/10 [train]: 100%|██████████| 1407/1407 [03:57<00:00,  5.92it/s]\n",
            "Epoch 9/10 [val]: 100%|██████████| 79/79 [00:18<00:00,  4.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9: train_loss=0.6236  train_acc=0.7767  val_loss=0.6554  val_acc=0.7693\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/10 [train]: 100%|██████████| 1407/1407 [04:04<00:00,  5.76it/s]\n",
            "Epoch 10/10 [val]: 100%|██████████| 79/79 [00:18<00:00,  4.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10: train_loss=0.5907  train_acc=0.7914  val_loss=0.6434  val_acc=0.7791\n",
            "\n",
            "Training complete. Best validation accuracy: 0.7791\n",
            "Loaded best model weights for explainability analysis.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Snippet 3 (Second User Correction): The Training and Validation Loop\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "# --- Setup ---\n",
        "# Choose the dataset to train on\n",
        "dataset_name = 'PathMNIST'\n",
        "info = medmnist.INFO[dataset_name.lower()]\n",
        "in_channels = info.get('n_channels', 3)\n",
        "n_classes = len(info['label'])\n",
        "\n",
        "# --- Model, Optimizer, and Loss Function ---\n",
        "# This will now use the patched QTFClassifier from the previous step\n",
        "model = QTFClassifier(q_feature_map=quantum_feature_map,\n",
        "                      n_classes=n_classes,\n",
        "                      in_channels=in_channels).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "# --- DataLoaders ---\n",
        "train_loader = dataloaders[dataset_name]['train']\n",
        "val_loader   = dataloaders[dataset_name]['val']\n",
        "\n",
        "def labels_to_indices(y):\n",
        "    \"\"\"\n",
        "    MedMNIST often returns one-hot labels.\n",
        "    Convert to class indices for CrossEntropyLoss.\n",
        "    \"\"\"\n",
        "    if y.ndim == 2 and y.size(1) > 1:\n",
        "        return y.argmax(dim=1)\n",
        "    return y.view(-1).long()\n",
        "\n",
        "# --- Training Loop ---\n",
        "num_epochs = 10\n",
        "best_val = 0.0\n",
        "print(f\"Training on {dataset_name} for {num_epochs} epochs...\")\n",
        "\n",
        "for epoch in range(1, num_epochs + 1):\n",
        "    # ---- Train ----\n",
        "    model.train()\n",
        "    train_loss, train_correct, train_total = 0.0, 0, 0\n",
        "    for x, y in tqdm(train_loader, desc=f\"Epoch {epoch}/{num_epochs} [train]\"):\n",
        "        x = x.to(device, non_blocking=True)\n",
        "        y = labels_to_indices(y).to(device, non_blocking=True)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(x)\n",
        "        loss = loss_fn(logits, y)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0) # Gradient clipping\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item() * x.size(0)\n",
        "        train_correct += (logits.argmax(1) == y).sum().item()\n",
        "        train_total += x.size(0)\n",
        "\n",
        "    tr_loss = train_loss / train_total\n",
        "    tr_acc  = train_correct / train_total\n",
        "\n",
        "    # ---- Validate ----\n",
        "    model.eval()\n",
        "    val_correct, val_total, val_loss = 0, 0, 0.0\n",
        "    with torch.no_grad():\n",
        "        for x, y in tqdm(val_loader, desc=f\"Epoch {epoch}/{num_epochs} [val]\"):\n",
        "            x = x.to(device, non_blocking=True)\n",
        "            y = labels_to_indices(y).to(device, non_blocking=True)\n",
        "            logits = model(x)\n",
        "            loss = loss_fn(logits, y)\n",
        "            val_loss += loss.item() * x.size(0)\n",
        "            val_correct += (logits.argmax(1) == y).sum().item()\n",
        "            val_total += x.size(0)\n",
        "\n",
        "    v_loss = val_loss / val_total\n",
        "    v_acc  = val_correct / val_total\n",
        "    print(f\"Epoch {epoch}: train_loss={tr_loss:.4f}  train_acc={tr_acc:.4f}  \"\n",
        "          f\"val_loss={v_loss:.4f}  val_acc={v_acc:.4f}\")\n",
        "\n",
        "    # Save the best model based on validation accuracy\n",
        "    if v_acc > best_val:\n",
        "        best_val = v_acc\n",
        "        best_state = {k: v.cpu() for k, v in model.state_dict().items()}\n",
        "\n",
        "print(f\"\\nTraining complete. Best validation accuracy: {best_val:.4f}\")\n",
        "\n",
        "# Load the best performing model state\n",
        "if 'best_state' in locals():\n",
        "    model.load_state_dict(best_state)\n",
        "    print(\"Loaded best model weights for explainability analysis.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPfId9bQAh0zX8CgkEB9nSO",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}