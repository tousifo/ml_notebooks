{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMn/Ol+5cPqede7YZGP9W6T",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tousifo/ml_notebooks/blob/main/pmicl.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision numpy pillow scikit-learn matplotlib torch-geometric\n",
        "!pip install torch-scatter torch-sparse torch-cluster torch-spline-conv -f https://data.pyg.org/whl/torch-2.6.0+cpu.html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HPLObLT54BgU",
        "outputId": "e1d218b2-54f6-42e5-c5cf-0a1085a7f8d3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.2.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.11/dist-packages (2.6.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.11.15)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.20.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2025.4.26)\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.6.0+cpu.html\n",
            "Requirement already satisfied: torch-scatter in /usr/local/lib/python3.11/dist-packages (2.1.2+pt26cpu)\n",
            "Requirement already satisfied: torch-sparse in /usr/local/lib/python3.11/dist-packages (0.6.18+pt26cpu)\n",
            "Requirement already satisfied: torch-cluster in /usr/local/lib/python3.11/dist-packages (1.6.3+pt26cpu)\n",
            "Requirement already satisfied: torch-spline-conv in /usr/local/lib/python3.11/dist-packages (1.2.2+pt26cpu)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch-sparse) (1.15.3)\n",
            "Requirement already satisfied: numpy<2.5,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from scipy->torch-sparse) (2.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Dataset_setting"
      ],
      "metadata": {
        "id": "maEGsiInUMWG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/oasis_dataset.py\n",
        "import os\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "\n",
        "ZIP_PATH = '/content/oaisis.zip'\n",
        "EXTRACT_DIR = '/content/oasis_data/'\n",
        "\n",
        "def extract_zip():\n",
        "    try:\n",
        "        if not os.path.exists(ZIP_PATH):\n",
        "            raise FileNotFoundError(f\"{ZIP_PATH} not found. Please upload the file to Colab.\")\n",
        "        os.makedirs(EXTRACT_DIR, exist_ok=True)\n",
        "        if not os.listdir(EXTRACT_DIR):\n",
        "            with zipfile.ZipFile(ZIP_PATH, 'r') as zip_ref:\n",
        "                zip_ref.extractall(EXTRACT_DIR)\n",
        "            print(f\"Extracted {ZIP_PATH} to {EXTRACT_DIR}\")\n",
        "        else:\n",
        "            print(f\"Directory {EXTRACT_DIR} already contains files, skipping extraction.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error extracting ZIP file: {e}\")\n",
        "        raise\n",
        "\n",
        "extract_zip()\n",
        "\n",
        "class PatchExtractor:\n",
        "    def __init__(self, patch_size=64, K=80, spatial_threshold=5):\n",
        "        self.patch_size = patch_size\n",
        "        self.K = K\n",
        "        self.spatial_threshold = spatial_threshold\n",
        "\n",
        "    def extract_patches(self, image, prob_map):\n",
        "        patches = []\n",
        "        coords = []\n",
        "        prob_map_copy = prob_map.copy()\n",
        "        for _ in range(self.K):\n",
        "            max_prob_idx = np.argmax(prob_map_copy)\n",
        "            y, x = np.unravel_index(max_prob_idx, prob_map_copy.shape)\n",
        "            patch = self.get_patch(image, (x, y))\n",
        "            patches.append(patch)\n",
        "            coords.append((x, y))\n",
        "            prob_map_copy = self.mask_neighbors(prob_map_copy, (x, y))\n",
        "        return patches, coords\n",
        "\n",
        "    def get_patch(self, image, center):\n",
        "        half_size = self.patch_size // 2\n",
        "        x, y = center\n",
        "        patch = image[\n",
        "            max(0, y - half_size):y + half_size,\n",
        "            max(0, x - half_size):x + half_size\n",
        "        ]\n",
        "        if patch.shape[0] < self.patch_size or patch.shape[1] < self.patch_size:\n",
        "            patch = np.pad(patch, [(0, max(0, self.patch_size - patch.shape[0])),\n",
        "                                   (0, max(0, self.patch_size - patch.shape[1]))],\n",
        "                           mode='constant')\n",
        "        return patch\n",
        "\n",
        "    def mask_neighbors(self, prob_map, center):\n",
        "        half_size = self.spatial_threshold\n",
        "        x, y = center\n",
        "        prob_map[\n",
        "            max(0, y - half_size):y + half_size + 1,\n",
        "            max(0, x - half_size):x + half_size + 1\n",
        "        ] = 0\n",
        "        return prob_map\n",
        "\n",
        "    def dynamic_sample(self, image, N=40):\n",
        "        candidate_patches = []\n",
        "        candidate_coords = []\n",
        "        stride = self.patch_size // 2\n",
        "        h, w = image.shape\n",
        "        for y in range(0, h - self.patch_size + 1, stride):\n",
        "            for x in range(0, w - self.patch_size + 1, stride):\n",
        "                patch = image[y:y+self.patch_size, x:x+self.patch_size]\n",
        "                candidate_patches.append(patch)\n",
        "                candidate_coords.append((x, y))\n",
        "        indices = np.random.choice(len(candidate_patches),\n",
        "                                   min(N, len(candidate_patches)),\n",
        "                                   replace=False)\n",
        "        return [candidate_patches[i] for i in indices], [candidate_coords[i] for i in indices]\n",
        "\n",
        "class OasisDataset(Dataset):\n",
        "    def __init__(self, data_dir, patch_size=64, n_sampled_patches=40):\n",
        "        self.data_dir = os.path.join(data_dir, 'Data')\n",
        "        self.patch_size = patch_size\n",
        "        self.n_sampled_patches = n_sampled_patches\n",
        "        self.patch_extractor = PatchExtractor(patch_size=patch_size)\n",
        "        self.class_map = {\n",
        "            'Non Demented': 0,\n",
        "            'Very mild Dementia': 1,\n",
        "            'Mild Dementia': 2,\n",
        "            'Moderate Dementia': 3\n",
        "        }\n",
        "        self.image_paths = []\n",
        "        self.labels = []\n",
        "\n",
        "        print(f\"Looking for images in {self.data_dir}\")\n",
        "        if not os.path.exists(self.data_dir):\n",
        "            raise FileNotFoundError(f\"Data directory {self.data_dir} not found\")\n",
        "\n",
        "        available_dirs = os.listdir(self.data_dir)\n",
        "        print(f\"Available directories: {available_dirs}\")\n",
        "\n",
        "        class_valid_paths = {}\n",
        "        for class_name in self.class_map:\n",
        "            matching_dir = next((d for d in available_dirs if d.lower() == class_name.lower()), None)\n",
        "            if not matching_dir:\n",
        "                print(f\"Warning: No directory found for {class_name}\")\n",
        "                continue\n",
        "            class_dir = os.path.join(self.data_dir, matching_dir)\n",
        "            print(f\"Checking directory: {class_dir}\")\n",
        "            img_files = [f for f in os.listdir(class_dir) if f.lower().endswith('.jpg')]\n",
        "            img_paths = [os.path.join(class_dir, f) for f in img_files]\n",
        "            print(f\"Found {len(img_paths)} .jpg files in {class_dir}\")\n",
        "\n",
        "            valid_paths = []\n",
        "            for img_path in img_paths:\n",
        "                try:\n",
        "                    with Image.open(img_path) as img:\n",
        "                        img.verify()\n",
        "                    valid_paths.append(img_path)\n",
        "                except Exception as e:\n",
        "                    print(f\"Warning: Failed to load {img_path}: {e}\")\n",
        "            class_valid_paths[class_name] = valid_paths\n",
        "\n",
        "        if not class_valid_paths:\n",
        "            raise ValueError(f\"No valid images found in {self.data_dir}.\")\n",
        "\n",
        "        min_images = min(len(paths) for paths in class_valid_paths.values())\n",
        "        self.images_per_class = min_images\n",
        "\n",
        "        for class_name in self.class_map:\n",
        "            if class_name not in class_valid_paths:\n",
        "                continue\n",
        "            valid_paths = class_valid_paths[class_name]\n",
        "            sampled_paths = np.random.choice(valid_paths,\n",
        "                                             self.images_per_class,\n",
        "                                             replace=False)\n",
        "            self.image_paths.extend(sampled_paths)\n",
        "            self.labels.extend([self.class_map[class_name]] * self.images_per_class)\n",
        "\n",
        "        print(f\"Loaded {len(self.image_paths)} images: \"\n",
        "              f\"{len([l for l in self.labels if l == 0])} CN, \"\n",
        "              f\"{len([l for l in self.labels if l == 1])} MCI, \"\n",
        "              f\"{len([l for l in self.labels if l == 2])} Mild, \"\n",
        "              f\"{len([l for l in self.labels if l == 3])} Moderate\")\n",
        "\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.ToPILImage(),\n",
        "            transforms.RandomRotation(10),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.ToTensor(),\n",
        "        ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_paths[idx]\n",
        "        label = self.labels[idx]\n",
        "        try:\n",
        "            image = np.array(Image.open(img_path).convert('L')) / 255.0\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading image {img_path}: {e}\")\n",
        "            raise\n",
        "        prob_map = np.random.rand(image.shape[0], image.shape[1])\n",
        "        patches, coords = self.patch_extractor.extract_patches(image, prob_map)\n",
        "        sampled_patches, sampled_coords = self.patch_extractor.dynamic_sample(\n",
        "            image, self.n_sampled_patches)\n",
        "        patches_tensor = torch.stack([self.transform(patch) for patch in sampled_patches])\n",
        "        label_tensor = torch.tensor(label, dtype=torch.long)\n",
        "        return patches_tensor, label_tensor, sampled_coords\n",
        "\n",
        "\n",
        "def custom_collate_fn(batch):\n",
        "    patches = torch.stack([item[0] for item in batch])\n",
        "    labels = torch.stack([item[1] for item in batch])\n",
        "    coords = [item[2] for item in batch]\n",
        "    return patches, labels, coords\n",
        "\n",
        "\n",
        "def get_dataloader(data_dir, batch_size=2):\n",
        "    dataset = OasisDataset(data_dir, patch_size=64, n_sampled_patches=40)\n",
        "    return DataLoader(\n",
        "        dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,      # finite, randomized per epoch\n",
        "        num_workers=0,\n",
        "        collate_fn=custom_collate_fn\n",
        "    )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XEboLVMEzFcF",
        "outputId": "4aaebb94-463b-4437-a666-4bedcf9452d5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/oasis_dataset.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from oasis_dataset import OasisDataset\n",
        "import numpy as np\n",
        "try:\n",
        "    dataset = OasisDataset('/content/oasis_data/', subset_size=1000)\n",
        "    print(f\"Class distribution: {np.bincount(dataset.labels)}\")\n",
        "except Exception as e:\n",
        "    print(f\"Dataset error: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p5Ks-LxI4xTK",
        "outputId": "6071ce6a-73e9-49e3-fd14-8d01a8124f13"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directory /content/oasis_data/ already contains files, skipping extraction.\n",
            "Dataset error: OasisDataset.__init__() got an unexpected keyword argument 'subset_size'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from oasis_dataset import get_dataloader\n",
        "try:\n",
        "    dataloader = get_dataloader('/content/oasis_data/', batch_size=2)\n",
        "    for patches, labels, coords in dataloader:\n",
        "        print(\"Patches shape:\", patches.shape)  # Expected: [2, 20, 1, 32, 32]\n",
        "        print(\"Labels shape:\", labels.shape)   # Expected: [2]\n",
        "        print(\"Coords length:\", len(coords))   # Expected: 2\n",
        "        break\n",
        "except Exception as e:\n",
        "    print(f\"DataLoader error: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KiFVnIT6oPYp",
        "outputId": "cbecbd93-914c-4818-ae95-e3d5cd9dada6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking for images in /content/oasis_data/Data\n",
            "Available directories: ['Mild Dementia', 'Non Demented', 'Moderate Dementia', 'Very mild Dementia']\n",
            "Checking directory: /content/oasis_data/Data/Non Demented\n",
            "Found 67222 .jpg files in /content/oasis_data/Data/Non Demented\n",
            "Checking directory: /content/oasis_data/Data/Very mild Dementia\n",
            "Found 13725 .jpg files in /content/oasis_data/Data/Very mild Dementia\n",
            "Checking directory: /content/oasis_data/Data/Mild Dementia\n",
            "Found 5002 .jpg files in /content/oasis_data/Data/Mild Dementia\n",
            "Checking directory: /content/oasis_data/Data/Moderate Dementia\n",
            "Found 488 .jpg files in /content/oasis_data/Data/Moderate Dementia\n",
            "Loaded 1952 images: 488 CN, 488 MCI, 488 Mild, 488 Moderate\n",
            "Patches shape: torch.Size([2, 40, 1, 64, 64])\n",
            "Labels shape: torch.Size([2])\n",
            "Coords length: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#pmicl_model"
      ],
      "metadata": {
        "id": "utWP-fX8TDvg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/pmicl_model.py\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "import torch.nn.init as init\n",
        "\n",
        "class GraphConstructor:\n",
        "    def __init__(self, k=10):\n",
        "        self.k = k\n",
        "\n",
        "    def build_graph(self, features):\n",
        "        from sklearn.neighbors import kneighbors_graph\n",
        "        adj = kneighbors_graph(features, n_neighbors=self.k, mode='distance', include_self=False)\n",
        "        edge_index = torch.tensor(adj.nonzero(), dtype=torch.long)\n",
        "        edge_weight = torch.tensor(adj[adj.nonzero()], dtype=torch.float)\n",
        "        edge_weight = 1.0 / (edge_weight + 1e-6)  # Inverse distance\n",
        "        return edge_index, edge_weight\n",
        "\n",
        "def graph_loss(embeddings, edge_index, edge_weight):\n",
        "    print(f\"graph_loss: embeddings shape: {embeddings.shape}, edge_index max: {edge_index.max()}\")\n",
        "    source = embeddings[edge_index[0]]\n",
        "    target = embeddings[edge_index[1]]\n",
        "    similarity = F.cosine_similarity(source, target, dim=-1)\n",
        "    print(f\"Cosine similarity (sample): {similarity[:5]}\")\n",
        "    loss = -torch.mean(edge_weight * similarity)\n",
        "    print(f\"Graph loss: {loss.item()}\")\n",
        "    return loss\n",
        "\n",
        "class PMICL(nn.Module):\n",
        "    def __init__(self, num_classes=4, embed_dim=128, num_prototypes=10):\n",
        "        super(PMICL, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 64, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(128)\n",
        "        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(256)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(256 * 8 * 8, embed_dim)\n",
        "        self.gcn = GCNConv(embed_dim, embed_dim)\n",
        "        self.fc2 = nn.Linear(embed_dim, num_classes)\n",
        "        self.prototypes = nn.Parameter(torch.randn(num_prototypes, embed_dim))\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "        # Kaiming initialization for fc1 and fc2, normal for prototypes\n",
        "        init.kaiming_normal_(self.fc1.weight, mode='fan_out', nonlinearity='relu')\n",
        "        init.kaiming_normal_(self.fc2.weight, mode='fan_out', nonlinearity='relu')\n",
        "        init.normal_(self.prototypes, mean=0.0, std=0.01)\n",
        "\n",
        "    def forward(self, patches, edge_index, batch, labels=None):\n",
        "        B, N, C, H, W = patches.shape\n",
        "        x = patches.view(B * N, C, H, W)\n",
        "        x = self.bn1(F.relu(self.conv1(x)))\n",
        "        x = self.pool(x)\n",
        "        x = self.bn2(F.relu(self.conv2(x)))\n",
        "        x = self.pool(x)\n",
        "        x = self.bn3(F.relu(self.conv3(x)))\n",
        "        x = self.pool(x)\n",
        "        x = x.view(B * N, -1)\n",
        "        x = self.dropout(F.relu(self.fc1(x)))\n",
        "\n",
        "        print(f\"Before GCN - embeddings shape: {x.shape}, Min: {x.min()}, Max: {x.max()}\")\n",
        "        x_gcn = F.relu(self.gcn(x, edge_index))\n",
        "        print(f\"GCN embeddings - Min: {x_gcn.min()}, Max: {x_gcn.max()}\")\n",
        "\n",
        "        attention_weights = F.softmax(torch.matmul(x_gcn, x_gcn.t()) / (x_gcn.shape[-1] ** 0.5), dim=-1)\n",
        "        x = torch.matmul(attention_weights, x_gcn)\n",
        "        print(f\"After Attention - Min: {x.min()}, Max: {x.max()}\")\n",
        "\n",
        "        graph_loss_val = graph_loss(x, edge_index, torch.ones(edge_index.shape[1], device=x.device))\n",
        "\n",
        "        x = x.view(B, N, -1)\n",
        "        x = x.mean(dim=1)\n",
        "        logits = self.fc2(x)\n",
        "        cls_loss = F.cross_entropy(logits, labels) if labels is not None else torch.tensor(0.0, device=logits.device)\n",
        "        proto_dist = torch.cdist(x, self.prototypes)\n",
        "        proto_loss = proto_dist.mean()\n",
        "\n",
        "        return logits, cls_loss, proto_loss, graph_loss_val, attention_weights\n"
      ],
      "metadata": {
        "id": "sCSvS3SDhlYF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60132e4e-b12a-4a39-87a7-8a5eb0fbbc20"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/pmicl_model.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Train\n"
      ],
      "metadata": {
        "id": "C8IcjcGCukLt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/train.py\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F  # Fix for NameError\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from oasis_dataset import get_dataloader\n",
        "from pmicl_model import PMICL, GraphConstructor\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "NUM_EPOCHS = 5\n",
        "BATCH_SIZE = 2\n",
        "LEARNING_RATE = 1e-2  # Increased from 5e-3\n",
        "NUM_CLASSES = 4\n",
        "PATIENCE = 5\n",
        "\n",
        "def train_epoch(model, dataloader, optimizer, device):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    cls_loss_total = 0\n",
        "    proto_loss_total = 0\n",
        "    graph_loss_total = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    graph_constructor = GraphConstructor(k=5)\n",
        "\n",
        "    for patches, labels, coords in dataloader:\n",
        "        patches, labels = patches.to(device), labels.to(device)\n",
        "        B, N, C, H, W = patches.shape\n",
        "        with torch.no_grad():\n",
        "            x = patches.view(B * N, C, H, W)\n",
        "            x = model.bn1(F.relu(model.conv1(x)))\n",
        "            x = model.pool(x)\n",
        "            x = model.bn2(F.relu(model.conv2(x)))\n",
        "            x = model.pool(x)\n",
        "            x = model.bn3(F.relu(model.conv3(x)))\n",
        "            x = model.pool(x)\n",
        "            x = x.view(B * N, -1)\n",
        "            x = F.relu(model.fc1(x))\n",
        "        patch_features = x.cpu().numpy()\n",
        "        edge_index, edge_weight = graph_constructor.build_graph(patch_features)\n",
        "        edge_index, edge_weight = edge_index.to(device), edge_weight.to(device)\n",
        "        batch = torch.repeat_interleave(torch.arange(B, device=device), N)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        logits, cls_loss, proto_loss, graph_loss, _ = model(patches, edge_index, batch, labels)\n",
        "        print(f\"Graph loss (batch): {graph_loss.item():.4f}\")\n",
        "\n",
        "        loss = 0.55 * cls_loss + 0.4 * proto_loss + 0.05 * graph_loss  # Reduced graph loss weight\n",
        "        loss.backward()\n",
        "\n",
        "        # Monitor gradient norms\n",
        "        total_grad_norm = 0\n",
        "        for p in model.parameters():\n",
        "            if p.grad is not None:\n",
        "                total_grad_norm += p.grad.norm().item() ** 2\n",
        "        total_grad_norm = total_grad_norm ** 0.5\n",
        "        print(f\"Gradients - GCN weights: {model.gcn.lin.weight.grad}\")\n",
        "        print(f\"Total gradient norm: {total_grad_norm:.6f}\")\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        cls_loss_total += cls_loss.item()\n",
        "        proto_loss_total += proto_loss.item()\n",
        "        graph_loss_total += graph_loss.item()\n",
        "\n",
        "        preds = torch.argmax(logits, dim=1)\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "    train_acc = correct / total\n",
        "    print(f\"Graph Loss (Epoch Total): {graph_loss_total / len(dataloader):.4f}\")\n",
        "    return (total_loss / len(dataloader), cls_loss_total / len(dataloader),\n",
        "            proto_loss_total / len(dataloader), graph_loss_total / len(dataloader), train_acc)\n",
        "\n",
        "def evaluate(model, dataloader, device):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    graph_constructor = GraphConstructor(k=5)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for patches, labels, coords in dataloader:\n",
        "            patches, labels = patches.to(device), labels.to(device)\n",
        "            B, N, C, H, W = patches.shape\n",
        "            x = patches.view(B * N, C, H, W)\n",
        "            x = model.bn1(F.relu(model.conv1(x)))\n",
        "            x = model.pool(x)\n",
        "            x = model.bn2(F.relu(model.conv2(x)))\n",
        "            x = model.pool(x)\n",
        "            x = model.bn3(F.relu(model.conv3(x)))\n",
        "            x = model.pool(x)\n",
        "            x = x.view(B * N, -1)\n",
        "            x = F.relu(model.fc1(x))\n",
        "            patch_features = x.cpu().numpy()\n",
        "            edge_index, edge_weight = graph_constructor.build_graph(patch_features)\n",
        "            edge_index, edge_weight = edge_index.to(device), edge_weight.to(device)\n",
        "            batch = torch.repeat_interleave(torch.arange(B, device=device), N)\n",
        "\n",
        "            logits, _, _, _, _ = model(patches, edge_index, batch)\n",
        "            preds = torch.argmax(logits, dim=1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "    return correct / total\n",
        "\n",
        "def main():\n",
        "    dataloader = get_dataloader('/content/oasis_data/', batch_size=BATCH_SIZE)\n",
        "    model = PMICL(num_classes=NUM_CLASSES).to(DEVICE)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-4)\n",
        "\n",
        "    best_val_acc = 0\n",
        "    patience_counter = 0\n",
        "\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "        print(f\"Epoch {epoch+1}/{NUM_EPOCHS}\")\n",
        "        loss, cls_loss, proto_loss, graph_loss, train_acc = train_epoch(model, dataloader, optimizer, DEVICE)\n",
        "        print(f\"Loss: {loss:.4f}, Cls: {cls_loss:.4f}, Proto: {proto_loss:.4f}, Graph: {graph_loss:.4f}, Train Acc: {train_acc:.4f}\")\n",
        "\n",
        "        val_acc = evaluate(model, dataloader, DEVICE)\n",
        "        print(f\"Val Acc: {val_acc:.4f}\")\n",
        "\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            if patience_counter >= PATIENCE:\n",
        "                print(\"Early stopping triggered\")\n",
        "                break\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "daNd8mzsvi0m",
        "outputId": "0e67f9ef-e8a2-4fdc-9183-9963ca0a809c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/train.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/__pycache__"
      ],
      "metadata": {
        "id": "BL8OfR3438-S"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%run /content/train.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LKVEMJFM4TXf",
        "outputId": "a1fb6917-4cd8-4625-bf05-dae25db43353"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking for images in /content/oasis_data/Data\n",
            "Available directories: ['Mild Dementia', 'Non Demented', 'Moderate Dementia', 'Very mild Dementia']\n",
            "Checking directory: /content/oasis_data/Data/Non Demented\n",
            "Found 67222 .jpg files in /content/oasis_data/Data/Non Demented\n",
            "Checking directory: /content/oasis_data/Data/Very mild Dementia\n",
            "Found 13725 .jpg files in /content/oasis_data/Data/Very mild Dementia\n",
            "Checking directory: /content/oasis_data/Data/Mild Dementia\n",
            "Found 5002 .jpg files in /content/oasis_data/Data/Mild Dementia\n",
            "Checking directory: /content/oasis_data/Data/Moderate Dementia\n",
            "Found 488 .jpg files in /content/oasis_data/Data/Moderate Dementia\n",
            "Loaded 1952 images: 488 CN, 488 MCI, 488 Mild, 488 Moderate\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/pmicl_model.py:14: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:254.)\n",
            "  edge_index = torch.tensor(adj.nonzero(), dtype=torch.long)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before GCN - embeddings shape: torch.Size([80, 128]), Min: 0.0, Max: 300.1095886230469\n",
            "GCN embeddings - Min: 0.0, Max: 133.39749145507812\n",
            "After Attention - Min: 0.0, Max: 133.39749145507812\n",
            "graph_loss: embeddings shape: torch.Size([80, 128]), edge_index max: 79\n",
            "Cosine similarity (sample): tensor([0.8900, 0.8900, 0.8900, 0.3943, 0.8900], grad_fn=<SliceBackward0>)\n",
            "Graph loss: -0.7880587577819824\n",
            "Graph loss (batch): -0.7881\n",
            "Gradients - GCN weights: tensor([[ 3.5685e-02,  3.2288e-01,  9.0518e-02,  ...,  4.6428e-01,\n",
            "         -4.6841e-12,  0.0000e+00],\n",
            "        [-4.4381e+00, -1.1026e-08, -1.5231e-01,  ..., -4.1010e-10,\n",
            "         -4.1534e-01, -2.7913e-02],\n",
            "        [ 8.6499e+00,  1.2290e+00,  5.1658e-01,  ...,  2.2316e+00,\n",
            "          1.3149e-01,  5.9684e-02],\n",
            "        ...,\n",
            "        [ 0.0000e+00,  0.0000e+00, -1.6083e-20,  ...,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00],\n",
            "        [ 2.9020e+00,  3.2730e-01,  4.0778e-01,  ...,  6.0154e-01,\n",
            "          2.4037e-01,  1.6121e-02],\n",
            "        [ 4.2460e-01,  1.9657e-01,  7.7963e-02,  ...,  5.8033e-01,\n",
            "          2.1933e-01,  5.0641e-05]])\n",
            "Total gradient norm: 7475.149709\n",
            "Before GCN - embeddings shape: torch.Size([80, 128]), Min: 0.0, Max: 437.6741638183594\n",
            "GCN embeddings - Min: 0.0, Max: 228.76478576660156\n",
            "After Attention - Min: 0.0, Max: 228.76478576660156\n",
            "graph_loss: embeddings shape: torch.Size([80, 128]), edge_index max: 79\n",
            "Cosine similarity (sample): tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000], grad_fn=<SliceBackward0>)\n",
            "Graph loss: -0.9690321087837219\n",
            "Graph loss (batch): -0.9690\n",
            "Gradients - GCN weights: tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00],\n",
            "        [ 8.3856e+00,  9.2590e+01,  3.2837e+00,  ..., -1.4848e-01,\n",
            "         -8.3471e-02,  5.7919e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00],\n",
            "        ...,\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00]])\n",
            "Total gradient norm: 8519.177682\n",
            "Before GCN - embeddings shape: torch.Size([80, 128]), Min: 0.0, Max: 303.9797058105469\n",
            "GCN embeddings - Min: 0.0, Max: 142.01173400878906\n",
            "After Attention - Min: 0.0, Max: 142.01173400878906\n",
            "graph_loss: embeddings shape: torch.Size([80, 128]), edge_index max: 79\n",
            "Cosine similarity (sample): tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000], grad_fn=<SliceBackward0>)\n",
            "Graph loss: -0.99220871925354\n",
            "Graph loss (batch): -0.9922\n",
            "Gradients - GCN weights: tensor([[0.0000e+00, 2.6854e-33, 5.9314e-35,  ..., 7.4402e-33, 0.0000e+00,\n",
            "         0.0000e+00],\n",
            "        [2.1833e-01, 2.0624e+00, 1.8484e-01,  ..., 6.8570e-01, 1.8444e-05,\n",
            "         1.1202e-01],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00],\n",
            "        ...,\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00]])\n",
            "Total gradient norm: 1087.132867\n",
            "Before GCN - embeddings shape: torch.Size([80, 128]), Min: 0.0, Max: 365.54571533203125\n",
            "GCN embeddings - Min: 0.0, Max: 220.8252716064453\n",
            "After Attention - Min: 0.0, Max: 220.8252716064453\n",
            "graph_loss: embeddings shape: torch.Size([80, 128]), edge_index max: 79\n",
            "Cosine similarity (sample): tensor([1., 1., 1., 1., 1.], grad_fn=<SliceBackward0>)\n",
            "Graph loss: -1.0\n",
            "Graph loss (batch): -1.0000\n",
            "Gradients - GCN weights: tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000, 13.0696,  0.0000,  ...,  4.5782,  0.0000,  0.1432],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        ...,\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]])\n",
            "Total gradient norm: 1792.593065\n",
            "Before GCN - embeddings shape: torch.Size([80, 128]), Min: 0.0, Max: 339.36798095703125\n",
            "GCN embeddings - Min: 0.0, Max: 116.25630187988281\n",
            "After Attention - Min: 0.0, Max: 113.71068572998047\n",
            "graph_loss: embeddings shape: torch.Size([80, 128]), edge_index max: 79\n",
            "Cosine similarity (sample): tensor([1.0000, 0.4792, 1.0000, 1.0000, 0.3928], grad_fn=<SliceBackward0>)\n",
            "Graph loss: -0.8717446327209473\n",
            "Graph loss (batch): -0.8717\n",
            "Gradients - GCN weights: tensor([[-7.3651e-01, -2.2514e+00, -1.8019e-01,  ..., -9.0598e-01,\n",
            "         -1.6402e-01, -3.3238e-01],\n",
            "        [-2.6647e+00, -5.7954e+00, -1.8237e-01,  ..., -5.2276e+00,\n",
            "         -5.9511e-01, -2.7198e-01],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  6.0978e-19,\n",
            "          0.0000e+00,  0.0000e+00],\n",
            "        ...,\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00]])\n",
            "Total gradient norm: 427.035996\n",
            "Before GCN - embeddings shape: torch.Size([80, 128]), Min: 0.0, Max: 442.08013916015625\n",
            "GCN embeddings - Min: 0.0, Max: 186.0709991455078\n",
            "After Attention - Min: 0.0, Max: 186.0709991455078\n",
            "graph_loss: embeddings shape: torch.Size([80, 128]), edge_index max: 79\n",
            "Cosine similarity (sample): tensor([0.3286, 0.3286, 0.5981, 0.3286, 0.2200], grad_fn=<SliceBackward0>)\n",
            "Graph loss: -0.9027571082115173\n",
            "Graph loss (batch): -0.9028\n",
            "Gradients - GCN weights: tensor([[ 1.3691e+00,  3.1090e+01,  6.5456e-05,  ...,  8.8095e-02,\n",
            "          0.0000e+00,  1.7828e+00],\n",
            "        [-5.4643e+01, -5.9485e+01,  3.8765e+00,  ...,  9.8422e+00,\n",
            "          2.5548e+01,  8.6523e-01],\n",
            "        [ 2.0908e+00,  4.7538e+01,  0.0000e+00,  ...,  0.0000e+00,\n",
            "          0.0000e+00,  2.7223e+00],\n",
            "        ...,\n",
            "        [-4.3070e+01, -2.9406e+01, -4.2483e-01,  ..., -6.6595e+00,\n",
            "         -7.8125e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "          4.9396e-02,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00]])\n",
            "Total gradient norm: 3793.412722\n",
            "Before GCN - embeddings shape: torch.Size([80, 128]), Min: 0.0, Max: 573.0222778320312\n",
            "GCN embeddings - Min: 0.0, Max: 206.89776611328125\n",
            "After Attention - Min: 0.0, Max: 206.89776611328125\n",
            "graph_loss: embeddings shape: torch.Size([80, 128]), edge_index max: 79\n",
            "Cosine similarity (sample): tensor([0.9758, 0.8384, 0.8384, 0.8384, 0.8384], grad_fn=<SliceBackward0>)\n",
            "Graph loss: -0.8746868968009949\n",
            "Graph loss (batch): -0.8747\n",
            "Gradients - GCN weights: tensor([[ 6.0811e-05,  4.0912e+01,  8.0433e-05,  ...,  7.4020e-05,\n",
            "          2.8771e-05,  4.0644e+00],\n",
            "        [-5.1871e+00, -8.8329e-02, -2.1920e-03,  ..., -8.6072e-04,\n",
            "         -1.1478e+00, -2.7056e-03],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00],\n",
            "        ...,\n",
            "        [-5.6125e+01, -1.4509e+02,  4.1046e-05,  ...,  4.6082e-05,\n",
            "         -1.1779e+01, -1.4283e+01],\n",
            "        [ 4.7879e-03,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "          3.1796e-03,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00]])\n",
            "Total gradient norm: 886.063475\n",
            "Before GCN - embeddings shape: torch.Size([80, 128]), Min: 0.0, Max: 638.646484375\n",
            "GCN embeddings - Min: 0.0, Max: 190.95179748535156\n",
            "After Attention - Min: 0.0, Max: 190.95179748535156\n",
            "graph_loss: embeddings shape: torch.Size([80, 128]), edge_index max: 79\n",
            "Cosine similarity (sample): tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000], grad_fn=<SliceBackward0>)\n",
            "Graph loss: -0.8623505234718323\n",
            "Graph loss (batch): -0.8624\n",
            "Gradients - GCN weights: tensor([[ 0.0000e+00,  9.6741e+00,  7.5613e-01,  ..., -2.4772e-01,\n",
            "         -4.7462e-02,  2.1168e+00],\n",
            "        [ 2.1011e+00,  1.1160e+00,  4.1606e-10,  ...,  5.3695e-10,\n",
            "          8.3257e+00,  4.4416e-10],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00],\n",
            "        ...,\n",
            "        [ 1.6286e+02,  1.6680e+02,  1.1830e+01,  ...,  3.0797e+00,\n",
            "          3.2077e+01,  2.8852e+01],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00]])\n",
            "Total gradient norm: 1583.480840\n",
            "Before GCN - embeddings shape: torch.Size([80, 128]), Min: 0.0, Max: 657.8432006835938\n",
            "GCN embeddings - Min: 0.0, Max: 343.88629150390625\n",
            "After Attention - Min: 0.0, Max: 343.88629150390625\n",
            "graph_loss: embeddings shape: torch.Size([80, 128]), edge_index max: 79\n",
            "Cosine similarity (sample): tensor([0.7225, 0.7818, 0.7818, 1.0000, 0.7818], grad_fn=<SliceBackward0>)\n",
            "Graph loss: -0.8900947570800781\n",
            "Graph loss (batch): -0.8901\n",
            "Gradients - GCN weights: tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 1.2400e-03,\n",
            "         0.0000e+00],\n",
            "        [6.9414e+00, 3.0438e-07, 6.5205e-07,  ..., 7.7443e-03, 1.5462e-01,\n",
            "         1.5412e-06],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00],\n",
            "        ...,\n",
            "        [5.5642e+01, 6.7466e+01, 7.4244e+01,  ..., 4.6568e+00, 3.5600e+01,\n",
            "         1.3870e+02],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 4.6421e-04,\n",
            "         0.0000e+00],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00]])\n",
            "Total gradient norm: 1293.982763\n",
            "Before GCN - embeddings shape: torch.Size([80, 128]), Min: 0.0, Max: 762.7686767578125\n",
            "GCN embeddings - Min: 0.0, Max: 319.810546875\n",
            "After Attention - Min: 0.0, Max: 319.810546875\n",
            "graph_loss: embeddings shape: torch.Size([80, 128]), edge_index max: 79\n",
            "Cosine similarity (sample): tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000], grad_fn=<SliceBackward0>)\n",
            "Graph loss: -0.9023734927177429\n",
            "Graph loss (batch): -0.9024\n",
            "Gradients - GCN weights: tensor([[ 2.7318e+00,  5.4247e+01,  3.4696e+01,  ...,  9.3333e-03,\n",
            "          1.8989e+01,  1.7059e+01],\n",
            "        [ 8.5532e+01,  0.0000e+00, -5.1478e-27,  ..., -9.2009e-28,\n",
            "          1.6907e+01, -2.0104e-27],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00],\n",
            "        ...,\n",
            "        [-1.0385e+02, -4.4272e+01, -2.8304e+01,  ..., -7.6177e-03,\n",
            "         -3.5845e+01, -1.8309e+01],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00]])\n",
            "Total gradient norm: 2445.538203\n",
            "Before GCN - embeddings shape: torch.Size([80, 128]), Min: 0.0, Max: 789.9561767578125\n",
            "GCN embeddings - Min: 0.0, Max: 276.1055908203125\n",
            "After Attention - Min: 0.0, Max: 276.1055908203125\n",
            "graph_loss: embeddings shape: torch.Size([80, 128]), edge_index max: 79\n",
            "Cosine similarity (sample): tensor([0.2454, 1.0000, 1.0000, 0.3300, 1.0000], grad_fn=<SliceBackward0>)\n",
            "Graph loss: -0.8372827768325806\n",
            "Graph loss (batch): -0.8373\n",
            "Gradients - GCN weights: tensor([[ 1.5492e-25,  3.3441e+00,  1.9314e+00,  ...,  1.4524e-01,\n",
            "          1.0745e+00,  5.9970e-01],\n",
            "        [-2.4780e+00, -1.3230e+01, -1.0426e+01,  ..., -2.1137e+00,\n",
            "         -1.0039e+01, -3.2371e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00],\n",
            "        ...,\n",
            "        [-3.1047e+01, -1.9472e+01, -1.6186e+01,  ..., -3.3894e+00,\n",
            "         -1.6095e+01, -5.0253e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00]])\n",
            "Total gradient norm: 5016.185908\n",
            "Before GCN - embeddings shape: torch.Size([80, 128]), Min: 0.0, Max: 839.9967651367188\n",
            "GCN embeddings - Min: 0.0, Max: 252.91848754882812\n",
            "After Attention - Min: 0.0, Max: 252.91848754882812\n",
            "graph_loss: embeddings shape: torch.Size([80, 128]), edge_index max: 79\n",
            "Cosine similarity (sample): tensor([1.0000, 0.9703, 0.9128, 1.0000, 1.0000], grad_fn=<SliceBackward0>)\n",
            "Graph loss: -0.9002912044525146\n",
            "Graph loss (batch): -0.9003\n",
            "Gradients - GCN weights: tensor([[  0.4342, -12.9279, -31.8765,  ...,  -2.5991, -12.4797, -10.1098],\n",
            "        [-13.2146, -22.4061, -48.3667,  ...,  -3.4838, -20.1313, -18.1387],\n",
            "        [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000],\n",
            "        ...,\n",
            "        [ -3.8073,  -0.5522,  -0.9324,  ...,   0.0000,  -1.3809,  -1.3917],\n",
            "        [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000],\n",
            "        [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000]])\n",
            "Total gradient norm: 2035.526006\n",
            "Before GCN - embeddings shape: torch.Size([80, 128]), Min: 0.0, Max: 830.3477783203125\n",
            "GCN embeddings - Min: 0.0, Max: 298.4415588378906\n",
            "After Attention - Min: 0.0, Max: 298.4415588378906\n",
            "graph_loss: embeddings shape: torch.Size([80, 128]), edge_index max: 79\n",
            "Cosine similarity (sample): tensor([0.5921, 0.5921, 0.7260, 0.7260, 0.7260], grad_fn=<SliceBackward0>)\n",
            "Graph loss: -0.8764029145240784\n",
            "Graph loss (batch): -0.8764\n",
            "Gradients - GCN weights: tensor([[ 3.4971,  1.9903,  5.1349,  ...,  1.0138,  1.3533,  0.7241],\n",
            "        [-3.9380, -3.4997, -1.9433,  ..., -1.0581, -1.8371, -1.5126],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        ...,\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]])\n",
            "Total gradient norm: 1061.013490\n",
            "Before GCN - embeddings shape: torch.Size([80, 128]), Min: 0.0, Max: 904.1478271484375\n",
            "GCN embeddings - Min: 0.0, Max: 285.4599609375\n",
            "After Attention - Min: 0.0, Max: 285.4599609375\n",
            "graph_loss: embeddings shape: torch.Size([80, 128]), edge_index max: 79\n",
            "Cosine similarity (sample): tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000], grad_fn=<SliceBackward0>)\n",
            "Graph loss: -0.8879693746566772\n",
            "Graph loss (batch): -0.8880\n",
            "Gradients - GCN weights: tensor([[ 14.6383,  24.4792,  56.1446,  ...,  12.8153,  29.7952,   3.7191],\n",
            "        [-19.6925,  -8.0854, -18.7838,  ...,  -4.6199, -10.5752,  -1.9286],\n",
            "        [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000],\n",
            "        ...,\n",
            "        [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000],\n",
            "        [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000],\n",
            "        [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000]])\n",
            "Total gradient norm: 1733.154244\n",
            "Before GCN - embeddings shape: torch.Size([80, 128]), Min: 0.0, Max: 954.2572021484375\n",
            "GCN embeddings - Min: 0.0, Max: 296.09320068359375\n",
            "After Attention - Min: 0.0, Max: 296.09320068359375\n",
            "graph_loss: embeddings shape: torch.Size([80, 128]), edge_index max: 79\n",
            "Cosine similarity (sample): tensor([1.0000, 1.0000, 0.8500, 1.0000, 1.0000], grad_fn=<SliceBackward0>)\n",
            "Graph loss: -0.8928642272949219\n",
            "Graph loss (batch): -0.8929\n",
            "Gradients - GCN weights: tensor([[14.5162, 42.9252, 98.8778,  ..., 20.8987, 45.1011,  7.5223],\n",
            "        [65.1546, 36.1600, 84.1003,  ..., 17.7386, 41.2061,  6.3081],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        ...,\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]])\n",
            "Total gradient norm: 1654.679295\n",
            "Before GCN - embeddings shape: torch.Size([80, 128]), Min: 0.0, Max: 910.0081787109375\n",
            "GCN embeddings - Min: 0.0, Max: 383.0638427734375\n",
            "After Attention - Min: 0.0, Max: 383.0638427734375\n",
            "graph_loss: embeddings shape: torch.Size([80, 128]), edge_index max: 79\n",
            "Cosine similarity (sample): tensor([1., 1., 1., 1., 1.], grad_fn=<SliceBackward0>)\n",
            "Graph loss: -0.9316490888595581\n",
            "Graph loss (batch): -0.9316\n",
            "Gradients - GCN weights: tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00],\n",
            "        [ 8.8424e-01,  3.0645e+01,  2.7868e+00,  ...,  4.2313e-01,\n",
            "          3.2333e+01, -6.9609e-20],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00],\n",
            "        ...,\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00]])\n",
            "Total gradient norm: 1118.043040\n",
            "Before GCN - embeddings shape: torch.Size([80, 128]), Min: 0.0, Max: 892.778076171875\n",
            "GCN embeddings - Min: 0.0, Max: 317.92047119140625\n",
            "After Attention - Min: 0.0, Max: 317.92047119140625\n",
            "graph_loss: embeddings shape: torch.Size([80, 128]), edge_index max: 79\n",
            "Cosine similarity (sample): tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000], grad_fn=<SliceBackward0>)\n",
            "Graph loss: -0.9411526322364807\n",
            "Graph loss (batch): -0.9412\n",
            "Gradients - GCN weights: tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 6.3889, 36.6951, 59.1246,  ...,  0.6563,  4.7376,  3.1841],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        ...,\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]])\n",
            "Total gradient norm: 1086.454211\n",
            "Before GCN - embeddings shape: torch.Size([80, 128]), Min: 0.0, Max: 837.427978515625\n",
            "GCN embeddings - Min: 0.0, Max: 206.52137756347656\n",
            "After Attention - Min: 0.0, Max: 206.52137756347656\n",
            "graph_loss: embeddings shape: torch.Size([80, 128]), edge_index max: 79\n",
            "Cosine similarity (sample): tensor([0.9586, 1.0000, 0.9555, 1.0000, 0.9586], grad_fn=<SliceBackward0>)\n",
            "Graph loss: -0.9131799936294556\n",
            "Graph loss (batch): -0.9132\n",
            "Gradients - GCN weights: tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00],\n",
            "        [ 5.1901e+00,  2.5652e+00,  3.2878e+00,  ..., -6.8683e-23,\n",
            "          1.9261e+00,  4.4841e-01],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00],\n",
            "        ...,\n",
            "        [ 1.3815e+01,  5.2969e+01,  1.1874e+02,  ...,  2.7010e-01,\n",
            "          1.0237e+02,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00],\n",
            "        [ 4.7283e+00,  8.9258e-01,  0.0000e+00,  ...,  0.0000e+00,\n",
            "          0.0000e+00,  2.4739e-01]])\n",
            "Total gradient norm: 1393.454624\n",
            "Before GCN - embeddings shape: torch.Size([80, 128]), Min: 0.0, Max: 950.2368774414062\n",
            "GCN embeddings - Min: 0.0, Max: 189.79562377929688\n",
            "After Attention - Min: 0.0, Max: 189.79562377929688\n",
            "graph_loss: embeddings shape: torch.Size([80, 128]), edge_index max: 79\n",
            "Cosine similarity (sample): tensor([0.9351, 0.9848, 0.9351, 1.0000, 0.9351], grad_fn=<SliceBackward0>)\n",
            "Graph loss: -0.8324508666992188\n",
            "Graph loss (batch): -0.8325\n",
            "Gradients - GCN weights: tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00],\n",
            "        [-3.5026e+01, -1.1135e-16, -1.9359e-16,  ..., -5.5136e-22,\n",
            "         -4.1043e-19, -1.5732e+01],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00],\n",
            "        ...,\n",
            "        [-3.6864e+00, -6.6212e-01, -7.2276e-01,  ..., -2.0688e-01,\n",
            "         -2.8319e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00]])\n",
            "Total gradient norm: 1494.250206\n",
            "Before GCN - embeddings shape: torch.Size([80, 128]), Min: 0.0, Max: 1076.1524658203125\n",
            "GCN embeddings - Min: 0.0, Max: 188.6258544921875\n",
            "After Attention - Min: 0.0, Max: 188.6258544921875\n",
            "graph_loss: embeddings shape: torch.Size([80, 128]), edge_index max: 79\n",
            "Cosine similarity (sample): tensor([1., 1., 1., 1., 1.], grad_fn=<SliceBackward0>)\n",
            "Graph loss: -0.795830249786377\n",
            "Graph loss (batch): -0.7958\n",
            "Gradients - GCN weights: tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00],\n",
            "        [1.9132e+01, 1.3553e-33, 7.9710e-34,  ..., 4.8480e-01, 6.5678e-34,\n",
            "         2.3192e+01],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00],\n",
            "        ...,\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00],\n",
            "        [2.5851e-26, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "         1.0813e-25]])\n",
            "Total gradient norm: 1970.469914\n",
            "Before GCN - embeddings shape: torch.Size([80, 128]), Min: 0.0, Max: 1119.13232421875\n",
            "GCN embeddings - Min: 0.0, Max: 145.19393920898438\n",
            "After Attention - Min: 0.0, Max: 145.19393920898438\n",
            "graph_loss: embeddings shape: torch.Size([80, 128]), edge_index max: 78\n",
            "Cosine similarity (sample): tensor([1.0000, 0.8750, 1.0000, 0.8750, 0.8750], grad_fn=<SliceBackward0>)\n",
            "Graph loss: -0.6975973844528198\n",
            "Graph loss (batch): -0.6976\n",
            "Gradients - GCN weights: tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [10.1719, 12.5175, 23.8118,  ...,  0.7948, 26.1834,  5.3994],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        ...,\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  1.7484,  1.3497,  ...,  0.0000,  0.8009,  0.0000]])\n",
            "Total gradient norm: 633.323495\n",
            "Before GCN - embeddings shape: torch.Size([80, 128]), Min: 0.0, Max: 1022.4112548828125\n",
            "GCN embeddings - Min: 0.0, Max: 185.52142333984375\n",
            "After Attention - Min: 0.0, Max: 185.52142333984375\n",
            "graph_loss: embeddings shape: torch.Size([80, 128]), edge_index max: 79\n",
            "Cosine similarity (sample): tensor([8.0689e-01, 2.5536e-09, 8.5340e-01, 5.3714e-01, 4.8560e-01],\n",
            "       grad_fn=<SliceBackward0>)\n",
            "Graph loss: -0.6841222643852234\n",
            "Graph loss (batch): -0.6841\n",
            "Gradients - GCN weights: tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00],\n",
            "        [ 6.7039e+01,  5.4443e-18,  1.1166e-06,  ...,  3.2195e+00,\n",
            "          4.2536e-18,  6.4682e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00],\n",
            "        ...,\n",
            "        [-5.8488e-37,  0.0000e+00, -8.5017e-38,  ...,  0.0000e+00,\n",
            "         -2.1600e-37, -1.8069e-37],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00]])\n",
            "Total gradient norm: 750.690434\n",
            "Before GCN - embeddings shape: torch.Size([80, 128]), Min: 0.0, Max: 1196.248779296875\n",
            "GCN embeddings - Min: 0.0, Max: 252.70944213867188\n",
            "After Attention - Min: 0.0, Max: 252.70944213867188\n",
            "graph_loss: embeddings shape: torch.Size([80, 128]), edge_index max: 79\n",
            "Cosine similarity (sample): tensor([1.0000, 0.7635, 0.7635, 1.0000, 0.7635], grad_fn=<SliceBackward0>)\n",
            "Graph loss: -0.8265467882156372\n",
            "Graph loss (batch): -0.8265\n",
            "Gradients - GCN weights: tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00],\n",
            "        ...,\n",
            "        [-2.6155e+00, -4.5891e+01, -2.0408e-07,  ..., -5.4842e-07,\n",
            "         -1.3954e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00]])\n",
            "Total gradient norm: 566.093438\n",
            "Before GCN - embeddings shape: torch.Size([80, 128]), Min: 0.0, Max: 1184.1490478515625\n",
            "GCN embeddings - Min: 0.0, Max: 307.1667175292969\n",
            "After Attention - Min: 0.0, Max: 307.1667175292969\n",
            "graph_loss: embeddings shape: torch.Size([80, 128]), edge_index max: 79\n",
            "Cosine similarity (sample): tensor([7.0065e-45, 7.0065e-45, 7.0065e-45, 6.5397e-17, 7.0065e-45],\n",
            "       grad_fn=<SliceBackward0>)\n",
            "Graph loss: -0.7416934370994568\n",
            "Graph loss (batch): -0.7417\n",
            "Gradients - GCN weights: tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00],\n",
            "        ...,\n",
            "        [ 0.0000e+00,  0.0000e+00, -2.0677e-14,  ..., -1.2693e-13,\n",
            "         -3.0618e-13,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00]])\n",
            "Total gradient norm: 418.834076\n",
            "Before GCN - embeddings shape: torch.Size([80, 128]), Min: 0.0, Max: 1070.08935546875\n",
            "GCN embeddings - Min: 0.0, Max: 167.18309020996094\n",
            "After Attention - Min: 0.0, Max: 167.18309020996094\n",
            "graph_loss: embeddings shape: torch.Size([80, 128]), edge_index max: 79\n",
            "Cosine similarity (sample): tensor([0.0751, 0.1481, 0.7708, 0.1481, 0.0308], grad_fn=<SliceBackward0>)\n",
            "Graph loss: -0.6385895609855652\n",
            "Graph loss (batch): -0.6386\n",
            "Gradients - GCN weights: tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0033, 0.0216],\n",
            "        [0.0000, 0.0020, 0.0018,  ..., 0.0002, 0.0014, 0.0000],\n",
            "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "        ...,\n",
            "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]])\n",
            "Total gradient norm: 1376.520908\n",
            "Before GCN - embeddings shape: torch.Size([80, 128]), Min: 0.0, Max: 1161.893310546875\n",
            "GCN embeddings - Min: 0.0, Max: 217.26898193359375\n",
            "After Attention - Min: 0.0, Max: 217.26898193359375\n",
            "graph_loss: embeddings shape: torch.Size([80, 128]), edge_index max: 79\n",
            "Cosine similarity (sample): tensor([5.8321e-26, 6.3551e-01, 6.3559e-01, 2.7101e-01, 3.1425e-01],\n",
            "       grad_fn=<SliceBackward0>)\n",
            "Graph loss: -0.5774583220481873\n",
            "Graph loss (batch): -0.5775\n",
            "Gradients - GCN weights: tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00],\n",
            "        [ 1.3740e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "          0.0000e+00,  2.9584e-01],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00],\n",
            "        ...,\n",
            "        [-1.2155e-02, -1.4019e+01, -4.4021e+00,  ..., -4.0964e-01,\n",
            "         -2.5941e-03, -9.5426e-02],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00]])\n",
            "Total gradient norm: 3526.214740\n",
            "Before GCN - embeddings shape: torch.Size([80, 128]), Min: 0.0, Max: 1071.150634765625\n",
            "GCN embeddings - Min: 0.0, Max: 115.55460357666016\n",
            "After Attention - Min: 0.0, Max: 115.55460357666016\n",
            "graph_loss: embeddings shape: torch.Size([80, 128]), edge_index max: 79\n",
            "Cosine similarity (sample): tensor([0.8994, 0.8994, 0.8994, 0.3375, 0.5584], grad_fn=<SliceBackward0>)\n",
            "Graph loss: -0.6558412909507751\n",
            "Graph loss (batch): -0.6558\n",
            "Gradients - GCN weights: tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00],\n",
            "        [8.6458e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00],\n",
            "        ...,\n",
            "        [5.4132e-02, 1.2946e-01, 4.0366e-03,  ..., 1.5815e-01, 3.7829e-01,\n",
            "         0.0000e+00],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00]])\n",
            "Total gradient norm: 933.184607\n",
            "Before GCN - embeddings shape: torch.Size([80, 128]), Min: 0.0, Max: 1397.1405029296875\n",
            "GCN embeddings - Min: 0.0, Max: 263.77099609375\n",
            "After Attention - Min: 0.0, Max: 263.77099609375\n",
            "graph_loss: embeddings shape: torch.Size([80, 128]), edge_index max: 79\n",
            "Cosine similarity (sample): tensor([0.1899, 0.1899, 1.0000, 0.1899, 1.0000], grad_fn=<SliceBackward0>)\n",
            "Graph loss: -0.6835262179374695\n",
            "Graph loss (batch): -0.6835\n",
            "Gradients - GCN weights: tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00],\n",
            "        [-3.8675e+01,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "         -6.5207e-05, -6.1768e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00],\n",
            "        ...,\n",
            "        [ 0.0000e+00,  1.3628e+00,  0.0000e+00,  ...,  2.0046e-01,\n",
            "          6.4847e-01,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00]])\n",
            "Total gradient norm: 1118.011227\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Evaluation\n"
      ],
      "metadata": {
        "id": "NgrIVyva0lLc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/evaluate_visualize.py\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix\n",
        "from torch.utils.data import DataLoader\n",
        "from oasis_dataset import get_dataloader\n",
        "from pmicl_model import PMICL, GraphConstructor\n",
        "\n",
        "# Device configuration\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Hyperparameters\n",
        "BATCH_SIZE = 2\n",
        "NUM_CLASSES = 4\n",
        "\n",
        "def evaluate(model, dataloader, device):\n",
        "    model.eval()\n",
        "    preds = []\n",
        "    true_labels = []\n",
        "    graph_constructor = GraphConstructor()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for patches, labels, coords in dataloader:\n",
        "            patches, labels = patches.to(device), labels.to(device)\n",
        "            B, N, C, H, W = patches.shape\n",
        "            patch_features = patches.view(B * N, -1).cpu().numpy()\n",
        "            edge_index, edge_weight = graph_constructor.build_graph(patch_features)\n",
        "            edge_index, edge_weight = edge_index.to(device), edge_weight.to(device)\n",
        "            batch = torch.repeat_interleave(torch.arange(B, device=device), N)\n",
        "\n",
        "            logits, _, _, _, _ = model(patches, edge_index, batch)\n",
        "            preds.append(torch.softmax(logits, dim=1).cpu().numpy())\n",
        "            true_labels.append(labels.cpu().numpy())\n",
        "\n",
        "    preds = np.concatenate(preds)\n",
        "    true_labels = np.concatenate(true_labels)\n",
        "\n",
        "    acc = accuracy_score(true_labels, np.argmax(preds, axis=1))\n",
        "    f1 = f1_score(true_labels, np.argmax(preds, axis=1), average='macro')\n",
        "    auc = roc_auc_score(true_labels, preds, multi_class='ovr')\n",
        "    return acc, f1, auc, true_labels, np.argmax(preds, axis=1)\n",
        "\n",
        "def generate_attention_map(model, dataloader, device):\n",
        "    model.eval()\n",
        "    graph_constructor = GraphConstructor()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for patches, _, coords in dataloader:\n",
        "            patches = patches.to(device)\n",
        "            B, N, C, H, W = patches.shape\n",
        "            patch_features = patches.view(B * N, -1).cpu().numpy()\n",
        "            edge_index, edge_weight = graph_constructor.build_graph(patch_features)\n",
        "            edge_index, edge_weight = edge_index.to(device), edge_weight.to(device)\n",
        "            batch = torch.repeat_interleave(torch.arange(B, device=device), N)\n",
        "\n",
        "            _, _, _, _, attention_weights = model(patches, edge_index, batch)\n",
        "            attention_weights = attention_weights.cpu().numpy()\n",
        "\n",
        "            attention_per_image = attention_weights[:N, :N]\n",
        "            plt.figure(figsize=(10, 10))\n",
        "            plt.imshow(attention_per_image, cmap='hot')\n",
        "            plt.colorbar()\n",
        "            plt.title(\"Attention Map\")\n",
        "            plt.savefig('/content/attention_map.png')\n",
        "            plt.close()\n",
        "            break\n",
        "\n",
        "def plot_confusion_matrix(true_labels, pred_labels, class_names):\n",
        "    cm = confusion_matrix(true_labels, pred_labels)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    plt.savefig('/content/confusion_matrix.png')\n",
        "    plt.close()\n",
        "\n",
        "def plot_metrics(train_accs, val_accs, val_f1s, val_aucs, losses):\n",
        "    epochs = range(1, len(train_accs) + 1)\n",
        "\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(epochs, train_accs, label='Training Accuracy')\n",
        "    plt.plot(epochs, val_accs, label='Validation Accuracy')\n",
        "    plt.title('Accuracy Over Epochs')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig('/content/accuracy_plot.png')\n",
        "    plt.close()\n",
        "\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(epochs, val_accs, label='Validation Accuracy')\n",
        "    plt.plot(epochs, val_f1s, label='Validation F1 Score')\n",
        "    plt.plot(epochs, val_aucs, label='Validation AUC')\n",
        "    plt.title('Validation Metrics Over Epochs')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Score')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig('/content/validation_metrics_plot.png')\n",
        "    plt.close()\n",
        "\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(epochs, losses, label='Training Loss')\n",
        "    plt.title('Training Loss Over Epochs')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig('/content/loss_plot.png')\n",
        "    plt.close()\n",
        "\n",
        "def main():\n",
        "    dataloader = get_dataloader('/content/oasis_data/', batch_size=BATCH_SIZE)\n",
        "    model = PMICL(num_classes=NUM_CLASSES).to(DEVICE)\n",
        "    class_names = ['Non Demented', 'Very mild Dementia', 'Mild Dementia', 'Moderate Dementia']\n",
        "\n",
        "    # Example metrics (replace with actual training results)\n",
        "    train_accs = [0.5, 0.6, 0.7]  # Placeholder\n",
        "    val_accs = [0.4, 0.5, 0.6]    # Placeholder\n",
        "    val_f1s = [0.3, 0.4, 0.5]     # Placeholder\n",
        "    val_aucs = [0.6, 0.7, 0.8]    # Placeholder\n",
        "    losses = [1.0, 0.8, 0.6]      # Placeholder\n",
        "\n",
        "    acc, f1, auc, true_labels, pred_labels = evaluate(model, dataloader, DEVICE)\n",
        "    print(f\"Val: Acc={acc:.4f}, F1={f1:.4f}, AUC={auc:.4f}\")\n",
        "\n",
        "    plot_confusion_matrix(true_labels, pred_labels, class_names)\n",
        "    plot_metrics(train_accs, val_accs, val_f1s, val_aucs, losses)\n",
        "    generate_attention_map(model, dataloader, DEVICE)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "3uJ48UEivVpN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}