{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPPmOu1hav40ctIerj95s/v",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tousifo/ml_notebooks/blob/main/cricket_match_data_scrap.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eevTQfdNMbMX"
      },
      "outputs": [],
      "source": [
        "# Colab Cell 1: Install dependencies and unzip dataset\n",
        "!pip install pandas requests\n",
        "!unzip \"/content/archive (1).zip\" -d \"/content/ipl_data\"\n",
        "\n",
        "import pandas as pd\n",
        "import requests\n",
        "import time\n",
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "# Step 1: Load and process IPL match data\n",
        "matches_file = \"/content/ipl_data/matches.csv\"\n",
        "deliveries_file = \"/content/ipl_data/deliveries.csv\"\n",
        "\n",
        "# Load matches.csv\n",
        "matches_df = pd.read_csv(matches_file)\n",
        "print(\"Matches columns:\", matches_df.columns.tolist())\n",
        "\n",
        "# Filter for seasons 2020‚Äì2024\n",
        "matches_df = matches_df[matches_df['season'].isin(['2020/21', '2021', '2022', '2023', '2024'])]\n",
        "\n",
        "# Standardize columns\n",
        "matches_df = matches_df.rename(columns={\n",
        "    'id': 'Match ID',\n",
        "    'date': 'Date',\n",
        "    'venue': 'Venue',\n",
        "    'city': 'City',\n",
        "    'team1': 'Team1',\n",
        "    'team2': 'Team2',\n",
        "    'toss_winner': 'Toss Winner',\n",
        "    'toss_decision': 'Toss Decision',\n",
        "    'winner': 'Match Result',\n",
        "})\n",
        "\n",
        "# Ensure Date is in YYYY-MM-DD format\n",
        "matches_df['Date'] = pd.to_datetime(matches_df['Date']).dt.strftime('%Y-%m-%d')\n",
        "\n",
        "# Load deliveries.csv for innings details\n",
        "deliveries_df = pd.read_csv(deliveries_file)\n",
        "print(\"Deliveries columns:\", deliveries_df.columns.tolist())\n",
        "\n",
        "# Calculate innings scores and wickets\n",
        "innings_summary = deliveries_df.groupby(['match_id', 'inning']).agg({\n",
        "    'batsman_runs': 'sum',\n",
        "    'player_dismissed': lambda x: x.notna().sum()\n",
        "}).reset_index()\n",
        "\n",
        "# Pivot to get first and second innings\n",
        "innings_pivot = innings_summary.pivot(index='match_id', columns='inning', values=['batsman_runs', 'player_dismissed'])\n",
        "innings_pivot.columns = [f\"{col[0]}_{col[1]}\" for col in innings_pivot.columns]\n",
        "innings_pivot = innings_pivot.reset_index()\n",
        "\n",
        "# Rename columns\n",
        "innings_pivot = innings_pivot.rename(columns={\n",
        "    'batsman_runs_1': 'First Innings Score',\n",
        "    'player_dismissed_1': 'First Innings Wickets',\n",
        "    'batsman_runs_2': 'Second Innings Score',\n",
        "    'player_dismissed_2': 'Second Innings Wickets',\n",
        "})\n",
        "\n",
        "# Determine batting teams\n",
        "batting_teams = deliveries_df.groupby(['match_id', 'inning'])['batting_team'].first().reset_index()\n",
        "batting_teams_pivot = batting_teams.pivot(index='match_id', columns='inning', values='batting_team').reset_index()\n",
        "batting_teams_pivot = batting_teams_pivot.rename(columns={\n",
        "    1: 'First Innings Team',\n",
        "    2: 'Second Innings Team',\n",
        "})\n",
        "\n",
        "# Merge innings details with matches\n",
        "matches_df = matches_df.merge(innings_pivot, left_on='Match ID', right_on='match_id', how='left')\n",
        "matches_df = matches_df.merge(batting_teams_pivot, left_on='Match ID', right_on='match_id', how='left')\n",
        "\n",
        "# Format score/wickets\n",
        "matches_df['First Innings Score'] = matches_df['First Innings Score'].astype(str) + '/' + matches_df['First Innings Wickets'].astype(str)\n",
        "matches_df['Second Innings Score'] = matches_df['Second Innings Score'].astype(str) + '/' + matches_df['Second Innings Wickets'].astype(str)\n",
        "\n",
        "# Standardize Match Result\n",
        "matches_df['Match Result'] = matches_df.apply(\n",
        "    lambda row: f\"{row['Match Result']} won\" if pd.notna(row['Match Result']) else 'No result', axis=1\n",
        ")\n",
        "\n",
        "# Infer City for missing values and standardize venue-to-city mapping\n",
        "venue_to_city = {\n",
        "    'Sheikh Zayed Stadium': 'Abu Dhabi',\n",
        "    'Dubai International Cricket Stadium': 'Dubai',\n",
        "    'Sharjah Cricket Stadium': 'Sharjah',\n",
        "    'Zayed Cricket Stadium, Abu Dhabi': 'Abu Dhabi',\n",
        "    'MA Chidambaram Stadium, Chepauk, Chennai': 'Chennai',\n",
        "    'Punjab Cricket Association IS Bindra Stadium, Mohali, Chandigarh': 'Mohali',\n",
        "    'Bharat Ratna Shri Atal Bihari Vajpayee Ekana Cricket Stadium, Lucknow': 'Lucknow',\n",
        "    'Rajiv Gandhi International Stadium, Uppal, Hyderabad': 'Hyderabad',\n",
        "    'Himachal Pradesh Cricket Association Stadium, Dharamsala': 'Dharamsala',\n",
        "    'Dr. Y.S. Rajasekhara Reddy ACA-VDCA Cricket Stadium, Visakhapatnam': 'Visakhapatnam',\n",
        "    'M Chinnaswamy Stadium, Bengaluru': 'Bengaluru',\n",
        "    'Wankhede Stadium, Mumbai': 'Mumbai',\n",
        "    'Narendra Modi Stadium, Ahmedabad': 'Ahmedabad',\n",
        "    'Arun Jaitley Stadium, Delhi': 'Delhi',\n",
        "    'Eden Gardens, Kolkata': 'Kolkata',\n",
        "    'Sawai Mansingh Stadium, Jaipur': 'Jaipur',\n",
        "    'Maharaja Yadavindra Singh International Cricket Stadium, Mullanpur': 'Mullanpur',\n",
        "    'Barsapara Cricket Stadium, Guwahati': 'Guwahati',\n",
        "    'Maharashtra Cricket Association Stadium, Pune': 'Pune',\n",
        "    'Brabourne Stadium, Mumbai': 'Mumbai',\n",
        "    'Dr DY Patil Sports Academy, Mumbai': 'Mumbai',\n",
        "}\n",
        "\n",
        "matches_df['City'] = matches_df.apply(\n",
        "    lambda row: venue_to_city.get(row['Venue'], row['City']), axis=1\n",
        ")\n",
        "\n",
        "# Select relevant columns\n",
        "ipl_df = matches_df[[\n",
        "    'Match ID', 'Date', 'Venue', 'City', 'Team1', 'Team2', 'Toss Winner', 'Toss Decision',\n",
        "    'First Innings Team', 'First Innings Score', 'First Innings Wickets',\n",
        "    'Second Innings Team', 'Second Innings Score', 'Second Innings Wickets', 'Match Result'\n",
        "]]\n",
        "\n",
        "print(\"‚úÖ IPL DataFrame shape:\", ipl_df.shape)\n",
        "print(ipl_df.head())\n",
        "\n",
        "# Step 2: Define city-to-country mapping for Visual Crossing\n",
        "city_country = {\n",
        "    'Abu Dhabi': 'United Arab Emirates',\n",
        "    'Dubai': 'United Arab Emirates',\n",
        "    'Sharjah': 'United Arab Emirates',\n",
        "    'Chennai': 'India',\n",
        "    'Mohali': 'India',\n",
        "    'Lucknow': 'India',\n",
        "    'Hyderabad': 'India',\n",
        "    'Dharamsala': 'India',\n",
        "    'Visakhapatnam': 'India',\n",
        "    'Bengaluru': 'India',\n",
        "    'Mumbai': 'India',\n",
        "    'Ahmedabad': 'India',\n",
        "    'Delhi': 'India',\n",
        "    'Kolkata': 'India',\n",
        "    'Jaipur': 'India',\n",
        "    'Mullanpur': 'India',\n",
        "    'Guwahati': 'India',\n",
        "    'Pune': 'India',\n",
        "}\n",
        "\n",
        "# Step 3: Fetch weather data using Visual Crossing\n",
        "API_KEY = 'ADUVHU7PFYMT68R3EQPL4QQ8N'  # Your provided API key\n",
        "weather_recs = []\n",
        "for _, row in ipl_df.iterrows():\n",
        "    city = row['City']\n",
        "    if pd.isna(city) or city not in city_country:\n",
        "        print(f\"‚ö†Ô∏è city missing or unmapped for {row['Venue']} ({city}); skipping\")\n",
        "        continue\n",
        "    location = f\"{city},{city_country[city]}\"\n",
        "    date = row['Date']\n",
        "\n",
        "    url = (\n",
        "        f\"https://weather.visualcrossing.com/VisualCrossingWebServices/rest/services/timeline/{location}/{date}/{date}\"\n",
        "        f\"?key={API_KEY}&include=days&elements=tempmax,tempmin,precip,windspeed\"\n",
        "    )\n",
        "    for attempt in range(3):\n",
        "        try:\n",
        "            response = requests.get(url, timeout=10)\n",
        "            response.raise_for_status()\n",
        "            data = response.json().get('days', [{}])[0]\n",
        "            if not data:\n",
        "                print(f\"‚ö†Ô∏è no weather for {city} ({row['Venue']}) on {date}\")\n",
        "                break\n",
        "\n",
        "            weather_recs.append({\n",
        "                'Date': date,\n",
        "                'Venue': row['Venue'],\n",
        "                'Max_Temp_C': data.get('tempmax'),\n",
        "                'Min_Temp_C': data.get('tempmin'),\n",
        "                'Total_Precip_mm': data.get('precip', 0.0),\n",
        "                'Max_Wind_kmh': float(data.get('windspeed', 0.0)) * 3.6,  # Convert mph to km/h\n",
        "            })\n",
        "            print(f\"üå¶Ô∏è Weather for {city} ({row['Venue']}) on {date}\")\n",
        "            break\n",
        "        except (requests.RequestException, KeyError, ValueError) as e:\n",
        "            print(f\"‚ö†Ô∏è Error fetching weather for {city} ({row['Venue']}) on {date}: {e}\")\n",
        "            time.sleep(1)\n",
        "    time.sleep(0.2)\n",
        "\n",
        "weather_df = pd.DataFrame(weather_recs)\n",
        "print(\"\\n‚úÖ Weather DataFrame shape:\", weather_df.shape)\n",
        "print(weather_df.head())\n",
        "\n",
        "# Step 4: Merge and save\n",
        "final_df = pd.merge(\n",
        "    ipl_df,\n",
        "    weather_df,\n",
        "    on=['Date', 'Venue'],\n",
        "    how='left'\n",
        ")\n",
        "final_df.to_csv('IPL_Match_Weather_Data_2020_2024.csv', index=False)\n",
        "print(f\"\\n‚úÖ Done! 'IPL_Match_Weather_Data_2020_2024.csv' with {final_df.shape[0]} rows created.\")\n",
        "print(final_df.head())\n",
        "\n",
        "# Download the file\n",
        "files.download('IPL_Match_Weather_Data_2020_2024.csv')"
      ]
    }
  ]
}